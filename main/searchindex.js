Search.setIndex({"docnames": ["api_ref_config", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "deep_dives/checkpointer", "deep_dives/configs", "deep_dives/recipe_deepdive", "deep_dives/wandb_logging", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.Tokenizer", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.argparse.TuneRecipeArgumentParser", "generated/torchtune.utils.collate.padded_collate", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.logging.get_logger", "generated/torchtune.utils.memory.set_activation_checkpointing", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.precision.get_autocast", "generated/torchtune.utils.precision.get_dtype", "generated/torchtune.utils.precision.get_gradient_scaler", "generated/torchtune.utils.precision.list_dtypes", "generated/torchtune.utils.seed.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times", "tutorials/e2e_flow", "tutorials/first_finetune_tutorial", "tutorials/lora_finetune"], "filenames": ["api_ref_config.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "deep_dives/checkpointer.rst", "deep_dives/configs.rst", "deep_dives/recipe_deepdive.rst", "deep_dives/wandb_logging.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.Tokenizer.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.argparse.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.collate.padded_collate.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.logging.get_logger.rst", "generated/torchtune.utils.memory.set_activation_checkpointing.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.precision.get_autocast.rst", "generated/torchtune.utils.precision.get_dtype.rst", "generated/torchtune.utils.precision.get_gradient_scaler.rst", "generated/torchtune.utils.precision.list_dtypes.rst", "generated/torchtune.utils.seed.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst", "tutorials/e2e_flow.rst", "tutorials/first_finetune_tutorial.rst", "tutorials/lora_finetune.rst"], "titles": ["torchtune.config", "torchtune.datasets", "torchtune.models.llama2", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "All about configs", "What are recipes?", "Logging to Weights &amp; Biases", "instantiate", "parse", "alpaca_cleaned_dataset", "alpaca_dataset", "grammar_dataset", "samsum_dataset", "slimorca_dataset", "llama2_7b", "lora_llama2", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "Tokenizer", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "padded_collate", "get_device", "get_world_size_and_rank", "init_distributed", "get_logger", "set_activation_checkpointing", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "get_autocast", "get_dtype", "get_gradient_scaler", "list_dtypes", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times", "End-to-End Workflow with torchtune", "Finetune your First LLM", "Finetuning Llama2 with LoRA"], "terms": {"These": [3, 5, 6, 7, 9, 34, 56, 57, 58], "ar": [3, 5, 6, 8, 9, 11, 12, 13, 14, 17, 24, 29, 32, 33, 46, 54, 56, 57, 58], "common": [3, 6, 58], "can": [3, 5, 6, 7, 8, 9, 11, 12, 21, 22, 23, 32, 34, 43, 44, 52, 53, 54, 56, 57, 58], "us": [3, 5, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 32, 33, 34, 36, 41, 42, 43, 44, 45, 46, 47, 49, 52, 53, 54, 57, 58], "all": [3, 7, 18, 19, 24, 26, 32, 34, 50, 52, 54, 55, 56, 57, 58], "offer": 4, "allow": [4, 43], "seamless": 4, "transit": 4, "between": [4, 5, 32, 56, 58], "format": [4, 11, 12, 13, 14, 15, 32, 33, 56, 57], "train": [4, 5, 7, 8, 11, 12, 13, 14, 15, 18, 27, 32, 33, 45, 46, 47, 52, 54, 56, 58], "interoper": [4, 5, 7, 54, 56], "rest": 4, "ecosystem": [4, 5, 7, 54, 56, 57], "For": [4, 5, 6, 7, 11, 12, 17, 18, 24, 34, 44, 49, 56, 57, 58], "comprehens": 4, "overview": [4, 6, 8, 57, 58], "pleas": [4, 53], "see": [4, 5, 8, 11, 20, 28, 34, 39, 44, 49, 53, 54, 56, 57, 58], "deep": [4, 5, 6, 7, 54], "dive": [4, 5, 6, 7, 54], "enabl": [4, 6, 7, 8, 29, 49, 57], "work": [4, 5, 7, 34, 54, 56], "set": [4, 5, 6, 7, 11, 12, 13, 14, 15, 22, 24, 31, 36, 40, 49, 54, 56, 57, 58], "consumpt": 4, "dure": [4, 5, 11, 12, 13, 14, 18, 20, 22, 24, 25, 56, 58], "variou": 4, "dataset": [4, 6, 11, 12, 13, 14, 15, 54, 56, 57, 58], "walk": [5, 7, 43, 54, 56, 57], "you": [5, 6, 7, 8, 9, 11, 12, 34, 43, 44, 52, 53, 54, 56, 57, 58], "through": [5, 6, 7, 19, 54, 56, 57], "design": [5, 7], "behavior": 5, "associ": [5, 6, 7, 56, 58], "util": [5, 6, 7, 8, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 54, 56, 57], "what": [5, 6, 52, 56, 57], "cover": [5, 6, 7, 56], "how": [5, 6, 7, 52, 56, 57], "we": [5, 6, 7, 8, 11, 12, 18, 20, 22, 23, 24, 29, 32, 33, 46, 54, 56, 57, 58], "them": [5, 6, 19, 23, 26, 56, 58], "scenario": 5, "full": [5, 6, 7, 23, 32, 33, 54, 58], "finetun": [5, 6, 7, 11, 12, 48, 52, 54], "compos": 5, "compon": [5, 7, 54, 57, 58], "which": [5, 7, 11, 12, 13, 14, 17, 18, 22, 23, 24, 25, 27, 32, 33, 41, 46, 47, 54, 56, 58], "plug": 5, "ani": [5, 6, 7, 9, 10, 23, 26, 30, 31, 32, 33, 49, 56, 58], "recip": [5, 6, 8, 9, 10, 13, 14, 19, 32, 33, 54, 56], "evalu": [5, 7, 52, 54, 57, 58], "gener": [5, 7, 15, 23, 49, 50, 52, 58], "each": [5, 7, 17, 18, 22, 23, 24, 49, 54, 56, 57, 58], "support": [5, 7, 8, 9, 11, 12, 13, 14, 17, 18, 29, 33, 45, 46, 48, 54, 56, 57], "model": [5, 6, 7, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 40, 52, 54], "make": [5, 6, 7, 8, 18, 25, 54, 56, 57, 58], "easi": [5, 7, 54, 57, 58], "understand": [5, 6, 7, 54, 58], "debug": [5, 6, 7], "extend": [5, 7, 54], "befor": [5, 24, 25, 29, 32, 56], "let": [5, 6, 8, 56, 57, 58], "s": [5, 6, 7, 8, 10, 17, 18, 22, 24, 25, 26, 28, 30, 32, 33, 36, 43, 54, 57, 58], "defin": [5, 6, 7, 19, 28, 29, 30, 58], "some": [5, 6, 17, 30, 31, 52, 54, 56, 57, 58], "concept": [5, 56], "In": [5, 6, 7, 22, 29, 43, 44, 56, 58], "ll": [5, 6, 7, 54, 56], "talk": 5, "about": [5, 7, 32, 44, 54, 56, 58], "take": [5, 6, 7, 9, 19, 20, 26, 32, 34, 36, 56, 57, 58], "close": [5, 7, 41, 42, 43, 44, 58], "look": [5, 6, 7, 43, 56, 57, 58], "veri": [5, 24, 56], "simpli": [5, 6], "dictat": 5, "state_dict": [5, 26, 32, 33, 58], "store": [5, 41, 44, 58], "file": [5, 6, 7, 8, 9, 10, 11, 12, 23, 32, 33, 34, 41, 44, 51, 54, 55, 56, 57, 58], "disk": [5, 41], "weight": [5, 7, 17, 18, 26, 28, 29, 32, 33, 44, 56, 57, 58], "string": [5, 23, 28, 36, 46], "kei": [5, 6, 8, 17, 18, 20, 24, 31, 32, 56, 58], "identifi": 5, "state": [5, 7, 26, 30, 31, 32, 33, 56, 58], "dict": [5, 6, 7, 8, 9, 26, 30, 31, 32, 33, 38], "If": [5, 6, 11, 12, 13, 14, 15, 17, 18, 26, 29, 32, 33, 36, 38, 43, 44, 46, 49, 53, 57, 58], "identif": 5, "don": [5, 6, 7, 49, 56], "t": [5, 6, 7, 15, 46, 49, 56], "match": [5, 56, 58], "up": [5, 7, 11, 12, 57, 58], "exactli": 5, "those": [5, 58], "definit": [5, 58], "either": [5, 32, 58], "run": [5, 6, 8, 10, 17, 19, 20, 24, 26, 32, 33, 43, 44, 53, 54, 57, 58], "explicit": 5, "error": [5, 6, 11, 32, 49], "load": [5, 7, 32, 33, 34, 43, 56, 58], "rais": [5, 9, 15, 18, 24, 32, 33, 38, 44, 46, 49], "an": [5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 24, 28, 30, 31, 32, 33, 44, 54, 56, 57, 58], "except": 5, "wors": 5, "silent": [5, 19], "succe": 5, "infer": [5, 18, 20, 22, 24, 25, 52, 56], "expect": [5, 6, 9, 22, 44, 58], "addit": [5, 6, 7, 9, 32, 33, 38, 40, 41, 43, 44, 46, 54, 58], "line": [5, 7, 34, 57], "also": [5, 6, 7, 8, 9, 17, 18, 24, 29, 36, 44, 53, 56, 57, 58], "need": [5, 6, 7, 8, 15, 18, 19, 24, 43, 44, 56, 57, 58], "shape": [5, 18, 20, 22, 24, 25, 29], "valu": [5, 6, 15, 16, 17, 18, 20, 21, 24, 27, 32, 34, 41, 42, 43, 44, 49, 58], "two": [5, 6, 54, 56, 57, 58], "popular": [5, 54, 56, 57], "llama2": [5, 6, 7, 9, 11, 12, 15, 16, 17, 19, 23, 24, 25, 52, 54, 57], "meta": [5, 13, 14, 32, 33, 56, 57], "offici": [5, 57], "implement": [5, 7, 11, 12, 13, 14, 15, 19, 21, 22, 27, 28, 29, 32, 43, 54, 58], "when": [5, 6, 7, 10, 24, 26, 27, 43, 56, 58], "download": [5, 50, 53, 58], "7b": [5, 11, 12, 16, 32, 33, 57, 58], "from": [5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 19, 23, 24, 25, 27, 28, 30, 32, 33, 34, 43, 44, 51, 53, 55, 56, 57, 58], "llama": [5, 13, 14, 21, 22, 32, 33, 56, 57], "websit": 5, "get": [5, 6, 7, 23, 37, 39, 46, 54, 56, 57, 58], "access": [5, 6, 7, 32, 56, 57], "singl": [5, 6, 9, 18, 32, 33, 56, 58], "pth": [5, 56, 57], "inspect": [5, 56, 58], "content": [5, 23], "easili": [5, 6, 54, 58], "torch": [5, 20, 24, 26, 27, 36, 38, 40, 45, 46, 49, 56, 57, 58], "import": [5, 6, 9, 43, 44, 56, 57, 58], "consolid": [5, 57], "00": [5, 51, 55, 57], "mmap": [5, 56], "true": [5, 6, 11, 12, 13, 14, 23, 26, 32, 33, 38, 43, 56, 57, 58], "weights_onli": 5, "map_loc": [5, 56], "cpu": [5, 7, 26, 46, 56], "tensor": [5, 18, 19, 20, 21, 22, 24, 25, 26, 29, 32, 35, 41, 42, 43, 44, 58], "item": 5, "print": [5, 11, 12, 13, 14, 15, 23, 58], "f": [5, 8, 11, 12, 13, 14, 56, 58], "tok_embed": [5, 24], "size": [5, 7, 9, 11, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 37, 54, 56], "32000": [5, 9], "4096": [5, 9, 11, 12, 18, 22, 58], "len": [5, 11, 12, 13, 14, 24], "292": 5, "The": [5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 21, 22, 23, 26, 27, 32, 34, 36, 39, 44, 46, 49, 53, 54, 56, 57, 58], "contain": [5, 18, 20, 22, 23, 24, 25, 28, 30, 31, 32, 33, 34, 35, 43, 56, 58], "includ": [5, 6, 7, 29, 32, 33, 34, 54, 56, 57, 58], "input": [5, 11, 12, 13, 14, 15, 18, 19, 21, 22, 23, 24, 25, 29, 32, 35, 49, 58], "embed": [5, 17, 18, 20, 21, 22, 24], "tabl": [5, 58], "call": [5, 9, 19, 26, 34, 41, 42, 43, 44, 57, 58], "layer": [5, 7, 17, 18, 24, 25, 29, 54, 58], "token": [5, 6, 7, 11, 12, 13, 14, 15, 17, 18, 22, 24, 25, 56, 57, 58], "have": [5, 6, 9, 18, 20, 28, 34, 43, 56, 57, 58], "dim": [5, 18, 19, 21, 22, 24, 25], "hf": [5, 32, 56, 57], "most": [5, 6, 57, 58], "within": [5, 6, 9, 15, 17, 19, 43, 49, 56], "hug": [5, 11, 12, 13, 14, 15, 27, 54, 56, 57], "face": [5, 11, 12, 13, 14, 15, 27, 54, 56, 57], "hub": [5, 56, 57], "default": [5, 6, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 32, 33, 34, 35, 41, 46, 49, 56, 58], "everi": [5, 7, 19, 43], "config": [5, 8, 9, 10, 18, 32, 34, 44, 54, 56, 58], "2": [5, 15, 18, 23, 32, 33, 35, 49, 56, 57, 58], "repo": [5, 32, 33, 56], "first": [5, 6, 9, 24, 32, 34, 52, 54, 56, 58], "big": [5, 56], "split": [5, 56], "across": [5, 7, 32, 43, 49, 56], "bin": [5, 56], "To": [5, 6, 7, 32, 53, 54, 56, 57, 58], "correctli": [5, 7, 32, 53, 57], "piec": 5, "one": [5, 7, 19, 23, 56, 58], "pytorch_model": [5, 56], "00001": 5, "00002": 5, "embed_token": 5, "241": 5, "Not": 5, "onli": [5, 8, 17, 18, 22, 23, 24, 25, 29, 30, 33, 34, 46, 56, 58], "doe": [5, 28, 32, 34, 56], "fewer": [5, 18], "sinc": [5, 6, 9, 19, 32, 56], "instead": [5, 7, 19, 20, 29, 56], "mismatch": 5, "name": [5, 6, 8, 28, 31, 32, 33, 34, 36, 41, 42, 43, 44, 56], "caus": [5, 23], "try": [5, 6, 56, 58], "same": [5, 6, 17, 18, 20, 23, 25, 34, 44, 56, 58], "As": [5, 6, 7, 29, 54, 56, 58], "re": [5, 6, 54, 56, 57, 58], "care": [5, 19, 32, 56, 58], "like": [5, 6, 7, 8, 56, 57, 58], "end": [5, 7, 23, 52, 54, 57], "number": [5, 7, 11, 12, 15, 17, 18, 20, 24, 27, 32, 33, 37, 49, 58], "just": [5, 54, 57, 58], "save": [5, 7, 8, 32, 33, 44, 56, 58], "less": [5, 15, 56, 57], "prone": 5, "manag": [5, 45], "invari": 5, "accept": [5, 6, 15, 23, 57], "multipl": [5, 6, 7, 29, 41, 42, 43, 44], "sourc": [5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 56], "worri": 5, "explicitli": [5, 28, 54, 58], "convert": [5, 32, 35, 56, 57], "time": [5, 23, 41, 43, 56], "produc": 5, "back": [5, 32, 58], "origin": [5, 11, 12, 26, 29, 56, 58], "form": [5, 6, 7, 11], "One": [5, 56], "advantag": [5, 58], "being": [5, 32, 33, 36, 47], "should": [5, 6, 7, 17, 18, 19, 28, 34, 41, 42, 43, 44, 53, 54, 56, 57, 58], "abl": [5, 7, 56, 57], "fine": [5, 7, 11, 12, 52, 54, 56, 57, 58], "tune": [5, 6, 7, 10, 11, 12, 52, 53, 54, 56, 57, 58], "post": 5, "tool": [5, 56, 57], "quantiz": [5, 17, 29, 52], "eval": [5, 52, 54], "without": [5, 6, 54, 56, 58], "code": [5, 7, 24, 50, 54], "chang": [5, 6, 8, 56, 57], "OR": 5, "convers": [5, 32, 54, 56, 58], "script": [5, 8, 56, 57], "wai": [5, 6, 57], "surround": [5, 7, 54], "load_checkpoint": [5, 7, 32, 33], "save_checkpoint": [5, 7, 8, 32, 33], "method": [5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 26, 28, 30, 34, 54, 56, 58], "convertor": 5, "avail": [5, 7, 34, 36, 54, 56, 58], "here": [5, 6, 8, 21, 22, 56, 57, 58], "three": [5, 7, 57], "hfcheckpoint": 5, "read": [5, 32, 33, 54], "write": [5, 7, 32, 33, 41, 57], "compat": [5, 32, 57], "transform": [5, 7, 17, 24, 25, 27, 58], "framework": [5, 7, 54], "mention": [5, 56], "abov": [5, 26, 56, 58], "assum": [5, 27, 30, 46, 56, 58], "checkpoint_dir": [5, 6, 32, 33, 56, 57], "necessari": [5, 15, 41, 42, 43, 44, 58], "json": [5, 32, 56], "easiest": [5, 57], "sure": [5, 6, 56, 57, 58], "everyth": [5, 7, 34, 54, 57], "follow": [5, 7, 18, 27, 44, 52, 53, 56, 57, 58], "flow": 5, "By": [5, 58], "ignor": [5, 18, 19], "safetensor": 5, "output": [5, 11, 12, 13, 15, 17, 18, 19, 21, 22, 24, 25, 29, 31, 42, 53, 56, 57, 58], "dir": [5, 56, 57], "output_dir": [5, 6, 32, 33, 56, 57, 58], "specifi": [5, 6, 7, 9, 17, 18, 56, 57], "argument": [5, 6, 9, 15, 18, 34, 38, 40, 41, 43, 44, 57, 58], "snippet": 5, "explain": 5, "setup": [5, 6, 7, 24, 40, 56, 58], "_component_": [5, 6, 8, 9, 56, 57, 58], "fullmodelhfcheckpoint": [5, 56], "directori": [5, 6, 32, 33, 41, 43, 44, 56, 57], "sort": [5, 32], "id": [5, 11, 12, 15, 23, 32, 35, 56], "so": [5, 6, 32, 34, 53, 54, 56, 57, 58], "order": [5, 7, 32, 43, 44, 57], "matter": [5, 32, 58], "checkpoint_fil": [5, 6, 8, 32, 33, 56, 57, 58], "restart": 5, "previou": [5, 32, 33], "more": [5, 6, 7, 11, 20, 22, 34, 44, 49, 54, 56, 57, 58], "next": 5, "section": [5, 7, 52, 56], "recipe_checkpoint": [5, 32, 33, 57], "null": [5, 6, 45, 57], "usual": [5, 22, 32, 56, 58], "model_typ": [5, 32, 33, 56, 57], "resume_from_checkpoint": [5, 32, 33, 57], "fals": [5, 6, 11, 12, 13, 14, 15, 17, 18, 23, 29, 32, 33, 47, 56, 57, 58], "requir": [5, 6, 15, 32, 43, 44, 49, 53], "param": [5, 7, 29, 30, 31, 32, 58], "directli": [5, 6, 7, 9, 32, 56, 57, 58], "help": [5, 24, 32, 34, 52, 53, 54, 56, 57], "ensur": [5, 6, 15, 17, 18, 32, 46, 54], "out": [5, 6, 7, 11, 12, 13, 14, 32, 33, 52, 54, 56, 57, 58], "case": [5, 7, 8, 17, 18, 32, 41, 46, 47, 54, 56, 58], "discrep": [5, 32], "along": 5, "detail": [5, 11, 20, 49, 56, 57, 58], "found": [5, 6, 8, 21, 22, 58], "metacheckpoint": 5, "github": [5, 11, 12, 13, 14, 18, 21, 22, 27, 53], "repositori": [5, 56, 57], "fullmodelmetacheckpoint": [5, 57], "torchtunecheckpoint": 5, "perform": [5, 19, 54, 56, 58], "current": [5, 17, 18, 22, 24, 25, 33, 37, 41, 43, 49, 56, 57], "test": [5, 6, 7, 54], "complet": [5, 7, 56, 57], "written": [5, 6, 7, 32, 33, 41, 42, 43, 44, 54], "begin": [5, 23], "partit": 5, "ha": [5, 23, 28, 30, 56, 58], "standard": [5, 42, 54, 56], "key_1": 5, "weight_1": 5, "key_2": 5, "weight_2": 5, "mid": 5, "chekpoint": 5, "middl": [5, 56], "inform": [5, 44, 54, 56, 57], "subsequ": [5, 7], "recipe_st": [5, 32, 33], "pt": [5, 8, 32, 33, 56], "epoch": [5, 7, 8, 27, 32, 33, 56, 57, 58], "optim": [5, 6, 7, 27, 56, 57, 58], "etc": [5, 7, 32], "prevent": 5, "flood": 5, "overwritten": 5, "note": [5, 6, 23, 24, 28, 32, 34, 46, 49, 56, 58], "updat": [5, 6, 7, 56, 57, 58], "hf_model_0001_0": [5, 56], "hf_model_0002_0": [5, 56], "both": [5, 56, 58], "adapt": [5, 28, 29, 30, 31, 32, 33, 56, 58], "merg": [5, 9, 32, 56], "would": [5, 6, 8, 24, 56, 58], "our": [5, 7, 54, 56, 57, 58], "tutori": [5, 54, 56, 57], "primari": [5, 6, 7, 57], "want": [5, 6, 7, 8, 9, 53, 58], "resum": [5, 7, 27, 32, 33], "initi": [5, 7, 10, 16, 23, 38, 57, 58], "frozen": [5, 58], "base": [5, 15, 17, 22, 27, 29, 31, 32, 34, 41, 45, 56, 58], "well": [5, 6, 7, 54, 56], "learnt": [5, 56], "someth": [5, 7, 8, 56], "NOT": 5, "refer": [5, 6, 7, 21, 22, 45, 54, 58], "adapter_checkpoint": [5, 32, 33], "adapter_0": [5, 56], "now": [5, 23, 56, 57, 58], "knowledg": 5, "creat": [5, 6, 9, 11, 12, 13, 14, 16, 20, 27, 32, 33, 41, 43, 56], "simpl": [5, 7, 52, 57], "forward": [5, 7, 18, 19, 21, 22, 24, 25, 29, 58], "13b": 5, "modeltyp": [5, 32, 33], "llama2_13b": 5, "right": [5, 32, 56, 57, 58], "pytorch_fil": 5, "00003": 5, "torchtune_sd": 5, "load_state_dict": [5, 58], "successfulli": 5, "vocab": [5, 9, 24], "70": 5, "x": [5, 18, 19, 21, 22, 24, 25, 29, 58], "randint": 5, "0": [5, 7, 17, 18, 23, 24, 27, 29, 35, 43, 44, 49, 51, 55, 56, 57, 58], "1": [5, 7, 15, 18, 23, 24, 27, 33, 35, 43, 44, 49, 56, 57, 58], "no_grad": 5, "6": [5, 21, 35, 56], "3989": 5, "9": [5, 56], "0531": 5, "3": [5, 34, 35, 39, 56], "2375": 5, "5": [5, 27, 35, 56, 57], "2822": 5, "4": [5, 6, 15, 18, 35, 54, 56], "4872": 5, "7469": 5, "8": [5, 11, 12, 13, 14, 56, 58], "6737": 5, "11": [5, 56], "0023": 5, "8235": 5, "6819": 5, "2424": 5, "0109": 5, "6915": 5, "7": [5, 35], "3618": 5, "1628": 5, "8594": 5, "5857": 5, "1151": 5, "7808": 5, "2322": 5, "8850": 5, "9604": 5, "7624": 5, "6040": 5, "3159": 5, "5849": 5, "8039": 5, "9322": 5, "2010": 5, "6824": 5, "8929": 5, "8465": 5, "3794": 5, "3500": 5, "6145": 5, "5931": 5, "do": [5, 7, 44, 56, 57, 58], "find": [5, 7, 8, 56, 57], "list": [5, 6, 11, 12, 15, 17, 23, 28, 29, 32, 33, 34, 35, 39, 48, 57], "builder": [5, 16], "hope": 5, "provid": [5, 6, 7, 9, 15, 24, 34, 54, 56, 57], "deeper": 5, "insight": [5, 56], "happi": [5, 56], "thi": [6, 7, 8, 9, 11, 12, 15, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 36, 41, 43, 44, 49, 52, 53, 54, 56, 57, 58], "guid": [6, 57, 58], "yaml": [6, 7, 8, 9, 10, 34, 44, 54, 56, 57, 58], "pars": [6, 9, 34, 57], "effect": 6, "cli": [6, 8, 10, 53, 56, 57], "prerequisit": [6, 56, 57, 58], "Be": [6, 56, 57, 58], "familiar": [6, 56, 57, 58], "torchtun": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 53, 57], "instal": [6, 8, 43, 44, 52, 56, 57, 58], "fundament": 6, "There": [6, 56, 58], "entri": [6, 7, 57], "point": [6, 7, 56, 57, 58], "locat": [6, 58], "thei": [6, 7, 24, 34, 58], "truth": [6, 56], "reproduc": 6, "overridden": [6, 19, 34], "quick": 6, "experiment": 6, "modifi": [6, 7, 8, 26, 54, 56, 58], "serv": [6, 58], "particular": [6, 15], "seed": [6, 7, 8, 49, 57], "shuffl": [6, 57], "devic": [6, 7, 36, 45, 46, 56, 57], "cuda": [6, 36, 46, 56, 57], "dtype": [6, 7, 20, 26, 45, 46, 48, 56, 57], "fp32": 6, "enable_fsdp": 6, "mani": [6, 56], "object": [6, 9, 18, 45, 47], "keyword": [6, 9, 15, 26], "loss": [6, 7, 11, 12, 13, 14, 57, 58], "function": [6, 7, 9, 10, 18, 19, 26, 36, 37, 49, 54], "exampl": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 23, 28, 32, 33, 35, 43, 44, 50, 51, 55, 56, 58], "subfield": 6, "dotpath": 6, "wish": 6, "exact": [6, 9, 56], "path": [6, 7, 8, 9, 23, 32, 33, 34, 56, 57, 58], "normal": [6, 21, 23, 24, 25, 58], "python": [6, 34, 39, 44, 49, 50, 56], "alpaca_dataset": [6, 11, 57], "custom": [6, 7, 54, 56, 57, 58], "train_on_input": [6, 11, 12, 13, 14, 15], "onc": [6, 56, 57, 58], "ve": [6, 20, 56, 58], "instanc": [6, 9, 11, 12, 17, 19, 23, 26, 30, 31, 58], "cfg": [6, 7, 10], "automat": [6, 8, 9], "under": [6, 56], "preced": [6, 9, 58], "actual": [6, 8], "throw": 6, "notic": [6, 58], "miss": [6, 58], "posit": [6, 9, 18, 22, 24, 25], "anoth": [6, 56], "handl": [6, 10, 23, 56, 58], "def": [6, 7, 8, 10, 58], "dictconfig": [6, 7, 9, 10, 44], "arg": [6, 9, 24, 26, 28, 34, 42], "tupl": [6, 9, 15, 23, 26, 34, 35, 37], "kwarg": [6, 9, 26, 28, 34, 38, 40, 41, 42, 43, 44], "str": [6, 9, 23, 26, 28, 29, 30, 31, 32, 33, 34, 36, 39, 41, 42, 43, 44, 46, 48, 49], "mean": [6, 21, 57, 58], "pass": [6, 9, 16, 17, 18, 19, 26, 38, 40, 43, 44, 46, 58], "add": [6, 8, 34, 56, 58], "d": [6, 18, 24, 25, 58], "llama2_token": [6, 56, 57], "tmp": [6, 56, 57], "option": [6, 7, 16, 17, 18, 22, 23, 24, 25, 26, 32, 33, 36, 39, 40, 41, 44, 46, 49, 53, 54, 56, 57], "bool": [6, 11, 12, 13, 14, 15, 17, 23, 26, 29, 32, 33, 38, 43, 47], "max_seq_len": [6, 9, 11, 12, 15, 17, 18, 20, 22, 23, 24], "int": [6, 8, 11, 12, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 29, 32, 33, 35, 37, 41, 42, 43, 44, 49, 58], "512": [6, 11, 12], "instructdataset": [6, 11, 12, 13, 14], "alreadi": [6, 38, 56, 57, 58], "overwrit": 6, "duplic": [6, 7, 54], "sometim": 6, "than": [6, 15, 18, 56, 57, 58], "resolv": 6, "alpaca": [6, 11, 12, 56, 57, 58], "metric_logg": [6, 7, 8], "metric_log": [6, 8, 41, 42, 43, 44], "disklogg": 6, "log_dir": [6, 41, 43], "conveni": [6, 7], "quickli": 6, "verifi": [6, 36, 46, 57, 58], "properli": 6, "experi": [6, 52, 54, 58], "wa": [6, 56, 58], "7b_full": [6, 56, 57], "batch_siz": [6, 11, 12, 13, 14, 18, 25, 56, 57], "discuss": [6, 58], "guidelin": 6, "while": [6, 7, 19, 54, 56, 57], "mai": [6, 57, 58], "tempt": 6, "put": [6, 7, 57, 58], "much": [6, 56, 58], "give": [6, 58], "maximum": [6, 11, 12, 15, 16, 17, 18, 20, 22, 24], "flexibl": 6, "switch": 6, "encourag": 6, "clariti": 6, "significantli": 6, "easier": [6, 56, 57], "dont": 6, "slimorca_dataset": 6, "privat": 6, "typic": 6, "expos": [6, 7, 57], "parent": 6, "modul": [6, 9, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 40, 49, 58], "__init__": [6, 7, 58], "py": [6, 10, 11, 12, 13, 14, 18, 20, 21, 22, 27, 56], "guarante": 6, "stabil": [6, 54], "underscor": 6, "_alpaca": 6, "collect": [6, 57], "differ": [6, 8, 23, 54, 56, 58], "itself": 6, "via": [6, 8, 29, 58], "pair": [6, 35], "k1": [6, 7], "v1": [6, 7], "k2": [6, 7], "v2": [6, 7], "full_finetun": [6, 8], "gpu": [6, 56, 57, 58], "full_finetune_distribut": [6, 56, 57], "checkpoint": [6, 7, 32, 33, 40, 44, 54, 57, 58], "home": 6, "my_model_checkpoint": 6, "file_1": 6, "file_2": 6, "class": [6, 8, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 41, 42, 43, 44, 57, 58], "assign": 6, "nest": 6, "dot": 6, "notat": [6, 18, 22, 24, 25], "my_config": 6, "core": [7, 54, 57], "i": [7, 26, 31, 56], "structur": [7, 56], "new": [7, 41, 43, 57, 58], "user": [7, 17, 18, 23, 57], "thought": [7, 54, 57], "target": [7, 54], "pipelin": [7, 54, 57], "llm": [7, 52, 54, 56, 58], "eg": [7, 24, 32, 54], "meaning": [7, 54, 56], "featur": [7, 8, 53, 54], "fsdp": [7, 47, 54, 57], "activ": [7, 19, 40, 54, 57], "gradient": [7, 47, 54, 56, 58], "accumul": [7, 54], "mix": [7, 45, 47, 54, 56], "precis": [7, 26, 45, 46, 47, 48, 54], "appli": [7, 17, 18, 21, 22, 24, 25, 54], "given": [7, 9, 29, 36, 46, 54, 58], "famili": [7, 54], "complex": 7, "becom": [7, 53], "harder": 7, "anticip": 7, "architectur": [7, 24], "methodolog": 7, "reason": [7, 56], "possibl": 7, "trade": 7, "off": [7, 23, 56], "memori": [7, 11, 12, 40, 56, 58], "vs": 7, "qualiti": [7, 56], "believ": 7, "best": 7, "suit": [7, 57], "specif": [7, 9, 56], "b": [7, 18, 22, 24, 25, 29, 44, 58], "fit": [7, 11, 12], "solut": 7, "result": [7, 23, 56, 57], "meant": [7, 26], "depend": [7, 8, 56, 58], "level": [7, 39, 54], "expertis": 7, "routin": 7, "yourself": [7, 58], "exist": [7, 57], "ad": [7, 23, 58], "ones": 7, "modular": [7, 54], "build": [7, 54, 58], "block": [7, 17, 54], "wandb": [7, 8, 44, 57], "log": [7, 39, 41, 42, 43, 44, 56, 57], "fulli": 7, "nativ": [7, 52, 54, 58], "pytorch": [7, 15, 24, 26, 43, 45, 49, 52, 53, 54, 57, 58], "correct": [7, 21, 22, 24, 36, 54], "numer": [7, 54], "pariti": [7, 54], "verif": 7, "extens": [7, 54], "comparison": [7, 58], "benchmark": [7, 49, 54, 56], "limit": 7, "hidden": [7, 19], "behind": 7, "100": [7, 11, 12, 13, 14, 15, 35, 58], "flag": [7, 11, 12, 13, 14], "prefer": [7, 54], "over": [7, 27, 34, 54, 56, 58], "unnecessari": 7, "abstract": [7, 54], "No": [7, 54], "inherit": [7, 34, 54], "go": [7, 23, 54, 56, 57], "upon": 7, "figur": [7, 58], "spectrum": 7, "decid": 7, "interact": [7, 52], "start": [7, 53, 54, 56, 57], "paradigm": 7, "consist": [7, 57], "configur": [7, 11, 12, 13, 14, 15, 25, 54, 57, 58], "paramet": [7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 52, 54, 56, 57, 58], "command": [7, 34, 53, 57, 58], "overrid": [7, 10, 56, 57], "togeth": [7, 57, 58], "valid": [7, 53, 56, 57], "environ": [7, 53, 56, 57], "logic": [7, 32, 54, 57, 58], "api": [7, 8, 56, 57], "closer": [7, 58], "monolith": [7, 54], "trainer": [7, 37], "A": [7, 8, 23, 26, 29, 32, 35, 51, 52, 55, 56, 58], "wrapper": [7, 23, 58], "around": [7, 23, 56, 58], "extern": 7, "primarili": [7, 58], "eleutherai": [7, 54], "har": [7, 54], "control": [7, 11, 12, 13, 14, 49, 56], "multi": [7, 18], "stage": 7, "distil": 7, "oper": [7, 49], "turn": 7, "dataload": [7, 11, 12, 13, 14], "applic": [7, 18, 32, 33, 44, 45], "clean": [7, 11], "after": [7, 20, 21, 41, 42, 43, 44], "process": [7, 26, 49, 57], "group": [7, 18, 41, 42, 43, 44], "init_process_group": [7, 38], "backend": 7, "gloo": 7, "els": [7, 34, 54], "nccl": 7, "fullfinetunerecipedistribut": 7, "cleanup": 7, "other": [7, 9, 11, 34, 57, 58], "stuff": 7, "carri": 7, "relev": [7, 56, 58], "interfac": [7, 28], "metric": [7, 57], "logger": [7, 39, 41, 42, 43, 44, 57], "self": [7, 8, 17, 18, 24, 25, 28, 58], "_devic": 7, "get_devic": 7, "_dtype": 7, "get_dtyp": 7, "ckpt_dict": 7, "wrap": [7, 40], "_model": 7, "_setup_model": 7, "_token": 7, "_setup_token": 7, "_optim": 7, "_setup_optim": 7, "_loss_fn": 7, "_setup_loss": 7, "_sampler": 7, "_dataload": 7, "_setup_data": 7, "backward": 7, "zero_grad": 7, "curr_epoch": 7, "rang": [7, 49], "epochs_run": [7, 8], "total_epoch": [7, 8], "idx": 7, "batch": [7, 11, 12, 13, 14, 16, 18, 20, 22, 23, 24, 25, 35, 54], "enumer": 7, "_autocast": 7, "logit": 7, "label": [7, 11, 12, 15, 35], "total_training_step": 7, "_log_every_n_step": 7, "_metric_logg": 7, "log_dict": [7, 41, 42, 43, 44], "step": [7, 24, 27, 41, 42, 43, 44, 52, 56, 58], "learn": [7, 27, 54, 57, 58], "decor": [7, 10], "recipe_main": [7, 10], "none": [7, 8, 17, 18, 22, 23, 24, 25, 31, 32, 33, 36, 39, 40, 41, 42, 43, 44, 46, 49, 56], "fullfinetunerecip": 7, "direct": 7, "topic": [8, 52], "your": [8, 9, 43, 44, 52, 53, 54, 56, 58], "http": [8, 11, 12, 13, 14, 15, 16, 18, 21, 22, 27, 32, 33, 34, 39, 43, 44, 45, 49, 53], "ai": [8, 18, 44], "packag": [8, 43, 44, 53], "pip": [8, 43, 44, 53], "Then": [8, 57], "login": [8, 44], "built": 8, "wandblogg": [8, 58], "project": [8, 17, 18, 19, 44, 52, 58], "grab": 8, "tab": [8, 11, 12], "click": 8, "sampl": [8, 15, 56], "workspac": 8, "capecap": [8, 44], "6053ofw0": [8, 44], "torchtune_config_j67sb73v": [8, 44], "desir": 8, "suggest": 8, "approach": 8, "joinpath": 8, "_checkpoint": [8, 56], "_output_dir": [8, 32, 33], "torchtune_model_": 8, "with_suffix": 8, "wandb_at": 8, "artifact": 8, "type": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 33, 37, 38, 39, 45, 46, 47, 56, 58], "descript": [8, 13], "whatev": 8, "metadata": 8, "seed_kei": 8, "epochs_kei": 8, "total_epochs_kei": 8, "max_steps_kei": 8, "max_steps_per_epoch": 8, "add_fil": 8, "log_artifact": 8, "field": [9, 11, 12, 13, 14], "num_lay": [9, 17, 24], "32": [9, 58], "num_head": [9, 17, 18, 20, 22, 24], "num_kv_head": [9, 17, 18, 20], "vocab_s": [9, 17, 23], "must": [9, 11, 12, 13, 14, 15, 28, 34], "return": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 45, 46, 47, 48, 49, 58], "nn": [9, 18, 19, 20, 24, 25, 26, 28, 30, 31, 40, 57, 58], "parsed_yaml": 9, "embed_dim": [9, 17, 18, 22, 25, 58], "omegaconf": 9, "valueerror": [9, 15, 18, 24, 32, 33, 46, 49], "callabl": [10, 24], "main": [10, 11, 12, 13, 14, 18, 21, 22], "my_recip": 10, "With": [10, 56, 58], "foo": 10, "bar": [10, 54], "huggingfac": [11, 12, 13, 14, 15, 27, 32, 33], "co": [11, 12, 13, 14, 15, 32, 33], "yahma": 11, "data": [11, 12, 13, 14, 15, 41, 42, 43, 44, 56], "tatsu": [11, 12], "lab": [11, 12], "prompt": [11, 12, 13, 14, 15, 23, 24, 56], "templat": [11, 12, 13, 14, 15], "codebas": [11, 12, 13, 14, 56], "com": [11, 12, 13, 14, 18, 21, 22, 27, 53], "stanford_alpaca": [11, 12], "blob": [11, 12, 13, 14, 18, 21, 22, 27], "761dc5bfbdeeffa89b8bff5d038781a4055f796a": [11, 12], "l31": [11, 12], "where": [11, 12, 13, 14, 18, 23, 24, 29], "instruct": [11, 12, 52, 57, 58], "mask": [11, 12, 13, 14, 18, 23, 25], "ref": [11, 12, 44], "tloen": [11, 12], "lora": [11, 12, 17, 29, 52, 54], "l49": [11, 12], "contribut": [11, 12, 13, 14], "replac": [11, 12, 13, 14, 26, 58], "version": [11, 17, 18, 53], "remov": 11, "hallucin": 11, "poorli": 11, "wrong": 11, "answer": [11, 56], "card": 11, "encod": [11, 12, 13, 14, 15, 23], "decod": [11, 12, 13, 14, 15, 17, 23, 24], "whether": [11, 12, 13, 14, 15, 17, 23, 26, 29, 46, 47], "stanford": [11, 12], "readm": [11, 12], "ov": [11, 12], "recommend": [11, 12, 43, 56], "highest": [11, 12], "sequenc": [11, 12, 15, 17, 18, 20, 22, 23, 24, 25, 35], "length": [11, 12, 15, 17, 18, 20, 22, 23, 24, 25, 33, 35], "alpaca_d": [11, 12], "grammar": 13, "its": [13, 14, 17, 49, 56, 58], "variant": [13, 14], "liweili": 13, "c4_200m": 13, "llama_recip": [13, 14], "src": [13, 14, 27], "l50": 13, "grammar_d": 13, "summar": 14, "samsum": 14, "l13": 14, "dialogu": 14, "summari": 14, "samsum_d": 14, "1024": 15, "chatdataset": 15, "represent": [15, 58], "slimorca": 15, "open": [15, 56], "orca": 15, "dedup": 15, "adher": 15, "chat": 15, "doesn": [15, 56], "prescrib": 15, "truncat": [15, 23], "least": [15, 58], "though": 15, "max": [15, 23, 24, 27, 58], "ds": 15, "10": [15, 35, 56], "351": 15, "82": [15, 56], "391": 15, "221": 15, "220": 15, "193": 15, "12": 15, "471": 15, "transformerdecod": [16, 17, 58], "w": [16, 43, 44, 56, 58], "arxiv": [16, 18, 21, 22], "org": [16, 18, 21, 22, 34, 39, 43, 45, 49], "ab": [16, 22], "2307": 16, "09288": 16, "max_batch_s": [16, 20], "kvcach": [16, 17, 18, 24], "instanti": [16, 17], "lora_attn_modul": [17, 58], "liter": 17, "q_proj": [17, 18, 58], "k_proj": [17, 18, 58], "v_proj": [17, 18, 58], "output_proj": [17, 18, 58], "apply_lora_to_mlp": 17, "apply_lora_to_output": 17, "intermediate_dim": 17, "attn_dropout": [17, 18, 24], "float": [17, 18, 21, 27, 29, 41, 42, 43, 44, 58], "norm_ep": 17, "1e": [17, 21, 57], "05": 17, "lora_rank": [17, 58], "lora_alpha": [17, 58], "lora_dropout": 17, "quantize_bas": [17, 29], "linear": [17, 24, 28, 29, 58], "attent": [17, 18, 20, 22, 24, 25, 58], "mlp": [17, 24, 25], "final": [17, 19, 24, 56, 58], "vocabulari": [17, 23], "queri": [17, 18, 20, 24], "head": [17, 18, 20, 22, 24], "mha": [17, 18, 24], "dimens": [17, 18, 20, 22, 24, 29, 58], "dropout": [17, 18, 29, 58], "onto": [17, 18], "scaled_dot_product_attent": [17, 18], "intermedi": 17, "comput": [17, 18, 19, 22, 24, 49, 56], "scale_hidden_dim_for_mlp": 17, "epsilon": 17, "rm": 17, "norm": [17, 24, 25], "rank": [17, 29, 37, 49, 57, 58], "low": [17, 29, 56, 58], "approxim": [17, 29, 58], "scale": [17, 29, 58], "factor": [17, 29, 56], "probabl": [17, 29, 56], "subset": [17, 30], "head_dim": [18, 20, 22, 24], "pos_embed": [18, 58], "kv_cach": 18, "gqa": 18, "introduc": [18, 21, 29, 58], "pdf": [18, 21], "2305": 18, "13245v1": 18, "multihead": 18, "n": [18, 23, 51, 55], "extrem": 18, "share": 18, "mqa": 18, "credit": 18, "document": 18, "lightn": 18, "lit": 18, "gpt": [18, 56], "lit_gpt": 18, "v": [18, 24, 58], "k": [18, 58], "q": [18, 58], "n_kv_head": 18, "calcul": 18, "e": [18, 26, 28, 31, 53, 56], "g": [18, 28], "rotarypositionalembed": [18, 58], "cach": [18, 20, 22], "rope": [18, 22], "input_po": [18, 22, 24, 25], "seq_length": [18, 25], "seq_len": [18, 22], "bigger": 18, "n_h": [18, 22], "num": [18, 22], "n_kv": 18, "kv": [18, 20, 24], "emb": [18, 24, 25], "h_d": [18, 22], "gate_proj": 19, "down_proj": 19, "up_proj": 19, "silu": 19, "feed": [19, 25], "network": [19, 58], "deriv": [19, 24, 25], "fed": 19, "multipli": 19, "subclass": [19, 34], "although": [19, 58], "afterward": 19, "former": 19, "regist": [19, 26], "hook": [19, 26], "latter": 19, "standalon": 20, "past": 20, "becaus": [20, 24, 56], "expand": 20, "per": [20, 26], "dpython": [20, 26, 45], "ep": 21, "06": [21, 58], "root": [21, 43], "squar": 21, "1910": 21, "07467": 21, "verfic": [21, 22], "facebookresearch": [21, 22], "small": [21, 56], "avoid": [21, 49], "divis": 21, "zero": [21, 56], "10000": 22, "rotari": 22, "propos": 22, "2104": 22, "09864": 22, "l450": 22, "upto": 22, "init": [22, 44], "exceed": 22, "freq": 22, "recomput": 22, "geometr": 22, "progress": 22, "rotat": 22, "angl": 22, "bsz": 22, "todo": 22, "below": [22, 58], "made": [22, 56], "effici": [22, 52, 54, 56, 58], "spm_model": 23, "sentencepieceprocessor": 23, "bos_id": 23, "eos_id": 23, "pad_id": 23, "sentencepiec": 23, "sentenc": 23, "pad": [23, 35], "non": 23, "from_fil": 23, "tokenized_text": 23, "hello": [23, 56], "world": [23, 37], "add_bo": 23, "add_eo": 23, "31587": 23, "29644": 23, "102": 23, "text": [23, 56], "trim_leading_whitespac": 23, "prefix": 23, "unbatch": 23, "prepend": 23, "bo": 23, "append": 23, "eo": 23, "trim": 23, "lead": 23, "whitespac": 23, "underli": 23, "s1": 23, "s2": 23, "due": [23, 58], "classmethod": 23, "tokenize_messag": 23, "messag": [23, 53], "concaten": 23, "problem": 23, "known": 23, "slice": 23, "tokenizer_path": 23, "role": 23, "system": 23, "assist": 23, "respons": [23, 56, 57], "separ": [23, 32, 58], "concat": 23, "1788": 23, "2643": 23, "13": [23, 56], "1792": 23, "9508": 23, "465": 23, "22137": 23, "2933": 23, "join": 23, "attribut": 23, "transformerdecoderlay": 24, "move": 24, "space": 24, "check": [24, 46, 52, 57, 58], "belong": 24, "reduc": [24, 58], "statement": 24, "improv": [24, 56], "readabl": [24, 56], "At": 24, "arang": 24, "prompt_length": 24, "causal_mask": 24, "m_": 24, "seq": 24, "attn": [25, 58], "causalselfattent": [25, 58], "sa_norm": 25, "mlp_norm": 25, "ff": 25, "common_util": 26, "bfloat16": [26, 56], "offload_to_cpu": 26, "nf4": 26, "restor": 26, "higher": 26, "offload": 26, "_register_state_dict_hook": 26, "m": 26, "mymodul": 26, "_after_": 26, "nf4tensor": 26, "unquant": [26, 56], "unus": 26, "num_warmup_step": 27, "num_training_step": 27, "num_cycl": 27, "last_epoch": 27, "lambdalr": 27, "rate": [27, 54, 57], "schedul": 27, "linearli": 27, "increas": [27, 58], "lr": [27, 57], "decreas": 27, "cosin": 27, "remain": [27, 58], "v4": 27, "23": 27, "l104": 27, "warmup": 27, "phase": 27, "total": [27, 37, 51, 55, 56, 58], "wave": 27, "half": [27, 45], "index": [27, 35, 56], "last": 27, "lr_schedul": 27, "appropri": 27, "peft": [28, 29, 30, 31, 58], "protocol": 28, "adapter_param": [28, 29, 30, 31], "correspond": [28, 30, 46, 58], "come": [28, 58], "proj": 28, "in_dim": [28, 29, 58], "out_dim": [28, 29, 58], "bia": [28, 29, 58], "loralinear": [28, 58], "alpha": [29, 58], "use_bia": 29, "larg": 29, "languag": 29, "perturb": 29, "decomposit": [29, 58], "matric": [29, 58], "trainabl": [29, 31, 58], "mapsto": 29, "w_0x": 29, "r": [29, 58], "bax": 29, "lora_a": [29, 58], "lora_b": [29, 58], "map": [31, 32, 41, 42, 43, 44, 56], "respect": 31, "get_adapter_param": [31, 58], "few": [32, 58], "0001_of_0003": 32, "0002_of_0003": 32, "preserv": 32, "weight_map": [32, 56], "intermediate_checkpoint": [32, 33], "parit": 32, "_weight_map": 32, "shard": [33, 47], "wip": 33, "argpars": 34, "tunerecipeargpars": 34, "argumentpars": 34, "builtin": [34, 45], "noth": 34, "treat": 34, "still": 34, "consult": 34, "doc": [34, 39, 43, 44, 45, 49], "info": 34, "librari": [34, 39, 49, 52, 54], "html": [34, 39, 43, 45, 49], "parse_known_arg": 34, "namespac": 34, "act": 34, "alwai": 34, "precid": 34, "parse_arg": 34, "intern": 34, "properti": [34, 58], "too": 34, "collat": 35, "padding_idx": 35, "ignore_idx": 35, "longest": 35, "integ": [35, 49], "tokenpair": 35, "token_pair": 35, "availab": 36, "machin": [36, 56], "distribut": [36, 38, 40, 49, 54, 57], "aka": 37, "runtimeerror": 38, "stream": 39, "handler": 39, "auto_wrap_polici": 40, "polici": 40, "filenam": 41, "log_": 41, "unixtimestamp": 41, "txt": [41, 57], "thread": 41, "safe": 41, "resourc": [41, 42, 43, 44], "flush": [41, 42, 43, 44], "union": [41, 42, 43, 44, 47, 49], "ndarrai": [41, 42, 43, 44], "scalar": [41, 42, 43, 44], "tag": [41, 42, 43, 44], "record": [41, 42, 43, 44], "payload": [41, 42, 43, 44], "dictionari": [41, 42, 43, 44, 56], "organize_log": 43, "tensorboard": 43, "stabl": [43, 45, 49, 53], "subdirectori": 43, "sub": 43, "compar": [43, 56, 58], "logdir": 43, "startup": 43, "recurs": 43, "tree": [43, 56], "tfevent": 43, "encount": 43, "frontend": 43, "organ": 43, "accordingli": 43, "my_log_dir": 43, "view": [43, 56], "my_metr": [43, 44], "termin": [43, 44], "entiti": 44, "bias": 44, "my_project": 44, "my_ent": 44, "my_group": 44, "importerror": 44, "account": [44, 58], "log_config": 44, "local": [44, 49, 53, 56, 57], "link": 44, "contextmanag": 45, "intellig": 45, "determin": 45, "autocast": 45, "amp": 45, "otherwis": 45, "context": 45, "bf16": [46, 57], "request": [46, 56], "inde": [46, 56], "kernel": 46, "float32": 46, "done": [46, 58], "isn": 46, "gradscal": 47, "shardedgradscal": 47, "scaler": 47, "awar": 47, "debug_mod": 49, "pseudo": 49, "random": [49, 57], "commonli": [49, 56, 58], "numpi": 49, "job": [49, 57], "own": [49, 56, 58], "determinist": 49, "global": 49, "warn": 49, "nondeterminist": 49, "addition": [49, 58], "cudnn": 49, "disabl": 49, "set_deterministic_debug_mod": 49, "algorithm": 49, "outsid": [49, 56], "generated_examples_python": 50, "zip": 50, "galleri": [50, 55], "sphinx": 50, "000": [51, 55], "execut": [51, 55], "generated_exampl": 51, "mem": [51, 55], "mb": [51, 55], "gentl": 52, "introduct": 52, "workflow": [52, 57], "readi": 52, "proper": [53, 57], "host": [53, 57], "page": [53, 54, 57], "latest": [53, 57], "pypi": 53, "confirm": 53, "And": [53, 56], "usag": [53, 56], "h": 53, "ls": [53, 56], "cp": [53, 56, 57], "welcom": 53, "show": [53, 58], "exit": 53, "greatest": [53, 57], "contributor": 53, "git": 53, "clone": [53, 56, 58], "cd": [53, 56], "On": 54, "pointer": 54, "author": [54, 57], "emphas": 54, "aspect": 54, "simplic": 54, "component": 54, "reus": 54, "high": [54, 58], "prove": 54, "democrat": 54, "box": 54, "hardwar": [54, 56, 58], "zoo": 54, "varieti": [54, 58], "techniqu": [54, 56, 58], "integr": [54, 56, 57], "excit": 54, "checkout": 54, "better": [54, 56], "chekckpoint": 54, "hyperparamet": [54, 57, 58], "embodi": 54, "philosophi": 54, "especi": [54, 56], "usabl": 54, "eluetherai": 54, "composit": 54, "hard": 54, "outlin": 54, "unecessari": 54, "never": 54, "thoroughli": 54, "unit": 54, "favorit": [56, 58], "commun": 56, "seemlessli": 56, "beyond": 56, "connect": 56, "larger": 56, "might": 56, "amount": 56, "natur": 56, "task": [56, 58], "export": 56, "mobil": 56, "phone": 56, "leverag": 56, "mode": 56, "lot": 56, "plai": 56, "freez": [56, 58], "percentag": 56, "learnabl": 56, "keep": [56, 58], "16gb": 56, "rtx": 56, "3090": 56, "4090": 56, "peak": [56, 58], "hour": 56, "full_finetune_single_devic": 56, "7b_full_single_devic": 56, "7b_full_single_device_low_memori": 56, "mistral": 56, "13b_full": 56, "lora_finetune_single_devic": 56, "7b_lora_single_devic": 56, "7b_qlora_single_devic": 56, "7b_lora": [56, 58], "473": 56, "98": 56, "gb": 56, "50": 56, "484": 56, "01": 56, "similar": [56, 58], "fact": [56, 58], "ident": 56, "third": 56, "smaller": [56, 58], "But": 56, "realli": 56, "eleuther_ev": 56, "eleuther_evalu": 56, "plan": 56, "copi": [56, 57], "element": 56, "custom_eval_config": 56, "truthfulqa_mc2": 56, "qa": 56, "measur": 56, "propens": 56, "question": 56, "shot": 56, "accuraci": 56, "baselin": [56, 58], "324": 56, "loglikelihood": 56, "195": 56, "121": 56, "27": 56, "second": 56, "197": 56, "acc": 56, "388": 56, "38": 56, "shown": 56, "489": 56, "48": 56, "great": 56, "seem": [56, 57], "custom_generation_config": 56, "kick": 56, "top_k": 56, "300": 56, "temperatur": 56, "interest": 56, "site": 56, "visit": 56, "bai": 56, "area": 56, "92": 56, "exploratorium": 56, "san": 56, "francisco": 56, "magazin": 56, "awesom": 56, "bridg": 56, "pretti": 56, "cool": 56, "96": 56, "61": 56, "sec": 56, "25": 56, "83": 56, "99": [56, 58], "15": 56, "72": 56, "know": [56, 58], "littl": 56, "saw": 56, "took": 56, "torchao": 56, "bit": [56, 58], "custom_quantization_config": 56, "68": 56, "19": 56, "76": 56, "69": 56, "95": 56, "67": 56, "4w": 56, "unlik": 56, "won": 56, "engin": 56, "fullmodeltorchtunecheckpoint": 56, "int4weightonlyquant": 56, "groupsiz": 56, "256": 56, "did": 56, "park": 56, "sit": 56, "top": 56, "hill": 56, "beauti": 56, "62": 56, "17": 56, "85": 56, "compil": 56, "hood": 56, "sped": 56, "almost": 56, "3x": 56, "benefit": 56, "yet": 56, "fast": 56, "assumpt": 56, "satisfi": 56, "new_dir": 56, "output_dict": 56, "sd_1": 56, "sd_2": 56, "dump": 56, "convert_hf_checkpoint": 56, "checkpoint_path": 56, "my": 56, "justin": 56, "am": 56, "school": 56, "math": 56, "teacher": 56, "ws": 56, "94": 56, "103": 56, "28": 56, "bandwidth": 56, "achiev": 56, "1391": 56, "84": 56, "thats": 56, "hopefulli": 56, "gave": 56, "launch": 57, "gate": 57, "grant": 57, "minut": 57, "agreement": 57, "signup": 57, "authent": 57, "dataclass": 57, "hold": 57, "It": 57, "alpaca_llama_full_finetun": 57, "good": [57, 58], "place": 57, "custom_config": 57, "replic": 57, "lower": [57, 58], "sooner": 57, "42": 57, "llama2_7b": [57, 58], "sgd": 57, "crossentropyloss": 57, "enable_activation_checkpoint": 57, "torchrun": 57, "therefor": 57, "nnode": [57, 58], "nproc_per_nod": [57, 58], "immedi": 57, "down": [57, 58], "indic": 57, "succesfulli": 57, "log_1707246452": 57, "manual": [57, 58], "sampler": 57, "7553404569625854": 57, "13000": 57, "03": 57, "e2": 57, "teach": 58, "straight": 58, "jump": 58, "neural": 58, "unfamiliar": 58, "oppos": 58, "substanti": 58, "reduct": 58, "momentum": 58, "adamw": 58, "further": 58, "arbitrari": 58, "could": 58, "min": 58, "relat": 58, "paper": 58, "aghajanyan": 58, "et": 58, "al": 58, "hypothes": 58, "intrins": 58, "often": 58, "four": 58, "eight": 58, "practic": 58, "imag": 58, "simplifi": 58, "left": 58, "blue": 58, "extra": 58, "rememb": 58, "approx": 58, "15m": 58, "8192": 58, "65k": 58, "minim": 58, "pretrain": 58, "p": 58, "requires_grad": 58, "frozen_out": 58, "lora_out": 58, "omit": 58, "construct": 58, "lora_llama2_7b": 58, "base_model": 58, "choos": 58, "lora_model": 58, "lora_llama_2_7b": 58, "alon": 58, "in_featur": 58, "out_featur": 58, "inplac": 58, "feel": 58, "free": 58, "why": 58, "strict": 58, "whenev": 58, "validate_state_dict_for_lora": 58, "peft_util": 58, "set_trainable_param": 58, "fetch": 58, "lora_param": 58, "total_param": 58, "sum": 58, "numel": 58, "trainable_param": 58, "2f": 58, "6742609920": 58, "4194304": 58, "taken": 58, "vram": 58, "23gb": 58, "lora_finetune_distribut": 58, "my_model_checkpoint_path": 58, "tokenizer_checkpoint": 58, "my_tokenizer_checkpoint_path": 58, "constraint": 58, "coupl": 58, "factori": 58, "16": 58, "benefici": 58, "long": 58, "impact": 58, "rel": 58, "minor": 58, "64": 58, "lora_experiment_1": 58, "smooth": 58, "curv": 58, "500": 58, "seen": 58, "exercis": 58, "longer": 58}, "objects": {"torchtune.config": [[9, 0, 1, "", "instantiate"], [10, 0, 1, "", "parse"]], "torchtune.datasets": [[11, 0, 1, "", "alpaca_cleaned_dataset"], [12, 0, 1, "", "alpaca_dataset"], [13, 0, 1, "", "grammar_dataset"], [14, 0, 1, "", "samsum_dataset"], [15, 0, 1, "", "slimorca_dataset"]], "torchtune.models.llama2": [[16, 0, 1, "", "llama2_7b"], [17, 0, 1, "", "lora_llama2"]], "torchtune.modules": [[18, 1, 1, "", "CausalSelfAttention"], [19, 1, 1, "", "FeedForward"], [20, 1, 1, "", "KVCache"], [21, 1, 1, "", "RMSNorm"], [22, 1, 1, "", "RotaryPositionalEmbeddings"], [23, 1, 1, "", "Tokenizer"], [24, 1, 1, "", "TransformerDecoder"], [25, 1, 1, "", "TransformerDecoderLayer"], [27, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[18, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[19, 2, 1, "", "forward"]], "torchtune.modules.RMSNorm": [[21, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[22, 2, 1, "", "forward"]], "torchtune.modules.Tokenizer": [[23, 2, 1, "", "decode"], [23, 2, 1, "", "encode"], [23, 2, 1, "", "from_file"], [23, 2, 1, "", "tokenize_messages"]], "torchtune.modules.TransformerDecoder": [[24, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoderLayer": [[25, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[26, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[28, 1, 1, "", "AdapterModule"], [29, 1, 1, "", "LoRALinear"], [30, 0, 1, "", "get_adapter_params"], [31, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[28, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[29, 2, 1, "", "adapter_params"], [29, 2, 1, "", "forward"]], "torchtune.utils": [[32, 1, 1, "", "FullModelHFCheckpointer"], [33, 1, 1, "", "FullModelMetaCheckpointer"], [36, 0, 1, "", "get_device"], [37, 0, 1, "", "get_world_size_and_rank"], [38, 0, 1, "", "init_distributed"]], "torchtune.utils.FullModelHFCheckpointer": [[32, 2, 1, "", "load_checkpoint"], [32, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[33, 2, 1, "", "load_checkpoint"], [33, 2, 1, "", "save_checkpoint"]], "torchtune.utils.argparse": [[34, 1, 1, "", "TuneRecipeArgumentParser"]], "torchtune.utils.argparse.TuneRecipeArgumentParser": [[34, 2, 1, "", "parse_known_args"]], "torchtune.utils.collate": [[35, 0, 1, "", "padded_collate"]], "torchtune.utils.logging": [[39, 0, 1, "", "get_logger"]], "torchtune.utils.memory": [[40, 0, 1, "", "set_activation_checkpointing"]], "torchtune.utils.metric_logging": [[41, 1, 1, "", "DiskLogger"], [42, 1, 1, "", "StdoutLogger"], [43, 1, 1, "", "TensorBoardLogger"], [44, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[41, 2, 1, "", "close"], [41, 2, 1, "", "log"], [41, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[42, 2, 1, "", "close"], [42, 2, 1, "", "log"], [42, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[43, 2, 1, "", "close"], [43, 2, 1, "", "log"], [43, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[44, 2, 1, "", "close"], [44, 2, 1, "", "log"], [44, 2, 1, "", "log_config"], [44, 2, 1, "", "log_dict"]], "torchtune.utils.precision": [[45, 0, 1, "", "get_autocast"], [46, 0, 1, "", "get_dtype"], [47, 0, 1, "", "get_gradient_scaler"], [48, 0, 1, "", "list_dtypes"]], "torchtune.utils.seed": [[49, 0, 1, "", "set_seed"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 52, 54, 56, 58], "config": [0, 6, 7, 57], "dataset": 1, "model": [2, 3, 8, 56, 57, 58], "llama2": [2, 56, 58], "modul": 3, "compon": [3, 6], "build": 3, "block": 3, "peft": 3, "util": [3, 4], "checkpoint": [4, 5, 8, 56], "distribut": 4, "reduc": 4, "precis": 4, "memori": 4, "manag": 4, "metric": [4, 8], "log": [4, 8], "data": 4, "miscellan": 4, "overview": [5, 54, 56], "format": 5, "handl": 5, "differ": 5, "intermedi": 5, "vs": 5, "final": 5, "lora": [5, 56, 58], "put": 5, "thi": 5, "all": [5, 6], "togeth": 5, "about": 6, "where": 6, "do": 6, "paramet": 6, "live": 6, "write": 6, "configur": 6, "us": [6, 7, 56], "instanti": [6, 9], "referenc": 6, "other": [6, 56], "field": 6, "interpol": 6, "valid": 6, "your": [6, 7, 57], "best": 6, "practic": 6, "airtight": 6, "public": 6, "api": 6, "onli": 6, "command": 6, "line": 6, "overrid": 6, "what": [7, 54, 58], "ar": 7, "recip": [7, 57, 58], "script": 7, "class": 7, "run": [7, 56], "cli": 7, "pars": [7, 10], "weight": 8, "bias": 8, "logger": 8, "w": 8, "b": 8, "alpaca_cleaned_dataset": 11, "alpaca_dataset": 12, "grammar_dataset": 13, "samsum_dataset": 14, "slimorca_dataset": 15, "llama2_7b": 16, "lora_llama2": 17, "causalselfattent": 18, "todo": [18, 25], "feedforward": 19, "kvcach": 20, "rmsnorm": 21, "rotarypositionalembed": 22, "token": 23, "transformerdecod": 24, "transformerdecoderlay": 25, "reparametrize_as_dtype_state_dict_post_hook": 26, "get_cosine_schedule_with_warmup": 27, "adaptermodul": 28, "loralinear": 29, "get_adapter_param": 30, "set_trainable_param": 31, "fullmodelhfcheckpoint": 32, "fullmodelmetacheckpoint": 33, "tunerecipeargumentpars": 34, "padded_col": 35, "get_devic": 36, "get_world_size_and_rank": 37, "init_distribut": 38, "get_logg": 39, "set_activation_checkpoint": 40, "disklogg": 41, "stdoutlogg": 42, "tensorboardlogg": 43, "wandblogg": 44, "get_autocast": 45, "get_dtyp": 46, "get_gradient_scal": 47, "list_dtyp": 48, "set_se": 49, "comput": [51, 55], "time": [51, 55], "welcom": 52, "document": 52, "get": 52, "start": 52, "tutori": 52, "instal": 53, "instruct": 53, "kei": 54, "concept": 54, "design": 54, "principl": 54, "end": 56, "workflow": 56, "download": [56, 57], "7b": 56, "finetun": [56, 57, 58], "evalu": 56, "eleutherai": 56, "s": 56, "eval": 56, "har": 56, "gener": 56, "speed": 56, "up": 56, "quantiz": 56, "librari": 56, "first": 57, "llm": 57, "select": 57, "modifi": 57, "train": 57, "next": 57, "step": 57, "how": 58, "doe": 58, "work": 58, "appli": 58}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})