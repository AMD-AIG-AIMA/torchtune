Search.setIndex({"docnames": ["api_ref_config", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "deep_dives/checkpointer", "deep_dives/configs", "deep_dives/recipe_deepdive", "deep_dives/wandb_logging", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.models.gemma.gemma_2b", "generated/torchtune.models.llama2.llama2_13b", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2_13b", "generated/torchtune.models.llama2.lora_llama2_7b", "generated/torchtune.models.llama2.qlora_llama2_13b", "generated/torchtune.models.llama2.qlora_llama2_7b", "generated/torchtune.models.mistral.lora_mistral_7b", "generated/torchtune.models.mistral.mistral_7b", "generated/torchtune.models.mistral.qlora_mistral_7b", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.Tokenizer", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.TuneRecipeArgumentParser", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_dtype", "generated/torchtune.utils.get_logger", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.list_dtypes", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.padded_collate", "generated/torchtune.utils.profiler", "generated/torchtune.utils.set_activation_checkpointing", "generated/torchtune.utils.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times", "tutorials/e2e_flow", "tutorials/first_finetune_tutorial", "tutorials/lora_finetune", "tutorials/qlora_finetune"], "filenames": ["api_ref_config.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "deep_dives/checkpointer.rst", "deep_dives/configs.rst", "deep_dives/recipe_deepdive.rst", "deep_dives/wandb_logging.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.models.gemma.gemma_2b.rst", "generated/torchtune.models.llama2.llama2_13b.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2_13b.rst", "generated/torchtune.models.llama2.lora_llama2_7b.rst", "generated/torchtune.models.llama2.qlora_llama2_13b.rst", "generated/torchtune.models.llama2.qlora_llama2_7b.rst", "generated/torchtune.models.mistral.lora_mistral_7b.rst", "generated/torchtune.models.mistral.mistral_7b.rst", "generated/torchtune.models.mistral.qlora_mistral_7b.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.Tokenizer.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_dtype.rst", "generated/torchtune.utils.get_logger.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.list_dtypes.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.padded_collate.rst", "generated/torchtune.utils.profiler.rst", "generated/torchtune.utils.set_activation_checkpointing.rst", "generated/torchtune.utils.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst", "tutorials/e2e_flow.rst", "tutorials/first_finetune_tutorial.rst", "tutorials/lora_finetune.rst", "tutorials/qlora_finetune.rst"], "titles": ["torchtune.config", "torchtune.datasets", "torchtune.models", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "All about configs", "What are recipes?", "Logging to Weights &amp; Biases", "instantiate", "parse", "alpaca_cleaned_dataset", "alpaca_dataset", "grammar_dataset", "samsum_dataset", "slimorca_dataset", "gemma_2b", "llama2_13b", "llama2_7b", "lora_llama2_13b", "lora_llama2_7b", "qlora_llama2_13b", "qlora_llama2_7b", "lora_mistral_7b", "mistral_7b", "qlora_mistral_7b", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "Tokenizer", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "get_device", "get_dtype", "get_logger", "get_world_size_and_rank", "init_distributed", "list_dtypes", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "padded_collate", "profiler", "set_activation_checkpointing", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times", "End-to-End Workflow with torchtune", "Finetune your First LLM", "Finetuning Llama2 with LoRA", "Finetuning Llama2 with QLoRA"], "terms": {"all": [2, 3, 7, 26, 27, 32, 34, 40, 42, 57, 59, 61, 62, 63, 64, 65], "from": [2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 24, 27, 31, 32, 33, 35, 36, 38, 40, 41, 42, 51, 52, 58, 60, 62, 63, 64, 65], "famili": [2, 7, 61], "pre": [2, 60], "train": [2, 4, 5, 7, 8, 11, 12, 13, 14, 15, 26, 35, 40, 41, 44, 54, 59, 61, 63, 65, 66], "can": [2, 3, 5, 6, 7, 8, 9, 11, 12, 29, 30, 31, 40, 42, 51, 52, 59, 60, 61, 63, 64, 65, 66], "download": [2, 5, 57, 60, 65, 66], "hug": [2, 5, 11, 12, 13, 14, 15, 35, 61, 63, 64], "face": [2, 5, 11, 12, 13, 14, 15, 35, 61, 63, 64], "hub": [2, 5, 63, 64], "follow": [2, 5, 7, 26, 35, 52, 59, 60, 63, 64, 65, 66], "command": [2, 7, 42, 60, 64, 65, 66], "tune": [2, 5, 6, 7, 8, 10, 11, 12, 59, 60, 61, 63, 64, 65, 66], "meta": [2, 5, 13, 14, 40, 41, 63, 64], "llama": [2, 5, 13, 14, 29, 30, 40, 41, 63, 64, 65], "2": [2, 5, 15, 26, 31, 40, 41, 53, 56, 63, 64, 65], "7b": [2, 5, 11, 12, 18, 20, 23, 24, 40, 41, 64, 65, 66], "hf": [2, 5, 40, 63, 64], "token": [2, 5, 6, 7, 11, 12, 13, 14, 15, 26, 30, 32, 33, 63, 64, 65, 66], "access_token": 2, "ai": [2, 24, 26, 52], "mistralai": 2, "v0": 2, "1": [2, 5, 7, 15, 26, 31, 32, 35, 41, 51, 52, 53, 56, 63, 64, 65, 66], "googl": [2, 16], "2b": [2, 16], "These": [3, 5, 6, 7, 9, 42, 63, 64, 65, 66], "ar": [3, 5, 6, 8, 9, 11, 12, 13, 14, 19, 20, 21, 22, 23, 25, 32, 37, 40, 41, 44, 61, 63, 64, 65, 66], "common": [3, 6, 65], "us": [3, 5, 8, 9, 10, 11, 12, 13, 14, 15, 26, 27, 29, 30, 31, 32, 33, 34, 40, 41, 42, 43, 44, 49, 50, 51, 52, 56, 59, 60, 61, 64, 65], "offer": 4, "allow": [4, 51, 66], "seamless": 4, "transit": 4, "between": [4, 5, 40, 63, 65, 66], "format": [4, 11, 12, 13, 14, 15, 40, 41, 63, 64, 65], "interoper": [4, 5, 7, 61, 63, 66], "rest": [4, 66], "ecosystem": [4, 5, 7, 61, 63, 64, 66], "For": [4, 5, 6, 7, 11, 12, 26, 32, 42, 52, 56, 63, 64, 65, 66], "comprehens": 4, "overview": [4, 6, 8, 64, 65, 66], "pleas": [4, 22, 25, 60, 66], "see": [4, 5, 8, 11, 22, 25, 28, 36, 42, 45, 52, 54, 56, 60, 61, 63, 64, 65, 66], "deep": [4, 5, 6, 7, 8, 61], "dive": [4, 5, 6, 7, 8, 61], "enabl": [4, 6, 7, 8, 19, 20, 21, 22, 23, 25, 37, 54, 56, 64, 65, 66], "work": [4, 5, 7, 42, 61, 63, 66], "set": [4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 30, 32, 39, 43, 55, 56, 61, 63, 64, 65], "consumpt": 4, "dure": [4, 5, 11, 12, 13, 14, 26, 28, 30, 32, 33, 63, 65, 66], "provid": [4, 5, 6, 7, 9, 15, 32, 42, 61, 63, 64], "debug": [4, 5, 6, 7], "your": [4, 8, 9, 51, 52, 59, 60, 61, 63, 65, 66], "finetun": [4, 5, 6, 7, 11, 12, 19, 20, 21, 48, 59, 61], "job": [4, 56, 64], "variou": 4, "dataset": [4, 6, 11, 12, 13, 14, 15, 61, 63, 64, 65, 66], "walk": [5, 7, 51, 61, 63, 64, 66], "you": [5, 6, 7, 8, 9, 11, 12, 42, 51, 52, 59, 60, 61, 63, 64, 65, 66], "through": [5, 6, 7, 8, 27, 61, 63, 64, 66], "design": [5, 7], "behavior": 5, "associ": [5, 6, 7, 63, 65], "util": [5, 6, 7, 8, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 61, 63, 64, 66], "what": [5, 6, 8, 59, 63, 64], "cover": [5, 6, 7, 8, 63, 66], "how": [5, 6, 7, 8, 59, 63, 64, 66], "we": [5, 6, 7, 8, 11, 12, 26, 28, 30, 31, 32, 37, 40, 41, 44, 61, 63, 64, 65, 66], "them": [5, 6, 27, 31, 34, 63, 65, 66], "scenario": 5, "full": [5, 6, 7, 22, 25, 31, 40, 41, 61, 65], "compos": 5, "compon": [5, 7, 54, 61, 64, 65, 66], "which": [5, 7, 11, 12, 13, 14, 19, 20, 21, 23, 26, 30, 31, 32, 33, 35, 40, 41, 44, 49, 61, 63, 65, 66], "plug": 5, "ani": [5, 6, 7, 9, 10, 31, 34, 38, 39, 40, 41, 56, 63, 65], "recip": [5, 6, 8, 9, 10, 13, 14, 27, 40, 41, 61, 63, 66], "evalu": [5, 7, 59, 61, 64, 65, 66], "gener": [5, 7, 15, 31, 56, 57, 59, 65, 66], "each": [5, 7, 19, 20, 21, 23, 26, 30, 31, 32, 56, 61, 63, 64, 65], "support": [5, 7, 8, 9, 11, 12, 13, 14, 26, 37, 41, 44, 48, 61, 63, 64, 65, 66], "model": [5, 6, 7, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 54, 55, 59, 61, 66], "make": [5, 6, 7, 8, 26, 33, 61, 63, 64, 65, 66], "easi": [5, 7, 61, 64, 65], "understand": [5, 6, 7, 59, 61, 65, 66], "extend": [5, 7, 61], "befor": [5, 32, 33, 37, 40, 63], "let": [5, 6, 8, 63, 64, 65, 66], "s": [5, 6, 7, 8, 10, 19, 20, 21, 23, 26, 30, 32, 33, 34, 36, 38, 40, 41, 43, 51, 54, 61, 64, 65, 66], "defin": [5, 6, 7, 27, 36, 37, 38, 65], "some": [5, 6, 38, 39, 59, 61, 63, 64, 65, 66], "concept": [5, 63], "In": [5, 6, 7, 30, 37, 51, 52, 63, 65, 66], "ll": [5, 6, 7, 61, 63, 66], "talk": 5, "about": [5, 7, 40, 52, 61, 63, 65, 66], "take": [5, 6, 7, 9, 27, 28, 34, 40, 42, 43, 63, 64, 65, 66], "close": [5, 7, 49, 50, 51, 52, 65], "look": [5, 6, 7, 51, 63, 64, 65], "veri": [5, 32, 63], "simpli": [5, 6, 66], "dictat": 5, "state_dict": [5, 34, 40, 41, 65, 66], "store": [5, 49, 52, 65, 66], "file": [5, 6, 7, 8, 9, 10, 11, 12, 31, 40, 41, 42, 49, 52, 54, 58, 61, 62, 63, 64, 65, 66], "disk": [5, 49], "weight": [5, 7, 19, 20, 21, 22, 23, 25, 26, 34, 36, 37, 40, 41, 52, 59, 63, 64, 65, 66], "string": [5, 31, 36, 43, 44], "kei": [5, 6, 8, 26, 28, 32, 39, 40, 63, 65, 66], "identifi": 5, "state": [5, 7, 34, 38, 39, 40, 41, 63, 65, 66], "dict": [5, 6, 7, 8, 9, 34, 38, 39, 40, 41, 47], "If": [5, 6, 11, 12, 13, 14, 15, 26, 34, 37, 40, 41, 43, 44, 47, 51, 52, 56, 60, 64, 65], "identif": 5, "don": [5, 6, 7, 56, 63, 66], "t": [5, 6, 7, 15, 44, 56, 63, 66], "match": [5, 63, 65], "up": [5, 7, 8, 11, 12, 64, 65, 66], "exactli": 5, "those": [5, 65], "definit": [5, 65], "either": [5, 40, 65, 66], "run": [5, 6, 8, 10, 27, 28, 32, 34, 40, 41, 51, 52, 60, 61, 64, 65, 66], "explicit": 5, "error": [5, 6, 11, 40, 56], "load": [5, 7, 40, 41, 42, 51, 63, 65], "rais": [5, 9, 15, 26, 32, 40, 41, 44, 47, 52, 56], "an": [5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 26, 32, 36, 38, 39, 40, 41, 52, 61, 63, 64, 65, 66], "except": 5, "wors": 5, "silent": [5, 27], "succe": 5, "infer": [5, 26, 28, 30, 32, 33, 59, 63, 66], "expect": [5, 6, 9, 30, 52, 65], "addit": [5, 6, 7, 9, 40, 41, 44, 47, 49, 51, 52, 55, 61, 65], "line": [5, 7, 42, 64], "also": [5, 6, 7, 8, 9, 26, 32, 37, 43, 52, 60, 63, 64, 65, 66], "need": [5, 6, 7, 8, 15, 26, 27, 32, 51, 52, 63, 64, 65, 66], "shape": [5, 26, 28, 30, 32, 33, 37], "valu": [5, 6, 15, 16, 17, 18, 24, 26, 28, 29, 32, 35, 40, 42, 49, 50, 51, 52, 56, 65], "two": [5, 6, 61, 63, 64, 65, 66], "popular": [5, 61, 63, 64], "llama2": [5, 6, 7, 9, 11, 12, 15, 17, 18, 19, 20, 21, 22, 27, 31, 32, 33, 59, 61, 64], "offici": [5, 64], "implement": [5, 7, 11, 12, 13, 14, 15, 27, 29, 30, 35, 36, 37, 40, 51, 61, 65, 66], "when": [5, 6, 7, 10, 32, 34, 35, 51, 63, 65, 66], "websit": 5, "get": [5, 6, 7, 8, 31, 44, 45, 46, 61, 63, 64, 65], "access": [5, 6, 7, 40, 63, 64], "singl": [5, 6, 9, 26, 40, 41, 63, 65, 66], "pth": [5, 63, 64], "inspect": [5, 63, 65, 66], "content": [5, 31], "easili": [5, 6, 61, 65, 66], "torch": [5, 28, 32, 34, 35, 43, 44, 47, 54, 55, 56, 63, 64, 65, 66], "import": [5, 6, 9, 51, 52, 63, 64, 65, 66], "consolid": [5, 64], "00": [5, 58, 62, 64], "mmap": [5, 63], "true": [5, 6, 11, 12, 13, 14, 21, 22, 25, 31, 34, 40, 41, 47, 51, 63, 64, 65, 66], "weights_onli": 5, "map_loc": [5, 63], "cpu": [5, 7, 34, 44, 63, 66], "tensor": [5, 26, 27, 28, 29, 30, 32, 33, 34, 37, 40, 49, 50, 51, 52, 53, 65, 66], "item": 5, "print": [5, 11, 12, 13, 14, 15, 31, 65, 66], "f": [5, 8, 11, 12, 13, 14, 63, 65, 66], "tok_embed": [5, 32], "size": [5, 7, 9, 11, 12, 13, 14, 26, 28, 29, 30, 31, 32, 33, 46, 61, 63, 65], "32000": [5, 9, 65], "4096": [5, 9, 11, 12, 26, 30, 65], "len": [5, 11, 12, 13, 14, 32], "292": 5, "The": [5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 19, 20, 21, 29, 30, 31, 34, 35, 40, 42, 43, 44, 45, 52, 54, 56, 60, 61, 63, 64, 65, 66], "contain": [5, 26, 28, 30, 31, 32, 33, 36, 38, 39, 40, 41, 42, 51, 53, 63, 65], "includ": [5, 6, 7, 37, 40, 41, 42, 61, 63, 64, 65, 66], "input": [5, 11, 12, 13, 14, 15, 26, 27, 29, 30, 31, 32, 33, 37, 40, 53, 56, 65, 66], "embed": [5, 26, 28, 29, 30, 32], "tabl": [5, 65, 66], "call": [5, 9, 27, 34, 42, 49, 50, 51, 52, 64, 65, 66], "layer": [5, 7, 19, 20, 21, 22, 23, 25, 26, 32, 33, 37, 61, 65, 66], "have": [5, 6, 9, 26, 28, 36, 42, 51, 54, 63, 64, 65, 66], "dim": [5, 26, 27, 29, 30, 32, 33], "most": [5, 6, 64, 65, 66], "within": [5, 6, 9, 15, 27, 51, 56, 63, 65, 66], "default": [5, 6, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 40, 41, 42, 44, 49, 53, 54, 56, 63, 65, 66], "everi": [5, 7, 27, 51, 66], "config": [5, 8, 9, 10, 26, 40, 42, 52, 61, 63, 65, 66], "repo": [5, 40, 41, 63], "first": [5, 6, 9, 32, 40, 42, 59, 61, 63, 65, 66], "big": [5, 63], "split": [5, 63], "across": [5, 7, 40, 51, 56, 63], "bin": [5, 63], "To": [5, 6, 7, 40, 60, 61, 63, 64, 65, 66], "correctli": [5, 7, 40, 60, 64, 66], "piec": 5, "one": [5, 7, 27, 31, 63, 66], "pytorch_model": [5, 63], "00001": 5, "00002": 5, "embed_token": 5, "241": 5, "Not": 5, "onli": [5, 8, 26, 30, 31, 32, 33, 37, 38, 41, 42, 44, 63, 65, 66], "doe": [5, 36, 40, 42, 63], "fewer": [5, 26], "sinc": [5, 6, 9, 27, 40, 63], "instead": [5, 7, 27, 28, 37, 63, 65], "mismatch": 5, "name": [5, 6, 8, 36, 39, 40, 41, 42, 43, 49, 50, 51, 52, 63], "caus": [5, 31], "try": [5, 6, 63, 66], "same": [5, 6, 19, 20, 21, 26, 28, 31, 33, 42, 52, 63, 65, 66], "As": [5, 6, 7, 37, 61, 63, 66], "re": [5, 6, 61, 63, 64, 65], "care": [5, 27, 40, 63, 65], "like": [5, 6, 7, 8, 63, 64, 65], "end": [5, 7, 31, 59, 61, 64, 65], "number": [5, 7, 11, 12, 15, 26, 28, 32, 35, 40, 41, 46, 56, 65], "just": [5, 61, 64, 65], "save": [5, 7, 8, 40, 41, 52, 59, 63, 65], "less": [5, 15, 63, 64, 66], "prone": 5, "manag": [5, 54], "invari": 5, "accept": [5, 6, 15, 31, 64, 66], "multipl": [5, 6, 7, 37, 49, 50, 51, 52], "sourc": [5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 63], "worri": 5, "explicitli": [5, 36, 61, 65], "convert": [5, 40, 53, 63, 64, 66], "time": [5, 31, 49, 51, 63, 66], "produc": [5, 66], "back": [5, 40, 65, 66], "origin": [5, 11, 12, 34, 37, 63, 65, 66], "form": [5, 6, 7, 11], "One": [5, 63], "advantag": [5, 65], "being": [5, 40, 41, 43, 66], "should": [5, 6, 7, 19, 20, 21, 23, 26, 27, 36, 42, 49, 50, 51, 52, 60, 61, 63, 64, 65, 66], "abl": [5, 7, 63, 64], "fine": [5, 7, 8, 11, 12, 59, 61, 63, 64, 65], "post": [5, 66], "tool": [5, 63, 64], "quantiz": [5, 19, 20, 21, 22, 23, 25, 37, 59, 66], "eval": [5, 59, 61], "without": [5, 6, 61, 63, 65], "code": [5, 7, 32, 57, 61], "chang": [5, 6, 8, 63, 64, 65, 66], "OR": 5, "convers": [5, 40, 61, 63, 65, 66], "script": [5, 8, 63, 64], "wai": [5, 6, 64], "surround": [5, 7, 61], "load_checkpoint": [5, 7, 40, 41], "save_checkpoint": [5, 7, 8, 40, 41], "method": [5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 34, 36, 38, 42, 61, 63, 65, 66], "convertor": 5, "avail": [5, 7, 42, 43, 61, 63, 65], "here": [5, 6, 8, 29, 30, 63, 64, 65, 66], "three": [5, 7, 64], "hfcheckpoint": 5, "read": [5, 40, 41, 61], "write": [5, 7, 40, 41, 49, 64], "compat": [5, 40, 64], "transform": [5, 7, 19, 20, 21, 23, 32, 33, 35, 65], "framework": [5, 7, 61], "mention": [5, 63, 66], "abov": [5, 34, 63, 65, 66], "assum": [5, 35, 38, 44, 63, 65], "checkpoint_dir": [5, 6, 40, 41, 63, 64], "necessari": [5, 15, 49, 50, 51, 52, 65], "json": [5, 40, 54, 63], "easiest": [5, 64], "sure": [5, 6, 63, 64, 65, 66], "everyth": [5, 7, 42, 61, 64], "flow": [5, 66], "By": [5, 65, 66], "ignor": [5, 26, 27], "safetensor": 5, "output": [5, 11, 12, 13, 15, 19, 20, 21, 23, 26, 27, 29, 30, 32, 33, 37, 39, 50, 54, 60, 63, 64, 65, 66], "dir": [5, 63, 64], "output_dir": [5, 6, 40, 41, 54, 63, 64, 65, 66], "specifi": [5, 6, 7, 9, 26, 63, 64, 66], "argument": [5, 6, 9, 15, 22, 25, 26, 42, 47, 49, 51, 52, 55, 64, 65], "snippet": 5, "explain": 5, "setup": [5, 6, 7, 32, 55, 63, 65, 66], "_component_": [5, 6, 8, 9, 63, 64, 65], "fullmodelhfcheckpoint": [5, 63], "directori": [5, 6, 40, 41, 49, 51, 52, 63, 64], "sort": [5, 40], "id": [5, 11, 12, 15, 31, 40, 53, 63], "so": [5, 6, 40, 42, 60, 61, 63, 64, 65, 66], "order": [5, 7, 40, 51, 52, 64], "matter": [5, 40, 65], "checkpoint_fil": [5, 6, 8, 40, 41, 63, 64, 65, 66], "restart": 5, "previou": [5, 40, 41], "more": [5, 6, 7, 11, 28, 30, 42, 52, 54, 56, 61, 63, 64, 65, 66], "next": [5, 66], "section": [5, 7, 59, 63, 66], "recipe_checkpoint": [5, 40, 41, 64], "null": [5, 6, 64], "usual": [5, 30, 40, 63, 65], "model_typ": [5, 40, 41, 63, 64], "resume_from_checkpoint": [5, 40, 41, 64], "fals": [5, 6, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 25, 26, 31, 37, 40, 41, 54, 63, 64, 65, 66], "requir": [5, 6, 15, 40, 51, 52, 56, 60, 66], "param": [5, 7, 19, 20, 21, 37, 38, 39, 40, 65, 66], "directli": [5, 6, 7, 9, 40, 63, 64, 65, 66], "help": [5, 32, 40, 42, 59, 60, 61, 63, 64, 66], "ensur": [5, 6, 15, 26, 40, 44, 61], "out": [5, 6, 7, 11, 12, 13, 14, 40, 41, 59, 61, 63, 64, 65, 66], "case": [5, 7, 8, 26, 40, 44, 49, 61, 63, 65, 66], "discrep": [5, 40], "along": [5, 65], "detail": [5, 11, 28, 54, 56, 63, 64, 65, 66], "found": [5, 6, 8, 29, 30, 65, 66], "metacheckpoint": 5, "github": [5, 11, 12, 13, 14, 19, 20, 21, 26, 29, 30, 35, 60], "repositori": [5, 63, 64], "fullmodelmetacheckpoint": [5, 64], "torchtunecheckpoint": 5, "perform": [5, 27, 61, 63, 66], "current": [5, 26, 30, 32, 33, 41, 46, 49, 51, 56, 63, 64], "test": [5, 6, 7, 61], "complet": [5, 7, 63, 64], "written": [5, 6, 7, 40, 41, 49, 50, 51, 52, 61], "begin": [5, 31, 66], "partit": [5, 66], "ha": [5, 31, 36, 38, 63, 65, 66], "standard": [5, 50, 61, 63], "key_1": 5, "weight_1": 5, "key_2": 5, "weight_2": 5, "mid": 5, "chekpoint": 5, "middl": [5, 63], "inform": [5, 52, 61, 63, 64], "subsequ": [5, 7], "recipe_st": [5, 40, 41], "pt": [5, 8, 40, 41, 63], "epoch": [5, 7, 8, 35, 40, 41, 63, 64], "optim": [5, 6, 7, 35, 63, 64, 65, 66], "etc": [5, 7, 40], "prevent": 5, "flood": 5, "overwritten": 5, "note": [5, 6, 31, 32, 36, 40, 42, 44, 54, 56, 63, 65, 66], "updat": [5, 6, 7, 63, 64, 65, 66], "hf_model_0001_0": [5, 63], "hf_model_0002_0": [5, 63], "both": [5, 63, 65, 66], "adapt": [5, 36, 37, 38, 39, 40, 41, 63, 65, 66], "merg": [5, 9, 40, 63, 66], "would": [5, 6, 8, 32, 63, 65, 66], "our": [5, 7, 61, 63, 64, 65, 66], "tutori": [5, 61, 63, 64, 65, 66], "primari": [5, 6, 7, 64], "want": [5, 6, 7, 8, 9, 60, 65], "resum": [5, 7, 35, 40, 41, 66], "initi": [5, 7, 10, 16, 17, 18, 24, 31, 47, 64, 65, 66], "frozen": [5, 65, 66], "base": [5, 15, 19, 20, 21, 22, 23, 25, 30, 35, 37, 39, 40, 42, 49, 59, 63, 65, 66], "well": [5, 6, 7, 61, 63, 66], "learnt": [5, 63], "someth": [5, 7, 8, 63], "NOT": 5, "refer": [5, 6, 7, 29, 30, 61, 65], "adapter_checkpoint": [5, 40, 41], "adapter_0": [5, 63], "now": [5, 31, 63, 64, 65, 66], "knowledg": 5, "creat": [5, 6, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 35, 40, 41, 49, 51, 63, 66], "simpl": [5, 7, 59, 64, 65, 66], "forward": [5, 7, 26, 27, 29, 30, 32, 33, 37, 65, 66], "13b": [5, 17, 19, 21], "modeltyp": [5, 40, 41], "llama2_13b": [5, 19, 21], "right": [5, 40, 63, 64, 65], "pytorch_fil": 5, "00003": 5, "torchtune_sd": 5, "load_state_dict": [5, 65], "successfulli": 5, "vocab": [5, 9, 32], "70": 5, "x": [5, 26, 27, 29, 30, 32, 33, 37, 65, 66], "randint": 5, "0": [5, 7, 20, 22, 26, 31, 32, 35, 37, 51, 52, 53, 56, 58, 62, 63, 64, 65, 66], "no_grad": 5, "6": [5, 29, 53, 63, 66], "3989": 5, "9": [5, 63, 66], "0531": 5, "3": [5, 42, 45, 53, 63, 66], "2375": 5, "5": [5, 35, 53, 54, 63, 64], "2822": 5, "4": [5, 6, 15, 26, 53, 61, 63, 65, 66], "4872": 5, "7469": 5, "8": [5, 11, 12, 13, 14, 19, 20, 21, 22, 23, 25, 63, 65, 66], "6737": 5, "11": [5, 63, 66], "0023": 5, "8235": 5, "6819": 5, "2424": 5, "0109": 5, "6915": 5, "7": [5, 53], "3618": 5, "1628": 5, "8594": 5, "5857": 5, "1151": 5, "7808": 5, "2322": 5, "8850": 5, "9604": 5, "7624": 5, "6040": 5, "3159": 5, "5849": 5, "8039": 5, "9322": 5, "2010": 5, "6824": 5, "8929": 5, "8465": 5, "3794": 5, "3500": 5, "6145": 5, "5931": 5, "do": [5, 7, 52, 63, 64, 65], "find": [5, 7, 8, 63, 64, 65], "list": [5, 6, 11, 12, 15, 19, 20, 21, 22, 23, 25, 31, 36, 37, 40, 41, 42, 45, 48, 53, 64], "builder": [5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 66], "hope": 5, "deeper": 5, "insight": [5, 63], "happi": [5, 63], "thi": [6, 7, 8, 9, 11, 12, 15, 26, 27, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 49, 51, 52, 54, 56, 59, 60, 61, 63, 64, 65, 66], "guid": [6, 8, 64, 65], "yaml": [6, 7, 9, 10, 42, 52, 61, 63, 64, 65, 66], "pars": [6, 9, 42, 64], "effect": 6, "cli": [6, 8, 10, 60, 63, 64], "prerequisit": [6, 63, 64, 65, 66], "Be": [6, 63, 64, 65, 66], "familiar": [6, 63, 64, 65, 66], "torchtun": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 60, 64], "instal": [6, 8, 51, 52, 59, 63, 64, 65, 66], "fundament": 6, "There": [6, 63, 65], "entri": [6, 7, 64], "point": [6, 7, 63, 64, 65, 66], "locat": [6, 65, 66], "thei": [6, 7, 32, 42, 65], "truth": [6, 63], "reproduc": 6, "overridden": [6, 27, 42], "quick": 6, "experiment": 6, "modifi": [6, 7, 8, 34, 61, 63, 65, 66], "serv": [6, 65], "particular": [6, 15, 65, 66], "seed": [6, 7, 8, 56, 64], "shuffl": [6, 64], "devic": [6, 7, 43, 44, 63, 64, 65], "cuda": [6, 43, 44, 63, 64, 66], "dtype": [6, 7, 28, 34, 44, 48, 63, 64, 66], "fp32": [6, 66], "enable_fsdp": 6, "mani": [6, 63], "object": [6, 9, 26], "keyword": [6, 9, 15, 34], "loss": [6, 7, 11, 12, 13, 14, 64, 65, 66], "function": [6, 7, 9, 10, 26, 27, 34, 43, 46, 56, 61, 66], "exampl": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 26, 31, 36, 40, 41, 51, 52, 53, 57, 58, 62, 63, 65, 66], "subfield": 6, "dotpath": 6, "wish": 6, "exact": [6, 9, 63], "path": [6, 7, 8, 9, 31, 40, 41, 42, 54, 63, 64, 65], "normal": [6, 29, 31, 32, 33, 65, 66], "python": [6, 42, 45, 52, 56, 57, 63], "alpaca_dataset": [6, 11, 64], "custom": [6, 7, 61, 63, 64, 65], "train_on_input": [6, 11, 12, 13, 14, 15], "onc": [6, 63, 64, 65, 66], "ve": [6, 28, 63, 65], "instanc": [6, 9, 11, 12, 27, 31, 34, 38, 39, 65], "cfg": [6, 7, 10], "automat": [6, 8, 9, 66], "under": [6, 63, 66], "preced": [6, 9, 65], "actual": [6, 8], "throw": 6, "notic": [6, 65], "miss": [6, 65], "posit": [6, 9, 26, 30, 32, 33], "anoth": [6, 63], "handl": [6, 10, 31, 63, 65, 66], "def": [6, 7, 8, 10, 65, 66], "dictconfig": [6, 7, 9, 10, 52], "arg": [6, 9, 32, 34, 36, 42, 50], "tupl": [6, 9, 15, 31, 34, 42, 46, 53], "kwarg": [6, 9, 34, 36, 42, 47, 49, 50, 51, 52, 55], "str": [6, 9, 31, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 54, 56], "mean": [6, 29, 64, 65], "pass": [6, 9, 26, 27, 34, 44, 47, 51, 52, 55, 65, 66], "add": [6, 8, 42, 63, 65, 66], "d": [6, 26, 32, 33, 65], "llama2_token": [6, 63, 64], "tmp": [6, 63, 64], "option": [6, 7, 19, 20, 21, 23, 26, 30, 31, 32, 33, 34, 40, 41, 43, 44, 45, 49, 52, 54, 55, 56, 60, 61, 63, 64], "bool": [6, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 25, 31, 34, 37, 40, 41, 47, 51, 54, 66], "max_seq_len": [6, 9, 11, 12, 15, 26, 28, 30, 31, 32], "int": [6, 8, 11, 12, 15, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 35, 37, 40, 41, 46, 49, 50, 51, 52, 53, 56, 65, 66], "512": [6, 11, 12, 66], "instructdataset": [6, 11, 12, 13, 14], "alreadi": [6, 47, 63, 64, 65], "overwrit": 6, "duplic": [6, 7, 61], "sometim": 6, "than": [6, 15, 26, 63, 64, 65, 66], "resolv": 6, "alpaca": [6, 11, 12, 19, 20, 21, 63, 64, 65, 66], "metric_logg": [6, 7, 8], "metric_log": [6, 8, 49, 50, 51, 52], "disklogg": 6, "log_dir": [6, 49, 51], "conveni": [6, 7], "quickli": 6, "verifi": [6, 43, 44, 64, 65], "properli": 6, "experi": [6, 59, 61, 65], "wa": [6, 63, 65, 66], "7b_full": [6, 63, 64], "batch_siz": [6, 11, 12, 13, 14, 26, 33, 63, 64], "discuss": [6, 65], "guidelin": 6, "while": [6, 7, 19, 20, 21, 27, 61, 63, 64, 66], "mai": [6, 54, 64, 65], "tempt": 6, "put": [6, 7, 64, 65], "much": [6, 63, 65, 66], "give": [6, 65], "maximum": [6, 11, 12, 15, 26, 28, 30, 32], "flexibl": 6, "switch": 6, "encourag": [6, 65], "clariti": 6, "significantli": 6, "easier": [6, 63, 64], "dont": 6, "slimorca_dataset": 6, "privat": 6, "typic": [6, 66], "expos": [6, 7, 64], "parent": 6, "modul": [6, 9, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 55, 56, 65, 66], "__init__": [6, 7, 65, 66], "py": [6, 10, 11, 12, 13, 14, 19, 20, 21, 26, 28, 29, 30, 35, 63], "guarante": 6, "stabil": [6, 61, 66], "underscor": 6, "_alpaca": 6, "collect": [6, 64], "differ": [6, 8, 31, 61, 63, 65, 66], "itself": 6, "via": [6, 8, 37, 65, 66], "pair": [6, 53], "k1": [6, 7], "v1": [6, 7], "k2": [6, 7], "v2": [6, 7], "full_finetun": [6, 8], "gpu": [6, 63, 64, 65, 66], "full_finetune_distribut": [6, 63, 64], "checkpoint": [6, 7, 40, 41, 52, 55, 61, 64, 65, 66], "home": 6, "my_model_checkpoint": 6, "file_1": 6, "file_2": 6, "class": [6, 8, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 49, 50, 51, 52, 64, 65, 66], "assign": 6, "nest": 6, "dot": 6, "notat": [6, 26, 30, 32, 33], "my_config": 6, "core": [7, 61, 64, 66], "i": [7, 34, 39, 63, 66], "structur": [7, 63], "new": [7, 24, 49, 51, 64, 65, 66], "user": [7, 26, 31, 64], "thought": [7, 61, 64, 66], "target": [7, 61], "pipelin": [7, 61, 64], "llm": [7, 59, 61, 63, 65], "eg": [7, 32, 40, 61], "meaning": [7, 61, 63], "featur": [7, 8, 60, 61], "fsdp": [7, 61, 64], "activ": [7, 27, 55, 61, 64, 66], "gradient": [7, 61, 63, 65, 66], "accumul": [7, 61], "mix": [7, 61, 63], "precis": [7, 34, 44, 61, 66], "appli": [7, 19, 20, 21, 22, 23, 25, 26, 29, 30, 32, 33, 61, 66], "given": [7, 9, 37, 43, 44, 61, 65], "complex": 7, "becom": [7, 60], "harder": 7, "anticip": 7, "architectur": [7, 32], "methodolog": 7, "reason": [7, 63], "possibl": 7, "trade": 7, "off": [7, 31, 63], "memori": [7, 11, 12, 59, 61, 63], "vs": 7, "qualiti": [7, 63, 65], "believ": 7, "best": 7, "suit": [7, 64], "specif": [7, 9, 63, 66], "b": [7, 26, 30, 32, 33, 37, 52, 65, 66], "fit": [7, 11, 12], "solut": 7, "result": [7, 31, 63, 64, 65, 66], "meant": [7, 34], "depend": [7, 8, 63, 65, 66], "level": [7, 45, 61, 66], "expertis": 7, "routin": 7, "yourself": [7, 65], "exist": [7, 64, 66], "ad": [7, 31, 65, 66], "ones": 7, "modular": [7, 61], "build": [7, 61, 65], "block": [7, 19, 20, 21, 23, 61], "wandb": [7, 8, 52, 64], "log": [7, 45, 49, 50, 51, 52, 63, 64, 66], "fulli": 7, "nativ": [7, 59, 61, 65, 66], "pytorch": [7, 15, 32, 34, 51, 54, 56, 59, 60, 61, 64, 65, 66], "correct": [7, 29, 30, 32, 43, 61], "numer": [7, 61], "pariti": [7, 61], "verif": 7, "extens": [7, 61], "comparison": [7, 65, 66], "benchmark": [7, 56, 61, 63, 65], "limit": 7, "hidden": [7, 27], "behind": 7, "100": [7, 11, 12, 13, 14, 15, 53, 54, 65, 66], "flag": [7, 11, 12, 13, 14, 66], "prefer": [7, 61], "over": [7, 35, 42, 61, 63, 65, 66], "unnecessari": 7, "abstract": [7, 61, 66], "No": [7, 61], "inherit": [7, 42, 61], "go": [7, 31, 61, 63, 64, 66], "upon": 7, "figur": [7, 65, 66], "spectrum": 7, "decid": 7, "interact": [7, 59], "start": [7, 8, 60, 61, 63, 64], "paradigm": 7, "consist": [7, 64], "configur": [7, 11, 12, 13, 14, 15, 33, 61, 64, 65, 66], "paramet": [7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 59, 61, 63, 64, 65, 66], "overrid": [7, 10, 63, 64, 66], "togeth": [7, 64, 65], "valid": [7, 60, 63, 64], "environ": [7, 60, 63, 64], "logic": [7, 40, 61, 64, 65], "api": [7, 8, 22, 25, 63, 64, 66], "closer": [7, 65], "monolith": [7, 61], "trainer": [7, 46], "A": [7, 8, 31, 34, 37, 40, 53, 58, 59, 62, 63, 65, 66], "wrapper": [7, 31, 65], "around": [7, 31, 54, 63, 65, 66], "extern": 7, "primarili": [7, 65], "eleutherai": [7, 61, 65], "har": [7, 61, 65], "control": [7, 11, 12, 13, 14, 56, 63], "multi": [7, 26], "stage": 7, "distil": 7, "oper": [7, 54, 56], "turn": 7, "dataload": [7, 11, 12, 13, 14], "applic": [7, 26, 40, 41, 52], "clean": [7, 11], "after": [7, 28, 29, 49, 50, 51, 52, 66], "process": [7, 34, 56, 64, 66], "group": [7, 26, 49, 50, 51, 52], "init_process_group": [7, 47], "backend": 7, "gloo": 7, "els": [7, 42, 61, 66], "nccl": 7, "fullfinetunerecipedistribut": 7, "cleanup": 7, "other": [7, 9, 11, 42, 64, 65], "stuff": 7, "carri": 7, "relev": [7, 63, 65], "interfac": [7, 36], "metric": [7, 64], "logger": [7, 45, 49, 50, 51, 52, 64], "self": [7, 8, 19, 20, 21, 23, 26, 32, 33, 36, 65, 66], "_devic": 7, "get_devic": 7, "_dtype": 7, "get_dtyp": 7, "ckpt_dict": 7, "wrap": [7, 54, 55], "_model": 7, "_setup_model": 7, "_token": 7, "_setup_token": 7, "_optim": 7, "_setup_optim": 7, "_loss_fn": 7, "_setup_loss": 7, "_sampler": 7, "_dataload": 7, "_setup_data": 7, "backward": [7, 66], "zero_grad": 7, "curr_epoch": 7, "rang": [7, 56], "epochs_run": [7, 8], "total_epoch": [7, 8], "idx": 7, "batch": [7, 11, 12, 13, 14, 26, 28, 30, 31, 32, 33, 53, 61, 65], "enumer": 7, "_autocast": 7, "logit": 7, "label": [7, 11, 12, 15, 53], "total_training_step": 7, "_log_every_n_step": 7, "_metric_logg": 7, "log_dict": [7, 49, 50, 51, 52], "step": [7, 32, 35, 49, 50, 51, 52, 54, 59, 63, 65, 66], "learn": [7, 35, 61, 64, 65, 66], "decor": [7, 10], "recipe_main": [7, 10], "none": [7, 8, 26, 30, 31, 32, 33, 39, 40, 41, 43, 44, 45, 49, 50, 51, 52, 55, 56, 63], "fullfinetunerecip": 7, "direct": 7, "wandblogg": [8, 65, 66], "workspac": 8, "seen": [8, 65, 66], "screenshot": 8, "below": [8, 30, 65, 66], "packag": [8, 51, 52, 60], "pip": [8, 51, 52, 60], "Then": [8, 64], "login": [8, 52], "built": [8, 66], "project": [8, 19, 20, 21, 23, 26, 27, 52, 59, 65, 66], "grab": 8, "tab": [8, 11, 12], "click": 8, "sampl": [8, 15, 63], "desir": 8, "suggest": 8, "approach": 8, "joinpath": 8, "_checkpoint": [8, 63], "_output_dir": [8, 40, 41], "torchtune_model_": 8, "with_suffix": 8, "wandb_at": 8, "artifact": 8, "type": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 44, 45, 46, 47, 54, 63, 65, 66], "descript": [8, 13], "whatev": 8, "metadata": 8, "seed_kei": 8, "epochs_kei": 8, "total_epochs_kei": 8, "max_steps_kei": 8, "max_steps_per_epoch": 8, "add_fil": 8, "log_artifact": 8, "field": [9, 11, 12, 13, 14], "num_lay": [9, 32], "32": [9, 65, 66], "num_head": [9, 26, 28, 30, 32], "num_kv_head": [9, 26, 28], "vocab_s": [9, 31], "must": [9, 11, 12, 13, 14, 15, 36, 42, 66], "return": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 53, 54, 56, 65, 66], "nn": [9, 26, 27, 28, 32, 33, 34, 36, 38, 39, 55, 64, 65, 66], "parsed_yaml": 9, "embed_dim": [9, 26, 30, 33, 65], "omegaconf": 9, "valueerror": [9, 15, 26, 32, 40, 41, 44, 56], "callabl": [10, 32], "main": [10, 11, 12, 13, 14, 26, 29, 30], "my_recip": 10, "With": [10, 63, 65, 66], "foo": 10, "bar": [10, 61], "http": [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 29, 30, 35, 40, 41, 42, 45, 51, 52, 54, 56, 60], "huggingfac": [11, 12, 13, 14, 15, 35, 40, 41], "co": [11, 12, 13, 14, 15, 40, 41], "yahma": 11, "data": [11, 12, 13, 14, 15, 49, 50, 51, 52, 63, 66], "tatsu": [11, 12], "lab": [11, 12], "prompt": [11, 12, 13, 14, 15, 31, 32, 63], "templat": [11, 12, 13, 14, 15], "codebas": [11, 12, 13, 14, 63], "com": [11, 12, 13, 14, 19, 20, 21, 26, 29, 30, 35, 60], "stanford_alpaca": [11, 12], "blob": [11, 12, 13, 14, 19, 20, 21, 26, 29, 30, 35], "761dc5bfbdeeffa89b8bff5d038781a4055f796a": [11, 12], "l31": [11, 12], "where": [11, 12, 13, 14, 26, 31, 32, 37], "instruct": [11, 12, 59, 64, 65, 66], "mask": [11, 12, 13, 14, 26, 31, 33], "ref": [11, 12, 52], "tloen": [11, 12, 19, 20, 21], "lora": [11, 12, 19, 20, 21, 22, 23, 25, 37, 59, 61], "l49": [11, 12], "contribut": [11, 12, 13, 14], "replac": [11, 12, 13, 14, 34, 65], "version": [11, 26, 60, 66], "remov": 11, "hallucin": 11, "poorli": 11, "wrong": 11, "answer": [11, 63], "card": 11, "encod": [11, 12, 13, 14, 15, 31], "decod": [11, 12, 13, 14, 15, 31, 32], "whether": [11, 12, 13, 14, 15, 19, 20, 21, 23, 31, 34, 37, 44], "stanford": [11, 12], "readm": [11, 12], "ov": [11, 12], "recommend": [11, 12, 51, 63, 66], "highest": [11, 12], "sequenc": [11, 12, 15, 26, 28, 30, 31, 32, 33, 53], "length": [11, 12, 15, 26, 28, 30, 31, 32, 33, 41, 53], "alpaca_d": [11, 12], "grammar": 13, "its": [13, 14, 56, 63, 65], "variant": [13, 14], "liweili": 13, "c4_200m": 13, "llama_recip": [13, 14], "src": [13, 14, 35], "l50": 13, "grammar_d": 13, "summar": 14, "samsum": 14, "l13": 14, "dialogu": 14, "summari": 14, "samsum_d": 14, "1024": 15, "chatdataset": 15, "represent": [15, 65, 66], "slimorca": 15, "open": [15, 16, 63], "orca": 15, "dedup": 15, "adher": 15, "chat": 15, "doesn": [15, 63], "prescrib": 15, "truncat": [15, 31], "least": [15, 65], "though": 15, "max": [15, 31, 32, 35, 65], "ds": 15, "10": [15, 53, 63, 66], "351": 15, "82": [15, 63], "391": 15, "221": 15, "220": 15, "193": 15, "12": 15, "471": 15, "gemma": 16, "transformerdecod": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 65], "w": [16, 17, 18, 24, 51, 52, 63, 65, 66], "blog": 16, "technolog": 16, "develop": [16, 66], "instanti": [16, 17, 18, 19, 20, 21, 23, 24], "arxiv": [17, 18, 22, 25, 26, 29, 30], "org": [17, 18, 22, 25, 26, 29, 30, 42, 45, 51, 54, 56], "ab": [17, 18, 22, 25, 30], "2307": [17, 18], "09288": [17, 18], "lora_attn_modul": [19, 20, 21, 22, 23, 25, 65, 66], "liter": [19, 20, 21, 22, 23, 25], "q_proj": [19, 20, 21, 22, 23, 25, 26, 65, 66], "k_proj": [19, 20, 21, 22, 23, 25, 26, 65, 66], "v_proj": [19, 20, 21, 22, 23, 25, 26, 65, 66], "output_proj": [19, 20, 21, 22, 23, 25, 26, 65, 66], "apply_lora_to_mlp": [19, 20, 21, 22, 23, 25, 65], "apply_lora_to_output": [19, 20, 21, 22, 23, 25, 65], "lora_rank": [19, 20, 21, 22, 23, 25, 65], "lora_alpha": [19, 20, 21, 22, 23, 25, 65], "float": [19, 20, 21, 22, 23, 25, 26, 29, 35, 37, 49, 50, 51, 52, 65, 66], "16": [19, 20, 21, 22, 23, 25, 65, 66], "quantize_bas": [19, 20, 21, 22, 23, 25, 37, 66], "8bb8579e403dc78e37fe81ffbb253c413007323f": [19, 20, 21], "l41": [19, 20, 21], "l43": [19, 20, 21], "linear": [19, 20, 21, 22, 23, 25, 32, 36, 37, 65, 66], "attent": [19, 20, 21, 23, 26, 28, 30, 32, 33, 65, 66], "mlp": [19, 20, 21, 23, 32, 33, 65], "final": [19, 20, 21, 23, 27, 32, 63, 65, 66], "rank": [19, 20, 21, 23, 37, 46, 56, 64, 65, 66], "low": [19, 20, 21, 23, 37, 63, 65, 66], "approxim": [19, 20, 21, 23, 37, 65], "scale": [19, 20, 21, 23, 37, 65, 66], "factor": [19, 20, 21, 23, 37, 63], "lora_dropout": [20, 22], "05": [20, 22], "llama2_7b": [20, 64, 65], "qlora": [22, 25, 59, 61, 65], "per": [22, 25, 28, 34, 66], "paper": [22, 25, 65, 66], "2305": [22, 25, 26], "14314": [22, 25], "lora_llama2_7b": [22, 65], "mistral": [23, 24, 25, 63], "announc": 24, "lora_mistral_7b": 25, "head_dim": [26, 28, 30, 32], "pos_embed": [26, 65], "kv_cach": 26, "kvcach": [26, 32], "attn_dropout": [26, 32], "head": [26, 28, 30, 32], "queri": [26, 28, 32], "gqa": 26, "introduc": [26, 29, 37, 65, 66], "pdf": [26, 29], "13245v1": 26, "multihead": 26, "mha": [26, 32], "n": [26, 31, 58, 62], "extrem": 26, "share": 26, "mqa": 26, "credit": 26, "document": 26, "lightn": 26, "lit": 26, "gpt": [26, 63], "lit_gpt": 26, "v": [26, 32, 65], "k": [26, 65], "q": [26, 65], "n_kv_head": 26, "dimens": [26, 28, 30, 32, 37, 65, 66], "calcul": 26, "e": [26, 34, 36, 39, 60, 63, 65, 66], "g": [26, 36, 65, 66], "rotarypositionalembed": [26, 65], "cach": [26, 28, 30], "comput": [26, 27, 30, 32, 56, 63, 66], "rope": [26, 30], "dropout": [26, 37, 65, 66], "onto": 26, "scaled_dot_product_attent": 26, "input_po": [26, 30, 32, 33], "seq_length": [26, 33], "seq_len": [26, 30], "bigger": 26, "n_h": [26, 30], "num": [26, 30], "n_kv": 26, "kv": [26, 28, 32], "emb": [26, 32, 33], "h_d": [26, 30], "gate_proj": 27, "down_proj": 27, "up_proj": 27, "silu": 27, "feed": [27, 33], "network": [27, 65, 66], "deriv": [27, 32, 33], "fed": 27, "multipli": 27, "subclass": [27, 42], "although": [27, 65], "afterward": 27, "former": 27, "regist": [27, 34, 66], "hook": [27, 34, 66], "latter": 27, "max_batch_s": 28, "standalon": 28, "past": 28, "becaus": [28, 32, 63], "expand": 28, "dpython": [28, 34], "ep": 29, "1e": [29, 64], "06": [29, 65], "root": [29, 51], "squar": 29, "1910": 29, "07467": 29, "verfic": [29, 30], "facebookresearch": [29, 30], "small": [29, 63], "avoid": [29, 56, 66], "divis": 29, "zero": [29, 63], "10000": 30, "rotari": 30, "propos": 30, "2104": 30, "09864": 30, "l450": 30, "upto": 30, "init": [30, 52, 66], "exceed": 30, "freq": 30, "recomput": 30, "geometr": 30, "progress": 30, "rotat": 30, "angl": 30, "bsz": 30, "todo": 30, "made": [30, 63], "effici": [30, 59, 61, 63, 65], "spm_model": 31, "sentencepieceprocessor": 31, "bos_id": 31, "eos_id": 31, "pad_id": 31, "sentencepiec": 31, "vocabulari": 31, "sentenc": 31, "pad": [31, 53], "non": 31, "from_fil": 31, "tokenized_text": 31, "hello": [31, 63], "world": [31, 46], "add_bo": 31, "add_eo": 31, "31587": 31, "29644": 31, "102": 31, "text": [31, 63], "trim_leading_whitespac": 31, "prefix": 31, "unbatch": 31, "prepend": 31, "bo": 31, "append": 31, "eo": 31, "trim": 31, "lead": 31, "whitespac": 31, "underli": [31, 66], "s1": 31, "s2": 31, "due": [31, 65, 66], "classmethod": 31, "tokenize_messag": 31, "messag": [31, 60], "concaten": 31, "problem": 31, "known": 31, "slice": 31, "tokenizer_path": 31, "role": 31, "system": 31, "assist": 31, "respons": [31, 63, 64], "separ": [31, 40, 65, 66], "concat": 31, "1788": 31, "2643": 31, "13": [31, 63, 66], "1792": 31, "9508": 31, "465": 31, "22137": 31, "2933": 31, "join": 31, "attribut": 31, "transformerdecoderlay": 32, "norm": [32, 33], "move": 32, "space": 32, "check": [32, 44, 59, 64, 65], "belong": 32, "reduc": [32, 65, 66], "statement": 32, "improv": [32, 63, 65], "readabl": [32, 63], "At": 32, "arang": 32, "prompt_length": 32, "causal_mask": 32, "m_": 32, "seq": 32, "attn": [33, 65, 66], "causalselfattent": [33, 65], "sa_norm": 33, "mlp_norm": 33, "ff": 33, "common_util": 34, "bfloat16": [34, 63, 65], "offload_to_cpu": 34, "nf4": [34, 66], "restor": 34, "higher": [34, 66], "offload": [34, 66], "_register_state_dict_hook": 34, "m": 34, "mymodul": 34, "_after_": 34, "nf4tensor": [34, 66], "unquant": [34, 63, 66], "unus": 34, "num_warmup_step": 35, "num_training_step": 35, "num_cycl": 35, "last_epoch": 35, "lambdalr": 35, "rate": [35, 61, 64], "schedul": [35, 54], "linearli": 35, "increas": [35, 65], "lr": [35, 64], "decreas": [35, 65, 66], "cosin": 35, "remain": [35, 65], "v4": 35, "23": 35, "l104": 35, "warmup": [35, 54], "phase": 35, "total": [35, 46, 58, 62, 63, 65], "wave": 35, "half": 35, "index": [35, 53, 63], "last": 35, "lr_schedul": 35, "appropri": [35, 66], "peft": [36, 37, 38, 39, 65, 66], "protocol": 36, "adapter_param": [36, 37, 38, 39], "correspond": [36, 38, 44], "come": [36, 65], "proj": 36, "in_dim": [36, 37, 65, 66], "out_dim": [36, 37, 65, 66], "bia": [36, 37, 65, 66], "loralinear": [36, 65, 66], "alpha": [37, 65, 66], "use_bia": 37, "larg": [37, 66], "languag": [37, 65], "perturb": 37, "decomposit": [37, 65], "matric": [37, 65, 66], "trainabl": [37, 39, 65, 66], "mapsto": 37, "w_0x": 37, "r": [37, 65], "bax": 37, "probabl": [37, 63], "lora_a": [37, 65, 66], "lora_b": [37, 65, 66], "subset": 38, "map": [39, 40, 49, 50, 51, 52, 63, 65], "respect": 39, "get_adapter_param": [39, 65], "few": [40, 65, 66], "0001_of_0003": 40, "0002_of_0003": 40, "preserv": [40, 66], "weight_map": [40, 63], "intermediate_checkpoint": [40, 41], "parit": 40, "_weight_map": 40, "shard": 41, "wip": 41, "tunerecipeargpars": 42, "argpars": 42, "argumentpars": 42, "builtin": 42, "noth": 42, "treat": 42, "still": [42, 65, 66], "consult": 42, "doc": [42, 45, 51, 52, 54, 56], "info": 42, "librari": [42, 45, 56, 59, 61, 66], "html": [42, 45, 51, 54, 56], "parse_known_arg": 42, "namespac": 42, "act": 42, "alwai": 42, "precid": 42, "parse_arg": 42, "intern": 42, "properti": [42, 65], "too": 42, "availab": 43, "machin": [43, 63], "distribut": [43, 47, 55, 56, 61, 64], "bf16": [44, 64, 66], "request": [44, 63], "inde": [44, 63], "kernel": 44, "float32": 44, "done": [44, 65, 66], "isn": 44, "stream": 45, "handler": 45, "aka": 46, "runtimeerror": 47, "filenam": 49, "log_": 49, "unixtimestamp": 49, "txt": [49, 64], "thread": 49, "safe": 49, "resourc": [49, 50, 51, 52], "flush": [49, 50, 51, 52], "union": [49, 50, 51, 52, 56], "ndarrai": [49, 50, 51, 52], "scalar": [49, 50, 51, 52], "tag": [49, 50, 51, 52], "record": [49, 50, 51, 52], "payload": [49, 50, 51, 52], "dictionari": [49, 50, 51, 52, 63], "organize_log": 51, "tensorboard": 51, "stabl": [51, 54, 56, 60], "subdirectori": 51, "sub": 51, "compar": [51, 63, 65, 66], "logdir": 51, "startup": 51, "recurs": 51, "tree": [51, 63], "tfevent": 51, "encount": 51, "frontend": 51, "organ": 51, "accordingli": 51, "my_log_dir": 51, "view": [51, 63], "my_metr": [51, 52], "termin": [51, 52], "entiti": 52, "bias": 52, "my_project": 52, "my_ent": 52, "my_group": 52, "importerror": 52, "account": [52, 65, 66], "log_config": 52, "local": [52, 56, 60, 63, 64], "link": 52, "capecap": 52, "6053ofw0": 52, "torchtune_config_j67sb73v": 52, "padding_idx": 53, "ignore_idx": 53, "longest": 53, "integ": [53, 56], "tokenpair": 53, "collat": 53, "token_pair": 53, "torchtune_perf_trac": 54, "contextmanag": 54, "wait": 54, "trace": 54, "speed": [54, 66], "reduct": [54, 65], "context": 54, "auto_wrap_polici": 55, "polici": 55, "debug_mod": 56, "pseudo": 56, "random": [56, 64], "commonli": [56, 63, 65, 66], "numpi": 56, "own": [56, 63, 65], "determinist": 56, "global": 56, "warn": 56, "nondeterminist": 56, "addition": [56, 65], "cudnn": 56, "disabl": 56, "set_deterministic_debug_mod": 56, "algorithm": 56, "outsid": [56, 63, 65], "generated_examples_python": 57, "zip": 57, "galleri": [57, 62], "sphinx": 57, "000": [58, 62], "execut": [58, 62], "generated_exampl": 58, "mem": [58, 62], "mb": [58, 62], "topic": 59, "gentl": 59, "introduct": 59, "workflow": [59, 64, 65], "readi": 59, "maxim": [59, 61], "requisit": 60, "proper": [60, 64], "host": [60, 64], "page": [60, 61, 64], "latest": [60, 64, 66], "confirm": 60, "And": [60, 63], "usag": [60, 63, 66], "h": 60, "ls": [60, 63], "cp": [60, 63, 64], "welcom": 60, "show": [60, 65], "exit": 60, "greatest": [60, 64], "contributor": 60, "cd": [60, 63], "On": [61, 65], "pointer": 61, "author": [61, 64], "emphas": 61, "aspect": 61, "simplic": 61, "component": 61, "reus": 61, "high": [61, 65], "prove": 61, "democrat": 61, "box": [61, 66], "hardwar": [61, 63, 65], "zoo": 61, "varieti": [61, 65], "techniqu": [61, 63, 65], "integr": [61, 63, 64, 65, 66], "excit": 61, "checkout": 61, "attain": 61, "better": [61, 63], "chekckpoint": 61, "hyperparamet": [61, 64, 65, 66], "embodi": 61, "philosophi": 61, "especi": [61, 63], "usabl": 61, "eluetherai": 61, "composit": 61, "hard": 61, "outlin": 61, "unecessari": 61, "never": 61, "thoroughli": 61, "unit": 61, "favorit": [63, 65], "commun": 63, "seemlessli": 63, "beyond": [63, 66], "connect": 63, "larger": 63, "might": 63, "amount": 63, "natur": 63, "task": [63, 65, 66], "export": 63, "mobil": 63, "phone": 63, "leverag": [63, 66], "mode": 63, "lot": 63, "plai": 63, "freez": [63, 65], "percentag": 63, "learnabl": 63, "keep": [63, 65], "16gb": [63, 65], "rtx": 63, "3090": 63, "4090": 63, "peak": [63, 65, 66], "hour": 63, "full_finetune_single_devic": 63, "7b_full_single_devic": 63, "7b_full_single_device_low_memori": 63, "13b_full": 63, "lora_finetune_single_devic": [63, 65, 66], "7b_lora_single_devic": [63, 65, 66], "7b_qlora_single_devic": [63, 66], "7b_lora": [63, 65], "473": 63, "98": [63, 66], "gb": [63, 65, 66], "50": 63, "484": 63, "01": 63, "similar": [63, 65, 66], "fact": [63, 65], "ident": 63, "third": 63, "smaller": [63, 65, 66], "But": [63, 65], "realli": 63, "eleuther_ev": 63, "eleuther_evalu": 63, "plan": 63, "copi": [63, 64, 66], "element": 63, "custom_eval_config": 63, "truthfulqa_mc2": [63, 65], "qa": 63, "measur": 63, "propens": 63, "question": 63, "shot": 63, "accuraci": [63, 65, 66], "baselin": [63, 65], "324": 63, "loglikelihood": 63, "195": 63, "121": 63, "27": 63, "second": [63, 65, 66], "197": 63, "acc": 63, "388": 63, "38": 63, "shown": 63, "489": 63, "48": [63, 66], "great": 63, "seem": [63, 64], "custom_generation_config": 63, "kick": 63, "top_k": 63, "300": 63, "temperatur": 63, "interest": 63, "site": 63, "visit": 63, "bai": 63, "area": 63, "92": 63, "exploratorium": 63, "san": 63, "francisco": 63, "magazin": 63, "awesom": 63, "bridg": 63, "pretti": 63, "cool": 63, "96": [63, 66], "61": 63, "sec": 63, "25": 63, "83": 63, "99": [63, 65], "15": [63, 65, 66], "72": 63, "know": [63, 65], "littl": 63, "saw": 63, "took": 63, "torchao": [63, 66], "bit": [63, 65, 66], "custom_quantization_config": 63, "68": 63, "19": [63, 66], "76": 63, "69": 63, "95": 63, "67": 63, "4w": 63, "unlik": 63, "won": 63, "engin": 63, "fullmodeltorchtunecheckpoint": 63, "int4weightonlyquant": 63, "groupsiz": 63, "256": 63, "did": [63, 66], "park": 63, "sit": 63, "top": [63, 66], "hill": 63, "beauti": 63, "62": 63, "17": [63, 65], "85": 63, "compil": [63, 66], "hood": [63, 66], "sped": 63, "almost": [63, 65], "3x": 63, "benefit": 63, "yet": 63, "fast": 63, "clone": [63, 65, 66], "assumpt": 63, "satisfi": 63, "new_dir": 63, "output_dict": 63, "sd_1": 63, "sd_2": 63, "dump": 63, "convert_hf_checkpoint": 63, "checkpoint_path": 63, "my": 63, "justin": 63, "am": 63, "school": 63, "math": 63, "teacher": 63, "ws": 63, "94": 63, "103": 63, "28": 63, "bandwidth": 63, "achiev": [63, 65, 66], "1391": 63, "84": 63, "thats": 63, "hopefulli": 63, "gave": 63, "launch": 64, "gate": 64, "grant": 64, "minut": 64, "agreement": 64, "signup": 64, "authent": 64, "dataclass": 64, "hold": 64, "It": [64, 66], "alpaca_llama_full_finetun": 64, "good": [64, 65], "place": 64, "custom_config": 64, "replic": 64, "lower": [64, 65], "sooner": 64, "42": 64, "sgd": 64, "crossentropyloss": 64, "enable_activation_checkpoint": 64, "torchrun": 64, "therefor": [64, 66], "nnode": [64, 65], "nproc_per_nod": [64, 65], "immedi": 64, "down": [64, 65, 66], "indic": 64, "succesfulli": 64, "log_1707246452": 64, "manual": [64, 66], "sampler": 64, "7553404569625854": 64, "13000": 64, "03": 64, "e2": 64, "teach": 65, "straight": 65, "jump": 65, "neural": [65, 66], "unfamiliar": 65, "oppos": [65, 66], "substanti": 65, "momentum": 65, "adamw": 65, "further": [65, 66], "arbitrari": 65, "could": 65, "min": 65, "relat": 65, "aghajanyan": 65, "et": 65, "al": 65, "hypothes": 65, "intrins": 65, "often": 65, "four": 65, "eight": 65, "practic": 65, "imag": 65, "simplifi": 65, "left": 65, "blue": 65, "extra": [65, 66], "rememb": 65, "approx": 65, "15m": 65, "8192": 65, "65k": 65, "minim": [65, 66], "pretrain": [65, 66], "p": [65, 66], "requires_grad": [65, 66], "frozen_out": [65, 66], "lora_out": [65, 66], "omit": 65, "construct": 65, "base_model": 65, "choos": 65, "lora_model": 65, "lora_llama_2_7b": [65, 66], "alon": 65, "in_featur": 65, "out_featur": 65, "inplac": 65, "feel": 65, "free": 65, "why": 65, "strict": 65, "whenev": 65, "validate_state_dict_for_lora": 65, "peft_util": 65, "set_trainable_param": 65, "fetch": 65, "lora_param": 65, "total_param": 65, "sum": 65, "numel": 65, "trainable_param": 65, "2f": 65, "6742609920": 65, "4194304": 65, "taken": [65, 66], "vram": 65, "lora_finetune_distribut": 65, "my_model_checkpoint_path": [65, 66], "tokenizer_checkpoint": [65, 66], "my_tokenizer_checkpoint_path": [65, 66], "constraint": 65, "coupl": [65, 66], "factori": 65, "benefici": 65, "long": 65, "impact": 65, "rel": 65, "minor": 65, "64": 65, "lora_experiment_1": 65, "smooth": [65, 66], "curv": [65, 66], "500": 65, "ran": 65, "footprint": 65, "commod": 65, "cogniz": 65, "ax": 65, "parallel": 65, "truthfulqa": 65, "previous": 65, "57": [65, 66], "475": 65, "87": 65, "508": 65, "128": 65, "86": 65, "504": 65, "04": 65, "514": 65, "lowest": 65, "absolut": 65, "4gb": 65, "tradeoff": 65, "even": [65, 66], "potenti": 65, "enhanc": 66, "maintain": 66, "therebi": 66, "highli": 66, "part": 66, "vanilla": 66, "style": 66, "held": 66, "intermedi": 66, "bespok": 66, "normalfloat": 66, "8x": 66, "retain": 66, "vast": 66, "major": 66, "highlight": 66, "degrad": 66, "normatfloat": 66, "doubl": 66, "themselv": 66, "prune": 66, "deepdiv": 66, "idea": 66, "distinct": 66, "storag": 66, "datatyp": 66, "de": 66, "incur": 66, "consum": 66, "counterpart": 66, "set_default_devic": 66, "qlora_linear": 66, "memory_alloc": 66, "177": 66, "152": 66, "byte": 66, "del": 66, "empty_cach": 66, "lora_linear": 66, "081": 66, "344": 66, "qlora_llama2_7b": 66, "qlora_model": 66, "essenti": 66, "reparametrize_as_dtype_state_dict_post_hook": 66, "entir": 66, "stat": 66, "iter": 66, "alloc": 66, "reserv": 66, "against": 66, "35": 66, "40": 66, "29": 66, "quit": 66, "slow": 66, "slower": 66, "149": 66, "9157477021217346": 66, "25880": 66, "02": 66, "08": 66, "14": 66, "15it": 66, "thing": 66, "nightli": 66, "200": 66, "hundr": 66, "228": 66, "8158286809921265": 66, "59": 66, "95it": 66, "exercis": 66, "portion": 66, "augment": 66, "linear_nf4": 66, "to_nf4": 66, "linear_weight": 66, "autograd": 66, "regular": 66, "incom": 66, "variabl": 66}, "objects": {"torchtune.config": [[9, 0, 1, "", "instantiate"], [10, 0, 1, "", "parse"]], "torchtune.datasets": [[11, 0, 1, "", "alpaca_cleaned_dataset"], [12, 0, 1, "", "alpaca_dataset"], [13, 0, 1, "", "grammar_dataset"], [14, 0, 1, "", "samsum_dataset"], [15, 0, 1, "", "slimorca_dataset"]], "torchtune.models.gemma": [[16, 0, 1, "", "gemma_2b"]], "torchtune.models.llama2": [[17, 0, 1, "", "llama2_13b"], [18, 0, 1, "", "llama2_7b"], [19, 0, 1, "", "lora_llama2_13b"], [20, 0, 1, "", "lora_llama2_7b"], [21, 0, 1, "", "qlora_llama2_13b"], [22, 0, 1, "", "qlora_llama2_7b"]], "torchtune.models.mistral": [[23, 0, 1, "", "lora_mistral_7b"], [24, 0, 1, "", "mistral_7b"], [25, 0, 1, "", "qlora_mistral_7b"]], "torchtune.modules": [[26, 1, 1, "", "CausalSelfAttention"], [27, 1, 1, "", "FeedForward"], [28, 1, 1, "", "KVCache"], [29, 1, 1, "", "RMSNorm"], [30, 1, 1, "", "RotaryPositionalEmbeddings"], [31, 1, 1, "", "Tokenizer"], [32, 1, 1, "", "TransformerDecoder"], [33, 1, 1, "", "TransformerDecoderLayer"], [35, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[26, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[27, 2, 1, "", "forward"]], "torchtune.modules.RMSNorm": [[29, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[30, 2, 1, "", "forward"]], "torchtune.modules.Tokenizer": [[31, 2, 1, "", "decode"], [31, 2, 1, "", "encode"], [31, 2, 1, "", "from_file"], [31, 2, 1, "", "tokenize_messages"]], "torchtune.modules.TransformerDecoder": [[32, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoderLayer": [[33, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[34, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[36, 1, 1, "", "AdapterModule"], [37, 1, 1, "", "LoRALinear"], [38, 0, 1, "", "get_adapter_params"], [39, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[36, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[37, 2, 1, "", "adapter_params"], [37, 2, 1, "", "forward"]], "torchtune.utils": [[40, 1, 1, "", "FullModelHFCheckpointer"], [41, 1, 1, "", "FullModelMetaCheckpointer"], [42, 1, 1, "", "TuneRecipeArgumentParser"], [43, 0, 1, "", "get_device"], [44, 0, 1, "", "get_dtype"], [45, 0, 1, "", "get_logger"], [46, 0, 1, "", "get_world_size_and_rank"], [47, 0, 1, "", "init_distributed"], [48, 0, 1, "", "list_dtypes"], [53, 0, 1, "", "padded_collate"], [54, 0, 1, "", "profiler"], [55, 0, 1, "", "set_activation_checkpointing"], [56, 0, 1, "", "set_seed"]], "torchtune.utils.FullModelHFCheckpointer": [[40, 2, 1, "", "load_checkpoint"], [40, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[41, 2, 1, "", "load_checkpoint"], [41, 2, 1, "", "save_checkpoint"]], "torchtune.utils.TuneRecipeArgumentParser": [[42, 2, 1, "", "parse_known_args"]], "torchtune.utils.metric_logging": [[49, 1, 1, "", "DiskLogger"], [50, 1, 1, "", "StdoutLogger"], [51, 1, 1, "", "TensorBoardLogger"], [52, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[49, 2, 1, "", "close"], [49, 2, 1, "", "log"], [49, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[50, 2, 1, "", "close"], [50, 2, 1, "", "log"], [50, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[51, 2, 1, "", "close"], [51, 2, 1, "", "log"], [51, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[52, 2, 1, "", "close"], [52, 2, 1, "", "log"], [52, 2, 1, "", "log_config"], [52, 2, 1, "", "log_dict"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 59, 61, 63, 65, 66], "config": [0, 6, 7, 64], "dataset": 1, "model": [2, 3, 8, 63, 64, 65], "llama2": [2, 63, 65, 66], "mistral": 2, "gemma": 2, "modul": 3, "compon": [3, 6], "build": [3, 66], "block": 3, "peft": 3, "util": [3, 4], "checkpoint": [4, 5, 8, 63], "distribut": 4, "reduc": 4, "precis": 4, "memori": [4, 65, 66], "manag": 4, "perform": [4, 65], "profil": [4, 54], "metric": [4, 8], "log": [4, 8], "data": 4, "miscellan": 4, "overview": [5, 61, 63], "format": 5, "handl": 5, "differ": 5, "intermedi": 5, "vs": 5, "final": 5, "lora": [5, 63, 65, 66], "put": [5, 66], "thi": 5, "all": [5, 6, 66], "togeth": [5, 66], "about": 6, "where": 6, "do": 6, "paramet": 6, "live": 6, "write": 6, "configur": 6, "us": [6, 7, 63, 66], "instanti": [6, 9], "referenc": 6, "other": [6, 63], "field": 6, "interpol": 6, "valid": 6, "your": [6, 7, 64], "best": 6, "practic": 6, "airtight": 6, "public": 6, "api": 6, "onli": 6, "command": 6, "line": 6, "overrid": 6, "what": [7, 61, 65, 66], "ar": 7, "recip": [7, 64, 65], "script": 7, "class": 7, "run": [7, 63], "cli": 7, "pars": [7, 10], "weight": 8, "bias": 8, "logger": 8, "w": 8, "b": 8, "alpaca_cleaned_dataset": 11, "alpaca_dataset": 12, "grammar_dataset": 13, "samsum_dataset": 14, "slimorca_dataset": 15, "gemma_2b": 16, "llama2_13b": 17, "llama2_7b": 18, "lora_llama2_13b": 19, "lora_llama2_7b": 20, "qlora_llama2_13b": 21, "qlora_llama2_7b": 22, "lora_mistral_7b": 23, "mistral_7b": 24, "qlora_mistral_7b": 25, "causalselfattent": 26, "todo": [26, 33], "feedforward": 27, "kvcach": 28, "rmsnorm": 29, "rotarypositionalembed": 30, "token": 31, "transformerdecod": 32, "transformerdecoderlay": 33, "reparametrize_as_dtype_state_dict_post_hook": 34, "get_cosine_schedule_with_warmup": 35, "adaptermodul": 36, "loralinear": 37, "get_adapter_param": 38, "set_trainable_param": 39, "fullmodelhfcheckpoint": 40, "fullmodelmetacheckpoint": 41, "tunerecipeargumentpars": 42, "get_devic": 43, "get_dtyp": 44, "get_logg": 45, "get_world_size_and_rank": 46, "init_distribut": 47, "list_dtyp": 48, "disklogg": 49, "stdoutlogg": 50, "tensorboardlogg": 51, "wandblogg": 52, "padded_col": 53, "set_activation_checkpoint": 55, "set_se": 56, "comput": [58, 62], "time": [58, 62], "welcom": 59, "document": 59, "get": 59, "start": 59, "tutori": 59, "instal": 60, "instruct": 60, "via": 60, "pypi": 60, "git": 60, "clone": 60, "kei": 61, "concept": 61, "design": 61, "principl": 61, "end": 63, "workflow": 63, "download": [63, 64], "7b": 63, "finetun": [63, 64, 65, 66], "evalu": 63, "eleutherai": 63, "s": 63, "eval": 63, "har": 63, "gener": 63, "speed": 63, "up": 63, "quantiz": 63, "librari": 63, "first": 64, "llm": 64, "select": 64, "modifi": 64, "train": 64, "next": 64, "step": 64, "how": 65, "doe": 65, "work": 65, "appli": 65, "trade": 65, "off": 65, "qlora": 66, "save": 66, "deep": 66, "dive": 66, "from": 66}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})