Search.setIndex({"docnames": ["api_ref_config", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "examples/checkpointer", "examples/configs", "examples/e2e_flow", "examples/finetune_llm", "examples/first_finetune_tutorial", "examples/lora_finetune", "examples/recipe_deepdive", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.Tokenizer", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.argparse.TuneRecipeArgumentParser", "generated/torchtune.utils.collate.padded_collate", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.logging.get_logger", "generated/torchtune.utils.memory.set_activation_checkpointing", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.precision.get_autocast", "generated/torchtune.utils.precision.get_dtype", "generated/torchtune.utils.precision.get_gradient_scaler", "generated/torchtune.utils.precision.list_dtypes", "generated/torchtune.utils.seed.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times"], "filenames": ["api_ref_config.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "examples/checkpointer.rst", "examples/configs.rst", "examples/e2e_flow.rst", "examples/finetune_llm.rst", "examples/first_finetune_tutorial.rst", "examples/lora_finetune.rst", "examples/recipe_deepdive.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.Tokenizer.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.argparse.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.collate.padded_collate.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.logging.get_logger.rst", "generated/torchtune.utils.memory.set_activation_checkpointing.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.precision.get_autocast.rst", "generated/torchtune.utils.precision.get_dtype.rst", "generated/torchtune.utils.precision.get_gradient_scaler.rst", "generated/torchtune.utils.precision.list_dtypes.rst", "generated/torchtune.utils.seed.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst"], "titles": ["torchtune.config", "torchtune.datasets", "torchtune.models.llama2", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "Configs Deep-Dive", "End-to-End Workflow with torchtune", "LLM Full Finetuning Recipe", "Finetune your First LLM", "Finetuning Llama2 with LoRA", "Training Recipe Deep-Dive", "instantiate", "parse", "alpaca_cleaned_dataset", "alpaca_dataset", "grammar_dataset", "samsum_dataset", "slimorca_dataset", "llama2_7b", "lora_llama2", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "Tokenizer", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "padded_collate", "get_device", "get_world_size_and_rank", "init_distributed", "get_logger", "set_activation_checkpointing", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "get_autocast", "get_dtype", "get_gradient_scaler", "list_dtypes", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times"], "terms": {"These": [3, 5, 6, 7, 9, 10, 11, 12, 37], "ar": [3, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 17, 20, 27, 32, 35, 36, 49, 56, 57], "common": [3, 6, 10], "can": [3, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 24, 25, 26, 35, 37, 46, 47, 55, 56, 57], "us": [3, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 27, 28, 29, 35, 36, 37, 39, 44, 45, 46, 47, 48, 49, 50, 52, 55, 57], "all": [3, 6, 7, 8, 9, 10, 11, 21, 22, 27, 29, 35, 37, 53, 55, 57, 58], "offer": 4, "allow": [4, 46], "seamless": 4, "transit": 4, "between": [4, 5, 7, 10, 35], "format": [4, 7, 9, 14, 15, 16, 17, 18, 35, 36], "train": [4, 5, 7, 10, 14, 15, 16, 17, 18, 21, 30, 35, 36, 48, 49, 50, 55, 57], "interoper": [4, 5, 7, 11, 57], "rest": 4, "ecosystem": [4, 5, 7, 9, 11, 57], "For": [4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 20, 21, 27, 37, 47, 52], "comprehens": 4, "overview": [4, 6, 9, 10], "pleas": 4, "see": [4, 5, 7, 8, 9, 10, 14, 23, 31, 37, 42, 47, 52, 56, 57], "deep": [4, 5, 8, 9, 10, 57], "dive": [4, 5, 8, 9, 10, 57], "enabl": [4, 6, 8, 9, 11, 32, 52], "work": [4, 5, 7, 11, 37, 57], "set": [4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 25, 27, 34, 39, 43, 52, 57], "consumpt": 4, "dure": [4, 5, 7, 8, 10, 14, 15, 16, 17, 21, 23, 25, 27, 28], "variou": 4, "dataset": [4, 6, 7, 9, 10, 14, 15, 16, 17, 18, 57], "walk": [5, 7, 8, 9, 11, 46, 57], "you": [5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 37, 46, 47, 55, 56, 57], "through": [5, 6, 7, 8, 9, 11, 22, 57], "design": [5, 11], "behavior": 5, "associ": [5, 6, 7, 10, 11], "util": [5, 6, 7, 8, 9, 11, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 57], "what": [5, 6, 7, 9, 55], "cover": [5, 6, 7, 11], "how": [5, 6, 7, 8, 9, 11, 55], "we": [5, 6, 7, 8, 10, 11, 14, 15, 21, 23, 25, 26, 27, 32, 35, 36, 49, 57], "them": [5, 6, 7, 8, 10, 22, 26, 29], "scenario": 5, "full": [5, 6, 9, 10, 11, 26, 35, 36, 55, 57], "finetun": [5, 6, 11, 14, 15, 51, 55, 57], "compos": 5, "compon": [5, 9, 10, 11, 57], "which": [5, 7, 10, 11, 14, 15, 16, 17, 20, 21, 25, 26, 27, 28, 30, 35, 36, 44, 49, 50, 56, 57], "plug": 5, "ani": [5, 6, 7, 8, 10, 11, 12, 13, 26, 29, 33, 34, 35, 36, 52], "recip": [5, 6, 7, 12, 13, 16, 17, 22, 35, 36, 55, 56, 57], "evalu": [5, 9, 10, 11, 55, 57], "gener": [5, 10, 11, 18, 26, 52, 53, 55], "each": [5, 7, 9, 10, 11, 20, 21, 25, 26, 27, 52, 57], "support": [5, 7, 8, 9, 11, 12, 14, 15, 16, 17, 20, 21, 32, 36, 48, 49, 51, 57], "model": [5, 6, 11, 12, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 43, 55, 57], "make": [5, 6, 7, 9, 10, 11, 21, 28, 57], "easi": [5, 9, 10, 11, 57], "understand": [5, 6, 9, 10, 11, 57], "debug": [5, 6, 11], "extend": [5, 11, 57], "befor": [5, 7, 27, 28, 32, 35], "let": [5, 6, 7, 9, 10], "s": [5, 6, 8, 9, 10, 11, 13, 20, 21, 25, 27, 28, 29, 31, 33, 35, 36, 39, 46, 57], "defin": [5, 6, 10, 11, 22, 31, 32, 33], "some": [5, 6, 7, 9, 10, 20, 33, 34, 55, 57], "concept": [5, 7], "In": [5, 6, 7, 8, 10, 11, 25, 32, 46, 47], "ll": [5, 6, 7, 9, 11, 57], "talk": 5, "about": [5, 7, 10, 11, 35, 47, 57], "take": [5, 6, 7, 9, 10, 11, 12, 22, 23, 29, 35, 37, 39], "close": [5, 10, 11, 44, 45, 46, 47], "look": [5, 6, 7, 8, 9, 10, 11, 46], "veri": [5, 7, 27], "simpli": [5, 6], "dictat": 5, "state_dict": [5, 10, 29, 35, 36], "store": [5, 10, 44], "file": [5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 26, 35, 36, 37, 44, 54, 57, 58], "disk": [5, 44], "weight": [5, 7, 9, 10, 11, 20, 21, 29, 31, 32, 35, 36, 47], "string": [5, 26, 31, 39, 49], "kei": [5, 6, 7, 10, 20, 21, 23, 27, 34, 35], "identifi": 5, "state": [5, 7, 10, 11, 29, 33, 34, 35, 36], "dict": [5, 6, 11, 12, 29, 33, 34, 35, 36, 41], "If": [5, 6, 9, 10, 14, 15, 16, 17, 18, 20, 21, 29, 32, 35, 36, 39, 41, 46, 47, 49, 52], "identif": 5, "don": [5, 6, 7, 8, 11, 52], "t": [5, 6, 7, 8, 11, 18, 49, 52], "match": [5, 7, 10], "up": [5, 9, 10, 11, 14, 15], "exactli": 5, "those": [5, 10], "definit": [5, 10], "either": [5, 10, 35], "run": [5, 6, 8, 9, 10, 13, 20, 22, 23, 27, 29, 35, 36, 46, 47, 56, 57], "explicit": 5, "error": [5, 6, 14, 35, 52, 56], "load": [5, 7, 8, 10, 11, 35, 36, 37, 46], "rais": [5, 12, 18, 21, 27, 35, 36, 41, 47, 49, 52], "an": [5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 27, 31, 33, 34, 35, 36, 57], "except": 5, "wors": 5, "silent": [5, 22], "succe": 5, "infer": [5, 7, 21, 23, 25, 27, 28], "expect": [5, 6, 10, 12, 25, 47], "addit": [5, 6, 10, 11, 12, 35, 36, 41, 43, 44, 46, 47, 49, 57], "line": [5, 9, 11, 37], "also": [5, 6, 7, 9, 10, 11, 12, 20, 21, 27, 32, 39], "need": [5, 6, 7, 9, 10, 11, 18, 21, 22, 27, 46, 47], "shape": [5, 21, 23, 25, 27, 28, 32], "valu": [5, 6, 8, 10, 18, 19, 20, 21, 23, 24, 27, 30, 35, 37, 44, 45, 46, 47, 52], "two": [5, 6, 7, 9, 10, 57], "popular": [5, 7, 9, 57], "llama2": [5, 6, 8, 9, 11, 12, 14, 15, 18, 19, 20, 22, 26, 27, 28, 55, 57], "meta": [5, 7, 9, 16, 17, 35, 36], "offici": [5, 9], "implement": [5, 8, 10, 11, 14, 15, 16, 17, 18, 22, 24, 25, 30, 31, 32, 35, 46, 57], "when": [5, 6, 7, 10, 11, 13, 27, 29, 30, 46], "download": [5, 10, 53, 56], "7b": [5, 8, 9, 10, 14, 15, 19, 35, 36], "from": [5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 22, 26, 27, 28, 30, 31, 33, 35, 36, 37, 46, 47, 54, 58], "llama": [5, 7, 8, 9, 16, 17, 24, 25, 35, 36], "websit": 5, "get": [5, 6, 7, 9, 10, 11, 26, 40, 42, 49, 57], "access": [5, 6, 7, 9, 11, 35], "singl": [5, 6, 7, 10, 12, 21, 35, 36], "pth": [5, 7, 8, 9], "inspect": [5, 7, 10], "content": [5, 26], "easili": [5, 6, 10, 57], "torch": [5, 7, 8, 9, 10, 23, 27, 29, 30, 39, 41, 43, 48, 49, 52], "import": [5, 6, 7, 9, 10, 12, 46, 47], "consolid": [5, 8, 9], "00": [5, 8, 9, 54, 58], "mmap": [5, 7], "true": [5, 6, 7, 8, 9, 10, 14, 15, 16, 17, 26, 29, 35, 36, 41, 46], "weights_onli": 5, "map_loc": [5, 7], "cpu": [5, 7, 11, 29, 49], "tensor": [5, 10, 21, 22, 23, 24, 25, 27, 28, 29, 32, 35, 38, 44, 45, 46, 47], "item": 5, "print": [5, 10, 14, 15, 16, 17, 18, 26], "f": [5, 7, 10, 14, 15, 16, 17], "tok_embed": [5, 27], "size": [5, 7, 8, 11, 12, 14, 15, 16, 17, 19, 21, 23, 24, 25, 26, 27, 28, 40, 57], "32000": [5, 12], "4096": [5, 10, 12, 14, 15, 21, 25], "len": [5, 14, 15, 16, 17, 27], "292": 5, "The": [5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 24, 25, 26, 29, 30, 35, 37, 39, 42, 49, 52, 57], "contain": [5, 7, 10, 21, 23, 25, 26, 27, 28, 31, 33, 34, 35, 36, 37, 38, 46], "includ": [5, 6, 7, 9, 10, 11, 32, 35, 36, 37, 57], "input": [5, 8, 10, 14, 15, 16, 17, 18, 21, 22, 24, 25, 26, 27, 28, 32, 35, 38, 52], "embed": [5, 20, 21, 23, 24, 25, 27], "tabl": [5, 10], "call": [5, 9, 10, 12, 22, 29, 37, 44, 45, 46, 47], "layer": [5, 10, 11, 20, 21, 27, 28, 32, 57], "token": [5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17, 18, 20, 21, 25, 27, 28], "have": [5, 6, 7, 9, 10, 12, 21, 23, 31, 37, 46], "dim": [5, 21, 22, 24, 25, 27, 28], "hf": [5, 7, 9, 35], "most": [5, 6, 9, 10], "within": [5, 6, 7, 12, 18, 20, 22, 46, 52], "hug": [5, 7, 9, 14, 15, 16, 17, 18, 30, 57], "face": [5, 7, 9, 14, 15, 16, 17, 18, 30, 57], "hub": [5, 7, 9], "default": [5, 6, 7, 8, 10, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 35, 36, 37, 38, 44, 49, 52], "everi": [5, 11, 22, 46], "config": [5, 7, 8, 10, 12, 13, 21, 35, 37, 57], "2": [5, 7, 8, 9, 10, 18, 21, 26, 35, 36, 38, 52], "repo": [5, 7, 35, 36], "first": [5, 6, 7, 10, 12, 27, 35, 37, 55, 57], "big": [5, 7], "split": [5, 7], "across": [5, 7, 11, 35, 46, 52], "bin": [5, 7], "To": [5, 6, 7, 8, 9, 10, 11, 35, 56, 57], "correctli": [5, 9, 11, 35, 56], "piec": 5, "one": [5, 7, 10, 11, 22, 26, 56], "pytorch_model": [5, 7], "00001": 5, "00002": 5, "embed_token": 5, "241": 5, "Not": 5, "onli": [5, 7, 8, 10, 20, 21, 25, 26, 27, 28, 32, 33, 36, 37, 49, 56], "doe": [5, 7, 31, 35, 37], "fewer": [5, 21], "sinc": [5, 6, 7, 8, 12, 22, 35], "instead": [5, 7, 8, 11, 22, 23, 32], "mismatch": 5, "name": [5, 6, 7, 31, 34, 35, 36, 37, 39, 44, 45, 46, 47], "caus": [5, 26], "try": [5, 6, 7, 10], "same": [5, 6, 7, 10, 20, 21, 23, 26, 28, 37], "As": [5, 6, 7, 10, 11, 32, 57], "re": [5, 6, 7, 9, 10, 57], "care": [5, 7, 10, 22, 35], "like": [5, 6, 7, 8, 9, 10, 11], "end": [5, 9, 11, 26, 55, 57], "number": [5, 10, 11, 14, 15, 18, 20, 21, 23, 27, 30, 35, 36, 40, 52], "just": [5, 9, 10, 57], "save": [5, 7, 10, 11, 35, 36], "less": [5, 7, 8, 9, 18], "prone": 5, "manag": [5, 48], "invari": 5, "accept": [5, 6, 9, 18, 26], "multipl": [5, 6, 11, 32, 44, 45, 46, 47], "sourc": [5, 6, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "worri": 5, "explicitli": [5, 10, 31, 57], "convert": [5, 7, 9, 35, 38], "time": [5, 7, 26, 44, 46], "produc": 5, "back": [5, 10, 35], "origin": [5, 7, 10, 14, 15, 29, 32], "form": [5, 6, 11, 14], "One": [5, 7], "advantag": [5, 10], "being": [5, 35, 36, 39, 50], "should": [5, 6, 7, 9, 10, 11, 20, 21, 22, 31, 37, 44, 45, 46, 47, 56, 57], "abl": [5, 7, 9, 11], "fine": [5, 7, 8, 9, 10, 11, 14, 15, 55, 57], "tune": [5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 55, 56, 57], "post": 5, "tool": [5, 7, 9], "quantiz": [5, 20, 32, 55], "eval": [5, 57], "without": [5, 6, 7, 8, 10, 57], "code": [5, 11, 27, 53, 57], "chang": [5, 6, 7, 8, 9], "OR": 5, "convers": [5, 7, 10, 35, 57], "script": [5, 7, 9], "wai": [5, 6, 9, 56], "surround": [5, 11, 57], "load_checkpoint": [5, 11, 35, 36], "save_checkpoint": [5, 11, 35, 36], "method": [5, 6, 7, 10, 11, 13, 14, 15, 16, 17, 18, 29, 31, 33, 37, 57], "convertor": 5, "avail": [5, 7, 9, 10, 11, 37, 39, 57], "here": [5, 6, 7, 9, 10, 24, 25], "three": [5, 9, 11], "hfcheckpoint": 5, "read": [5, 35, 36, 57], "write": [5, 9, 11, 35, 36, 44], "compat": [5, 9, 35], "transform": [5, 10, 11, 20, 27, 28, 30], "framework": [5, 11, 57], "mention": [5, 7], "abov": [5, 7, 10, 29], "assum": [5, 7, 10, 30, 33, 49], "checkpoint_dir": [5, 6, 7, 8, 9, 35, 36], "necessari": [5, 10, 18, 44, 45, 46, 47], "json": [5, 7, 35], "easiest": [5, 9], "sure": [5, 6, 7, 9, 10], "everyth": [5, 9, 11, 37, 57], "follow": [5, 7, 8, 9, 10, 11, 21, 30, 55, 56], "flow": 5, "By": [5, 10], "ignor": [5, 21, 22], "safetensor": 5, "output": [5, 7, 9, 10, 14, 15, 16, 18, 20, 21, 22, 24, 25, 27, 28, 32, 34, 45, 56], "dir": [5, 7, 9], "output_dir": [5, 6, 7, 8, 9, 10, 35, 36], "specifi": [5, 6, 7, 9, 11, 12, 20, 21], "argument": [5, 6, 8, 9, 10, 12, 18, 21, 37, 41, 43, 44, 46, 47, 56], "snippet": 5, "explain": 5, "setup": [5, 6, 7, 10, 11, 27, 43], "_component_": [5, 6, 7, 8, 9, 10, 12], "fullmodelhfcheckpoint": [5, 7], "directori": [5, 6, 7, 9, 35, 36, 44, 46], "sort": [5, 35], "id": [5, 7, 14, 15, 18, 26, 35, 38], "so": [5, 6, 7, 9, 10, 35, 37, 57], "order": [5, 9, 11, 35, 46, 47], "matter": [5, 10, 35], "checkpoint_fil": [5, 6, 7, 8, 9, 10, 35, 36], "restart": [5, 8], "previou": [5, 35, 36], "more": [5, 6, 7, 8, 9, 10, 11, 14, 23, 25, 37, 47, 52, 57], "next": 5, "section": [5, 7, 11, 55], "recipe_checkpoint": [5, 8, 9, 35, 36], "null": [5, 6, 8, 9, 48], "usual": [5, 7, 8, 10, 25, 35], "model_typ": [5, 7, 8, 9, 35, 36], "resume_from_checkpoint": [5, 8, 9, 35, 36], "fals": [5, 6, 7, 8, 9, 10, 14, 15, 16, 17, 18, 20, 21, 26, 32, 35, 36, 50], "requir": [5, 6, 18, 35, 46, 47, 52, 56], "param": [5, 10, 11, 32, 33, 34, 35], "directli": [5, 6, 7, 9, 10, 11, 12, 35], "help": [5, 7, 9, 27, 35, 37, 55, 57], "ensur": [5, 6, 18, 20, 21, 35, 49, 57], "out": [5, 6, 7, 8, 10, 11, 14, 15, 16, 17, 35, 36, 55, 57], "case": [5, 7, 10, 11, 20, 21, 35, 44, 49, 50, 57], "discrep": [5, 35], "along": 5, "detail": [5, 7, 9, 10, 14, 23, 52], "found": [5, 6, 10, 24, 25], "metacheckpoint": 5, "github": [5, 14, 15, 16, 17, 21, 24, 25, 30, 56], "repositori": [5, 7, 9], "fullmodelmetacheckpoint": [5, 8, 9], "torchtunecheckpoint": 5, "perform": [5, 7, 10, 22, 57], "current": [5, 7, 9, 20, 21, 25, 27, 28, 36, 40, 44, 46, 52, 56], "test": [5, 6, 11, 57], "complet": [5, 7, 9, 11], "written": [5, 6, 11, 35, 36, 44, 45, 46, 47, 57], "begin": [5, 8, 26], "partit": 5, "ha": [5, 7, 10, 26, 31, 33], "standard": [5, 7, 45, 57], "key_1": 5, "weight_1": 5, "key_2": 5, "weight_2": 5, "mid": 5, "chekpoint": 5, "middl": [5, 7], "inform": [5, 7, 8, 9, 47, 57], "subsequ": [5, 11], "recipe_st": [5, 35, 36], "pt": [5, 7, 35, 36], "epoch": [5, 7, 8, 9, 10, 11, 30, 35, 36], "optim": [5, 6, 7, 8, 9, 10, 11, 30], "etc": [5, 11, 35], "prevent": 5, "flood": 5, "overwritten": 5, "note": [5, 6, 7, 10, 26, 27, 31, 35, 37, 49, 52], "updat": [5, 6, 7, 8, 9, 10, 11], "hf_model_0001_0": [5, 7], "hf_model_0002_0": [5, 7], "both": [5, 7, 10], "adapt": [5, 7, 10, 31, 32, 33, 34, 35, 36], "merg": [5, 7, 12, 35], "would": [5, 6, 7, 10, 27], "our": [5, 7, 10, 11, 57], "tutori": [5, 7, 8, 9, 57], "primari": [5, 6, 9, 11], "want": [5, 6, 8, 10, 11, 12], "resum": [5, 11, 30, 35, 36], "initi": [5, 9, 10, 11, 13, 19, 26, 41], "frozen": [5, 10], "base": [5, 7, 10, 18, 20, 25, 30, 32, 34, 35, 37, 44, 48], "well": [5, 6, 7, 11, 57], "learnt": [5, 7], "someth": [5, 7, 8, 11], "NOT": 5, "refer": [5, 6, 8, 10, 11, 24, 25, 48, 57], "adapter_checkpoint": [5, 35, 36], "adapter_0": [5, 7], "now": [5, 7, 9, 10, 26], "knowledg": 5, "creat": [5, 6, 7, 12, 14, 15, 16, 17, 19, 23, 30, 35, 36, 44, 46], "simpl": [5, 9, 11, 55], "forward": [5, 10, 11, 21, 22, 24, 25, 27, 28, 32], "13b": 5, "modeltyp": [5, 35, 36], "llama2_13b": 5, "right": [5, 7, 9, 10, 35], "pytorch_fil": 5, "00003": 5, "torchtune_sd": 5, "load_state_dict": [5, 10], "successfulli": 5, "vocab": [5, 12, 27], "70": 5, "x": [5, 10, 21, 22, 24, 25, 27, 28, 32], "randint": 5, "0": [5, 7, 9, 10, 11, 20, 21, 26, 27, 30, 32, 38, 46, 47, 52, 54, 58], "1": [5, 7, 8, 9, 10, 11, 18, 21, 26, 27, 30, 36, 38, 46, 47, 52], "no_grad": 5, "6": [5, 7, 24, 38], "3989": 5, "9": [5, 7], "0531": 5, "3": [5, 7, 8, 37, 38, 42], "2375": 5, "5": [5, 7, 8, 9, 30, 38], "2822": 5, "4": [5, 6, 7, 8, 18, 21, 38, 57], "4872": 5, "7469": 5, "8": [5, 7, 10, 14, 15, 16, 17], "6737": 5, "11": [5, 7], "0023": 5, "8235": 5, "6819": 5, "2424": 5, "0109": 5, "6915": 5, "7": [5, 38], "3618": 5, "1628": 5, "8594": 5, "5857": 5, "1151": 5, "7808": 5, "2322": 5, "8850": 5, "9604": 5, "7624": 5, "6040": 5, "3159": 5, "5849": 5, "8039": 5, "9322": 5, "2010": 5, "6824": 5, "8929": 5, "8465": 5, "3794": 5, "3500": 5, "6145": 5, "5931": 5, "do": [5, 7, 9, 10, 11, 47], "find": [5, 7, 9, 11], "list": [5, 6, 9, 14, 15, 18, 20, 26, 31, 32, 35, 36, 37, 38, 42, 51], "builder": [5, 19], "hope": 5, "provid": [5, 6, 7, 9, 11, 12, 18, 27, 37, 57], "deeper": 5, "insight": [5, 7], "happi": [5, 7], "thi": [6, 7, 8, 9, 10, 11, 12, 14, 15, 18, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 35, 36, 37, 39, 44, 46, 47, 52, 55, 57], "guid": [6, 8, 9, 10], "yaml": [6, 7, 9, 10, 11, 12, 13, 37, 57], "pars": [6, 9, 12, 37], "effect": 6, "cli": [6, 7, 9, 13], "prerequisit": [6, 7, 9, 10], "Be": [6, 7, 9, 10], "familiar": [6, 7, 9, 10], "torchtun": [6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56], "instal": [6, 7, 9, 10, 46, 47, 55], "fundament": 6, "There": [6, 7, 10, 56], "entri": [6, 9, 11], "point": [6, 7, 8, 9, 10, 11], "locat": [6, 10], "thei": [6, 10, 11, 27, 37], "truth": [6, 7], "reproduc": 6, "overridden": [6, 22, 37], "quick": 6, "experiment": 6, "modifi": [6, 7, 10, 11, 29, 57], "serv": [6, 10], "particular": [6, 18], "seed": [6, 9, 11, 52], "shuffl": [6, 8, 9], "devic": [6, 7, 8, 9, 11, 39, 48, 49], "cuda": [6, 7, 8, 9, 39, 49], "dtype": [6, 7, 8, 9, 11, 23, 29, 48, 49, 51], "fp32": 6, "enable_fsdp": 6, "mani": [6, 7], "object": [6, 12, 21, 48, 50], "keyword": [6, 12, 18, 29], "loss": [6, 8, 9, 10, 11, 14, 15, 16, 17], "function": [6, 11, 12, 13, 21, 22, 29, 39, 40, 52, 57], "exampl": [6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 26, 31, 35, 36, 38, 46, 47, 53, 54, 58], "subfield": 6, "dotpath": 6, "wish": 6, "exact": [6, 7, 12], "path": [6, 7, 8, 9, 10, 11, 12, 26, 35, 36, 37], "normal": [6, 10, 24, 26, 27, 28], "python": [6, 7, 37, 42, 47, 52, 53], "alpaca_dataset": [6, 8, 9, 14], "custom": [6, 7, 9, 10, 11, 57], "train_on_input": [6, 8, 14, 15, 16, 17, 18], "onc": [6, 7, 9, 10], "ve": [6, 7, 10, 23], "instanc": [6, 10, 12, 14, 15, 20, 22, 26, 29, 33, 34], "cfg": [6, 11, 13], "automat": [6, 12], "under": [6, 7], "preced": [6, 10, 12], "actual": 6, "throw": 6, "notic": [6, 10], "miss": [6, 10], "posit": [6, 12, 21, 25, 27, 28], "anoth": [6, 7], "handl": [6, 7, 10, 13, 26], "def": [6, 10, 11, 13], "dictconfig": [6, 11, 12, 13], "arg": [6, 12, 27, 29, 31, 37, 45], "tupl": [6, 12, 18, 26, 29, 37, 38, 40], "kwarg": [6, 12, 29, 31, 37, 41, 43, 44, 45, 46, 47], "str": [6, 12, 26, 29, 31, 32, 33, 34, 35, 36, 37, 39, 42, 44, 45, 46, 47, 49, 51, 52], "mean": [6, 9, 10, 24], "pass": [6, 10, 12, 19, 20, 21, 22, 29, 41, 43, 46, 47, 49], "add": [6, 7, 10, 37], "d": [6, 10, 21, 27, 28], "llama2_token": [6, 7, 8, 9], "tmp": [6, 7, 8, 9], "option": [6, 7, 9, 11, 19, 20, 21, 25, 26, 27, 28, 29, 35, 36, 39, 42, 43, 44, 47, 49, 52, 56, 57], "bool": [6, 14, 15, 16, 17, 18, 20, 26, 29, 32, 35, 36, 41, 46, 50], "max_seq_len": [6, 8, 12, 14, 15, 18, 20, 21, 23, 25, 26, 27], "int": [6, 10, 14, 15, 18, 19, 20, 21, 23, 24, 25, 26, 27, 30, 32, 35, 36, 38, 40, 44, 45, 46, 47, 52], "512": [6, 8, 14, 15], "instructdataset": [6, 14, 15, 16, 17], "alreadi": [6, 7, 9, 10, 41], "overwrit": 6, "duplic": [6, 11, 57], "sometim": 6, "than": [6, 7, 9, 10, 18, 21], "resolv": 6, "alpaca": [6, 7, 8, 9, 10, 14, 15], "metric_logg": [6, 11], "metric_log": [6, 44, 45, 46, 47], "disklogg": 6, "log_dir": [6, 44, 46], "conveni": [6, 11], "quickli": 6, "verifi": [6, 9, 10, 39, 49], "properli": 6, "experi": [6, 10, 55, 57], "wa": [6, 7, 10], "7b_full": [6, 7, 9], "batch_siz": [6, 7, 8, 9, 14, 15, 16, 17, 21, 28], "discuss": [6, 10], "guidelin": 6, "while": [6, 7, 9, 11, 22, 57], "mai": [6, 9, 10], "tempt": 6, "put": [6, 9, 10, 11], "much": [6, 7, 10], "give": [6, 10], "maximum": [6, 8, 14, 15, 18, 19, 20, 21, 23, 25, 27], "flexibl": 6, "switch": 6, "encourag": 6, "clariti": 6, "significantli": 6, "easier": [6, 7, 9], "dont": 6, "slimorca_dataset": 6, "privat": 6, "typic": 6, "expos": [6, 9, 11], "parent": 6, "modul": [6, 10, 12, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 43, 52], "__init__": [6, 10, 11], "py": [6, 7, 13, 14, 15, 16, 17, 21, 23, 24, 25, 30], "guarante": 6, "stabil": [6, 57], "underscor": 6, "_alpaca": 6, "collect": [6, 9], "differ": [6, 7, 8, 10, 26, 57], "itself": 6, "via": [6, 10, 32], "pair": [6, 8, 38], "k1": [6, 11], "v1": [6, 11], "k2": [6, 11], "v2": [6, 11], "full_finetun": 6, "gpu": [6, 7, 8, 9, 10], "full_finetune_distribut": [6, 7, 8, 9], "checkpoint": [6, 8, 9, 10, 11, 35, 36, 43, 57], "home": 6, "my_model_checkpoint": 6, "file_1": 6, "file_2": 6, "class": [6, 9, 10, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 44, 45, 46, 47], "assign": 6, "nest": 6, "dot": 6, "notat": [6, 21, 25, 27, 28], "my_config": 6, "your": [7, 10, 12, 46, 47, 55, 57], "favorit": [7, 10], "llm": [7, 10, 11, 55, 57], "go": [7, 8, 9, 11, 26, 57], "over": [7, 10, 11, 30, 37, 57], "commun": 7, "seemlessli": 7, "type": [7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 32, 33, 35, 36, 40, 41, 42, 48, 49, 50], "beyond": 7, "connect": 7, "step": [7, 10, 11, 27, 30, 44, 45, 46, 47, 55], "larger": 7, "might": 7, "relev": [7, 10, 11], "techniqu": [7, 8, 10, 57], "depend": [7, 10, 11], "factor": [7, 20, 32], "amount": 7, "natur": 7, "data": [7, 8, 14, 15, 16, 17, 18, 44, 45, 46, 47], "hardwar": [7, 10, 57], "task": [7, 10], "benchmark": [7, 11, 52, 57], "valid": [7, 9, 11], "qualiti": [7, 8, 11], "reason": [7, 11], "effici": [7, 8, 10, 25, 55, 57], "export": 7, "specif": [7, 9, 11, 12], "environ": [7, 9, 11], "mobil": 7, "phone": 7, "leverag": 7, "integr": [7, 9, 57], "mode": 7, "paramet": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 55, 57], "especi": [7, 57], "lot": [7, 8], "memori": [7, 8, 10, 11, 14, 15, 43], "plai": 7, "freez": [7, 10], "small": [7, 24], "percentag": 7, "learnabl": 7, "keep": [7, 10], "gradient": [7, 10, 11, 50, 57], "low": [7, 10, 20, 32], "16gb": 7, "bfloat16": [7, 29], "rtx": 7, "3090": 7, "4090": 7, "With": [7, 10, 13], "peak": [7, 10], "usag": [7, 8, 56], "total": [7, 10, 30, 40, 54, 58], "around": [7, 10, 11, 26], "hour": 7, "ls": 7, "full_finetune_single_devic": 7, "7b_full_single_devic": 7, "7b_full_single_device_low_memori": 7, "mistral": 7, "13b_full": 7, "lora_finetune_single_devic": 7, "7b_lora_single_devic": 7, "7b_qlora_single_devic": 7, "7b_lora": [7, 10], "overrid": [7, 9, 11, 13], "start": [7, 9, 11, 57], "log": [7, 9, 11, 42, 44, 45, 46, 47], "_checkpoint": 7, "473": 7, "98": 7, "gb": 7, "50": 7, "484": 7, "01": 7, "final": [7, 10, 20, 22, 27], "similar": [7, 10], "fact": [7, 10], "ident": 7, "third": 7, "smaller": [7, 10], "But": 7, "realli": 7, "eleuther_ev": 7, "its": [7, 10, 16, 17, 20, 52], "eleuther_evalu": 7, "plan": 7, "copi": [7, 9], "local": [7, 8, 9, 52, 56], "element": 7, "cp": [7, 9], "custom_eval_config": 7, "truthfulqa_mc2": 7, "qa": 7, "measur": 7, "propens": 7, "answer": [7, 14], "question": 7, "zero": [7, 24], "shot": 7, "accuraci": 7, "respons": [7, 9, 26], "baselin": [7, 10], "324": 7, "loglikelihood": 7, "request": [7, 49], "195": 7, "121": 7, "27": 7, "second": 7, "197": 7, "acc": 7, "none": [7, 11, 20, 21, 25, 26, 27, 28, 34, 35, 36, 39, 42, 43, 44, 45, 46, 47, 49, 52], "388": 7, "38": 7, "compar": [7, 10, 46], "shown": 7, "result": [7, 8, 9, 11, 26], "489": 7, "48": 7, "10": [7, 18, 38], "better": [7, 8, 9, 57], "great": 7, "seem": [7, 9], "meaning": [7, 11, 57], "text": [7, 26], "prompt": [7, 8, 14, 15, 16, 17, 18, 26, 27], "custom_generation_config": 7, "kick": 7, "off": [7, 11, 26], "sampl": [7, 18], "top_k": 7, "300": 7, "temperatur": 7, "control": [7, 8, 11, 14, 15, 16, 17, 52], "probabl": [7, 20, 32], "comput": [7, 8, 20, 21, 22, 25, 27, 52], "recommend": [7, 14, 15, 46], "interest": 7, "site": 7, "visit": [7, 9], "bai": 7, "area": 7, "92": 7, "exploratorium": 7, "san": 7, "francisco": 7, "made": [7, 25], "magazin": 7, "awesom": 7, "And": [7, 8, 56], "bridg": 7, "pretti": 7, "cool": 7, "96": 7, "61": 7, "sec": 7, "25": 7, "83": 7, "99": [7, 10], "15": 7, "72": 7, "inde": [7, 49], "know": [7, 10], "littl": 7, "saw": 7, "took": 7, "commonli": [7, 10, 52], "torchao": 7, "api": [7, 9, 11], "bit": [7, 10], "improv": [7, 27], "custom_quantization_config": 7, "68": 7, "19": 7, "76": 7, "69": 7, "13": [7, 26], "95": 7, "82": [7, 18], "67": 7, "4w": 7, "unlik": 7, "becaus": [7, 23, 27], "won": 7, "outsid": [7, 52], "engin": 7, "fullmodeltorchtunecheckpoint": 7, "int4weightonlyquant": 7, "groupsiz": 7, "256": 7, "did": 7, "unquant": [7, 29], "A": [7, 10, 11, 26, 29, 32, 35, 38, 54, 55, 58], "park": 7, "sit": 7, "top": 7, "hill": 7, "tree": [7, 46], "beauti": 7, "view": [7, 46], "62": 7, "17": 7, "85": 7, "compil": 7, "hood": 7, "sped": 7, "almost": 7, "3x": 7, "benefit": 7, "doesn": [7, 18], "yet": 7, "mix": [7, 8, 11, 48, 50, 57], "codebas": [7, 14, 15, 16, 17], "gpt": [7, 21], "fast": 7, "clone": [7, 10, 56], "machin": [7, 39], "assumpt": 7, "map": [7, 34, 35, 44, 45, 46, 47], "i": [7, 8, 11, 29, 34], "e": [7, 8, 21, 29, 31, 34, 56], "satisfi": 7, "new_dir": 7, "dictionari": [7, 44, 45, 46, 47], "output_dict": 7, "weight_map": [7, 35], "sd_1": 7, "sd_2": 7, "open": [7, 18], "index": [7, 30, 38], "w": [7, 10, 19, 46, 47], "dump": 7, "structur": [7, 11], "cd": [7, 56], "readabl": [7, 27], "convert_hf_checkpoint": 7, "checkpoint_path": 7, "hello": [7, 26], "my": 7, "justin": 7, "am": 7, "school": 7, "math": 7, "teacher": 7, "ws": 7, "94": 7, "103": 7, "28": 7, "bandwidth": 7, "achiev": 7, "1391": 7, "84": 7, "thats": 7, "own": [7, 10, 52], "hopefulli": 7, "gave": 7, "supervis": 8, "learn": [8, 9, 10, 11, 30, 57], "given": [8, 10, 11, 12, 32, 39, 49, 57], "compris": 8, "label": [8, 11, 14, 15, 18, 38], "cross": 8, "entropi": 8, "expens": 8, "lora": [8, 14, 15, 20, 32, 55, 57], "higher": [8, 29], "precis": [8, 11, 29, 48, 49, 50, 51, 57], "distribut": [8, 9, 39, 41, 43, 52, 57], "fsdp": [8, 9, 11, 50, 57], "activ": [8, 9, 11, 22, 43, 57], "aspect": [8, 57], "llama2_7b": [8, 9, 10], "sgd": [8, 9], "lr": [8, 9, 30], "2e": 8, "nn": [8, 9, 10, 12, 21, 22, 23, 27, 28, 29, 31, 33, 34, 43], "crossentropyloss": [8, 9], "bf16": [8, 9, 49], "enable_activation_checkpoint": [8, 9], "launch": [8, 9], "tunecli": 8, "nnode": [8, 9, 10], "nproc_per_nod": [8, 9, 10], "stanford": [8, 14, 15], "relat": [8, 10], "mask": [8, 14, 15, 16, 17, 21, 26, 28], "truncat": [8, 18, 26], "after": [8, 11, 23, 24, 44, 45, 46, 47], "sequenc": [8, 14, 15, 18, 20, 21, 23, 25, 26, 27, 28, 38], "length": [8, 14, 15, 18, 20, 21, 23, 25, 26, 27, 28, 36, 38], "limit": [8, 11], "down": [8, 9, 10], "slower": 8, "tokenizer_checkpoint": [8, 10], "path_to_model_token": 8, "batch": [8, 11, 14, 15, 16, 17, 19, 21, 23, 25, 26, 27, 28, 38, 57], "global": [8, 52], "num_gpu": 8, "gradient_accumulation_step": 8, "correspond": [8, 10, 31, 33, 49], "accumul": [8, 11, 57], "previous": 8, "incomplet": 8, "adam": 8, "known": [8, 26], "process": [9, 11, 29, 52], "job": [9, 52], "latest": 9, "greatest": 9, "gate": 9, "grant": 9, "instruct": [9, 10, 14, 15, 55], "page": [9, 57], "host": 9, "minut": 9, "agreement": 9, "signup": 9, "author": [9, 57], "authent": 9, "Then": 9, "command": [9, 10, 11, 37, 56], "other": [9, 10, 11, 12, 14, 37], "user": [9, 11, 20, 21, 26], "thought": [9, 11, 57], "pipelin": [9, 11, 57], "consist": [9, 11], "configur": [9, 10, 11, 14, 15, 16, 17, 18, 28, 57], "dataclass": 9, "core": [9, 11, 57], "logic": [9, 10, 11, 35, 57], "togeth": [9, 10, 11], "basic": 9, "hold": 9, "hyperparamet": [9, 10, 57], "metric": [9, 11], "logger": [9, 11, 42, 44, 45, 46, 47], "wandb": [9, 11, 47], "new": [9, 10, 11, 44, 46], "exist": [9, 11], "Or": 9, "past": [9, 23], "It": 9, "alpaca_llama_full_finetun": 9, "good": [9, 10], "place": 9, "custom_config": 9, "random": [9, 52], "replic": 9, "lower": [9, 10], "sooner": 9, "rate": [9, 30, 57], "42": 9, "1e": [9, 20, 24], "proper": 9, "suit": [9, 11], "pytorch": [9, 10, 11, 18, 27, 29, 46, 48, 52, 55, 56, 57], "torchrun": 9, "therefor": 9, "immedi": 9, "indic": 9, "succesfulli": 9, "log_1707246452": 9, "txt": [9, 44], "manual": [9, 10], "rank": [9, 10, 20, 32, 40, 52], "sampler": 9, "7553404569625854": 9, "13000": 9, "03": 9, "closer": [9, 10, 11], "teach": 10, "show": 10, "straight": 10, "jump": 10, "trainabl": [10, 32, 34], "decomposit": [10, 32], "matric": [10, 32], "neural": 10, "network": [10, 22], "remain": [10, 30], "linear": [10, 20, 27, 31, 32], "project": [10, 20, 21, 22, 47, 55], "self": [10, 11, 20, 21, 27, 28, 31], "attent": [10, 20, 21, 23, 25, 27, 28], "unfamiliar": 10, "check": [10, 27, 49, 55], "approxim": [10, 20, 32], "oppos": 10, "due": [10, 26], "substanti": 10, "reduct": 10, "momentum": 10, "adamw": 10, "further": 10, "come": [10, 31], "primarili": [10, 11], "reduc": [10, 27], "replac": [10, 14, 15, 16, 17, 29], "arbitrari": 10, "in_dim": [10, 31, 32], "out_dim": [10, 31, 32], "could": 10, "high": [10, 57], "min": 10, "paper": 10, "aghajanyan": 10, "et": 10, "al": 10, "hypothes": 10, "intrins": 10, "dimens": [10, 20, 21, 23, 25, 27, 32], "properti": [10, 37], "b": [10, 11, 21, 25, 27, 28, 32], "often": 10, "four": 10, "eight": 10, "practic": 10, "imag": 10, "below": [10, 25], "simplifi": 10, "represent": [10, 18], "left": 10, "blue": 10, "although": [10, 22], "introduc": [10, 21, 24, 32], "few": [10, 35], "extra": 10, "r": [10, 32], "rememb": 10, "q": [10, 21], "k": [10, 21], "v": [10, 21, 27], "approx": 10, "15m": 10, "8192": 10, "65k": 10, "minim": 10, "nativ": [10, 11, 55, 57], "loralinear": [10, 31], "alpha": [10, 32], "float": [10, 20, 21, 24, 30, 32, 44, 45, 46, 47], "dropout": [10, 20, 21, 32], "pretrain": 10, "bia": [10, 31, 32], "lora_a": [10, 32], "lora_b": [10, 32], "p": 10, "requires_grad": 10, "frozen_out": 10, "lora_out": 10, "scale": [10, 20, 32], "return": [10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 48, 49, 50, 51, 52], "omit": 10, "varieti": [10, 57], "construct": 10, "lora_llama2_7b": 10, "build": [10, 11, 57], "base_model": 10, "choos": 10, "q_proj": [10, 20, 21], "k_proj": [10, 20, 21], "v_proj": [10, 20, 21], "output_proj": [10, 20, 21], "lora_model": 10, "lora_attn_modul": [10, 20], "lora_llama_2_7b": 10, "alon": 10, "attn": [10, 28], "causalselfattent": [10, 28], "in_featur": 10, "out_featur": 10, "pos_embed": [10, 21], "rotarypositionalembed": [10, 21], "inplac": 10, "addition": [10, 52], "transformerdecod": [10, 19, 20], "feel": 10, "free": 10, "yourself": [10, 11], "why": 10, "wrapper": [10, 11, 26], "strict": 10, "whenev": 10, "peft": [10, 31, 32, 33, 34], "validate_state_dict_for_lora": 10, "peft_util": 10, "get_adapter_param": [10, 34], "set_trainable_param": 10, "fetch": 10, "lora_param": 10, "total_param": 10, "sum": 10, "numel": 10, "trainable_param": 10, "100": [10, 11, 14, 15, 16, 17, 18, 38], "2f": 10, "6742609920": 10, "4194304": 10, "06": [10, 24], "taken": 10, "vram": 10, "least": [10, 18], "23gb": 10, "lora_finetune_distribut": 10, "done": [10, 49], "ad": [10, 11, 26], "my_model_checkpoint_path": 10, "my_tokenizer_checkpoint_path": 10, "constraint": 10, "coupl": 10, "factori": 10, "lora_rank": [10, 20], "lora_alpha": [10, 20], "16": 10, "benefici": 10, "increas": [10, 30], "32": [10, 12], "max": [10, 18, 26, 27, 30], "long": 10, "embed_dim": [10, 12, 20, 21, 25, 28], "impact": 10, "rel": 10, "minor": 10, "64": 10, "lora_experiment_1": 10, "comparison": [10, 11], "smooth": 10, "curv": 10, "500": 10, "seen": 10, "figur": [10, 11], "wandblogg": 10, "account": [10, 47], "separ": [10, 26, 35], "exercis": 10, "longer": 10, "target": [11, 57], "eg": [11, 27, 35, 57], "featur": [11, 57], "appli": [11, 20, 21, 24, 25, 27, 28, 57], "famili": [11, 57], "complex": 11, "becom": 11, "harder": 11, "anticip": 11, "architectur": [11, 27], "methodolog": 11, "possibl": 11, "trade": 11, "vs": 11, "believ": 11, "best": 11, "fit": [11, 14, 15], "solut": 11, "meant": [11, 29], "level": [11, 42, 57], "expertis": 11, "routin": 11, "ones": 11, "modular": [11, 57], "block": [11, 20, 57], "fulli": 11, "correct": [11, 24, 25, 27, 39, 57], "numer": [11, 57], "pariti": [11, 57], "verif": 11, "extens": [11, 57], "hidden": [11, 22], "behind": 11, "flag": [11, 14, 15, 16, 17], "prefer": [11, 57], "unnecessari": 11, "abstract": [11, 57], "No": [11, 57], "inherit": [11, 37, 57], "upon": 11, "spectrum": 11, "decid": 11, "interact": [11, 55], "paradigm": 11, "monolith": [11, 57], "trainer": [11, 40], "extern": 11, "eleutherai": [11, 57], "har": [11, 57], "multi": [11, 21], "stage": 11, "distil": 11, "oper": [11, 52], "turn": 11, "dataload": [11, 14, 15, 16, 17], "applic": [11, 21, 35, 36, 47, 48], "clean": [11, 14], "group": [11, 21, 44, 45, 46, 47], "init_process_group": [11, 41], "backend": 11, "gloo": 11, "els": [11, 37, 57], "nccl": 11, "fullfinetunerecipedistribut": 11, "cleanup": 11, "stuff": 11, "carri": 11, "interfac": [11, 31], "_devic": 11, "get_devic": 11, "_dtype": 11, "get_dtyp": 11, "ckpt_dict": 11, "wrap": [11, 43], "_model": 11, "_setup_model": 11, "_token": 11, "_setup_token": 11, "_optim": 11, "_setup_optim": 11, "_loss_fn": 11, "_setup_loss": 11, "_sampler": 11, "_dataload": 11, "_setup_data": 11, "backward": 11, "zero_grad": 11, "curr_epoch": 11, "rang": [11, 52], "epochs_run": 11, "total_epoch": 11, "idx": 11, "enumer": 11, "_autocast": 11, "logit": 11, "total_training_step": 11, "_log_every_n_step": 11, "_metric_logg": 11, "log_dict": [11, 44, 45, 46, 47], "decor": [11, 13], "recipe_main": [11, 13], "fullfinetunerecip": 11, "direct": 11, "field": [12, 14, 15, 16, 17], "num_lay": [12, 20, 27], "num_head": [12, 20, 21, 23, 25, 27], "num_kv_head": [12, 20, 21, 23], "vocab_s": [12, 20, 26], "must": [12, 14, 15, 16, 17, 18, 31, 37], "parsed_yaml": 12, "omegaconf": 12, "valueerror": [12, 18, 21, 27, 35, 36, 49, 52], "callabl": [13, 27], "main": [13, 14, 15, 16, 17, 21, 24, 25], "my_recip": 13, "foo": 13, "bar": [13, 57], "http": [14, 15, 16, 17, 18, 19, 21, 24, 25, 30, 35, 36, 37, 42, 46, 47, 48, 52, 56], "huggingfac": [14, 15, 16, 17, 18, 30, 35, 36], "co": [14, 15, 16, 17, 18, 35, 36], "yahma": 14, "tatsu": [14, 15], "lab": [14, 15], "templat": [14, 15, 16, 17, 18], "com": [14, 15, 16, 17, 21, 24, 25, 30, 56], "stanford_alpaca": [14, 15], "blob": [14, 15, 16, 17, 21, 24, 25, 30], "761dc5bfbdeeffa89b8bff5d038781a4055f796a": [14, 15], "l31": [14, 15], "where": [14, 15, 16, 17, 21, 26, 27, 32], "ref": [14, 15, 47], "tloen": [14, 15], "l49": [14, 15], "contribut": [14, 15, 16, 17], "version": [14, 20, 21], "remov": 14, "hallucin": 14, "poorli": 14, "wrong": 14, "card": 14, "encod": [14, 15, 16, 17, 18, 26], "decod": [14, 15, 16, 17, 18, 20, 26, 27], "whether": [14, 15, 16, 17, 18, 20, 26, 29, 32, 49, 50], "tab": [14, 15], "readm": [14, 15], "ov": [14, 15], "highest": [14, 15], "alpaca_d": [14, 15], "grammar": 16, "variant": [16, 17], "liweili": 16, "c4_200m": 16, "descript": 16, "llama_recip": [16, 17], "src": [16, 17, 30], "l50": 16, "grammar_d": 16, "summar": 17, "samsum": 17, "l13": 17, "dialogu": 17, "summari": 17, "samsum_d": 17, "1024": 18, "chatdataset": 18, "slimorca": 18, "orca": 18, "dedup": 18, "adher": 18, "chat": 18, "prescrib": 18, "though": 18, "ds": 18, "351": 18, "391": 18, "221": 18, "220": 18, "193": 18, "12": 18, "471": 18, "arxiv": [19, 21, 24, 25], "org": [19, 21, 24, 25, 37, 42, 46, 48, 52], "ab": [19, 25], "2307": 19, "09288": 19, "max_batch_s": [19, 23], "kvcach": [19, 20, 21, 27], "instanti": [19, 20], "liter": 20, "apply_lora_to_mlp": 20, "apply_lora_to_output": 20, "intermediate_dim": 20, "attn_dropout": [20, 21, 27], "norm_ep": 20, "05": 20, "lora_dropout": 20, "quantize_bas": [20, 32], "mlp": [20, 27, 28], "vocabulari": [20, 26], "queri": [20, 21, 23, 27], "head": [20, 21, 23, 25, 27], "mha": [20, 21, 27], "onto": [20, 21], "scaled_dot_product_attent": [20, 21], "intermedi": 20, "scale_hidden_dim_for_mlp": 20, "epsilon": 20, "rm": 20, "norm": [20, 27, 28], "subset": [20, 33], "head_dim": [21, 23, 25, 27], "kv_cach": 21, "gqa": 21, "pdf": [21, 24], "2305": 21, "13245v1": 21, "multihead": 21, "n": [21, 26, 54, 58], "extrem": 21, "share": 21, "mqa": 21, "credit": 21, "document": 21, "lightn": 21, "ai": [21, 47], "lit": 21, "lit_gpt": 21, "n_kv_head": 21, "calcul": 21, "g": [21, 31], "cach": [21, 23, 25], "rope": [21, 25], "input_po": [21, 25, 27, 28], "seq_length": [21, 28], "seq_len": [21, 25], "bigger": 21, "n_h": [21, 25], "num": [21, 25], "n_kv": 21, "kv": [21, 23, 27], "emb": [21, 27, 28], "h_d": [21, 25], "gate_proj": 22, "down_proj": 22, "up_proj": 22, "silu": 22, "feed": [22, 28], "deriv": [22, 27, 28], "fed": 22, "multipli": 22, "subclass": [22, 37], "afterward": 22, "former": 22, "regist": [22, 29], "hook": [22, 29], "latter": 22, "standalon": 23, "expand": 23, "per": [23, 29], "dpython": [23, 29, 48], "ep": 24, "root": [24, 46], "squar": 24, "1910": 24, "07467": 24, "verfic": [24, 25], "facebookresearch": [24, 25], "avoid": [24, 52], "divis": 24, "10000": 25, "rotari": 25, "propos": 25, "2104": 25, "09864": 25, "l450": 25, "upto": 25, "init": [25, 47], "exceed": 25, "freq": 25, "recomput": 25, "geometr": 25, "progress": 25, "rotat": 25, "angl": 25, "bsz": 25, "todo": 25, "spm_model": 26, "sentencepieceprocessor": 26, "bos_id": 26, "eos_id": 26, "pad_id": 26, "sentencepiec": 26, "sentenc": 26, "pad": [26, 38], "non": 26, "from_fil": 26, "tokenized_text": 26, "world": [26, 40], "add_bo": 26, "add_eo": 26, "31587": 26, "29644": 26, "102": 26, "trim_leading_whitespac": 26, "prefix": 26, "unbatch": 26, "prepend": 26, "bo": 26, "append": 26, "eo": 26, "trim": 26, "lead": 26, "whitespac": 26, "underli": 26, "s1": 26, "s2": 26, "classmethod": 26, "tokenize_messag": 26, "messag": 26, "concaten": 26, "problem": 26, "slice": 26, "tokenizer_path": 26, "role": 26, "system": 26, "assist": 26, "concat": 26, "1788": 26, "2643": 26, "1792": 26, "9508": 26, "465": 26, "22137": 26, "2933": 26, "join": 26, "attribut": 26, "transformerdecoderlay": 27, "move": 27, "space": 27, "belong": 27, "statement": 27, "At": 27, "arang": 27, "prompt_length": 27, "causal_mask": 27, "m_": 27, "seq": 27, "sa_norm": 28, "mlp_norm": 28, "ff": 28, "common_util": 29, "offload_to_cpu": 29, "nf4": 29, "restor": 29, "offload": 29, "_register_state_dict_hook": 29, "m": 29, "mymodul": 29, "_after_": 29, "nf4tensor": 29, "unus": 29, "num_warmup_step": 30, "num_training_step": 30, "num_cycl": 30, "last_epoch": 30, "lambdalr": 30, "schedul": 30, "linearli": 30, "decreas": 30, "cosin": 30, "v4": 30, "23": 30, "l104": 30, "warmup": 30, "phase": 30, "wave": 30, "half": [30, 48], "last": 30, "lr_schedul": 30, "appropri": 30, "protocol": 31, "adapter_param": [31, 32, 33, 34], "proj": 31, "use_bia": 32, "larg": 32, "languag": 32, "perturb": 32, "mapsto": 32, "w_0x": 32, "bax": 32, "respect": 34, "0001_of_0003": 35, "0002_of_0003": 35, "preserv": 35, "intermediate_checkpoint": [35, 36], "_output_dir": [35, 36], "parit": 35, "_weight_map": 35, "shard": [36, 50], "wip": 36, "argpars": 37, "tunerecipeargpars": 37, "argumentpars": 37, "builtin": [37, 48], "noth": 37, "treat": 37, "still": 37, "consult": 37, "doc": [37, 42, 46, 47, 48, 52], "info": 37, "librari": [37, 42, 52, 55, 57], "html": [37, 42, 46, 48, 52], "parse_known_arg": 37, "namespac": 37, "act": 37, "alwai": 37, "precid": 37, "parse_arg": 37, "intern": 37, "too": 37, "collat": 38, "padding_idx": 38, "ignore_idx": 38, "longest": 38, "integ": [38, 52], "tokenpair": 38, "token_pair": 38, "availab": 39, "aka": 40, "runtimeerror": 41, "stream": 42, "handler": 42, "auto_wrap_polici": 43, "polici": 43, "filenam": 44, "log_": 44, "unixtimestamp": 44, "thread": 44, "safe": 44, "resourc": [44, 45, 46, 47], "flush": [44, 45, 46, 47], "union": [44, 45, 46, 47, 50, 52], "ndarrai": [44, 45, 46, 47], "scalar": [44, 45, 46, 47], "tag": [44, 45, 46, 47], "record": [44, 45, 46, 47], "payload": [44, 45, 46, 47], "organize_log": 46, "tensorboard": 46, "stabl": [46, 48, 52], "subdirectori": 46, "sub": 46, "logdir": 46, "startup": 46, "recurs": 46, "tfevent": 46, "encount": 46, "frontend": 46, "organ": 46, "accordingli": 46, "my_log_dir": 46, "my_metr": [46, 47], "packag": [46, 47, 56], "pip": [46, 47, 56], "termin": [46, 47], "entiti": 47, "bias": 47, "my_project": 47, "my_ent": 47, "my_group": 47, "importerror": 47, "login": 47, "contextmanag": 48, "intellig": 48, "determin": 48, "autocast": 48, "amp": 48, "otherwis": 48, "context": 48, "kernel": 49, "float32": 49, "isn": 49, "gradscal": 50, "shardedgradscal": 50, "scaler": 50, "awar": 50, "debug_mod": 52, "pseudo": 52, "numpi": 52, "determinist": 52, "warn": 52, "nondeterminist": 52, "cudnn": 52, "disabl": 52, "set_deterministic_debug_mod": 52, "algorithm": 52, "generated_examples_python": 53, "zip": 53, "galleri": [53, 58], "sphinx": 53, "000": [54, 58], "execut": [54, 58], "generated_exampl": 54, "mem": [54, 58], "mb": [54, 58], "topic": 55, "gentl": 55, "introduct": 55, "workflow": 55, "readi": 55, "git": 56, "confirm": 56, "recipe_arg": 56, "On": 57, "pointer": 57, "emphas": 57, "simplic": 57, "component": 57, "reus": 57, "prove": 57, "democrat": 57, "box": 57, "zoo": 57, "excit": 57, "checkout": 57, "chekckpoint": 57, "embodi": 57, "philosophi": 57, "usabl": 57, "eluetherai": 57, "composit": 57, "hard": 57, "outlin": 57, "unecessari": 57, "never": 57, "thoroughli": 57, "unit": 57}, "objects": {"torchtune.config": [[12, 0, 1, "", "instantiate"], [13, 0, 1, "", "parse"]], "torchtune.datasets": [[14, 0, 1, "", "alpaca_cleaned_dataset"], [15, 0, 1, "", "alpaca_dataset"], [16, 0, 1, "", "grammar_dataset"], [17, 0, 1, "", "samsum_dataset"], [18, 0, 1, "", "slimorca_dataset"]], "torchtune.models.llama2": [[19, 0, 1, "", "llama2_7b"], [20, 0, 1, "", "lora_llama2"]], "torchtune.modules": [[21, 1, 1, "", "CausalSelfAttention"], [22, 1, 1, "", "FeedForward"], [23, 1, 1, "", "KVCache"], [24, 1, 1, "", "RMSNorm"], [25, 1, 1, "", "RotaryPositionalEmbeddings"], [26, 1, 1, "", "Tokenizer"], [27, 1, 1, "", "TransformerDecoder"], [28, 1, 1, "", "TransformerDecoderLayer"], [30, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[21, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[22, 2, 1, "", "forward"]], "torchtune.modules.RMSNorm": [[24, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[25, 2, 1, "", "forward"]], "torchtune.modules.Tokenizer": [[26, 2, 1, "", "decode"], [26, 2, 1, "", "encode"], [26, 2, 1, "", "from_file"], [26, 2, 1, "", "tokenize_messages"]], "torchtune.modules.TransformerDecoder": [[27, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoderLayer": [[28, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[29, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[31, 1, 1, "", "AdapterModule"], [32, 1, 1, "", "LoRALinear"], [33, 0, 1, "", "get_adapter_params"], [34, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[31, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[32, 2, 1, "", "adapter_params"], [32, 2, 1, "", "forward"]], "torchtune.utils": [[35, 1, 1, "", "FullModelHFCheckpointer"], [36, 1, 1, "", "FullModelMetaCheckpointer"], [39, 0, 1, "", "get_device"], [40, 0, 1, "", "get_world_size_and_rank"], [41, 0, 1, "", "init_distributed"]], "torchtune.utils.FullModelHFCheckpointer": [[35, 2, 1, "", "load_checkpoint"], [35, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[36, 2, 1, "", "load_checkpoint"], [36, 2, 1, "", "save_checkpoint"]], "torchtune.utils.argparse": [[37, 1, 1, "", "TuneRecipeArgumentParser"]], "torchtune.utils.argparse.TuneRecipeArgumentParser": [[37, 2, 1, "", "parse_known_args"]], "torchtune.utils.collate": [[38, 0, 1, "", "padded_collate"]], "torchtune.utils.logging": [[42, 0, 1, "", "get_logger"]], "torchtune.utils.memory": [[43, 0, 1, "", "set_activation_checkpointing"]], "torchtune.utils.metric_logging": [[44, 1, 1, "", "DiskLogger"], [45, 1, 1, "", "StdoutLogger"], [46, 1, 1, "", "TensorBoardLogger"], [47, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[44, 2, 1, "", "close"], [44, 2, 1, "", "log"], [44, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[45, 2, 1, "", "close"], [45, 2, 1, "", "log"], [45, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[46, 2, 1, "", "close"], [46, 2, 1, "", "log"], [46, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[47, 2, 1, "", "close"], [47, 2, 1, "", "log"], [47, 2, 1, "", "log_dict"]], "torchtune.utils.precision": [[48, 0, 1, "", "get_autocast"], [49, 0, 1, "", "get_dtype"], [50, 0, 1, "", "get_gradient_scaler"], [51, 0, 1, "", "list_dtypes"]], "torchtune.utils.seed": [[52, 0, 1, "", "set_seed"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 7, 10, 55, 57], "config": [0, 6, 9, 11], "dataset": [1, 8], "model": [2, 3, 7, 8, 9, 10], "llama2": [2, 7, 10], "modul": 3, "compon": [3, 6], "build": 3, "block": 3, "peft": 3, "util": [3, 4], "checkpoint": [4, 5, 7], "distribut": 4, "reduc": 4, "precis": 4, "memori": 4, "manag": 4, "metric": 4, "log": 4, "data": 4, "miscellan": 4, "overview": [5, 7, 57], "format": 5, "handl": 5, "differ": 5, "intermedi": 5, "vs": 5, "final": 5, "lora": [5, 7, 10], "put": 5, "thi": 5, "all": 5, "togeth": 5, "deep": [6, 11], "dive": [6, 11], "where": 6, "do": 6, "paramet": 6, "live": 6, "write": 6, "configur": 6, "us": [6, 7, 11], "instanti": [6, 12], "referenc": 6, "other": [6, 7], "field": 6, "interpol": 6, "valid": 6, "your": [6, 9, 11], "best": 6, "practic": 6, "airtight": 6, "public": 6, "api": 6, "onli": 6, "command": 6, "line": 6, "overrid": 6, "end": 7, "workflow": 7, "download": [7, 9], "7b": 7, "finetun": [7, 8, 9, 10], "run": [7, 11], "evalu": 7, "eleutherai": 7, "s": 7, "eval": 7, "har": 7, "gener": 7, "speed": 7, "up": 7, "quantiz": 7, "librari": 7, "llm": [8, 9], "full": 8, "recip": [8, 9, 10, 11], "train": [8, 9, 11], "first": 9, "select": 9, "modifi": 9, "next": 9, "step": 9, "what": [10, 11, 57], "how": 10, "doe": 10, "work": 10, "appli": 10, "ar": 11, "script": 11, "class": 11, "cli": 11, "pars": [11, 13], "alpaca_cleaned_dataset": 14, "alpaca_dataset": 15, "grammar_dataset": 16, "samsum_dataset": 17, "slimorca_dataset": 18, "llama2_7b": 19, "lora_llama2": 20, "causalselfattent": 21, "todo": [21, 28], "feedforward": 22, "kvcach": 23, "rmsnorm": 24, "rotarypositionalembed": 25, "token": 26, "transformerdecod": 27, "transformerdecoderlay": 28, "reparametrize_as_dtype_state_dict_post_hook": 29, "get_cosine_schedule_with_warmup": 30, "adaptermodul": 31, "loralinear": 32, "get_adapter_param": 33, "set_trainable_param": 34, "fullmodelhfcheckpoint": 35, "fullmodelmetacheckpoint": 36, "tunerecipeargumentpars": 37, "padded_col": 38, "get_devic": 39, "get_world_size_and_rank": 40, "init_distribut": 41, "get_logg": 42, "set_activation_checkpoint": 43, "disklogg": 44, "stdoutlogg": 45, "tensorboardlogg": 46, "wandblogg": 47, "get_autocast": 48, "get_dtyp": 49, "get_gradient_scal": 50, "list_dtyp": 51, "set_se": 52, "comput": [54, 58], "time": [54, 58], "welcom": 55, "document": 55, "get": 55, "start": 55, "tutori": 55, "instal": 56, "instruct": 56, "kei": 57, "concept": 57, "design": 57, "principl": 57}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})