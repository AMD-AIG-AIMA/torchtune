Search.setIndex({"docnames": ["api_ref_config", "api_ref_data", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "deep_dives/checkpointer", "deep_dives/configs", "deep_dives/recipe_deepdive", "deep_dives/wandb_logging", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.config.validate", "generated/torchtune.data.AlpacaInstructTemplate", "generated/torchtune.data.ChatFormat", "generated/torchtune.data.ChatMLFormat", "generated/torchtune.data.GrammarErrorCorrectionTemplate", "generated/torchtune.data.InstructTemplate", "generated/torchtune.data.Llama2ChatFormat", "generated/torchtune.data.Message", "generated/torchtune.data.MistralChatFormat", "generated/torchtune.data.SummarizeTemplate", "generated/torchtune.data.sharegpt_to_llama2_messages", "generated/torchtune.data.truncate", "generated/torchtune.data.validate_messages", "generated/torchtune.datasets.ChatDataset", "generated/torchtune.datasets.ConcatDataset", "generated/torchtune.datasets.InstructDataset", "generated/torchtune.datasets.PackedDataset", "generated/torchtune.datasets.PreferenceDataset", "generated/torchtune.datasets.TextCompletionDataset", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.chat_dataset", "generated/torchtune.datasets.cnn_dailymail_articles_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.instruct_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.datasets.stack_exchanged_paired_dataset", "generated/torchtune.datasets.text_completion_dataset", "generated/torchtune.datasets.wikitext_dataset", "generated/torchtune.models.gemma.gemma_2b", "generated/torchtune.models.gemma.gemma_7b", "generated/torchtune.models.llama2.llama2_13b", "generated/torchtune.models.llama2.llama2_70b", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2_13b", "generated/torchtune.models.llama2.lora_llama2_70b", "generated/torchtune.models.llama2.lora_llama2_7b", "generated/torchtune.models.llama2.qlora_llama2_13b", "generated/torchtune.models.llama2.qlora_llama2_7b", "generated/torchtune.models.llama3.llama3_70b", "generated/torchtune.models.llama3.llama3_8b", "generated/torchtune.models.llama3.lora_llama3_70b", "generated/torchtune.models.llama3.lora_llama3_8b", "generated/torchtune.models.llama3.qlora_llama3_8b", "generated/torchtune.models.mistral.lora_mistral_7b", "generated/torchtune.models.mistral.mistral_7b", "generated/torchtune.models.mistral.qlora_mistral_7b", "generated/torchtune.models.phi3.lora_phi3_mini", "generated/torchtune.models.phi3.phi3_mini", "generated/torchtune.models.phi3.qlora_phi3_mini", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.modules.tokenizers.SentencePieceTokenizer", "generated/torchtune.modules.tokenizers.TikTokenTokenizer", "generated/torchtune.utils.FSDPPolicyType", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.TuneRecipeArgumentParser", "generated/torchtune.utils.generate", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_dtype", "generated/torchtune.utils.get_full_finetune_fsdp_wrap_policy", "generated/torchtune.utils.get_logger", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.list_dtypes", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.padded_collate", "generated/torchtune.utils.profiler", "generated/torchtune.utils.set_activation_checkpointing", "generated/torchtune.utils.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times", "tutorials/chat", "tutorials/datasets", "tutorials/e2e_flow", "tutorials/first_finetune_tutorial", "tutorials/llama3", "tutorials/lora_finetune", "tutorials/qlora_finetune"], "filenames": ["api_ref_config.rst", "api_ref_data.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "deep_dives/checkpointer.rst", "deep_dives/configs.rst", "deep_dives/recipe_deepdive.rst", "deep_dives/wandb_logging.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.config.validate.rst", "generated/torchtune.data.AlpacaInstructTemplate.rst", "generated/torchtune.data.ChatFormat.rst", "generated/torchtune.data.ChatMLFormat.rst", "generated/torchtune.data.GrammarErrorCorrectionTemplate.rst", "generated/torchtune.data.InstructTemplate.rst", "generated/torchtune.data.Llama2ChatFormat.rst", "generated/torchtune.data.Message.rst", "generated/torchtune.data.MistralChatFormat.rst", "generated/torchtune.data.SummarizeTemplate.rst", "generated/torchtune.data.sharegpt_to_llama2_messages.rst", "generated/torchtune.data.truncate.rst", "generated/torchtune.data.validate_messages.rst", "generated/torchtune.datasets.ChatDataset.rst", "generated/torchtune.datasets.ConcatDataset.rst", "generated/torchtune.datasets.InstructDataset.rst", "generated/torchtune.datasets.PackedDataset.rst", "generated/torchtune.datasets.PreferenceDataset.rst", "generated/torchtune.datasets.TextCompletionDataset.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.chat_dataset.rst", "generated/torchtune.datasets.cnn_dailymail_articles_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.instruct_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.datasets.stack_exchanged_paired_dataset.rst", "generated/torchtune.datasets.text_completion_dataset.rst", "generated/torchtune.datasets.wikitext_dataset.rst", "generated/torchtune.models.gemma.gemma_2b.rst", "generated/torchtune.models.gemma.gemma_7b.rst", "generated/torchtune.models.llama2.llama2_13b.rst", "generated/torchtune.models.llama2.llama2_70b.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2_13b.rst", "generated/torchtune.models.llama2.lora_llama2_70b.rst", "generated/torchtune.models.llama2.lora_llama2_7b.rst", "generated/torchtune.models.llama2.qlora_llama2_13b.rst", "generated/torchtune.models.llama2.qlora_llama2_7b.rst", "generated/torchtune.models.llama3.llama3_70b.rst", "generated/torchtune.models.llama3.llama3_8b.rst", "generated/torchtune.models.llama3.lora_llama3_70b.rst", "generated/torchtune.models.llama3.lora_llama3_8b.rst", "generated/torchtune.models.llama3.qlora_llama3_8b.rst", "generated/torchtune.models.mistral.lora_mistral_7b.rst", "generated/torchtune.models.mistral.mistral_7b.rst", "generated/torchtune.models.mistral.qlora_mistral_7b.rst", "generated/torchtune.models.phi3.lora_phi3_mini.rst", "generated/torchtune.models.phi3.phi3_mini.rst", "generated/torchtune.models.phi3.qlora_phi3_mini.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.modules.tokenizers.SentencePieceTokenizer.rst", "generated/torchtune.modules.tokenizers.TikTokenTokenizer.rst", "generated/torchtune.utils.FSDPPolicyType.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.generate.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_dtype.rst", "generated/torchtune.utils.get_full_finetune_fsdp_wrap_policy.rst", "generated/torchtune.utils.get_logger.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.list_dtypes.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.padded_collate.rst", "generated/torchtune.utils.profiler.rst", "generated/torchtune.utils.set_activation_checkpointing.rst", "generated/torchtune.utils.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst", "tutorials/chat.rst", "tutorials/datasets.rst", "tutorials/e2e_flow.rst", "tutorials/first_finetune_tutorial.rst", "tutorials/llama3.rst", "tutorials/lora_finetune.rst", "tutorials/qlora_finetune.rst"], "titles": ["torchtune.config", "torchtune.data", "torchtune.datasets", "torchtune.models", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "All About Configs", "What Are Recipes?", "Logging to Weights &amp; Biases", "instantiate", "parse", "validate", "AlpacaInstructTemplate", "ChatFormat", "ChatMLFormat", "GrammarErrorCorrectionTemplate", "InstructTemplate", "Llama2ChatFormat", "Message", "MistralChatFormat", "SummarizeTemplate", "sharegpt_to_llama2_messages", "truncate", "validate_messages", "ChatDataset", "ConcatDataset", "InstructDataset", "PackedDataset", "PreferenceDataset", "TextCompletionDataset", "alpaca_cleaned_dataset", "alpaca_dataset", "chat_dataset", "cnn_dailymail_articles_dataset", "grammar_dataset", "instruct_dataset", "samsum_dataset", "slimorca_dataset", "stack_exchanged_paired_dataset", "text_completion_dataset", "wikitext_dataset", "gemma_2b", "gemma_7b", "llama2_13b", "llama2_70b", "llama2_7b", "lora_llama2_13b", "lora_llama2_70b", "lora_llama2_7b", "qlora_llama2_13b", "qlora_llama2_7b", "llama3_70b", "llama3_8b", "lora_llama3_70b", "lora_llama3_8b", "qlora_llama3_8b", "lora_mistral_7b", "mistral_7b", "qlora_mistral_7b", "lora_phi3_mini", "phi3_mini", "qlora_phi3_mini", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "SentencePieceTokenizer", "TikTokenTokenizer", "torchtune.utils.FSDPPolicyType", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "generate", "get_device", "get_dtype", "get_full_finetune_fsdp_wrap_policy", "get_logger", "get_world_size_and_rank", "init_distributed", "list_dtypes", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "padded_collate", "profiler", "set_activation_checkpointing", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times", "Fine-tuning Llama3 with Chat Data", "Configuring Datasets for Fine-Tuning", "End-to-End Workflow with torchtune", "Fine-Tune Your First LLM", "Meta Llama3 in torchtune", "Finetuning Llama2 with LoRA", "Finetuning Llama2 with QLoRA"], "terms": {"For": [2, 5, 6, 7, 8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 40, 41, 63, 68, 79, 81, 93, 96, 97, 101, 104, 105, 106, 107, 108, 109, 110], "detail": [2, 6, 33, 38, 65, 78, 85, 95, 97, 106, 107, 108, 109, 110], "usag": [2, 70, 101, 105, 106, 107, 108, 110], "guid": [2, 7, 9, 102, 104, 105, 107, 109], "pleas": [2, 5, 50, 51, 56, 59, 62, 78, 85, 96, 101, 110], "see": [2, 5, 6, 9, 18, 20, 33, 38, 41, 50, 51, 56, 59, 62, 65, 72, 78, 81, 85, 86, 93, 95, 96, 97, 101, 102, 104, 105, 106, 107, 108, 109, 110], "our": [2, 6, 8, 102, 104, 105, 106, 107, 109, 110], "tutori": [2, 6, 96, 102, 104, 105, 106, 107, 108, 109, 110], "support": [2, 6, 8, 9, 10, 20, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 61, 63, 73, 80, 84, 89, 102, 104, 105, 106, 107, 108, 109, 110], "sever": 2, "wide": 2, "us": [2, 4, 6, 9, 10, 11, 15, 18, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 63, 64, 66, 67, 68, 69, 70, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 90, 91, 92, 93, 97, 100, 101, 102, 105, 107, 108, 109], "help": [2, 6, 18, 68, 79, 81, 100, 101, 102, 104, 105, 106, 107, 108, 110], "quickli": [2, 7, 30, 104, 105], "bootstrap": 2, "your": [2, 5, 9, 10, 25, 30, 92, 93, 100, 101, 102, 104, 105, 108, 109, 110], "fine": [2, 6, 8, 9, 28, 100, 102, 106, 109], "tune": [2, 3, 6, 7, 8, 9, 11, 28, 100, 101, 102, 106, 109, 110], "also": [2, 6, 7, 8, 9, 10, 33, 36, 40, 63, 68, 73, 83, 85, 93, 101, 104, 105, 106, 107, 108, 109, 110], "common": [2, 4, 7, 104, 105, 108, 109], "format": [2, 5, 13, 14, 15, 16, 17, 18, 20, 21, 22, 25, 27, 29, 31, 32, 33, 36, 38, 79, 80, 104, 106, 107, 108, 109], "like": [2, 6, 7, 8, 9, 25, 101, 104, 105, 106, 107, 109], "chat": [2, 14, 15, 18, 19, 22, 25, 33, 38], "model": [2, 6, 7, 8, 10, 15, 20, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 79, 80, 82, 85, 95, 96, 100, 102, 104, 105, 110], "instruct": [2, 3, 13, 15, 17, 19, 20, 27, 28, 29, 31, 32, 36, 40, 61, 100, 104, 107, 109, 110], "These": [2, 4, 6, 7, 8, 10, 28, 81, 104, 105, 106, 107, 108, 109, 110], "ar": [2, 4, 6, 7, 9, 10, 13, 16, 17, 18, 19, 20, 21, 24, 27, 28, 29, 31, 32, 33, 35, 36, 37, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 68, 73, 78, 79, 80, 82, 84, 101, 102, 104, 105, 106, 107, 108, 109, 110], "especi": [2, 102, 106], "specifi": [2, 6, 7, 8, 10, 33, 63, 68, 69, 78, 82, 85, 93, 96, 104, 105, 106, 107, 108, 110], "from": [2, 3, 6, 7, 8, 9, 10, 13, 16, 17, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 58, 64, 68, 69, 71, 72, 74, 76, 79, 80, 81, 82, 92, 93, 99, 101, 103, 105, 106, 107, 108, 109], "yaml": [2, 7, 8, 10, 11, 33, 36, 40, 81, 93, 102, 104, 105, 106, 107, 108, 109, 110], "config": [2, 6, 9, 10, 11, 12, 33, 36, 40, 63, 79, 81, 93, 102, 104, 105, 106, 108, 109, 110], "represent": [2, 109, 110], "abov": [2, 6, 70, 101, 106, 108, 109, 110], "all": [3, 4, 8, 12, 25, 26, 28, 33, 63, 64, 68, 70, 77, 79, 81, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109], "famili": [3, 8, 31, 32, 34, 38, 39, 41, 102, 108], "download": [3, 6, 98, 101, 104, 105, 108, 109, 110], "meta": [3, 6, 18, 79, 80, 104, 106, 107], "llama": [3, 6, 18, 25, 33, 66, 67, 79, 80, 104, 106, 107, 108, 109], "8b": [3, 53, 54, 55, 60, 104], "hf": [3, 6, 79, 104, 106, 107, 108], "token": [3, 6, 7, 8, 19, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 63, 67, 68, 69, 76, 77, 82, 85, 94, 105, 106, 107, 108, 109, 110], "access_token": 3, "pre": [3, 18, 28, 101, 104, 105], "train": [3, 5, 6, 8, 9, 18, 25, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 63, 67, 68, 69, 70, 71, 79, 80, 84, 95, 100, 102, 104, 105, 106, 108, 109, 110], "can": [3, 4, 6, 7, 8, 9, 10, 12, 19, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 40, 41, 66, 67, 76, 78, 79, 81, 85, 92, 93, 96, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110], "hug": [3, 6, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 71, 102, 107, 108], "face": [3, 6, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 71, 102, 107, 108], "hub": [3, 6, 105, 107], "follow": [3, 6, 8, 22, 25, 28, 63, 71, 93, 100, 101, 105, 106, 107, 108, 109, 110], "command": [3, 8, 9, 81, 101, 104, 105, 106, 107, 108, 109, 110], "2": [3, 6, 9, 24, 28, 38, 63, 76, 79, 80, 94, 97, 104, 106, 107, 108, 109], "7b": [3, 6, 27, 29, 30, 31, 32, 34, 36, 40, 41, 43, 46, 49, 51, 57, 58, 79, 80, 104, 107, 108, 109, 110], "mini": [3, 60, 61, 62], "microsoft": [3, 61], "4k": [3, 61], "hf_token": 3, "ignor": [3, 6, 63, 64], "pattern": [3, 77], "ai": [3, 58, 63, 93, 104, 108], "mistralai": 3, "v0": 3, "1": [3, 6, 8, 28, 38, 63, 68, 71, 76, 77, 80, 82, 92, 93, 94, 97, 104, 106, 107, 108, 109, 110], "size": [3, 6, 8, 10, 31, 32, 35, 37, 63, 65, 66, 67, 68, 69, 87, 102, 105, 106, 107, 108, 109], "2b": [3, 42], "googl": [3, 42, 43], "offer": 5, "allow": [5, 26, 92, 110], "seamless": 5, "transit": 5, "between": [5, 6, 79, 105, 106, 108, 109, 110], "interoper": [5, 6, 8, 102, 106, 110], "rest": [5, 104, 110], "ecosystem": [5, 6, 8, 102, 106, 108, 110], "comprehens": 5, "overview": [5, 7, 9, 100, 107, 109, 110], "deep": [5, 6, 7, 8, 9, 102, 107, 108], "dive": [5, 6, 7, 8, 9, 102, 107, 108], "enabl": [5, 7, 8, 9, 26, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 73, 95, 97, 108, 109, 110], "work": [5, 6, 8, 81, 102, 106, 108, 110], "set": [5, 6, 7, 8, 9, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 40, 41, 67, 68, 75, 78, 83, 85, 96, 97, 102, 104, 106, 107, 108, 109], "consumpt": [5, 26], "dure": [5, 6, 26, 27, 28, 31, 32, 35, 37, 63, 65, 67, 68, 69, 70, 104, 106, 108, 109, 110], "provid": [5, 6, 7, 8, 10, 15, 20, 23, 25, 26, 27, 28, 29, 38, 68, 81, 85, 93, 102, 104, 105, 106, 107, 108], "debug": [5, 6, 7, 8], "finetun": [5, 6, 7, 8, 47, 48, 49, 54, 55, 60, 89, 100, 102, 107, 108], "job": [5, 9, 97, 107], "variou": [5, 17], "dataset": [5, 7, 13, 16, 17, 19, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 102, 107, 108], "walk": [6, 8, 92, 102, 104, 105, 106, 107, 110], "you": [6, 7, 8, 9, 10, 17, 18, 25, 27, 29, 30, 31, 32, 34, 36, 40, 41, 81, 82, 92, 93, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110], "through": [6, 7, 8, 9, 64, 102, 104, 105, 106, 107, 110], "design": [6, 8], "behavior": [6, 104, 105], "associ": [6, 7, 8, 82, 106, 109], "util": [6, 7, 8, 9, 10, 26, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 102, 106, 107, 108, 110], "what": [6, 7, 9, 18, 20, 35, 37, 100, 104, 105, 106, 107, 108], "cover": [6, 7, 8, 9, 104, 106, 110], "how": [6, 7, 8, 9, 78, 96, 100, 104, 105, 106, 107, 108, 110], "we": [6, 7, 8, 9, 27, 28, 29, 30, 31, 32, 34, 36, 40, 41, 63, 65, 67, 68, 73, 76, 79, 80, 82, 84, 102, 104, 105, 106, 107, 108, 109, 110], "them": [6, 7, 25, 26, 27, 29, 36, 64, 70, 76, 104, 105, 106, 109, 110], "scenario": [6, 26], "full": [6, 7, 8, 33, 36, 50, 51, 56, 59, 62, 76, 102, 105, 108, 109], "compos": 6, "compon": [6, 8, 12, 95, 102, 105, 107, 109, 110], "which": [6, 8, 26, 27, 28, 31, 32, 35, 37, 47, 48, 49, 54, 55, 57, 60, 63, 67, 68, 69, 71, 76, 79, 80, 84, 90, 93, 96, 102, 104, 105, 106, 107, 108, 109, 110], "plug": 6, "ani": [6, 7, 8, 10, 11, 12, 13, 16, 17, 21, 22, 23, 25, 27, 29, 30, 33, 34, 36, 40, 41, 70, 74, 75, 76, 79, 80, 82, 97, 104, 105, 106, 107, 108, 109], "recip": [6, 7, 9, 10, 11, 64, 79, 80, 102, 104, 105, 106, 108, 110], "evalu": [6, 8, 100, 102, 107, 109, 110], "gener": [6, 8, 13, 16, 21, 25, 27, 28, 29, 34, 38, 76, 97, 98, 100, 104, 105, 109, 110], "each": [6, 8, 14, 17, 26, 28, 47, 48, 49, 54, 55, 57, 60, 63, 67, 68, 69, 76, 77, 97, 102, 105, 106, 107, 108, 109], "make": [6, 7, 8, 9, 63, 69, 102, 106, 107, 108, 109, 110], "easi": [6, 8, 102, 105, 109], "understand": [6, 7, 8, 100, 102, 104, 105, 109, 110], "extend": [6, 8, 102], "befor": [6, 24, 27, 28, 29, 63, 68, 69, 73, 79, 106], "let": [6, 7, 9, 104, 105, 106, 107, 108, 109, 110], "s": [6, 7, 8, 9, 10, 11, 13, 14, 15, 18, 20, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 47, 48, 49, 54, 55, 57, 60, 63, 65, 67, 68, 69, 70, 72, 74, 77, 78, 79, 80, 83, 85, 92, 95, 96, 102, 104, 105, 107, 109, 110], "defin": [6, 7, 8, 64, 72, 73, 74, 105, 107, 109], "some": [6, 7, 15, 74, 75, 100, 102, 104, 105, 106, 107, 109, 110], "concept": [6, 106, 107], "In": [6, 7, 8, 25, 67, 73, 78, 92, 93, 104, 106, 108, 109, 110], "ll": [6, 7, 8, 77, 82, 102, 104, 105, 106, 107, 108, 110], "talk": 6, "about": [6, 8, 79, 93, 102, 104, 106, 107, 108, 109, 110], "take": [6, 7, 8, 10, 64, 65, 70, 79, 81, 83, 104, 105, 106, 107, 108, 109, 110], "close": [6, 8, 90, 91, 92, 93, 109], "look": [6, 7, 8, 92, 101, 104, 105, 106, 107, 108, 109], "veri": [6, 26, 68, 106], "simpli": [6, 7, 28, 104, 105, 106, 108, 110], "dictat": 6, "state_dict": [6, 70, 79, 80, 109, 110], "store": [6, 26, 90, 93, 109, 110], "file": [6, 7, 8, 9, 10, 11, 76, 77, 79, 80, 81, 90, 93, 95, 99, 102, 103, 104, 105, 106, 107, 108, 109, 110], "disk": [6, 30, 90], "weight": [6, 8, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 63, 70, 72, 73, 79, 80, 93, 100, 104, 106, 107, 108, 109, 110], "string": [6, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 72, 76, 77, 83, 84, 105], "kei": [6, 7, 9, 25, 27, 29, 36, 63, 65, 68, 69, 75, 79, 106, 107, 109, 110], "identifi": 6, "state": [6, 8, 70, 74, 75, 79, 80, 106, 108, 109, 110], "dict": [6, 7, 8, 9, 10, 13, 16, 17, 19, 21, 22, 25, 27, 29, 30, 33, 34, 36, 40, 41, 70, 74, 75, 79, 80, 88, 94, 105], "If": [6, 7, 12, 13, 16, 17, 20, 21, 23, 24, 25, 27, 29, 31, 32, 35, 36, 37, 38, 63, 67, 68, 69, 70, 73, 79, 80, 82, 83, 84, 85, 88, 92, 93, 97, 101, 104, 105, 106, 107, 108, 109], "don": [6, 7, 8, 93, 97, 104, 105, 106, 107, 108, 110], "t": [6, 7, 8, 77, 84, 93, 97, 104, 105, 106, 107, 108, 110], "match": [6, 25, 27, 29, 36, 101, 105, 106, 108, 109], "up": [6, 8, 9, 27, 28, 29, 30, 31, 32, 34, 36, 40, 41, 104, 105, 107, 108, 109, 110], "exactli": 6, "those": [6, 109], "definit": [6, 109], "either": [6, 79, 82, 96, 109, 110], "run": [6, 7, 9, 11, 64, 65, 68, 70, 79, 80, 92, 93, 101, 102, 104, 105, 107, 108, 109, 110], "explicit": 6, "error": [6, 7, 24, 79, 97], "load": [6, 8, 25, 26, 27, 28, 29, 30, 79, 80, 81, 92, 104, 105, 106, 108, 109], "rais": [6, 10, 12, 20, 24, 33, 38, 63, 65, 68, 79, 80, 84, 88, 93, 97], "an": [6, 7, 8, 9, 10, 13, 19, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 63, 68, 72, 74, 75, 78, 79, 80, 85, 93, 102, 104, 105, 106, 107, 108, 109, 110], "except": [6, 19, 20, 105], "wors": 6, "silent": [6, 64], "succe": 6, "infer": [6, 18, 25, 63, 65, 67, 68, 69, 100, 104, 106, 107, 108, 110], "expect": [6, 7, 10, 13, 16, 17, 21, 25, 27, 29, 33, 36, 67, 93, 104, 105, 109], "addit": [6, 7, 8, 10, 25, 27, 29, 30, 33, 34, 36, 40, 41, 78, 79, 80, 84, 85, 88, 90, 92, 93, 96, 102, 104, 107, 109], "line": [6, 8, 81, 105, 107, 108], "need": [6, 7, 8, 9, 17, 25, 28, 38, 63, 64, 68, 92, 93, 101, 104, 105, 106, 107, 108, 109, 110], "shape": [6, 63, 65, 67, 68, 69, 73, 82], "valu": [6, 7, 22, 38, 42, 43, 44, 45, 46, 52, 53, 58, 63, 65, 66, 68, 69, 71, 79, 81, 82, 90, 91, 92, 93, 97, 105, 107, 108, 109], "two": [6, 7, 24, 102, 106, 107, 108, 109, 110], "popular": [6, 102, 105, 106], "llama2": [6, 7, 8, 10, 18, 22, 25, 27, 29, 30, 31, 32, 34, 36, 38, 40, 41, 44, 45, 46, 47, 48, 49, 50, 51, 64, 68, 69, 76, 100, 102, 107, 108], "offici": [6, 18, 104, 107, 108], "implement": [6, 8, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 64, 66, 67, 71, 72, 73, 79, 92, 102, 105, 109, 110], "when": [6, 7, 8, 11, 19, 26, 28, 63, 67, 68, 69, 70, 71, 82, 85, 92, 106, 108, 109, 110], "websit": 6, "get": [6, 7, 8, 9, 25, 76, 84, 86, 87, 101, 102, 104, 105, 106, 107, 109], "access": [6, 7, 8, 26, 79, 106, 107], "singl": [6, 7, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 26, 28, 63, 79, 80, 104, 105, 106, 107, 108, 109, 110], "pth": [6, 106, 108], "inspect": [6, 106, 109, 110], "content": [6, 19, 22, 25, 76, 104, 105], "easili": [6, 7, 102, 105, 109, 110], "torch": [6, 26, 65, 68, 70, 71, 82, 83, 84, 88, 95, 96, 97, 106, 107, 108, 109, 110], "import": [6, 7, 10, 33, 36, 40, 92, 93, 104, 105, 106, 107, 109, 110], "consolid": [6, 108], "00": [6, 99, 103, 107, 108], "mmap": [6, 106], "true": [6, 7, 19, 27, 28, 31, 32, 33, 35, 36, 37, 50, 51, 56, 59, 62, 63, 68, 69, 70, 76, 77, 78, 79, 80, 85, 88, 92, 104, 105, 106, 108, 109, 110], "weights_onli": 6, "map_loc": [6, 106], "cpu": [6, 8, 70, 84, 101, 106, 110], "tensor": [6, 63, 64, 65, 66, 67, 68, 69, 70, 73, 79, 82, 90, 91, 92, 93, 94, 109, 110], "item": 6, "print": [6, 9, 26, 31, 32, 35, 37, 38, 76, 82, 104, 105, 107, 109, 110], "f": [6, 9, 31, 32, 35, 37, 104, 106, 109, 110], "tok_embed": [6, 68], "32000": [6, 10, 109], "4096": [6, 10, 27, 29, 30, 31, 32, 34, 36, 40, 41, 63, 67, 105, 109], "len": [6, 26, 31, 32, 35, 37, 68], "292": 6, "The": [6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 35, 37, 38, 39, 47, 48, 49, 54, 55, 60, 66, 67, 70, 71, 76, 77, 78, 79, 81, 83, 84, 86, 93, 95, 97, 101, 102, 104, 105, 106, 107, 108, 109, 110], "contain": [6, 19, 26, 28, 30, 40, 63, 65, 67, 68, 69, 72, 74, 75, 76, 77, 79, 80, 81, 92, 94, 104, 106, 108, 109], "includ": [6, 7, 8, 14, 17, 73, 79, 80, 81, 102, 104, 105, 106, 107, 108, 109, 110], "input": [6, 13, 14, 17, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 63, 64, 66, 67, 68, 69, 73, 76, 79, 94, 97, 104, 105, 109, 110], "embed": [6, 63, 65, 66, 67, 68, 85, 104, 108], "tabl": [6, 104, 110], "call": [6, 10, 19, 64, 70, 81, 90, 91, 92, 93, 104, 105, 109, 110], "layer": [6, 8, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 63, 68, 69, 73, 78, 85, 102, 108, 109, 110], "have": [6, 7, 10, 63, 65, 72, 81, 85, 92, 95, 101, 104, 105, 106, 107, 108, 109, 110], "dim": [6, 63, 64, 66, 67, 68, 69], "most": [6, 7, 77, 104, 107, 109, 110], "within": [6, 7, 10, 25, 28, 38, 64, 82, 92, 97, 105, 106, 108, 109, 110], "default": [6, 7, 15, 19, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 57, 58, 60, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 77, 79, 80, 81, 82, 84, 90, 93, 94, 95, 97, 101, 104, 105, 106, 108, 109, 110], "everi": [6, 8, 64, 92, 101, 110], "repo": [6, 79, 80, 106], "first": [6, 7, 10, 24, 28, 65, 68, 77, 79, 81, 100, 102, 104, 105, 106, 108, 109, 110], "big": [6, 106], "split": [6, 28, 104, 105, 106], "across": [6, 8, 26, 79, 92, 97, 106, 108], "bin": [6, 106], "To": [6, 7, 8, 9, 28, 79, 101, 102, 104, 105, 106, 107, 108, 109, 110], "correctli": [6, 8, 12, 79, 101, 104, 107, 110], "piec": 6, "one": [6, 8, 24, 64, 76, 104, 105, 106, 107, 108, 110], "pytorch_model": [6, 106], "00001": 6, "00002": 6, "embed_token": 6, "241": 6, "Not": 6, "onli": [6, 9, 19, 28, 34, 73, 74, 76, 80, 81, 82, 84, 85, 105, 106, 107, 108, 109, 110], "doe": [6, 20, 25, 28, 61, 63, 68, 69, 72, 79, 81, 104, 106], "fewer": [6, 63], "sinc": [6, 7, 10, 64, 79, 104, 106, 108], "instead": [6, 8, 28, 33, 36, 40, 64, 65, 73, 106, 108, 109], "mismatch": 6, "name": [6, 7, 9, 13, 16, 17, 21, 25, 27, 29, 30, 36, 38, 40, 41, 72, 75, 77, 79, 80, 81, 82, 83, 90, 91, 92, 93, 104, 106, 108], "caus": [6, 76], "try": [6, 7, 104, 106, 107, 108, 110], "same": [6, 7, 47, 48, 49, 54, 55, 60, 63, 65, 69, 76, 81, 85, 93, 104, 106, 108, 109, 110], "As": [6, 7, 8, 9, 73, 102, 106, 108, 110], "re": [6, 7, 77, 102, 104, 106, 107, 108, 109], "care": [6, 64, 79, 106, 108, 109], "end": [6, 8, 19, 26, 77, 100, 102, 104, 108, 109], "number": [6, 8, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 63, 65, 68, 71, 79, 80, 82, 87, 97, 107, 109], "just": [6, 13, 102, 104, 105, 107, 108, 109], "save": [6, 8, 9, 70, 79, 80, 85, 93, 100, 104, 105, 106, 108, 109], "less": [6, 38, 106, 107, 108, 110], "prone": 6, "manag": [6, 26, 95, 104], "invari": 6, "accept": [6, 7, 38, 76, 78, 105, 107, 110], "multipl": [6, 7, 8, 19, 25, 26, 63, 68, 69, 73, 90, 91, 92, 93, 107, 108], "sourc": [6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 57, 58, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 104, 105, 106], "worri": [6, 104, 107], "explicitli": [6, 72, 102, 109], "convert": [6, 22, 25, 79, 94, 104, 106, 110], "time": [6, 76, 90, 92, 104, 105, 106, 108, 110], "produc": [6, 110], "back": [6, 24, 79, 105, 109, 110], "origin": [6, 31, 32, 70, 73, 104, 106, 108, 109, 110], "form": [6, 7, 8, 24], "One": [6, 106], "advantag": [6, 109], "being": [6, 79, 80, 83, 110], "should": [6, 7, 8, 14, 17, 18, 19, 20, 22, 28, 33, 36, 40, 47, 48, 49, 54, 55, 57, 60, 63, 64, 72, 78, 81, 90, 91, 92, 93, 101, 102, 105, 106, 107, 108, 109, 110], "abl": [6, 8, 106, 107, 108], "post": [6, 110], "tool": [6, 105, 106, 107], "quantiz": [6, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 73, 100, 107, 110], "eval": [6, 100, 102], "without": [6, 7, 9, 101, 102, 104, 106, 109], "code": [6, 8, 68, 98, 102, 105, 107], "chang": [6, 7, 9, 13, 101, 106, 107, 108, 109, 110], "OR": 6, "convers": [6, 14, 15, 18, 20, 22, 24, 25, 33, 38, 79, 102, 104, 105, 106, 108, 109, 110], "script": [6, 9, 106, 107, 108], "wai": [6, 7, 25, 104, 105, 106, 107, 108], "surround": [6, 8, 102], "load_checkpoint": [6, 8, 79, 80], "save_checkpoint": [6, 8, 9, 79, 80], "method": [6, 7, 8, 9, 11, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 70, 72, 74, 81, 101, 102, 105, 106, 108, 109, 110], "convertor": 6, "avail": [6, 8, 41, 81, 83, 84, 102, 106, 108, 109], "here": [6, 7, 9, 15, 35, 66, 67, 104, 105, 106, 107, 108, 109, 110], "three": [6, 8, 107], "hfcheckpoint": 6, "read": [6, 79, 80, 102], "write": [6, 8, 79, 80, 90, 104, 105, 107], "compat": [6, 79], "transform": [6, 8, 25, 27, 29, 47, 48, 49, 54, 55, 57, 60, 68, 69, 71, 96, 109], "framework": [6, 8, 102], "mention": [6, 106, 110], "assum": [6, 13, 16, 17, 21, 27, 29, 36, 63, 67, 68, 69, 71, 74, 77, 84, 106, 109], "checkpoint_dir": [6, 7, 79, 80, 106, 108], "necessari": [6, 38, 90, 91, 92, 93, 104, 109], "json": [6, 79, 95, 105, 106], "easiest": [6, 106, 107], "sure": [6, 7, 106, 107, 108, 109, 110], "everyth": [6, 8, 81, 102, 107], "flow": [6, 25, 27, 28, 29, 110], "By": [6, 108, 109, 110], "safetensor": 6, "output": [6, 17, 31, 32, 35, 38, 47, 48, 49, 54, 55, 57, 60, 63, 64, 66, 67, 68, 69, 73, 75, 82, 85, 91, 95, 101, 104, 105, 106, 107, 108, 109, 110], "dir": [6, 93, 101, 106, 107, 108], "output_dir": [6, 7, 79, 80, 95, 106, 108, 109, 110], "argument": [6, 7, 10, 17, 25, 27, 29, 30, 33, 34, 36, 38, 40, 41, 50, 51, 56, 59, 62, 63, 78, 81, 85, 88, 90, 92, 93, 96, 104, 105, 108, 109], "snippet": 6, "explain": 6, "setup": [6, 7, 8, 68, 96, 105, 106, 109, 110], "_component_": [6, 7, 9, 10, 33, 36, 40, 104, 105, 106, 108, 109], "fullmodelhfcheckpoint": [6, 106], "directori": [6, 7, 79, 80, 90, 92, 93, 106, 107, 108], "sort": [6, 79], "id": [6, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 63, 67, 68, 69, 76, 77, 79, 82, 94, 104, 105, 106], "so": [6, 7, 28, 79, 81, 101, 102, 104, 106, 107, 108, 109, 110], "order": [6, 8, 79, 92, 93, 107], "matter": [6, 79, 109], "checkpoint_fil": [6, 7, 9, 79, 80, 106, 108, 109, 110], "restart": 6, "previou": [6, 28, 79, 80], "more": [6, 7, 8, 33, 38, 65, 67, 78, 81, 93, 95, 96, 97, 102, 105, 106, 107, 108, 109, 110], "next": [6, 28, 82, 108, 110], "section": [6, 8, 100, 106, 108, 110], "recipe_checkpoint": [6, 79, 80], "null": [6, 7], "usual": [6, 67, 79, 93, 106, 109], "model_typ": [6, 79, 80, 106, 108], "resume_from_checkpoint": [6, 79, 80], "fals": [6, 7, 19, 22, 25, 27, 28, 31, 32, 33, 35, 36, 37, 38, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 63, 68, 69, 73, 76, 77, 79, 80, 95, 104, 105, 106, 108, 109, 110], "requir": [6, 7, 26, 30, 38, 40, 79, 92, 93, 97, 101, 104, 105, 107, 110], "param": [6, 8, 47, 48, 49, 54, 55, 60, 73, 74, 75, 79, 109, 110], "directli": [6, 7, 8, 10, 33, 36, 40, 78, 79, 106, 107, 108, 109, 110], "ensur": [6, 7, 12, 24, 38, 63, 79, 84, 102, 105, 107], "out": [6, 7, 8, 25, 27, 31, 32, 33, 35, 37, 79, 80, 100, 102, 104, 106, 107, 108, 109, 110], "case": [6, 8, 9, 19, 63, 79, 84, 90, 96, 102, 104, 105, 106, 108, 109, 110], "discrep": [6, 79], "along": [6, 108, 109], "found": [6, 7, 9, 66, 67, 109, 110], "metacheckpoint": 6, "github": [6, 10, 47, 48, 49, 54, 55, 60, 63, 66, 67, 71, 101, 105, 107], "repositori": [6, 18, 106, 107], "fullmodelmetacheckpoint": [6, 108], "torchtunecheckpoint": 6, "perform": [6, 28, 64, 82, 102, 104, 106, 108, 110], "current": [6, 28, 61, 63, 65, 67, 68, 69, 80, 85, 87, 90, 92, 97, 106, 107, 108], "test": [6, 7, 8, 102, 104], "complet": [6, 8, 28, 34, 104, 105, 106, 107, 108], "written": [6, 7, 8, 79, 80, 90, 91, 92, 93, 102], "begin": [6, 28, 76, 77, 104, 108, 110], "partit": [6, 110], "ha": [6, 72, 74, 76, 105, 106, 107, 108, 109, 110], "standard": [6, 91, 102, 104, 106, 108], "key_1": 6, "weight_1": 6, "key_2": 6, "weight_2": 6, "mid": 6, "chekpoint": 6, "middl": [6, 106], "inform": [6, 19, 93, 96, 102, 106, 107, 108], "subsequ": [6, 8], "recipe_st": [6, 79, 80], "pt": [6, 9, 79, 80, 106, 108], "epoch": [6, 8, 9, 71, 79, 80, 104, 106, 107, 108], "optim": [6, 7, 8, 26, 61, 71, 104, 106, 107, 108, 109, 110], "etc": [6, 8, 79, 107], "prevent": [6, 28], "flood": 6, "overwritten": 6, "note": [6, 7, 17, 19, 68, 72, 76, 79, 95, 97, 104, 105, 106, 109, 110], "updat": [6, 7, 8, 65, 101, 104, 106, 107, 108, 109, 110], "hf_model_0001_0": [6, 106], "hf_model_0002_0": [6, 106], "both": [6, 26, 106, 109, 110], "adapt": [6, 72, 73, 74, 75, 79, 80, 104, 106, 109, 110], "merg": [6, 10, 79, 106, 108, 110], "would": [6, 7, 9, 28, 68, 101, 104, 105, 106, 109, 110], "primari": [6, 7, 8, 107], "want": [6, 7, 8, 9, 10, 25, 82, 101, 104, 105, 106, 107, 108, 109], "resum": [6, 8, 71, 79, 80, 110], "initi": [6, 8, 11, 26, 28, 42, 43, 44, 45, 46, 52, 53, 58, 88, 107, 109, 110], "frozen": [6, 109, 110], "base": [6, 10, 27, 29, 38, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 67, 71, 73, 75, 79, 81, 85, 90, 100, 104, 106, 107, 108, 109, 110], "well": [6, 7, 8, 102, 105, 106, 108, 110], "learnt": [6, 104, 106], "someth": [6, 8, 9, 104, 106], "NOT": 6, "refer": [6, 7, 8, 66, 67, 102, 109], "adapter_checkpoint": [6, 79, 80], "adapter_0": [6, 106], "now": [6, 76, 104, 105, 106, 107, 108, 109, 110], "knowledg": 6, "creat": [6, 7, 10, 28, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 65, 71, 78, 79, 80, 90, 92, 104, 105, 106, 108, 110], "simpl": [6, 8, 100, 105, 107, 109, 110], "forward": [6, 8, 63, 64, 66, 67, 68, 69, 73, 108, 109, 110], "13b": [6, 44, 47, 50], "modeltyp": [6, 79, 80], "llama2_13b": [6, 47], "right": [6, 79, 106, 108, 109], "pytorch_fil": 6, "00003": 6, "torchtune_sd": 6, "load_state_dict": [6, 109], "successfulli": [6, 107], "vocab": [6, 10, 68, 108], "70": [6, 52], "x": [6, 63, 64, 66, 67, 68, 69, 73, 82, 109, 110], "randint": 6, "0": [6, 8, 28, 47, 48, 49, 50, 51, 63, 68, 71, 73, 76, 82, 92, 93, 94, 97, 99, 103, 104, 105, 106, 107, 108, 109, 110], "no_grad": 6, "6": [6, 28, 66, 94, 106, 110], "3989": 6, "9": [6, 106, 110], "0531": 6, "3": [6, 28, 60, 61, 77, 81, 86, 94, 104, 106, 107, 108, 110], "2375": 6, "5": [6, 71, 94, 95, 106, 107, 108], "2822": 6, "4": [6, 38, 63, 94, 102, 106, 108, 109, 110], "4872": 6, "7469": 6, "8": [6, 31, 32, 35, 37, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 106, 109, 110], "6737": 6, "11": [6, 106, 108, 110], "0023": 6, "8235": 6, "6819": 6, "2424": 6, "0109": 6, "6915": 6, "7": [6, 94], "3618": 6, "1628": 6, "8594": 6, "5857": 6, "1151": 6, "7808": 6, "2322": 6, "8850": 6, "9604": 6, "7624": 6, "6040": 6, "3159": 6, "5849": 6, "8039": 6, "9322": 6, "2010": 6, "6824": 6, "8929": 6, "8465": 6, "3794": 6, "3500": 6, "6145": 6, "5931": 6, "do": [6, 8, 25, 27, 29, 36, 38, 93, 104, 105, 106, 107, 108, 109], "find": [6, 8, 9, 106, 107, 109], "list": [6, 7, 14, 15, 18, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 72, 73, 76, 77, 79, 80, 81, 82, 86, 89, 94, 104, 105, 107, 108], "builder": [6, 34, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 104, 105, 110], "hope": 6, "deeper": [6, 107], "insight": [6, 106], "happi": [6, 106], "thi": [7, 8, 9, 10, 19, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 40, 41, 61, 63, 64, 67, 68, 69, 70, 71, 72, 76, 78, 79, 80, 81, 82, 83, 84, 90, 92, 93, 95, 96, 97, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110], "pars": [7, 10, 77, 81, 104, 107], "effect": 7, "cli": [7, 9, 11, 101, 106, 107], "prerequisit": [7, 104, 105, 106, 107, 108, 109, 110], "Be": [7, 104, 106, 107, 108, 109, 110], "familiar": [7, 104, 106, 107, 108, 109, 110], "torchtun": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 101, 104, 105, 107], "instal": [7, 9, 92, 93, 100, 106, 107, 108, 109, 110], "fundament": 7, "There": [7, 14, 24, 104, 106, 107, 108, 109], "entri": [7, 8, 107], "point": [7, 8, 22, 105, 106, 107, 108, 109, 110], "locat": [7, 108, 109, 110], "thei": [7, 8, 19, 26, 68, 81, 104, 105, 109], "truth": [7, 106, 108], "reproduc": 7, "overridden": [7, 64, 81], "quick": [7, 26], "experiment": 7, "modifi": [7, 8, 9, 70, 102, 106, 108, 109, 110], "serv": [7, 78, 105, 109], "particular": [7, 25, 26, 38, 78, 105, 109, 110], "seed": [7, 8, 9, 97, 107], "shuffl": [7, 28], "devic": [7, 8, 83, 84, 104, 106, 107, 108, 109], "cuda": [7, 83, 84, 101, 106, 110], "dtype": [7, 8, 65, 68, 70, 84, 89, 106, 110], "fp32": [7, 110], "enable_fsdp": 7, "mani": [7, 28, 105, 106], "object": [7, 10, 14, 15, 18, 20, 63, 78, 104], "keyword": [7, 10, 25, 27, 29, 30, 33, 34, 36, 38, 40, 41, 70, 104, 105], "loss": [7, 8, 27, 31, 32, 35, 37, 107, 109, 110], "function": [7, 8, 10, 11, 25, 63, 64, 70, 78, 82, 83, 87, 97, 102, 104, 105, 110], "exampl": [7, 8, 9, 10, 11, 15, 18, 20, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 63, 72, 76, 78, 79, 80, 82, 92, 93, 94, 98, 99, 101, 103, 104, 105, 106, 108, 109, 110], "subfield": 7, "dotpath": 7, "wish": [7, 105], "exact": [7, 10, 106], "path": [7, 8, 9, 10, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 76, 77, 79, 80, 81, 95, 104, 105, 106, 108, 109], "normal": [7, 25, 28, 66, 68, 69, 76, 104, 105, 109, 110], "python": [7, 77, 81, 86, 93, 97, 98, 106], "alpaca_dataset": [7, 31, 105], "custom": [7, 8, 25, 27, 29, 33, 36, 40, 96, 102, 106, 107, 108, 109], "train_on_input": [7, 22, 25, 27, 31, 32, 33, 35, 36, 37, 38, 104, 105], "onc": [7, 106, 107, 108, 109, 110], "ve": [7, 65, 77, 104, 105, 106, 108, 109], "instanc": [7, 10, 26, 64, 70, 74, 75, 109], "cfg": [7, 8, 11, 12], "automat": [7, 9, 10, 33, 106, 110], "under": [7, 105, 106, 108, 110], "preced": [7, 10, 108, 109], "actual": [7, 9, 25, 104], "throw": 7, "notic": [7, 104, 105, 109], "miss": [7, 109], "posit": [7, 10, 28, 63, 65, 67, 68, 69, 108], "anoth": [7, 106], "handl": [7, 11, 19, 26, 76, 104, 106, 109, 110], "def": [7, 8, 9, 11, 78, 104, 105, 109, 110], "dictconfig": [7, 8, 10, 11, 12, 93], "arg": [7, 10, 68, 70, 72, 81, 91], "tupl": [7, 10, 26, 38, 65, 70, 76, 77, 78, 81, 87, 94], "kwarg": [7, 10, 70, 72, 81, 88, 90, 91, 92, 93, 96, 105], "str": [7, 10, 13, 16, 17, 19, 21, 22, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 70, 72, 73, 74, 75, 76, 77, 79, 80, 81, 83, 84, 86, 89, 90, 91, 92, 93, 94, 95, 97, 104, 105], "mean": [7, 63, 66, 68, 69, 104, 105, 107, 109], "pass": [7, 10, 25, 26, 27, 29, 30, 33, 34, 36, 40, 41, 63, 64, 70, 78, 84, 85, 88, 92, 93, 96, 104, 105, 109, 110], "add": [7, 9, 25, 28, 77, 81, 105, 106, 108, 109, 110], "d": [7, 19, 63, 65, 68, 69, 77, 104, 109], "llama2_token": [7, 106], "tmp": [7, 104, 107, 108], "option": [7, 8, 13, 16, 17, 21, 23, 25, 27, 28, 29, 30, 33, 34, 36, 38, 40, 41, 47, 48, 49, 54, 55, 57, 60, 63, 67, 68, 69, 70, 76, 77, 79, 80, 82, 83, 84, 86, 90, 93, 95, 97, 101, 102, 105, 106], "bool": [7, 19, 22, 25, 27, 28, 31, 32, 33, 35, 36, 37, 38, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 70, 73, 76, 77, 78, 79, 80, 85, 88, 92, 95, 96, 104, 110], "max_seq_len": [7, 10, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 63, 65, 67, 68, 76, 77, 104, 105], "int": [7, 9, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 63, 65, 66, 67, 68, 71, 73, 76, 77, 78, 79, 80, 82, 85, 87, 90, 91, 92, 93, 94, 96, 97, 104, 105, 109, 110], "512": [7, 31, 32, 105, 110], "instructdataset": [7, 31, 32, 35, 36, 37, 105], "alreadi": [7, 88, 101, 105, 106, 109], "overwrit": [7, 101], "duplic": [7, 8, 102], "sometim": 7, "than": [7, 24, 38, 63, 65, 78, 104, 105, 106, 107, 108, 109, 110], "resolv": [7, 107], "alpaca": [7, 13, 31, 32, 47, 48, 49, 54, 55, 60, 105], "metric_logg": [7, 8, 9], "metric_log": [7, 9, 90, 91, 92, 93], "disklogg": 7, "log_dir": [7, 90, 92, 93], "conveni": [7, 8], "verifi": [7, 83, 84, 85, 104, 107, 109], "properli": 7, "experi": [7, 93, 100, 102, 104, 108, 109], "wa": [7, 104, 106, 108, 109, 110], "cp": [7, 101, 104, 106, 107, 108], "7b_lora_single_devic": [7, 106, 107, 109, 110], "my_config": 7, "discuss": [7, 107, 109], "guidelin": 7, "while": [7, 8, 47, 48, 49, 54, 55, 60, 64, 102, 106, 110], "mai": [7, 9, 85, 95, 104, 105, 107, 109], "tempt": 7, "put": [7, 8, 107, 109], "much": [7, 106, 108, 109, 110], "give": [7, 105, 109], "maximum": [7, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 63, 65, 67, 68, 77], "flexibl": [7, 26, 105], "switch": 7, "encourag": [7, 109], "clariti": 7, "significantli": 7, "easier": [7, 106, 107], "dont": 7, "slimorca_dataset": 7, "privat": 7, "typic": [7, 28, 30, 40, 105, 110], "expos": [7, 8, 104, 107], "parent": 7, "modul": [7, 10, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 85, 96, 97, 104, 107, 109, 110], "__init__": [7, 8, 109, 110], "py": [7, 10, 47, 48, 49, 54, 55, 60, 63, 65, 66, 67, 71, 106, 108], "guarante": 7, "stabil": [7, 102, 110], "underscor": 7, "_alpaca": 7, "collect": [7, 82, 107], "differ": [7, 9, 25, 26, 27, 29, 76, 102, 104, 106, 108, 109, 110], "itself": 7, "via": [7, 9, 33, 36, 40, 73, 79, 109, 110], "pair": [7, 39, 94, 105], "k1": [7, 8], "v1": [7, 8, 41], "k2": [7, 8], "v2": [7, 8, 105], "lora_finetune_single_devic": [7, 104, 106, 107, 108, 109, 110], "checkpoint": [7, 8, 70, 77, 79, 80, 93, 96, 102, 108, 109, 110], "home": 7, "my_model_checkpoint": 7, "file_1": 7, "file_2": 7, "my_tokenizer_path": 7, "class": [7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 33, 36, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 79, 80, 81, 90, 91, 92, 93, 104, 105, 107, 109, 110], "assign": 7, "nest": 7, "dot": 7, "notat": [7, 63, 67, 68, 69], "core": [8, 102, 105, 107, 110], "i": [8, 18, 20, 63, 68, 69, 70, 75, 77, 82, 105, 106, 108, 110], "structur": [8, 14, 15, 18, 20, 25, 104, 105, 106], "new": [8, 34, 58, 90, 92, 104, 106, 107, 108, 109, 110], "user": [8, 14, 15, 18, 19, 20, 22, 24, 25, 63, 76, 104, 105, 107], "thought": [8, 102, 107, 110], "target": [8, 102], "pipelin": [8, 102], "llm": [8, 100, 102, 105, 106, 109], "eg": [8, 68, 79, 102], "meaning": [8, 102, 106], "featur": [8, 9, 101, 102, 106, 107], "fsdp": [8, 78, 85, 102, 107, 108], "activ": [8, 64, 96, 102, 110], "gradient": [8, 102, 106, 108, 109, 110], "accumul": [8, 102], "mix": [8, 105, 106], "precis": [8, 70, 84, 102, 107, 110], "appli": [8, 25, 27, 29, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 63, 66, 67, 68, 69, 96, 102, 110], "given": [8, 10, 17, 24, 73, 82, 83, 84, 102, 109], "complex": 8, "becom": [8, 101, 105], "harder": 8, "anticip": 8, "architectur": [8, 18, 20, 68, 105], "methodolog": 8, "reason": [8, 82, 106], "possibl": [8, 25, 28, 33, 105], "trade": 8, "off": [8, 76, 106], "memori": [8, 26, 27, 28, 29, 30, 31, 32, 34, 36, 40, 41, 70, 85, 100, 102, 106, 107, 108], "vs": [8, 107], "qualiti": [8, 106, 109], "believ": 8, "best": [8, 104], "suit": [8, 107], "specif": [8, 10, 85, 104, 105, 106, 110], "b": [8, 63, 65, 67, 68, 69, 73, 93, 109, 110], "fit": [8, 25, 27, 28, 29, 30, 31, 32, 34, 36, 40, 41, 105], "solut": 8, "result": [8, 76, 106, 108, 109, 110], "meant": [8, 70], "depend": [8, 9, 13, 105, 106, 109, 110], "level": [8, 86, 102, 110], "expertis": 8, "routin": 8, "yourself": [8, 108, 109], "exist": [8, 101, 106, 107, 108, 110], "ad": [8, 76, 104, 109, 110], "ones": 8, "modular": [8, 102], "build": [8, 33, 36, 40, 102, 108, 109], "block": [8, 28, 47, 48, 49, 54, 55, 57, 60, 102], "wandb": [8, 9, 93, 107], "log": [8, 86, 90, 91, 92, 93, 106, 107, 108, 110], "fulli": [8, 26], "nativ": [8, 100, 102, 109, 110], "pytorch": [8, 68, 70, 78, 92, 95, 96, 97, 100, 101, 102, 108, 109, 110], "correct": [8, 16, 35, 66, 67, 68, 83, 102, 104, 105], "numer": [8, 102], "pariti": [8, 102], "verif": 8, "extens": [8, 102], "comparison": [8, 109, 110], "benchmark": [8, 97, 102, 106, 108, 109], "limit": [8, 105], "hidden": [8, 64], "behind": 8, "100": [8, 27, 31, 32, 35, 37, 38, 82, 94, 95, 109, 110], "flag": [8, 27, 31, 32, 35, 37, 78, 85, 110], "prefer": [8, 39, 102, 105], "over": [8, 71, 81, 102, 106, 108, 109, 110], "unnecessari": 8, "abstract": [8, 14, 17, 102, 107, 110], "No": [8, 102], "inherit": [8, 81, 102, 105], "go": [8, 18, 20, 76, 102, 105, 106, 107, 110], "upon": [8, 26, 108], "figur": [8, 109, 110], "spectrum": 8, "decid": 8, "interact": [8, 100, 107], "start": [8, 9, 26, 77, 101, 102, 104, 105, 106, 107], "paradigm": 8, "consist": [8, 41, 107], "configur": [8, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 69, 102, 104, 107, 108, 109, 110], "paramet": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 88, 90, 91, 92, 93, 94, 95, 96, 97, 100, 102, 104, 105, 106, 107, 108, 109, 110], "overrid": [8, 11, 106, 107, 108, 110], "togeth": [8, 28, 93, 107, 109], "valid": [8, 24, 101, 106, 107], "environ": [8, 101, 106, 107], "logic": [8, 79, 102, 107, 109], "api": [8, 9, 50, 51, 56, 59, 62, 104, 106, 107, 108, 110], "closer": [8, 109], "monolith": [8, 102], "trainer": [8, 87], "A": [8, 9, 22, 26, 28, 63, 68, 69, 70, 73, 76, 77, 78, 79, 81, 94, 99, 100, 103, 104, 106, 109, 110], "wrapper": [8, 76, 77, 109], "around": [8, 25, 76, 77, 95, 104, 106, 109, 110], "extern": [8, 105], "primarili": [8, 26, 109], "eleutherai": [8, 102, 109], "har": [8, 102, 109], "control": [8, 27, 31, 32, 35, 37, 97, 106], "multi": [8, 25, 63, 108], "stage": 8, "distil": 8, "oper": [8, 26, 95, 97], "turn": [8, 19, 24, 25, 77, 104], "dataload": [8, 28, 31, 32, 35, 37], "applic": [8, 63, 79, 80, 93], "clean": [8, 9, 31], "after": [8, 63, 65, 66, 68, 69, 90, 91, 92, 93, 104, 110], "process": [8, 9, 70, 97, 105, 107, 110], "group": [8, 63, 90, 91, 92, 93, 108], "init_process_group": [8, 88], "backend": 8, "gloo": 8, "els": [8, 81, 93, 102, 110], "nccl": 8, "fullfinetunerecipedistribut": 8, "cleanup": 8, "other": [8, 10, 26, 81, 85, 105, 107, 108, 109], "stuff": 8, "carri": 8, "relev": [8, 19, 106, 109], "interfac": [8, 14, 17, 26, 72], "metric": [8, 107], "logger": [8, 86, 90, 91, 92, 93, 107], "self": [8, 9, 28, 47, 48, 49, 54, 55, 57, 60, 63, 68, 69, 72, 105, 109, 110], "_devic": 8, "get_devic": 8, "_dtype": 8, "get_dtyp": 8, "ckpt_dict": 8, "wrap": [8, 78, 85, 95, 96, 104], "_model": 8, "_setup_model": 8, "_token": [8, 105], "_setup_token": 8, "_optim": 8, "_setup_optim": 8, "_loss_fn": 8, "_setup_loss": 8, "_sampler": 8, "_dataload": 8, "_setup_data": 8, "backward": [8, 110], "zero_grad": 8, "curr_epoch": 8, "rang": [8, 97, 108], "epochs_run": [8, 9], "total_epoch": [8, 9], "idx": [8, 28], "batch": [8, 28, 31, 32, 35, 37, 63, 65, 67, 68, 69, 76, 94, 102, 105, 107, 108, 109], "enumer": 8, "_autocast": 8, "logit": [8, 82], "label": [8, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 94], "global_step": 8, "_log_every_n_step": 8, "_metric_logg": 8, "log_dict": [8, 90, 91, 92, 93], "step": [8, 28, 68, 71, 77, 90, 91, 92, 93, 95, 100, 106, 109, 110], "learn": [8, 26, 71, 102, 104, 105, 107, 108, 109, 110], "decor": [8, 11], "recipe_main": [8, 11], "none": [8, 9, 12, 13, 16, 17, 20, 21, 23, 24, 25, 27, 28, 29, 30, 33, 34, 36, 38, 40, 41, 63, 65, 67, 68, 69, 75, 76, 77, 79, 80, 82, 83, 84, 86, 90, 91, 92, 93, 96, 97, 104, 105, 106], "fullfinetunerecip": 8, "direct": [8, 101], "wandblogg": [9, 109, 110], "workspac": 9, "seen": [9, 109, 110], "screenshot": 9, "below": [9, 67, 78, 105, 108, 109, 110], "packag": [9, 92, 93, 101], "pip": [9, 92, 93, 101, 106, 108], "Then": [9, 107], "login": [9, 93, 106], "built": [9, 39, 101, 104, 107, 110], "project": [9, 47, 48, 49, 54, 55, 57, 60, 63, 64, 85, 93, 100, 109, 110], "grab": [9, 108], "tab": 9, "tip": 9, "straggler": 9, "background": 9, "crash": 9, "otherwis": [9, 104], "exit": [9, 101], "resourc": [9, 90, 91, 92, 93], "kill": 9, "ps": 9, "aux": 9, "grep": 9, "awk": 9, "xarg": 9, "click": 9, "sampl": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 29, 30, 36, 38, 40, 63, 67, 68, 69, 82, 104, 106], "desir": [9, 25, 104], "suggest": 9, "approach": [9, 26, 105], "full_finetun": 9, "joinpath": 9, "_checkpoint": [9, 106], "_output_dir": [9, 79, 80], "torchtune_model_": 9, "with_suffix": 9, "wandb_at": 9, "artifact": 9, "type": [9, 10, 11, 19, 22, 23, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 73, 74, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 88, 95, 96, 105, 106, 109, 110], "descript": [9, 33, 38], "whatev": 9, "metadata": 9, "seed_kei": 9, "epochs_kei": 9, "total_epochs_kei": 9, "max_steps_kei": 9, "max_steps_per_epoch": 9, "add_fil": 9, "log_artifact": 9, "field": [10, 17, 19, 22, 25, 28, 31, 32, 35, 37, 105], "hydra": 10, "facebook": 10, "research": 10, "http": [10, 25, 27, 29, 30, 33, 34, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 54, 55, 56, 58, 59, 60, 61, 62, 63, 66, 67, 71, 78, 79, 80, 81, 86, 92, 93, 95, 96, 97, 101, 105, 106], "com": [10, 47, 48, 49, 54, 55, 60, 63, 66, 67, 71, 101], "facebookresearch": [10, 66, 67], "blob": [10, 47, 48, 49, 54, 55, 60, 63, 66, 67, 71], "main": [10, 11, 63, 66, 67, 101, 106, 108], "_intern": 10, "_instantiate2": 10, "l148": 10, "omegaconf": 10, "num_lay": [10, 68], "32": [10, 108, 109, 110], "num_head": [10, 63, 65, 67, 68], "num_kv_head": [10, 63, 65], "vocab_s": 10, "must": [10, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 72, 77, 81, 110], "return": [10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 79, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 97, 104, 105, 109, 110], "nn": [10, 63, 64, 65, 68, 69, 70, 72, 74, 75, 78, 96, 109, 110], "parsed_yaml": 10, "embed_dim": [10, 63, 67, 69, 109], "valueerror": [10, 20, 24, 33, 38, 63, 65, 68, 79, 80, 84, 97], "callabl": [11, 25, 27, 29, 68, 78, 82, 85, 96], "With": [11, 106, 109, 110], "my_recip": 11, "foo": 11, "bar": [11, 102, 107], "instanti": [12, 42, 43, 44, 45, 46, 47, 48, 49, 52, 53, 54, 55, 57, 58, 60, 61], "configerror": 12, "cannot": [12, 108], "data": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 90, 91, 92, 93, 105, 106, 110], "prompt": [13, 14, 16, 17, 18, 20, 21, 22, 25, 27, 29, 31, 32, 33, 35, 36, 37, 38, 40, 68, 76, 82, 105, 106, 108], "templat": [13, 14, 16, 17, 21, 25, 27, 29, 31, 32, 35, 36, 37, 38], "style": [13, 28, 31, 32, 33, 38, 110], "slightli": 13, "classmethod": [13, 14, 15, 16, 17, 18, 19, 20, 21, 105], "map": [13, 16, 17, 21, 22, 25, 26, 27, 28, 29, 36, 75, 79, 90, 91, 92, 93, 104, 105, 106, 109], "column_map": [13, 16, 17, 21, 25, 27, 29, 36, 105], "placehold": [13, 14, 16, 17, 21, 25, 27, 29, 36, 105], "column": [13, 16, 17, 21, 25, 27, 29, 30, 36, 40, 63, 68, 69, 104, 105], "ident": [13, 16, 17, 20, 21, 27, 28, 29, 36, 106], "role": [14, 19, 22, 25, 76, 104, 105], "system": [14, 15, 18, 19, 20, 22, 24, 25, 76, 104, 105], "assist": [14, 15, 18, 19, 22, 24, 25, 76, 82, 104, 105], "messag": [14, 15, 18, 20, 22, 24, 25, 33, 76, 77, 101, 104, 105], "accord": [14, 20, 104], "openai": [15, 33, 105], "markup": 15, "languag": [15, 73, 82, 109], "It": [15, 20, 104, 105, 110], "huggingfac": [15, 25, 27, 29, 30, 33, 34, 36, 40, 41, 61, 71, 79, 80, 106], "im_start": 15, "context": [15, 61, 95, 105], "im_end": 15, "goe": 15, "respons": [15, 76, 105, 106, 107, 108], "appropri": [15, 18, 20, 26, 71, 105, 110], "tag": [15, 18, 20, 25, 77, 90, 91, 92, 93, 104], "grammar": [16, 35, 105], "sentenc": [16, 28], "alwai": [17, 81], "human": [18, 22, 104], "taken": [18, 109, 110], "inst": [18, 20, 25, 104, 105], "sy": [18, 104, 105], "respect": [18, 26, 75, 104, 105], "honest": [18, 104, 105], "am": [18, 20, 104, 105, 106, 108], "pari": [18, 20, 105], "capit": [18, 20, 105], "franc": [18, 20, 105], "known": [18, 20, 76, 105], "its": [18, 20, 28, 63, 67, 68, 69, 97, 105, 106, 108, 109], "stun": [18, 20, 105], "liter": [19, 47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62], "mask": [19, 27, 28, 31, 32, 35, 37, 63, 68, 69, 76, 77, 104, 105], "ipython": 19, "eot": 19, "dataclass": [19, 104], "repres": [19, 104], "individu": [19, 28, 93, 96, 104, 105], "tiktoken": [19, 77, 108], "special": [19, 25, 77, 105], "variabl": [19, 25, 26, 27, 29, 36, 110], "writer": 19, "whether": [19, 22, 25, 27, 31, 32, 33, 35, 36, 37, 38, 47, 48, 49, 54, 55, 57, 60, 70, 73, 76, 77, 78, 84, 104, 105], "correspond": [19, 72, 74, 84, 107, 108], "consecut": [19, 24], "from_dict": [19, 104], "construct": [19, 109], "dictionari": [19, 28, 90, 91, 92, 93, 106], "mistral": [20, 25, 38, 57, 58, 59, 104, 106, 107], "llama2chatformat": [20, 104, 105], "summar": [21, 37, 104, 105], "task": [21, 26, 34, 104, 105, 106, 108, 109, 110], "dialogu": [21, 37, 104], "dialog": 21, "adher": 22, "sharegpt": [22, 33], "gpt": [22, 63, 106], "remain": [22, 71, 109], "unmask": 22, "eos_id": 23, "length": [23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 36, 38, 40, 41, 61, 63, 65, 67, 68, 69, 76, 77, 80, 94], "last": [23, 28, 71, 105], "replac": [23, 27, 31, 32, 35, 37, 70, 109], "forth": [24, 105], "come": [24, 72, 109], "empti": 24, "shorter": 24, "min": [24, 109], "invalid": 24, "convert_to_messag": [25, 104], "chat_format": [25, 33, 38, 104, 105], "chatformat": [25, 33, 105], "load_dataset_kwarg": [25, 27, 29, 30, 33, 34, 36, 40, 41], "multiturn": [25, 104], "foreach": 25, "prepar": [25, 104], "truncat": [25, 27, 28, 29, 30, 34, 36, 38, 40, 41, 76, 77, 105], "encod": [25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 76, 77, 104], "decod": [25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 68, 76, 77, 82, 104], "anyth": [25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], "load_dataset": [25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 104, 105], "co": [25, 27, 29, 30, 33, 34, 36, 40, 41, 61, 79, 80, 106], "doc": [25, 27, 29, 30, 33, 34, 36, 40, 41, 78, 81, 86, 92, 93, 95, 97, 106], "en": [25, 27, 29, 30, 33, 34, 36, 40, 41], "package_refer": [25, 27, 29, 30, 33, 34, 36, 40, 41], "loading_method": [25, 27, 29, 30, 33, 34, 36, 40, 41], "text": [25, 28, 30, 34, 40, 41, 76, 77, 104, 106], "extra": [25, 101, 109, 110], "still": [25, 81, 109, 110], "llama3": [25, 38, 52, 53, 54, 55, 56, 82, 85, 100, 105], "where": [25, 26, 31, 32, 35, 37, 63, 68, 73, 76, 105], "unless": 25, "check": [25, 33, 68, 84, 100, 104, 106, 107, 109], "concaten": [26, 76], "sub": [26, 92], "unifi": 26, "were": [26, 104, 107], "simplifi": [26, 109], "simultan": 26, "intern": [26, 81], "aggreg": 26, "transpar": 26, "index": [26, 63, 67, 68, 69, 71, 94, 101, 104, 106], "howev": [26, 101], "constitu": 26, "might": [26, 106], "larg": [26, 73, 110], "comput": [26, 63, 64, 67, 68, 97, 106, 110], "cumul": 26, "maintain": [26, 110], "indic": [26, 28, 63, 67, 68, 69, 78, 104], "deleg": 26, "retriev": [26, 85], "lead": [26, 76], "high": [26, 102, 109], "scale": [26, 47, 48, 49, 54, 55, 57, 60, 73, 82, 109, 110], "consid": 26, "strategi": 26, "stream": [26, 86], "demand": 26, "deriv": [26, 64, 68, 69], "_dataset": 26, "_len": 26, "total": [26, 71, 87, 99, 103, 106, 108, 109], "combin": 26, "_index": 26, "lookup": 26, "dataset1": 26, "mycustomdataset": 26, "params1": 26, "dataset2": 26, "params2": 26, "concat_dataset": 26, "data_point": 26, "1500": 26, "element": [26, 77, 106], "focus": [26, 107], "enhanc": [26, 110], "divers": 26, "machin": [26, 83, 106], "instructtempl": [27, 29, 105], "contribut": [27, 31, 32, 35, 37], "disabl": [27, 29, 30, 34, 36, 40, 41, 97], "recommend": [27, 29, 30, 31, 32, 34, 36, 40, 41, 92, 104, 106, 110], "highest": [27, 29, 30, 31, 32, 34, 36, 40, 41], "sequenc": [27, 28, 29, 30, 31, 32, 34, 36, 38, 40, 41, 63, 65, 67, 68, 69, 76, 77, 94, 104], "ds": [28, 38], "max_pack": 28, "split_across_pack": 28, "greedi": 28, "pack": [28, 31, 32, 33, 35, 36, 37, 38, 63, 67, 68, 69], "done": [28, 84, 109, 110], "preprocess": 28, "outsid": [28, 97, 106, 108, 109], "sampler": [28, 107], "part": [28, 104, 110], "buffer": 28, "long": [28, 104, 109], "enough": [28, 104], "attent": [28, 47, 48, 49, 54, 55, 57, 60, 61, 63, 65, 67, 68, 69, 108, 109, 110], "lower": [28, 109], "triangular": 28, "cross": 28, "attend": [28, 63, 68, 69], "rel": [28, 63, 67, 68, 69, 109], "pad": [28, 82, 94, 105], "max": [28, 38, 68, 71, 76, 109], "wise": 28, "collat": [28, 94, 105], "made": [28, 33, 36, 40, 67, 106], "smaller": [28, 106, 108, 109, 110], "jam": 28, "vari": 28, "s1": [28, 76], "s2": [28, 76], "s3": 28, "s4": 28, "contamin": 28, "input_po": [28, 63, 65, 67, 68, 69], "matrix": 28, "causal": [28, 63, 68, 69], "continu": [28, 105], "increment": 28, "move": [28, 68], "entir": [28, 104, 110], "avoid": [28, 66, 70, 97, 110], "freeform": [30, 40], "unstructur": [30, 41], "corpu": [30, 34, 41], "local": [30, 40, 93, 97, 101, 104, 106, 107], "tabular": [30, 40], "omit": [30, 40, 109], "yahma": [31, 36], "codebas": [31, 32, 35, 37, 106], "prior": [31, 32, 33, 35, 36, 37, 38], "alpaca_d": [31, 32], "batch_siz": [31, 32, 35, 37, 63, 65, 68, 69, 106], "tatsu": 32, "lab": 32, "conversation_styl": [33, 105], "chatdataset": [33, 38, 104, 105], "friendli": [33, 36, 40, 82, 104], "huggingfaceh4": 33, "no_robot": 33, "chatmlformat": 33, "2096": [33, 36, 40], "accomplish": [33, 36, 40], "packeddataset": [33, 36, 105], "ccdv": 34, "cnn_dailymail": 34, "textcompletiondataset": [34, 40, 41, 105], "similar": [34, 39, 41, 105, 106, 108, 109, 110], "cnn": 34, "dailymail": 34, "articl": [34, 41], "extract": 34, "highlight": [34, 110], "liweili": 35, "c4_200m": 35, "variant": [35, 37], "mirror": [35, 37], "llama_recip": [35, 37], "grammar_d": 35, "alpaca_clean": 36, "alpacainstructtempl": [36, 105], "samsum": [37, 105], "summari": [37, 105], "samsum_d": 37, "open": [38, 42, 43, 105, 106], "orca": 38, "slimorca": 38, "dedup": 38, "1024": [38, 39, 105], "prescrib": 38, "least": [38, 108, 109], "though": [38, 104], "10": [38, 94, 106, 108, 110], "351": 38, "82": [38, 106], "391": 38, "221": 38, "220": 38, "193": 38, "12": [38, 101], "471": 38, "lvwerra": [39, 105], "stack": [39, 105], "exchang": [39, 105], "preferencedataset": [39, 105], "stackexchangepair": 39, "textdataset": 40, "allenai": [40, 105], "c4": [40, 105], "data_dir": [40, 105], "realnewslik": [40, 105], "wikitext": 41, "subset": [41, 74], "103": [41, 106], "raw": 41, "wikipedia": 41, "page": [41, 101, 102, 107, 108], "gemma": [42, 43], "gemmatransformerdecod": [42, 43], "w": [42, 43, 44, 45, 46, 52, 53, 58, 92, 93, 104, 106, 109, 110], "blog": [42, 43], "technolog": [42, 43], "develop": [42, 43, 110], "transformerdecod": [44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 82, 109], "arxiv": [44, 45, 46, 50, 51, 56, 59, 62, 63, 66, 67], "org": [44, 45, 46, 50, 51, 56, 59, 62, 63, 66, 67, 78, 81, 86, 92, 95, 96, 97, 101], "ab": [44, 45, 46, 50, 51, 56, 59, 62, 67], "2307": [44, 45, 46], "09288": [44, 45, 46], "70b": [45, 48, 52, 54, 108], "lora_attn_modul": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 109, 110], "q_proj": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 63, 109, 110], "k_proj": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 63, 109, 110], "v_proj": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 63, 109, 110], "output_proj": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 63, 109, 110], "apply_lora_to_mlp": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 109], "apply_lora_to_output": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 109], "lora_rank": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 109], "lora_alpha": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 109], "float": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 63, 66, 71, 73, 82, 90, 91, 92, 93, 109, 110], "16": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 109, 110], "lora_dropout": [47, 48, 49, 50, 51], "05": [47, 48, 49, 50, 51], "quantize_bas": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 73, 110], "lora": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 73, 79, 100, 102, 104, 107, 108], "tloen": [47, 48, 49, 54, 55, 60], "8bb8579e403dc78e37fe81ffbb253c413007323f": [47, 48, 49, 54, 55, 60], "l41": [47, 48, 49, 54, 55, 60], "l43": [47, 48, 49, 54, 55, 60], "linear": [47, 48, 49, 50, 51, 54, 55, 56, 57, 59, 60, 62, 68, 72, 73, 109, 110], "mlp": [47, 48, 49, 54, 55, 57, 60, 68, 69, 108, 109], "final": [47, 48, 49, 54, 55, 57, 60, 64, 68, 77, 106, 108, 109, 110], "rank": [47, 48, 49, 54, 55, 57, 60, 73, 87, 97, 107, 109, 110], "low": [47, 48, 49, 54, 55, 57, 60, 73, 106, 109, 110], "approxim": [47, 48, 49, 54, 55, 57, 60, 73, 109], "factor": [47, 48, 49, 54, 55, 57, 60, 73, 106], "llama2_70b": 48, "llama2_7b": [49, 109], "qlora": [50, 51, 56, 59, 62, 70, 100, 102, 108, 109], "per": [50, 51, 56, 59, 62, 65, 70, 108, 110], "paper": [50, 51, 56, 59, 62, 109, 110], "2305": [50, 51, 56, 59, 62, 63], "14314": [50, 51, 56, 59, 62], "lora_llama2_13b": 50, "lora_llama2_7b": [51, 109], "llama3_70b": 54, "llama3_8b": [55, 82, 108], "lora_llama3_8b": 56, "announc": 58, "lora_mistral_7b": 59, "phi3": [60, 61, 62], "phi3_mini": 60, "ref": [61, 93], "phi": 61, "128k": 61, "nor": 61, "slide": 61, "window": [61, 105], "lora_phi3_mini": 62, "head_dim": [63, 65, 68], "pos_embed": [63, 109], "kv_cach": 63, "kvcach": [63, 68], "attn_dropout": [63, 68], "head": [63, 65, 67, 68, 108], "queri": [63, 65, 68, 69, 108], "gqa": 63, "introduc": [63, 66, 73, 104, 105, 109, 110], "pdf": [63, 66], "13245v1": 63, "version": [63, 82, 101, 104, 108, 110], "multihead": 63, "mha": [63, 68], "n": [63, 76, 77, 99, 103, 104, 105], "extrem": 63, "share": [63, 105, 106], "mqa": 63, "credit": 63, "document": [63, 78, 85, 105], "lightn": 63, "lit": 63, "lit_gpt": 63, "v": [63, 68, 109], "k": [63, 109], "q": [63, 109], "n_kv_head": 63, "dimens": [63, 65, 67, 68, 73, 108, 109, 110], "calcul": [63, 68, 108], "e": [63, 70, 72, 75, 79, 101, 106, 108, 109, 110], "g": [63, 72, 79, 108, 109, 110], "rotarypositionalembed": [63, 109], "cach": [63, 65, 67, 68, 101], "rope": [63, 67], "dropout": [63, 73, 109, 110], "onto": 63, "scaled_dot_product_attent": 63, "seq_length": [63, 69, 82], "boolean": [63, 68, 69, 78], "softmax": [63, 68, 69], "row": [63, 68, 69, 104], "j": [63, 68, 69], "seq_len": 63, "bigger": 63, "n_h": [63, 67], "num": [63, 67], "n_kv": 63, "kv": [63, 65, 68], "emb": [63, 68, 69], "h_d": [63, 67], "gate_proj": 64, "down_proj": 64, "up_proj": 64, "silu": 64, "feed": [64, 69], "network": [64, 109, 110], "fed": [64, 104], "multipli": 64, "subclass": [64, 81], "although": [64, 109], "afterward": 64, "former": 64, "regist": [64, 70, 110], "hook": [64, 70, 110], "latter": 64, "standalon": 65, "past": 65, "becaus": [65, 68, 104, 106, 108], "expand": 65, "dpython": [65, 68, 70], "reset": [65, 68], "zero": [65, 66, 106, 108], "k_val": 65, "v_val": 65, "h": [65, 101], "longer": [65, 105], "ep": 66, "1e": 66, "06": [66, 109], "root": [66, 92, 93], "squar": 66, "1910": 66, "07467": 66, "verfic": [66, 67], "small": [66, 106], "divis": 66, "10000": 67, "rotari": [67, 108], "propos": 67, "2104": 67, "09864": 67, "l450": 67, "upto": 67, "init": [67, 93, 110], "exceed": 67, "freq": 67, "recomput": 67, "geometr": 67, "progress": [67, 107], "rotat": 67, "angl": 67, "todo": 67, "effici": [67, 85, 100, 102, 106, 107, 109], "transformerdecoderlay": 68, "norm": [68, 69], "space": 68, "belong": 68, "reduc": [68, 102, 105, 109, 110], "statement": 68, "improv": [68, 85, 106, 108, 109], "readabl": [68, 106], "At": 68, "arang": 68, "prompt_length": 68, "causal_mask": 68, "m_": 68, "seq": 68, "reset_cach": 68, "setup_cach": 68, "attn": [69, 109, 110], "causalselfattent": [69, 109], "sa_norm": 69, "mlp_norm": 69, "ff": 69, "common_util": 70, "bfloat16": [70, 106, 107, 108, 109], "offload_to_cpu": 70, "nf4": [70, 110], "restor": 70, "higher": [70, 108, 110], "offload": [70, 110], "increas": [70, 71, 108, 109], "peak": [70, 106, 108, 109, 110], "gpu": [70, 106, 107, 108, 109, 110], "_register_state_dict_hook": 70, "m": [70, 77, 82, 104], "mymodul": 70, "_after_": 70, "nf4tensor": [70, 110], "unquant": [70, 106, 110], "unus": 70, "num_warmup_step": 71, "num_training_step": 71, "num_cycl": 71, "last_epoch": 71, "lambdalr": 71, "rate": [71, 102, 107], "schedul": [71, 95, 107], "linearli": 71, "lr": 71, "decreas": [71, 105, 109, 110], "cosin": 71, "v4": 71, "23": [71, 108], "src": 71, "l104": 71, "warmup": [71, 95], "phase": 71, "wave": 71, "half": 71, "lr_schedul": 71, "peft": [72, 73, 74, 75, 79, 109, 110], "protocol": 72, "adapter_param": [72, 73, 74, 75], "proj": 72, "in_dim": [72, 73, 109, 110], "out_dim": [72, 73, 109, 110], "bia": [72, 73, 109, 110], "loralinear": [72, 109, 110], "alpha": [73, 109, 110], "use_bia": 73, "perturb": 73, "decomposit": [73, 109], "matric": [73, 109, 110], "trainabl": [73, 75, 109, 110], "mapsto": 73, "w_0x": 73, "r": [73, 77, 109], "bax": 73, "probabl": [73, 82, 106], "lora_a": [73, 109, 110], "lora_b": [73, 109, 110], "get_adapter_param": [75, 109], "sentencepieceprocessor": 76, "pretrain": [76, 77, 104, 107, 109, 110], "non": 76, "spm_model": [76, 104], "tokenized_text": 76, "hello": [76, 104, 106, 108], "world": [76, 87, 106], "add_bo": [76, 77, 104], "add_eo": [76, 77, 104], "31587": 76, "29644": 76, "102": 76, "trim_leading_whitespac": 76, "prefix": 76, "unbatch": 76, "prepend": [76, 77], "bo": [76, 77, 104, 105], "append": [76, 101], "eo": [76, 77, 104, 105], "trim": 76, "whitespac": 76, "underli": [76, 110], "sentencepiec": [76, 108], "due": [76, 109, 110], "tokenize_messag": [76, 77, 104, 105], "problem": 76, "slice": 76, "tokenizer_path": 76, "separ": [76, 79, 104, 107, 108, 109, 110], "concat": 76, "1788": 76, "2643": 76, "13": [76, 106, 108, 110], "1792": 76, "9508": 76, "465": 76, "22137": 76, "2933": 76, "join": 76, "attribut": 76, "llama3_tiktoken": 77, "p": [77, 78, 109, 110], "l": 77, "all_special_token": 77, "bos_token": 77, "begin_of_text": [77, 104], "eos_token": 77, "end_of_text": 77, "start_header_id": [77, 104], "end_header_id": [77, 104], "step_id": 77, "eom_id": 77, "eot_id": [77, 104], "python_tag": 77, "identif": 77, "regex": 77, "second": [77, 106, 108, 109, 110], "uniqu": 77, "256": [77, 106, 108], "header": [77, 104], "token_id": 77, "truncate_at_eo": 77, "tokenize_head": 77, "datatyp": [78, 110], "polici": [78, 85, 96], "denot": 78, "integ": [78, 94, 97], "auto_wrap_polici": [78, 85, 96], "submodul": 78, "obei": 78, "contract": 78, "get_fsdp_polici": 78, "modules_to_wrap": [78, 85], "min_num_param": 78, "my_fsdp_polici": 78, "recurs": [78, 92], "isinst": [78, 105], "sum": [78, 109], "numel": [78, 109], "1000": 78, "functool": 78, "partial": 78, "stabl": [78, 92, 95, 97, 101], "html": [78, 81, 86, 92, 95, 96, 97, 100], "alia": 78, "from_pretrain": 79, "few": [79, 105, 108, 109, 110], "0001_of_0003": 79, "0002_of_0003": 79, "preserv": [79, 110], "weight_map": [79, 106], "intermediate_checkpoint": [79, 80], "parit": 79, "_weight_map": 79, "shard": [80, 108], "wip": 80, "argpars": 81, "argumentpars": 81, "builtin": 81, "said": 81, "noth": 81, "treat": [81, 104], "consult": 81, "info": [81, 107], "librari": [81, 86, 97, 100, 102, 105, 110], "parse_known_arg": 81, "namespac": 81, "act": 81, "precid": 81, "parse_arg": 81, "properti": [81, 109], "too": [81, 108], "max_generated_token": 82, "pad_id": 82, "temperatur": [82, 106], "top_k": [82, 106], "stop_token": 82, "custom_generate_next_token": 82, "condit": [82, 105], "bsz": 82, "predict": 82, "prune": [82, 110], "stop": 82, "compil": [82, 106, 108, 110], "generate_next_token": 82, "llama3_token": [82, 108], "hi": [82, 104], "my": [82, 104, 105, 106, 108], "jeremi": 82, "availab": 83, "distribut": [83, 88, 96, 97, 102, 107, 108], "bf16": [84, 110], "request": [84, 105, 106], "inde": [84, 106], "kernel": 84, "runtimeerror": [84, 88], "float32": 84, "isn": 84, "hardwar": [84, 102, 105, 106, 109], "memory_efficient_fsdp_wrap": 85, "maxim": [85, 100, 102], "been": [85, 108], "workload": 85, "15": [85, 104, 106, 109, 110], "alongsid": 85, "ac": 85, "fullyshardeddataparallel": 85, "const": 85, "fsdppolicytyp": 85, "handler": 86, "aka": 87, "filenam": 90, "log_": 90, "unixtimestamp": 90, "txt": [90, 105, 107], "thread": 90, "safe": 90, "flush": [90, 91, 92, 93], "union": [90, 91, 92, 93, 96, 97], "ndarrai": [90, 91, 92, 93], "scalar": [90, 91, 92, 93], "record": [90, 91, 92, 93], "payload": [90, 91, 92, 93], "organize_log": 92, "tensorboard": 92, "subdirectori": 92, "compar": [92, 106, 109, 110], "logdir": 92, "startup": 92, "tree": [92, 105, 106], "tfevent": 92, "encount": 92, "frontend": 92, "organ": 92, "accordingli": 92, "my_log_dir": 92, "view": [92, 106, 107], "my_metr": [92, 93], "termin": [92, 93], "entiti": 93, "bias": 93, "sent": 93, "usernam": 93, "my_project": 93, "my_ent": 93, "my_group": 93, "importerror": 93, "account": [93, 109, 110], "log_config": 93, "link": [93, 106], "capecap": 93, "6053ofw0": 93, "torchtune_config_j67sb73v": 93, "padding_idx": 94, "ignore_idx": 94, "longest": 94, "token_pair": 94, "torchtune_perf_trac": 95, "contextmanag": 95, "wait": 95, "trace": 95, "speed": [95, 108, 110], "reduct": [95, 109], "acwrappolicytyp": 96, "describ": [96, 105], "author": [96, 102, 107, 110], "intermedi": [96, 108, 110], "fsdp_adavnced_tutori": 96, "debug_mod": 97, "pseudo": 97, "random": [97, 107], "commonli": [97, 106, 109, 110], "numpi": 97, "own": [97, 104, 105, 106, 109], "determinist": 97, "global": [97, 105], "warn": 97, "nondeterminist": 97, "addition": [97, 105, 109], "cudnn": 97, "set_deterministic_debug_mod": 97, "algorithm": 97, "generated_examples_python": 98, "zip": 98, "galleri": [98, 103], "sphinx": 98, "000": [99, 103, 108], "execut": [99, 103], "generated_exampl": 99, "mem": [99, 103], "mb": [99, 103], "topic": 100, "gentl": 100, "introduct": 100, "first_finetune_tutori": 100, "readi": [100, 104], "workflow": [100, 105, 107, 109], "requisit": 101, "proper": [101, 107], "host": [101, 107], "latest": [101, 107, 110], "confirm": 101, "And": [101, 106, 108], "ls": [101, 106, 107, 108], "welcom": 101, "show": [101, 104, 109], "greatest": [101, 107], "contributor": 101, "cd": [101, 106], "even": [101, 104, 105, 108, 109, 110], "commit": 101, "branch": 101, "url": 101, "whl": 101, "therebi": [101, 110], "forc": 101, "reinstal": 101, "opt": [101, 107], "suffix": 101, "cu121": 101, "On": [102, 109], "pointer": 102, "emphas": 102, "aspect": 102, "simplic": 102, "component": 102, "reus": 102, "prove": 102, "democrat": 102, "box": [102, 110], "zoo": 102, "varieti": [102, 109], "techniqu": [102, 106, 107, 109], "integr": [102, 106, 107, 108, 109, 110], "excit": 102, "checkout": 102, "quickstart": 102, "attain": 102, "better": [102, 104, 105, 106], "chekckpoint": 102, "hyperparamet": [102, 107, 109, 110], "embodi": 102, "philosophi": 102, "usabl": 102, "composit": 102, "hard": [102, 105], "outlin": 102, "unecessari": 102, "never": 102, "thoroughli": 102, "unit": 102, "know": [104, 105, 106, 108, 109], "align": 104, "intend": 104, "nice": 104, "meet": 104, "overhaul": 104, "sai": [104, 107], "accompani": 104, "who": 104, "influenti": 104, "hip": 104, "hop": 104, "artist": [104, 108], "2pac": 104, "rakim": 104, "c": 104, "na": 104, "flavor": [104, 105], "certain": 104, "msg": 104, "formatted_messag": [104, 105], "nyou": [104, 105], "nwho": 104, "sentencepiecetoken": 104, "why": [104, 107, 109], "user_messag": 104, "518": 104, "25580": 104, "29962": 104, "3532": 104, "14816": 104, "29903": 104, "6778": 104, "piece_to_id": 104, "reserv": [104, 110], "vector": 104, "place": 104, "manual": [104, 110], "529": 104, "29879": 104, "29958": 104, "tiktokentoken": 104, "nhere": 104, "_encode_special_token": 104, "128000": 104, "128009": 104, "pure": 104, "That": 104, "won": [104, 106, 108], "mess": 104, "govern": 104, "prime": 104, "strictli": 104, "summarizetempl": [104, 105], "lightweight": 104, "ask": 104, "untouch": 104, "nsummari": 104, "robust": 104, "csv": [104, 105], "question": [104, 105, 106, 108], "answer": [104, 106, 108], "onlin": 104, "forum": 104, "panda": 104, "pd": 104, "df": 104, "read_csv": 104, "your_fil": 104, "nrow": 104, "tolist": 104, "iloc": 104, "gp": 104, "receiv": 104, "commun": [104, 105, 106], "satellit": 104, "thing": [104, 110], "message_convert": 104, "input_msg": 104, "output_msg": 104, "assistant_messag": 104, "But": [104, 106, 108, 109], "mistralchatformat": 104, "custom_dataset": 104, "2048": 104, "data_fil": [104, 105], "honor": 104, "copi": [104, 106, 107, 108, 110], "8b_lora_single_devic": [104, 108], "launch": [104, 107], "custom_8b_lora_single_devic": 104, "steer": 105, "wheel": 105, "publicli": 105, "great": [105, 106], "full_finetune_single_devic": [105, 106, 107], "8b_full_single_devic": 105, "hood": [105, 106, 110], "text_completion_dataset": 105, "padded_col": 105, "upper": 105, "constraint": [105, 109], "slow": [105, 110], "down": [105, 109, 110], "signific": 105, "speedup": [105, 108], "minim": [105, 107, 109, 110], "my_data": 105, "instruct_dataset": 105, "fix": 105, "goal": 105, "agnost": 105, "respond": 105, "further": [105, 109, 110], "classifi": 105, "anim": 105, "plant": 105, "miner": 105, "oak": 105, "copper": 105, "ore": 105, "eleph": 105, "customtempl": 105, "cl": 105, "chat_dataset": 105, "quit": [105, 110], "similarli": 105, "incorpor": 105, "advanc": 105, "customchatformat": 105, "vicgal": 105, "gpt4": 105, "drive": 105, "rajpurkar": 105, "io": 105, "squad": 105, "explor": 105, "rlhf": 105, "adjust": 105, "chosen": 105, "reject": 105, "chosen_messag": 105, "transformed_sampl": 105, "key_chosen": 105, "rejected_messag": 105, "key_reject": 105, "chosen_input_id": 105, "c_mask": 105, "chosen_label": 105, "np": 105, "cross_entropy_ignore_idx": 105, "rejected_input_id": 105, "r_mask": 105, "rejected_label": 105, "stack_exchanged_paired_dataset": 105, "had": 105, "stackexchangedpairedtempl": 105, "response_j": 105, "response_k": 105, "rl": 105, "favorit": [106, 108, 109], "seemlessli": 106, "beyond": [106, 110], "connect": 106, "larger": [106, 108], "amount": 106, "natur": 106, "export": 106, "mobil": 106, "phone": 106, "leverag": [106, 108, 110], "mode": 106, "lot": 106, "plai": 106, "freez": [106, 109], "percentag": 106, "learnabl": 106, "keep": [106, 109], "16gb": [106, 109], "rtx": 106, "3090": 106, "4090": 106, "hour": 106, "7b_full_low_memori": [106, 107], "full_finetune_distribut": [106, 107], "7b_full": [106, 107], "13b_full": [106, 107], "7b_qlora_single_devic": [106, 107, 110], "473": 106, "98": [106, 110], "gb": [106, 108, 109, 110], "50": 106, "484": 106, "01": [106, 107], "fact": [106, 108, 109], "third": 106, "realli": 106, "eleuther_ev": [106, 108], "eleuther_evalu": [106, 108], "lm_eval": [106, 108], "plan": 106, "custom_eval_config": [106, 108], "truthfulqa_mc2": [106, 108, 109], "measur": [106, 108], "propens": [106, 108], "shot": [106, 108], "accuraci": [106, 108, 109, 110], "baselin": [106, 109], "324": 106, "loglikelihood": 106, "195": 106, "121": 106, "27": 106, "197": 106, "acc": 106, "388": 106, "38": 106, "shown": 106, "489": 106, "48": [106, 110], "seem": 106, "custom_generation_config": [106, 108], "kick": 106, "300": 106, "interest": 106, "site": 106, "visit": 106, "bai": 106, "area": 106, "92": [106, 108], "exploratorium": 106, "san": 106, "francisco": 106, "magazin": 106, "awesom": 106, "bridg": 106, "pretti": 106, "cool": 106, "96": [106, 110], "61": 106, "sec": [106, 108], "25": 106, "83": 106, "99": [106, 109], "72": 106, "littl": 106, "saw": 106, "took": [106, 108], "torchao": [106, 108, 110], "bit": [106, 108, 109, 110], "custom_quantization_config": [106, 108], "68": 106, "19": [106, 108, 110], "76": 106, "69": 106, "95": [106, 108], "67": 106, "4w": [106, 108], "unlik": [106, 108], "engin": [106, 108], "fullmodeltorchtunecheckpoint": [106, 108], "int4weightonlyquant": [106, 108], "groupsiz": [106, 108], "did": [106, 108, 110], "park": 106, "sit": 106, "top": [106, 110], "hill": 106, "beauti": 106, "62": [106, 108], "17": [106, 109], "85": 106, "sped": 106, "almost": [106, 108, 109], "3x": [106, 108], "benefit": 106, "doesn": 106, "yet": 106, "fast": 106, "clone": [106, 109, 110], "assumpt": 106, "satisfi": 106, "new_dir": 106, "output_dict": 106, "sd_1": 106, "sd_2": 106, "dump": 106, "convert_hf_checkpoint": 106, "checkpoint_path": 106, "justin": 106, "school": 106, "math": 106, "teacher": 106, "ws": 106, "94": [106, 108], "28": 106, "bandwidth": [106, 108], "achiev": [106, 108, 109, 110], "1391": 106, "84": 106, "thats": 106, "seamlessli": 106, "authent": [106, 107], "hopefulli": 106, "gave": 106, "gate": 107, "grant": 107, "minut": 107, "agreement": 107, "altern": 107, "hackabl": 107, "singularli": 107, "technic": 107, "purpos": [107, 108], "depth": 107, "principl": 107, "boilerpl": 107, "hold": 107, "substanti": [107, 109], "custom_config": 107, "replic": 107, "lorafinetunerecipesingledevic": 107, "lora_finetune_output": 107, "log_1713194212": 107, "52": 107, "3697006702423096": 107, "25880": [107, 110], "24": [107, 108], "55": 107, "83it": 107, "monitor": 107, "tqdm": 107, "interv": 107, "e2": 107, "releas": 108, "focu": 108, "128": [108, 109], "theta": 108, "gain": 108, "illustr": 108, "basic": 108, "observ": 108, "18": 108, "consum": [108, 110], "vram": [108, 109], "overal": 108, "nproc_per_nod": [108, 109], "lora_finetune_distribut": [108, 109], "8b_lora": 108, "8b_qlora_single_devic": 108, "alloc": [108, 110], "coupl": [108, 109, 110], "122": 108, "sarah": 108, "busi": 108, "mum": 108, "young": 108, "children": 108, "live": 108, "north": 108, "east": 108, "england": 108, "135": 108, "88": 108, "138": 108, "346": 108, "09": 108, "139": 108, "31": 108, "far": 108, "drill": 108, "90": 108, "93": 108, "91": 108, "104": 108, "four": [108, 109], "again": 108, "jake": 108, "disciplin": 108, "passion": 108, "draw": 108, "paint": 108, "57": [108, 109, 110], "broader": 108, "teach": 109, "straight": 109, "jump": 109, "neural": [109, 110], "unfamiliar": 109, "oppos": [109, 110], "momentum": 109, "adamw": 109, "arbitrari": 109, "could": 109, "relat": 109, "aghajanyan": 109, "et": 109, "al": 109, "hypothes": 109, "intrins": 109, "often": 109, "eight": 109, "practic": 109, "imag": 109, "left": 109, "blue": 109, "rememb": 109, "approx": 109, "15m": 109, "8192": 109, "65k": 109, "requires_grad": [109, 110], "frozen_out": [109, 110], "lora_out": [109, 110], "base_model": 109, "choos": 109, "lora_model": 109, "lora_llama_2_7b": [109, 110], "alon": 109, "in_featur": 109, "out_featur": 109, "inplac": 109, "feel": 109, "free": 109, "strict": 109, "whenev": 109, "validate_state_dict_for_lora": 109, "peft_util": 109, "set_trainable_param": 109, "fetch": 109, "lora_param": 109, "total_param": 109, "trainable_param": 109, "2f": 109, "6742609920": 109, "4194304": 109, "nnode": 109, "7b_lora": 109, "my_model_checkpoint_path": [109, 110], "tokenizer_checkpoint": [109, 110], "my_tokenizer_checkpoint_path": [109, 110], "factori": 109, "benefici": 109, "impact": 109, "minor": 109, "good": 109, "64": 109, "lora_experiment_1": 109, "smooth": [109, 110], "curv": [109, 110], "500": 109, "ran": 109, "footprint": 109, "commod": 109, "cogniz": 109, "ax": 109, "parallel": 109, "truthfulqa": 109, "previous": 109, "475": 109, "87": 109, "508": 109, "86": 109, "504": 109, "04": 109, "514": 109, "lowest": 109, "absolut": 109, "4gb": 109, "tradeoff": 109, "potenti": 109, "highli": 110, "vanilla": 110, "held": 110, "therefor": 110, "bespok": 110, "normalfloat": 110, "8x": 110, "retain": 110, "vast": 110, "major": 110, "degrad": 110, "normatfloat": 110, "doubl": 110, "themselv": 110, "deepdiv": 110, "idea": 110, "distinct": 110, "storag": 110, "de": 110, "incur": 110, "counterpart": 110, "set_default_devic": 110, "qlora_linear": 110, "memory_alloc": 110, "177": 110, "152": 110, "byte": 110, "del": 110, "empty_cach": 110, "lora_linear": 110, "081": 110, "344": 110, "qlora_llama2_7b": 110, "qlora_model": 110, "essenti": 110, "reparametrize_as_dtype_state_dict_post_hook": 110, "stat": 110, "iter": 110, "against": 110, "35": 110, "40": 110, "29": 110, "slower": 110, "149": 110, "9157477021217346": 110, "02": 110, "08": 110, "14": 110, "15it": 110, "nightli": 110, "200": 110, "hundr": 110, "228": 110, "8158286809921265": 110, "59": 110, "95it": 110, "exercis": 110, "portion": 110, "augment": 110, "linear_nf4": 110, "to_nf4": 110, "linear_weight": 110, "autograd": 110, "regular": 110, "incom": 110}, "objects": {"torchtune.config": [[10, 0, 1, "", "instantiate"], [11, 0, 1, "", "parse"], [12, 0, 1, "", "validate"]], "torchtune.data": [[13, 1, 1, "", "AlpacaInstructTemplate"], [14, 1, 1, "", "ChatFormat"], [15, 1, 1, "", "ChatMLFormat"], [16, 1, 1, "", "GrammarErrorCorrectionTemplate"], [17, 1, 1, "", "InstructTemplate"], [18, 1, 1, "", "Llama2ChatFormat"], [19, 1, 1, "", "Message"], [20, 1, 1, "", "MistralChatFormat"], [21, 1, 1, "", "SummarizeTemplate"], [22, 0, 1, "", "sharegpt_to_llama2_messages"], [23, 0, 1, "", "truncate"], [24, 0, 1, "", "validate_messages"]], "torchtune.data.AlpacaInstructTemplate": [[13, 2, 1, "", "format"]], "torchtune.data.ChatFormat": [[14, 2, 1, "", "format"]], "torchtune.data.ChatMLFormat": [[15, 2, 1, "", "format"]], "torchtune.data.GrammarErrorCorrectionTemplate": [[16, 2, 1, "", "format"]], "torchtune.data.InstructTemplate": [[17, 2, 1, "", "format"]], "torchtune.data.Llama2ChatFormat": [[18, 2, 1, "", "format"]], "torchtune.data.Message": [[19, 2, 1, "", "from_dict"]], "torchtune.data.MistralChatFormat": [[20, 2, 1, "", "format"], [20, 3, 1, "", "system"]], "torchtune.data.SummarizeTemplate": [[21, 2, 1, "", "format"]], "torchtune.datasets": [[25, 1, 1, "", "ChatDataset"], [26, 1, 1, "", "ConcatDataset"], [27, 1, 1, "", "InstructDataset"], [28, 1, 1, "", "PackedDataset"], [29, 1, 1, "", "PreferenceDataset"], [30, 1, 1, "", "TextCompletionDataset"], [31, 0, 1, "", "alpaca_cleaned_dataset"], [32, 0, 1, "", "alpaca_dataset"], [33, 0, 1, "", "chat_dataset"], [34, 0, 1, "", "cnn_dailymail_articles_dataset"], [35, 0, 1, "", "grammar_dataset"], [36, 0, 1, "", "instruct_dataset"], [37, 0, 1, "", "samsum_dataset"], [38, 0, 1, "", "slimorca_dataset"], [39, 0, 1, "", "stack_exchanged_paired_dataset"], [40, 0, 1, "", "text_completion_dataset"], [41, 0, 1, "", "wikitext_dataset"]], "torchtune.models.gemma": [[42, 0, 1, "", "gemma_2b"], [43, 0, 1, "", "gemma_7b"]], "torchtune.models.llama2": [[44, 0, 1, "", "llama2_13b"], [45, 0, 1, "", "llama2_70b"], [46, 0, 1, "", "llama2_7b"], [47, 0, 1, "", "lora_llama2_13b"], [48, 0, 1, "", "lora_llama2_70b"], [49, 0, 1, "", "lora_llama2_7b"], [50, 0, 1, "", "qlora_llama2_13b"], [51, 0, 1, "", "qlora_llama2_7b"]], "torchtune.models.llama3": [[52, 0, 1, "", "llama3_70b"], [53, 0, 1, "", "llama3_8b"], [54, 0, 1, "", "lora_llama3_70b"], [55, 0, 1, "", "lora_llama3_8b"], [56, 0, 1, "", "qlora_llama3_8b"]], "torchtune.models.mistral": [[57, 0, 1, "", "lora_mistral_7b"], [58, 0, 1, "", "mistral_7b"], [59, 0, 1, "", "qlora_mistral_7b"]], "torchtune.models.phi3": [[60, 0, 1, "", "lora_phi3_mini"], [61, 0, 1, "", "phi3_mini"], [62, 0, 1, "", "qlora_phi3_mini"]], "torchtune.modules": [[63, 1, 1, "", "CausalSelfAttention"], [64, 1, 1, "", "FeedForward"], [65, 1, 1, "", "KVCache"], [66, 1, 1, "", "RMSNorm"], [67, 1, 1, "", "RotaryPositionalEmbeddings"], [68, 1, 1, "", "TransformerDecoder"], [69, 1, 1, "", "TransformerDecoderLayer"], [71, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[63, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[64, 2, 1, "", "forward"]], "torchtune.modules.KVCache": [[65, 2, 1, "", "reset"], [65, 2, 1, "", "update"]], "torchtune.modules.RMSNorm": [[66, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[67, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoder": [[68, 2, 1, "", "forward"], [68, 2, 1, "", "reset_caches"], [68, 2, 1, "", "setup_caches"]], "torchtune.modules.TransformerDecoderLayer": [[69, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[70, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[72, 1, 1, "", "AdapterModule"], [73, 1, 1, "", "LoRALinear"], [74, 0, 1, "", "get_adapter_params"], [75, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[72, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[73, 2, 1, "", "adapter_params"], [73, 2, 1, "", "forward"]], "torchtune.modules.tokenizers": [[76, 1, 1, "", "SentencePieceTokenizer"], [77, 1, 1, "", "TikTokenTokenizer"]], "torchtune.modules.tokenizers.SentencePieceTokenizer": [[76, 2, 1, "", "decode"], [76, 2, 1, "", "encode"], [76, 2, 1, "", "tokenize_messages"]], "torchtune.modules.tokenizers.TikTokenTokenizer": [[77, 2, 1, "", "decode"], [77, 2, 1, "", "encode"], [77, 2, 1, "", "tokenize_message"], [77, 2, 1, "", "tokenize_messages"]], "torchtune.utils": [[78, 4, 1, "", "FSDPPolicyType"], [79, 1, 1, "", "FullModelHFCheckpointer"], [80, 1, 1, "", "FullModelMetaCheckpointer"], [81, 1, 1, "", "TuneRecipeArgumentParser"], [82, 0, 1, "", "generate"], [83, 0, 1, "", "get_device"], [84, 0, 1, "", "get_dtype"], [85, 0, 1, "", "get_full_finetune_fsdp_wrap_policy"], [86, 0, 1, "", "get_logger"], [87, 0, 1, "", "get_world_size_and_rank"], [88, 0, 1, "", "init_distributed"], [89, 0, 1, "", "list_dtypes"], [94, 0, 1, "", "padded_collate"], [95, 0, 1, "", "profiler"], [96, 0, 1, "", "set_activation_checkpointing"], [97, 0, 1, "", "set_seed"]], "torchtune.utils.FullModelHFCheckpointer": [[79, 2, 1, "", "load_checkpoint"], [79, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[80, 2, 1, "", "load_checkpoint"], [80, 2, 1, "", "save_checkpoint"]], "torchtune.utils.TuneRecipeArgumentParser": [[81, 2, 1, "", "parse_known_args"]], "torchtune.utils.metric_logging": [[90, 1, 1, "", "DiskLogger"], [91, 1, 1, "", "StdoutLogger"], [92, 1, 1, "", "TensorBoardLogger"], [93, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[90, 2, 1, "", "close"], [90, 2, 1, "", "log"], [90, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[91, 2, 1, "", "close"], [91, 2, 1, "", "log"], [91, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[92, 2, 1, "", "close"], [92, 2, 1, "", "log"], [92, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[93, 2, 1, "", "close"], [93, 2, 1, "", "log"], [93, 2, 1, "", "log_config"], [93, 2, 1, "", "log_dict"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:data"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "data", "Python data"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 6, 78, 100, 102, 106, 108, 109, 110], "config": [0, 7, 8, 107], "data": [1, 5, 104], "instruct": [1, 101, 105, 108], "templat": [1, 104, 105], "chat": [1, 104, 105], "format": [1, 6, 105], "type": 1, "convert": 1, "helper": 1, "func": 1, "dataset": [2, 104, 105], "exampl": 2, "gener": [2, 82, 106, 108], "builder": 2, "class": [2, 8], "model": [3, 4, 9, 106, 107, 108, 109], "llama3": [3, 104, 108], "llama2": [3, 104, 106, 109, 110], "phi": 3, "3": 3, "mistral": 3, "gemma": 3, "modul": 4, "compon": [4, 7], "build": [4, 101, 110], "block": 4, "token": [4, 104], "peft": 4, "util": [4, 5, 78], "checkpoint": [5, 6, 9, 106], "distribut": 5, "reduc": 5, "precis": 5, "memori": [5, 105, 109, 110], "manag": 5, "perform": [5, 109], "profil": [5, 95], "metric": [5, 9], "log": [5, 9], "miscellan": 5, "overview": [6, 102, 106], "handl": 6, "differ": 6, "intermedi": 6, "vs": 6, "final": 6, "lora": [6, 106, 109, 110], "put": [6, 110], "thi": 6, "all": [6, 7, 110], "togeth": [6, 110], "about": 7, "where": 7, "do": 7, "paramet": 7, "live": 7, "write": 7, "configur": [7, 105], "us": [7, 8, 104, 106, 110], "instanti": [7, 10], "referenc": 7, "other": [7, 106], "field": 7, "interpol": 7, "valid": [7, 12], "your": [7, 8, 106, 107], "best": 7, "practic": 7, "airtight": 7, "public": 7, "api": 7, "onli": 7, "command": 7, "line": 7, "overrid": 7, "what": [8, 102, 109, 110], "ar": 8, "recip": [8, 107, 109], "script": 8, "run": [8, 106], "cli": 8, "pars": [8, 11], "weight": 9, "bias": 9, "logger": 9, "w": 9, "b": 9, "alpacainstructtempl": 13, "chatformat": 14, "chatmlformat": 15, "grammarerrorcorrectiontempl": 16, "instructtempl": 17, "llama2chatformat": 18, "messag": 19, "mistralchatformat": 20, "summarizetempl": 21, "sharegpt_to_llama2_messag": 22, "truncat": 23, "validate_messag": 24, "chatdataset": 25, "concatdataset": 26, "instructdataset": 27, "packeddataset": 28, "preferencedataset": 29, "textcompletiondataset": 30, "alpaca_cleaned_dataset": 31, "alpaca_dataset": 32, "chat_dataset": 33, "cnn_dailymail_articles_dataset": 34, "grammar_dataset": 35, "instruct_dataset": 36, "samsum_dataset": 37, "slimorca_dataset": 38, "stack_exchanged_paired_dataset": 39, "text_completion_dataset": 40, "wikitext_dataset": 41, "gemma_2b": 42, "gemma_7b": 43, "llama2_13b": 44, "llama2_70b": 45, "llama2_7b": 46, "lora_llama2_13b": 47, "lora_llama2_70b": 48, "lora_llama2_7b": 49, "qlora_llama2_13b": 50, "qlora_llama2_7b": 51, "llama3_70b": 52, "llama3_8b": 53, "lora_llama3_70b": 54, "lora_llama3_8b": 55, "qlora_llama3_8b": 56, "lora_mistral_7b": 57, "mistral_7b": 58, "qlora_mistral_7b": 59, "lora_phi3_mini": 60, "phi3_mini": 61, "qlora_phi3_mini": 62, "causalselfattent": 63, "todo": [63, 69], "feedforward": 64, "kvcach": 65, "rmsnorm": 66, "rotarypositionalembed": 67, "transformerdecod": 68, "transformerdecoderlay": 69, "reparametrize_as_dtype_state_dict_post_hook": 70, "get_cosine_schedule_with_warmup": 71, "adaptermodul": 72, "loralinear": 73, "get_adapter_param": 74, "set_trainable_param": 75, "sentencepiecetoken": 76, "tiktokentoken": 77, "fsdppolicytyp": 78, "fullmodelhfcheckpoint": 79, "fullmodelmetacheckpoint": 80, "tunerecipeargumentpars": 81, "get_devic": 83, "get_dtyp": 84, "get_full_finetune_fsdp_wrap_polici": 85, "get_logg": 86, "get_world_size_and_rank": 87, "init_distribut": 88, "list_dtyp": 89, "disklogg": 90, "stdoutlogg": 91, "tensorboardlogg": 92, "wandblogg": 93, "padded_col": 94, "set_activation_checkpoint": 96, "set_se": 97, "comput": [99, 103], "time": [99, 103], "welcom": 100, "document": 100, "get": [100, 108], "start": 100, "tutori": 100, "instal": 101, "via": [101, 108], "pypi": 101, "git": 101, "clone": 101, "nightli": 101, "kei": 102, "concept": 102, "design": 102, "principl": 102, "fine": [104, 105, 107, 108], "tune": [104, 105, 107, 108], "chang": 104, "from": [104, 110], "prompt": 104, "special": 104, "when": 104, "should": 104, "i": 104, "custom": [104, 105], "built": 105, "hug": [105, 106], "face": [105, 106], "set": 105, "max": 105, "sequenc": 105, "length": 105, "sampl": 105, "pack": 105, "unstructur": 105, "text": [105, 108], "corpu": 105, "multipl": 105, "local": 105, "remot": 105, "fulli": 105, "end": 106, "workflow": 106, "download": [106, 107], "7b": 106, "finetun": [106, 109, 110], "evalu": [106, 108], "eleutherai": [106, 108], "s": [106, 108], "eval": [106, 108], "har": [106, 108], "speed": 106, "up": 106, "quantiz": [106, 108], "librari": 106, "upload": 106, "hub": 106, "first": 107, "llm": 107, "select": 107, "modifi": 107, "train": 107, "next": 107, "step": 107, "meta": 108, "8b": 108, "access": 108, "our": 108, "faster": 108, "how": 109, "doe": 109, "work": 109, "appli": 109, "trade": 109, "off": 109, "qlora": 110, "save": 110, "deep": 110, "dive": 110}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})