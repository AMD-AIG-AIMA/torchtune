Search.setIndex({"docnames": ["api_ref_config", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "deep_dives/checkpointer", "deep_dives/configs", "deep_dives/recipe_deepdive", "deep_dives/wandb_logging", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.models.gemma.gemma_2b", "generated/torchtune.models.llama2.llama2_13b", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2_13b", "generated/torchtune.models.llama2.lora_llama2_7b", "generated/torchtune.models.llama2.qlora_llama2_13b", "generated/torchtune.models.llama2.qlora_llama2_7b", "generated/torchtune.models.mistral.lora_mistral_7b", "generated/torchtune.models.mistral.mistral_7b", "generated/torchtune.models.mistral.qlora_mistral_7b", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.Tokenizer", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.TuneRecipeArgumentParser", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_dtype", "generated/torchtune.utils.get_logger", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.list_dtypes", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.padded_collate", "generated/torchtune.utils.profiler", "generated/torchtune.utils.set_activation_checkpointing", "generated/torchtune.utils.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times", "tutorials/datasets", "tutorials/e2e_flow", "tutorials/first_finetune_tutorial", "tutorials/lora_finetune", "tutorials/qlora_finetune"], "filenames": ["api_ref_config.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "deep_dives/checkpointer.rst", "deep_dives/configs.rst", "deep_dives/recipe_deepdive.rst", "deep_dives/wandb_logging.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.models.gemma.gemma_2b.rst", "generated/torchtune.models.llama2.llama2_13b.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2_13b.rst", "generated/torchtune.models.llama2.lora_llama2_7b.rst", "generated/torchtune.models.llama2.qlora_llama2_13b.rst", "generated/torchtune.models.llama2.qlora_llama2_7b.rst", "generated/torchtune.models.mistral.lora_mistral_7b.rst", "generated/torchtune.models.mistral.mistral_7b.rst", "generated/torchtune.models.mistral.qlora_mistral_7b.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.Tokenizer.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_dtype.rst", "generated/torchtune.utils.get_logger.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.list_dtypes.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.padded_collate.rst", "generated/torchtune.utils.profiler.rst", "generated/torchtune.utils.set_activation_checkpointing.rst", "generated/torchtune.utils.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst", "tutorials/datasets.rst", "tutorials/e2e_flow.rst", "tutorials/first_finetune_tutorial.rst", "tutorials/lora_finetune.rst", "tutorials/qlora_finetune.rst"], "titles": ["torchtune.config", "torchtune.datasets", "torchtune.models", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "All about configs", "What are recipes?", "Logging to Weights &amp; Biases", "instantiate", "parse", "alpaca_cleaned_dataset", "alpaca_dataset", "grammar_dataset", "samsum_dataset", "slimorca_dataset", "gemma_2b", "llama2_13b", "llama2_7b", "lora_llama2_13b", "lora_llama2_7b", "qlora_llama2_13b", "qlora_llama2_7b", "lora_mistral_7b", "mistral_7b", "qlora_mistral_7b", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "Tokenizer", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "get_device", "get_dtype", "get_logger", "get_world_size_and_rank", "init_distributed", "list_dtypes", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "padded_collate", "profiler", "set_activation_checkpointing", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times", "Configuring Datasets for Fine-tuning", "End-to-End Workflow with torchtune", "Finetune your first LLM", "Finetuning Llama2 with LoRA", "Finetuning Llama2 with QLoRA"], "terms": {"all": [2, 3, 7, 26, 27, 32, 34, 40, 42, 57, 59, 61, 62, 64, 65, 66], "from": [2, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 24, 27, 31, 32, 33, 35, 36, 38, 40, 41, 42, 51, 52, 58, 60, 62, 63, 64, 65, 66], "famili": [2, 7, 61], "pre": [2, 60], "train": [2, 4, 5, 7, 8, 11, 12, 13, 14, 15, 26, 35, 40, 41, 44, 54, 59, 61, 63, 64, 66, 67], "can": [2, 3, 5, 6, 7, 8, 9, 11, 12, 29, 30, 31, 40, 42, 51, 52, 59, 60, 61, 63, 64, 65, 66, 67], "download": [2, 5, 57, 60, 66, 67], "hug": [2, 5, 11, 12, 13, 14, 15, 35, 61, 63, 64, 65], "face": [2, 5, 11, 12, 13, 14, 15, 35, 61, 63, 64, 65], "hub": [2, 5, 64, 65], "follow": [2, 5, 7, 26, 35, 52, 59, 60, 63, 64, 65, 66, 67], "command": [2, 7, 42, 60, 65, 66, 67], "tune": [2, 5, 6, 7, 8, 10, 11, 12, 59, 60, 61, 64, 65, 66, 67], "meta": [2, 5, 13, 14, 40, 41, 64, 65], "llama": [2, 5, 13, 14, 29, 30, 40, 41, 64, 65, 66], "2": [2, 5, 15, 26, 31, 40, 41, 53, 56, 64, 65, 66], "7b": [2, 5, 11, 12, 18, 20, 23, 24, 40, 41, 65, 66, 67], "hf": [2, 5, 40, 64, 65], "token": [2, 5, 6, 7, 11, 12, 13, 14, 15, 26, 30, 32, 33, 63, 64, 65, 66, 67], "access_token": 2, "ai": [2, 24, 26, 52], "mistralai": 2, "v0": 2, "1": [2, 5, 7, 15, 26, 31, 32, 35, 41, 51, 52, 53, 56, 64, 65, 66, 67], "googl": [2, 16], "2b": [2, 16], "These": [3, 5, 6, 7, 9, 42, 63, 64, 65, 66, 67], "ar": [3, 5, 6, 8, 9, 11, 12, 13, 14, 19, 20, 21, 22, 23, 25, 32, 37, 40, 41, 44, 61, 63, 64, 65, 66, 67], "common": [3, 6, 63, 66], "us": [3, 5, 8, 9, 10, 11, 12, 13, 14, 15, 26, 27, 29, 30, 31, 32, 33, 34, 40, 41, 42, 43, 44, 49, 50, 51, 52, 56, 59, 60, 61, 63, 65, 66], "offer": 4, "allow": [4, 51, 67], "seamless": 4, "transit": 4, "between": [4, 5, 40, 64, 66, 67], "format": [4, 11, 12, 13, 14, 15, 40, 41, 64, 65, 66], "interoper": [4, 5, 7, 61, 64, 67], "rest": [4, 67], "ecosystem": [4, 5, 7, 61, 64, 67], "For": [4, 5, 6, 7, 11, 12, 26, 32, 42, 52, 56, 63, 64, 65, 66, 67], "comprehens": 4, "overview": [4, 6, 8, 65, 66, 67], "pleas": [4, 22, 25, 60, 67], "see": [4, 5, 8, 11, 22, 25, 28, 36, 42, 45, 52, 54, 56, 60, 61, 63, 64, 65, 66, 67], "deep": [4, 5, 6, 7, 8, 61, 65], "dive": [4, 5, 6, 7, 8, 61, 65], "enabl": [4, 6, 7, 8, 19, 20, 21, 22, 23, 25, 37, 54, 56, 66, 67], "work": [4, 5, 7, 42, 61, 64, 67], "set": [4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 30, 32, 39, 43, 55, 56, 61, 63, 64, 65, 66], "consumpt": 4, "dure": [4, 5, 11, 12, 13, 14, 26, 28, 30, 32, 33, 64, 66, 67], "provid": [4, 5, 6, 7, 9, 15, 32, 42, 61, 63, 64, 65], "debug": [4, 5, 6, 7], "your": [4, 8, 9, 51, 52, 59, 60, 61, 63, 64, 66, 67], "finetun": [4, 5, 6, 7, 11, 12, 19, 20, 21, 48, 59, 61], "job": [4, 56, 65], "variou": 4, "dataset": [4, 6, 11, 12, 13, 14, 15, 61, 64, 65, 66, 67], "walk": [5, 7, 51, 61, 63, 64, 65, 67], "you": [5, 6, 7, 8, 9, 11, 12, 42, 51, 52, 59, 60, 61, 63, 64, 65, 66, 67], "through": [5, 6, 7, 8, 27, 61, 63, 64, 65, 67], "design": [5, 7], "behavior": [5, 63], "associ": [5, 6, 7, 64, 66], "util": [5, 6, 7, 8, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 61, 64, 65, 67], "what": [5, 6, 8, 59, 63, 64, 65], "cover": [5, 6, 7, 8, 64, 67], "how": [5, 6, 7, 8, 59, 63, 64, 65, 67], "we": [5, 6, 7, 8, 11, 12, 26, 28, 30, 31, 32, 37, 40, 41, 44, 61, 63, 64, 65, 66, 67], "them": [5, 6, 27, 31, 34, 63, 64, 66, 67], "scenario": 5, "full": [5, 6, 7, 22, 25, 31, 40, 41, 61, 66], "compos": 5, "compon": [5, 7, 54, 61, 63, 65, 66, 67], "which": [5, 7, 11, 12, 13, 14, 19, 20, 21, 23, 26, 30, 31, 32, 33, 35, 40, 41, 44, 49, 61, 63, 64, 65, 66, 67], "plug": 5, "ani": [5, 6, 7, 9, 10, 31, 34, 38, 39, 40, 41, 56, 63, 64, 65, 66], "recip": [5, 6, 8, 9, 10, 13, 14, 27, 40, 41, 61, 63, 64, 67], "evalu": [5, 7, 59, 61, 65, 66, 67], "gener": [5, 7, 15, 31, 56, 57, 59, 63, 66, 67], "each": [5, 7, 19, 20, 21, 23, 26, 30, 31, 32, 56, 61, 63, 64, 65, 66], "support": [5, 7, 8, 9, 11, 12, 13, 14, 26, 37, 41, 44, 48, 61, 63, 64, 65, 66, 67], "model": [5, 6, 7, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 41, 54, 55, 59, 61, 63, 67], "make": [5, 6, 7, 8, 26, 33, 61, 64, 65, 66, 67], "easi": [5, 7, 61, 66], "understand": [5, 6, 7, 59, 61, 63, 66, 67], "extend": [5, 7, 61], "befor": [5, 32, 33, 37, 40, 64], "let": [5, 6, 8, 63, 64, 65, 66, 67], "s": [5, 6, 7, 8, 10, 19, 20, 21, 23, 26, 30, 32, 33, 34, 36, 38, 40, 41, 43, 51, 54, 61, 63, 65, 66, 67], "defin": [5, 6, 7, 27, 36, 37, 38, 65, 66], "some": [5, 6, 38, 39, 59, 61, 64, 65, 66, 67], "concept": [5, 64, 65], "In": [5, 6, 7, 30, 37, 51, 52, 64, 66, 67], "ll": [5, 6, 7, 61, 63, 64, 65, 67], "talk": 5, "about": [5, 7, 40, 52, 61, 64, 65, 66, 67], "take": [5, 6, 7, 9, 27, 28, 34, 40, 42, 43, 63, 64, 65, 66, 67], "close": [5, 7, 49, 50, 51, 52, 66], "look": [5, 6, 7, 51, 63, 64, 65, 66], "veri": [5, 32, 64], "simpli": [5, 6, 63, 67], "dictat": 5, "state_dict": [5, 34, 40, 41, 66, 67], "store": [5, 49, 52, 66, 67], "file": [5, 6, 7, 8, 9, 10, 11, 12, 31, 40, 41, 42, 49, 52, 54, 58, 61, 62, 63, 64, 65, 66, 67], "disk": [5, 49], "weight": [5, 7, 19, 20, 21, 22, 23, 25, 26, 34, 36, 37, 40, 41, 52, 59, 64, 65, 66, 67], "string": [5, 31, 36, 43, 44], "kei": [5, 6, 8, 26, 28, 32, 39, 40, 64, 65, 66, 67], "identifi": 5, "state": [5, 7, 34, 38, 39, 40, 41, 64, 66, 67], "dict": [5, 6, 7, 8, 9, 34, 38, 39, 40, 41, 47], "If": [5, 6, 11, 12, 13, 14, 15, 26, 34, 37, 40, 41, 43, 44, 47, 51, 52, 56, 60, 63, 65, 66], "identif": 5, "don": [5, 6, 7, 56, 64, 65, 67], "t": [5, 6, 7, 15, 44, 56, 64, 65, 67], "match": [5, 64, 66], "up": [5, 7, 8, 11, 12, 63, 65, 66, 67], "exactli": 5, "those": [5, 66], "definit": [5, 66], "either": [5, 40, 66, 67], "run": [5, 6, 8, 10, 27, 28, 32, 34, 40, 41, 51, 52, 60, 61, 65, 66, 67], "explicit": 5, "error": [5, 6, 11, 40, 56], "load": [5, 7, 40, 41, 42, 51, 64, 66], "rais": [5, 9, 15, 26, 32, 40, 41, 44, 47, 52, 56], "an": [5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 26, 32, 36, 38, 39, 40, 41, 52, 61, 63, 64, 65, 66, 67], "except": [5, 63], "wors": 5, "silent": [5, 27], "succe": 5, "infer": [5, 26, 28, 30, 32, 33, 59, 64, 65, 67], "expect": [5, 6, 9, 30, 52, 63, 66], "addit": [5, 6, 7, 9, 40, 41, 44, 47, 49, 51, 52, 55, 61, 65, 66], "line": [5, 7, 42, 65], "also": [5, 6, 7, 8, 9, 26, 32, 37, 43, 52, 60, 63, 64, 65, 66, 67], "need": [5, 6, 7, 8, 15, 26, 27, 32, 51, 52, 63, 64, 65, 66, 67], "shape": [5, 26, 28, 30, 32, 33, 37], "valu": [5, 6, 15, 16, 17, 18, 24, 26, 28, 29, 32, 35, 40, 42, 49, 50, 51, 52, 56, 65, 66], "two": [5, 6, 61, 64, 65, 66, 67], "popular": [5, 61, 63, 64], "llama2": [5, 6, 7, 9, 11, 12, 15, 17, 18, 19, 20, 21, 22, 27, 31, 32, 33, 59, 61, 65], "offici": [5, 65], "implement": [5, 7, 11, 12, 13, 14, 15, 27, 29, 30, 35, 36, 37, 40, 51, 61, 66, 67], "when": [5, 6, 7, 10, 32, 34, 35, 51, 64, 66, 67], "websit": 5, "get": [5, 6, 7, 8, 31, 44, 45, 46, 61, 63, 64, 65, 66], "access": [5, 6, 7, 40, 64, 65], "singl": [5, 6, 9, 26, 40, 41, 64, 65, 66, 67], "pth": [5, 64], "inspect": [5, 64, 66, 67], "content": [5, 31, 63], "easili": [5, 6, 61, 63, 66, 67], "torch": [5, 28, 32, 34, 35, 43, 44, 47, 54, 55, 56, 64, 65, 66, 67], "import": [5, 6, 9, 51, 52, 63, 64, 65, 66, 67], "consolid": 5, "00": [5, 58, 62, 65], "mmap": [5, 64], "true": [5, 6, 11, 12, 13, 14, 21, 22, 25, 31, 34, 40, 41, 47, 51, 63, 64, 66, 67], "weights_onli": 5, "map_loc": [5, 64], "cpu": [5, 7, 34, 44, 64, 67], "tensor": [5, 26, 27, 28, 29, 30, 32, 33, 34, 37, 40, 49, 50, 51, 52, 53, 66, 67], "item": 5, "print": [5, 11, 12, 13, 14, 15, 31, 63, 65, 66, 67], "f": [5, 8, 11, 12, 13, 14, 64, 66, 67], "tok_embed": [5, 32], "size": [5, 7, 9, 11, 12, 13, 14, 26, 28, 29, 30, 31, 32, 33, 46, 61, 63, 64, 65, 66], "32000": [5, 9, 66], "4096": [5, 9, 11, 12, 26, 30, 66], "len": [5, 11, 12, 13, 14, 32], "292": 5, "The": [5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 19, 20, 21, 29, 30, 31, 34, 35, 40, 42, 43, 44, 45, 52, 54, 56, 60, 61, 64, 65, 66, 67], "contain": [5, 26, 28, 30, 31, 32, 33, 36, 38, 39, 40, 41, 42, 51, 53, 64, 66], "includ": [5, 6, 7, 37, 40, 41, 42, 61, 64, 65, 66, 67], "input": [5, 11, 12, 13, 14, 15, 26, 27, 29, 30, 31, 32, 33, 37, 40, 53, 56, 63, 66, 67], "embed": [5, 26, 28, 29, 30, 32], "tabl": [5, 67], "call": [5, 9, 27, 34, 42, 49, 50, 51, 52, 66, 67], "layer": [5, 7, 19, 20, 21, 22, 23, 25, 26, 32, 33, 37, 61, 66, 67], "have": [5, 6, 9, 26, 28, 36, 42, 51, 54, 63, 64, 65, 66, 67], "dim": [5, 26, 27, 29, 30, 32, 33], "most": [5, 6, 65, 66, 67], "within": [5, 6, 9, 15, 27, 51, 56, 64, 66, 67], "default": [5, 6, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 40, 41, 42, 44, 49, 53, 54, 56, 64, 66, 67], "everi": [5, 7, 27, 51, 67], "config": [5, 8, 9, 10, 26, 40, 42, 52, 61, 63, 64, 66, 67], "repo": [5, 40, 41, 64], "first": [5, 6, 9, 32, 40, 42, 59, 61, 64, 66, 67], "big": [5, 64], "split": [5, 63, 64], "across": [5, 7, 40, 51, 56, 64], "bin": [5, 64], "To": [5, 6, 7, 40, 60, 61, 63, 64, 65, 66, 67], "correctli": [5, 7, 40, 60, 65, 67], "piec": 5, "one": [5, 7, 27, 31, 63, 64, 65, 67], "pytorch_model": [5, 64], "00001": 5, "00002": 5, "embed_token": 5, "241": 5, "Not": 5, "onli": [5, 8, 26, 30, 31, 32, 33, 37, 38, 41, 42, 44, 64, 65, 66, 67], "doe": [5, 36, 40, 42, 64], "fewer": [5, 26], "sinc": [5, 6, 9, 27, 40, 64], "instead": [5, 7, 27, 28, 37, 64, 66], "mismatch": 5, "name": [5, 6, 8, 36, 39, 40, 41, 42, 43, 49, 50, 51, 52, 64], "caus": [5, 31], "try": [5, 6, 64, 65, 67], "same": [5, 6, 19, 20, 21, 26, 28, 31, 33, 42, 52, 64, 66, 67], "As": [5, 6, 7, 37, 61, 64, 67], "re": [5, 6, 61, 64, 65, 66], "care": [5, 27, 40, 64, 66], "like": [5, 6, 7, 8, 63, 64, 65, 66], "end": [5, 7, 31, 59, 61, 66], "number": [5, 7, 11, 12, 15, 26, 28, 32, 35, 40, 41, 46, 56, 65, 66], "just": [5, 61, 63, 65, 66], "save": [5, 7, 8, 40, 41, 52, 59, 64, 66], "less": [5, 15, 64, 65, 67], "prone": 5, "manag": [5, 54], "invari": 5, "accept": [5, 6, 15, 31, 65, 67], "multipl": [5, 6, 7, 37, 49, 50, 51, 52, 65], "sourc": [5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 63, 64], "worri": [5, 65], "explicitli": [5, 36, 61, 66], "convert": [5, 40, 53, 64, 67], "time": [5, 31, 49, 51, 64, 67], "produc": [5, 67], "back": [5, 40, 66, 67], "origin": [5, 11, 12, 34, 37, 63, 64, 66, 67], "form": [5, 6, 7, 11], "One": [5, 64], "advantag": [5, 66], "being": [5, 40, 41, 43, 67], "should": [5, 6, 7, 19, 20, 21, 23, 26, 27, 36, 42, 49, 50, 51, 52, 60, 61, 63, 64, 65, 66, 67], "abl": [5, 7, 63, 64, 65], "fine": [5, 7, 8, 11, 12, 59, 61, 64, 66], "post": [5, 67], "tool": [5, 64, 65], "quantiz": [5, 19, 20, 21, 22, 23, 25, 37, 59, 65, 67], "eval": [5, 59, 61], "without": [5, 6, 61, 63, 64, 66], "code": [5, 7, 32, 57, 61, 63, 65], "chang": [5, 6, 8, 63, 64, 65, 66, 67], "OR": 5, "convers": [5, 40, 61, 63, 64, 66, 67], "script": [5, 8, 64, 65], "wai": [5, 6, 63, 65], "surround": [5, 7, 61], "load_checkpoint": [5, 7, 40, 41], "save_checkpoint": [5, 7, 8, 40, 41], "method": [5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 34, 36, 38, 42, 61, 64, 66, 67], "convertor": 5, "avail": [5, 7, 42, 43, 44, 61, 64, 66], "here": [5, 6, 8, 29, 30, 63, 64, 65, 66, 67], "three": [5, 7, 65], "hfcheckpoint": 5, "read": [5, 40, 41, 61], "write": [5, 7, 40, 41, 49, 63, 65], "compat": [5, 40], "transform": [5, 7, 19, 20, 21, 23, 32, 33, 35, 66], "framework": [5, 7, 61], "mention": [5, 64, 67], "abov": [5, 34, 64, 66, 67], "assum": [5, 35, 38, 44, 64, 66], "checkpoint_dir": [5, 6, 40, 41, 64], "necessari": [5, 15, 49, 50, 51, 52, 66], "json": [5, 40, 54, 64], "easiest": [5, 65], "sure": [5, 6, 64, 65, 66, 67], "everyth": [5, 7, 42, 61, 65], "flow": [5, 67], "By": [5, 66, 67], "ignor": [5, 26, 27], "safetensor": 5, "output": [5, 11, 12, 13, 15, 19, 20, 21, 23, 26, 27, 29, 30, 32, 33, 37, 39, 50, 54, 60, 63, 64, 65, 66, 67], "dir": [5, 64, 65], "output_dir": [5, 6, 40, 41, 54, 64, 66, 67], "specifi": [5, 6, 7, 9, 26, 63, 64, 65, 67], "argument": [5, 6, 9, 15, 22, 25, 26, 42, 47, 49, 51, 52, 55, 66], "snippet": 5, "explain": 5, "setup": [5, 6, 7, 32, 55, 64, 66, 67], "_component_": [5, 6, 8, 9, 63, 64, 66], "fullmodelhfcheckpoint": [5, 64], "directori": [5, 6, 40, 41, 49, 51, 52, 64, 65], "sort": [5, 40], "id": [5, 11, 12, 15, 31, 40, 53, 64], "so": [5, 6, 40, 42, 60, 61, 64, 65, 66, 67], "order": [5, 7, 40, 51, 52, 65], "matter": [5, 40, 66], "checkpoint_fil": [5, 6, 8, 40, 41, 64, 66, 67], "restart": 5, "previou": [5, 40, 41], "more": [5, 6, 7, 11, 28, 30, 42, 52, 54, 56, 61, 63, 64, 65, 66, 67], "next": [5, 67], "section": [5, 7, 59, 64, 67], "recipe_checkpoint": [5, 40, 41], "null": [5, 6], "usual": [5, 30, 40, 64, 66], "model_typ": [5, 40, 41, 64], "resume_from_checkpoint": [5, 40, 41], "fals": [5, 6, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 25, 26, 31, 37, 40, 41, 54, 64, 66, 67], "requir": [5, 6, 15, 40, 51, 52, 56, 60, 63, 65, 67], "param": [5, 7, 19, 20, 21, 37, 38, 39, 40, 66, 67], "directli": [5, 6, 7, 9, 40, 63, 64, 65, 66, 67], "help": [5, 32, 40, 42, 59, 60, 61, 63, 64, 65, 67], "ensur": [5, 6, 15, 26, 40, 44, 61, 65], "out": [5, 6, 7, 11, 12, 13, 14, 40, 41, 59, 61, 64, 65, 66, 67], "case": [5, 7, 8, 26, 40, 44, 49, 61, 63, 64, 66, 67], "discrep": [5, 40], "along": [5, 66], "detail": [5, 11, 28, 54, 56, 64, 65, 66, 67], "found": [5, 6, 8, 29, 30, 66, 67], "metacheckpoint": 5, "github": [5, 11, 12, 13, 14, 19, 20, 21, 26, 29, 30, 35, 60, 65], "repositori": [5, 64, 65], "fullmodelmetacheckpoint": 5, "torchtunecheckpoint": 5, "perform": [5, 27, 61, 64, 67], "current": [5, 26, 30, 32, 33, 41, 46, 49, 51, 56, 64, 65], "test": [5, 6, 7, 61], "complet": [5, 7, 63, 64, 65], "written": [5, 6, 7, 40, 41, 49, 50, 51, 52, 61], "begin": [5, 31, 67], "partit": [5, 67], "ha": [5, 31, 36, 38, 63, 64, 65, 66, 67], "standard": [5, 50, 61, 64], "key_1": 5, "weight_1": 5, "key_2": 5, "weight_2": 5, "mid": 5, "chekpoint": 5, "middl": [5, 64], "inform": [5, 52, 61, 64, 65], "subsequ": [5, 7], "recipe_st": [5, 40, 41], "pt": [5, 8, 40, 41, 64], "epoch": [5, 7, 8, 35, 40, 41, 64, 65], "optim": [5, 6, 7, 35, 64, 65, 66, 67], "etc": [5, 7, 40, 65], "prevent": 5, "flood": 5, "overwritten": 5, "note": [5, 6, 31, 32, 36, 40, 42, 44, 54, 56, 63, 64, 66, 67], "updat": [5, 6, 7, 64, 65, 66, 67], "hf_model_0001_0": [5, 64], "hf_model_0002_0": [5, 64], "both": [5, 64, 66, 67], "adapt": [5, 36, 37, 38, 39, 40, 41, 64, 66, 67], "merg": [5, 9, 40, 64, 67], "would": [5, 6, 8, 32, 63, 64, 66, 67], "our": [5, 7, 61, 63, 64, 65, 66, 67], "tutori": [5, 61, 63, 64, 65, 66, 67], "primari": [5, 6, 7, 65], "want": [5, 6, 7, 8, 9, 60, 65, 66], "resum": [5, 7, 35, 40, 41, 67], "initi": [5, 7, 10, 16, 17, 18, 24, 31, 47, 65, 66, 67], "frozen": [5, 66, 67], "base": [5, 15, 19, 20, 21, 22, 23, 25, 30, 35, 37, 39, 40, 42, 49, 59, 64, 65, 66, 67], "well": [5, 6, 7, 61, 63, 64, 67], "learnt": [5, 64], "someth": [5, 7, 8, 64], "NOT": 5, "refer": [5, 6, 7, 29, 30, 61, 66], "adapter_checkpoint": [5, 40, 41], "adapter_0": [5, 64], "now": [5, 31, 63, 64, 65, 66, 67], "knowledg": 5, "creat": [5, 6, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 35, 40, 41, 49, 51, 63, 64, 67], "simpl": [5, 7, 59, 65, 66, 67], "forward": [5, 7, 26, 27, 29, 30, 32, 33, 37, 66, 67], "13b": [5, 17, 19, 21], "modeltyp": [5, 40, 41], "llama2_13b": [5, 19, 21], "right": [5, 40, 64, 66], "pytorch_fil": 5, "00003": 5, "torchtune_sd": 5, "load_state_dict": [5, 66], "successfulli": [5, 65], "vocab": [5, 9, 32], "70": 5, "x": [5, 26, 27, 29, 30, 32, 33, 37, 66, 67], "randint": 5, "0": [5, 7, 20, 22, 26, 31, 32, 35, 37, 51, 52, 53, 56, 58, 62, 64, 65, 66, 67], "no_grad": 5, "6": [5, 29, 53, 64, 67], "3989": 5, "9": [5, 64, 67], "0531": 5, "3": [5, 42, 45, 53, 64, 65, 67], "2375": 5, "5": [5, 35, 53, 54, 64, 65], "2822": 5, "4": [5, 6, 15, 26, 53, 61, 64, 66, 67], "4872": 5, "7469": 5, "8": [5, 11, 12, 13, 14, 19, 20, 21, 22, 23, 25, 64, 66, 67], "6737": 5, "11": [5, 64, 67], "0023": 5, "8235": 5, "6819": 5, "2424": 5, "0109": 5, "6915": 5, "7": [5, 53], "3618": 5, "1628": 5, "8594": 5, "5857": 5, "1151": 5, "7808": 5, "2322": 5, "8850": 5, "9604": 5, "7624": 5, "6040": 5, "3159": 5, "5849": 5, "8039": 5, "9322": 5, "2010": 5, "6824": 5, "8929": 5, "8465": 5, "3794": 5, "3500": 5, "6145": 5, "5931": 5, "do": [5, 7, 52, 63, 64, 65, 66], "find": [5, 7, 8, 64, 65, 66], "list": [5, 6, 11, 12, 15, 19, 20, 21, 22, 23, 25, 31, 36, 37, 40, 41, 42, 45, 48, 53, 63, 65], "builder": [5, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 63, 67], "hope": 5, "deeper": [5, 65], "insight": [5, 64], "happi": [5, 64], "thi": [6, 7, 8, 9, 11, 12, 15, 26, 27, 30, 31, 32, 33, 34, 35, 36, 40, 41, 42, 43, 44, 49, 51, 52, 54, 56, 59, 60, 61, 63, 64, 65, 66, 67], "guid": [6, 8, 61, 63, 65, 66], "yaml": [6, 7, 9, 10, 42, 52, 61, 64, 65, 66, 67], "pars": [6, 9, 42, 65], "effect": 6, "cli": [6, 8, 10, 60, 64, 65], "prerequisit": [6, 63, 64, 65, 66, 67], "Be": [6, 64, 65, 66, 67], "familiar": [6, 64, 65, 66, 67], "torchtun": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 60, 63, 65], "instal": [6, 8, 51, 52, 59, 64, 65, 66, 67], "fundament": 6, "There": [6, 64, 65, 66], "entri": [6, 7, 65], "point": [6, 7, 63, 64, 65, 66, 67], "locat": [6, 66, 67], "thei": [6, 7, 32, 42, 63, 66], "truth": [6, 64], "reproduc": 6, "overridden": [6, 27, 42], "quick": 6, "experiment": 6, "modifi": [6, 7, 8, 34, 61, 64, 66, 67], "serv": [6, 63, 66], "particular": [6, 15, 63, 66, 67], "seed": [6, 7, 8, 56, 65], "shuffl": 6, "devic": [6, 7, 43, 44, 64, 65, 66], "cuda": [6, 43, 44, 64, 67], "dtype": [6, 7, 28, 34, 44, 48, 64, 67], "fp32": [6, 67], "enable_fsdp": 6, "mani": [6, 63, 64], "object": [6, 9, 26, 63], "keyword": [6, 9, 15, 34], "loss": [6, 7, 11, 12, 13, 14, 65, 66, 67], "function": [6, 7, 9, 10, 26, 27, 34, 43, 46, 56, 61, 63, 67], "exampl": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 26, 31, 36, 40, 41, 51, 52, 53, 57, 58, 62, 63, 64, 66, 67], "subfield": 6, "dotpath": 6, "wish": 6, "exact": [6, 9, 64], "path": [6, 7, 8, 9, 31, 40, 41, 42, 54, 64, 66], "normal": [6, 29, 31, 32, 33, 63, 66, 67], "python": [6, 42, 45, 52, 56, 57, 64], "alpaca_dataset": [6, 11, 63], "custom": [6, 7, 61, 64, 65, 66], "train_on_input": [6, 11, 12, 13, 14, 15, 63], "onc": [6, 64, 65, 66, 67], "ve": [6, 28, 63, 64, 66], "instanc": [6, 9, 11, 12, 27, 31, 34, 38, 39, 66], "cfg": [6, 7, 10], "automat": [6, 8, 9, 67], "under": [6, 64, 67], "preced": [6, 9, 66], "actual": [6, 8], "throw": 6, "notic": [6, 63, 66], "miss": [6, 66], "posit": [6, 9, 26, 30, 32, 33], "anoth": [6, 64], "handl": [6, 10, 31, 64, 66, 67], "def": [6, 7, 8, 10, 63, 66, 67], "dictconfig": [6, 7, 9, 10, 52], "arg": [6, 9, 32, 34, 36, 42, 50], "tupl": [6, 9, 15, 31, 34, 42, 46, 53], "kwarg": [6, 9, 34, 36, 42, 47, 49, 50, 51, 52, 55], "str": [6, 9, 31, 34, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 52, 54, 56], "mean": [6, 29, 65, 66], "pass": [6, 9, 26, 27, 34, 44, 47, 51, 52, 55, 66, 67], "add": [6, 8, 42, 63, 64, 66, 67], "d": [6, 26, 32, 33, 63, 66], "llama2_token": [6, 64], "tmp": [6, 65], "option": [6, 7, 19, 20, 21, 23, 26, 30, 31, 32, 33, 34, 40, 41, 43, 44, 45, 49, 52, 54, 55, 56, 60, 61, 64], "bool": [6, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 25, 31, 34, 37, 40, 41, 47, 51, 54, 67], "max_seq_len": [6, 9, 11, 12, 15, 26, 28, 30, 31, 32, 63], "int": [6, 8, 11, 12, 15, 19, 20, 21, 22, 23, 25, 26, 28, 29, 30, 31, 32, 35, 37, 40, 41, 46, 49, 50, 51, 52, 53, 56, 63, 66, 67], "512": [6, 11, 12, 63, 67], "instructdataset": [6, 11, 12, 13, 14, 63], "alreadi": [6, 47, 64, 66], "overwrit": 6, "duplic": [6, 7, 61], "sometim": 6, "than": [6, 15, 26, 64, 65, 66, 67], "resolv": [6, 65], "alpaca": [6, 11, 12, 19, 20, 21, 63, 64, 65, 66, 67], "metric_logg": [6, 7, 8], "metric_log": [6, 8, 49, 50, 51, 52], "disklogg": 6, "log_dir": [6, 49, 51], "conveni": [6, 7], "quickli": [6, 63], "verifi": [6, 43, 44, 65, 66], "properli": 6, "experi": [6, 59, 61, 66], "wa": [6, 64, 66, 67], "7b_full": [6, 64, 65], "batch_siz": [6, 11, 12, 13, 14, 26, 33, 64], "discuss": [6, 65, 66], "guidelin": 6, "while": [6, 7, 19, 20, 21, 27, 61, 64, 67], "mai": [6, 54, 63, 65, 66], "tempt": 6, "put": [6, 7, 65, 66], "much": [6, 64, 66, 67], "give": [6, 66], "maximum": [6, 11, 12, 15, 26, 28, 30, 32], "flexibl": [6, 63], "switch": 6, "encourag": [6, 66], "clariti": 6, "significantli": 6, "easier": [6, 64, 65], "dont": 6, "slimorca_dataset": 6, "privat": 6, "typic": [6, 67], "expos": [6, 7, 63, 65], "parent": 6, "modul": [6, 9, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 55, 56, 65, 66, 67], "__init__": [6, 7, 66, 67], "py": [6, 10, 11, 12, 13, 14, 19, 20, 21, 26, 28, 29, 30, 35, 64], "guarante": 6, "stabil": [6, 61, 67], "underscor": 6, "_alpaca": 6, "collect": [6, 65], "differ": [6, 8, 31, 61, 64, 66, 67], "itself": 6, "via": [6, 8, 37, 66, 67], "pair": [6, 53, 63], "k1": [6, 7], "v1": [6, 7], "k2": [6, 7], "v2": [6, 7], "full_finetun": [6, 8], "gpu": [6, 64, 65, 66, 67], "full_finetune_distribut": [6, 64, 65], "checkpoint": [6, 7, 40, 41, 52, 55, 61, 66, 67], "home": 6, "my_model_checkpoint": 6, "file_1": 6, "file_2": 6, "class": [6, 8, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 41, 42, 49, 50, 51, 52, 63, 65, 66, 67], "assign": 6, "nest": 6, "dot": 6, "notat": [6, 26, 30, 32, 33], "my_config": 6, "core": [7, 61, 63, 65, 67], "i": [7, 34, 39, 63, 64, 67], "structur": [7, 63, 64], "new": [7, 24, 49, 51, 65, 66, 67], "user": [7, 26, 31, 63, 65], "thought": [7, 61, 65, 67], "target": [7, 61], "pipelin": [7, 61], "llm": [7, 59, 61, 63, 64, 66], "eg": [7, 32, 40, 61], "meaning": [7, 61, 64], "featur": [7, 8, 60, 61, 65], "fsdp": [7, 61, 65], "activ": [7, 27, 55, 61, 67], "gradient": [7, 61, 64, 66, 67], "accumul": [7, 61], "mix": [7, 61, 64], "precis": [7, 34, 44, 61, 65, 67], "appli": [7, 19, 20, 21, 22, 23, 25, 26, 29, 30, 32, 33, 61, 67], "given": [7, 9, 37, 43, 44, 61, 66], "complex": 7, "becom": [7, 60, 63], "harder": 7, "anticip": 7, "architectur": [7, 32, 63], "methodolog": 7, "reason": [7, 64], "possibl": 7, "trade": 7, "off": [7, 31, 64], "memori": [7, 11, 12, 59, 61, 63, 64, 65], "vs": [7, 65], "qualiti": [7, 64, 66], "believ": 7, "best": 7, "suit": [7, 65], "specif": [7, 9, 63, 64, 67], "b": [7, 26, 30, 32, 33, 37, 52, 66, 67], "fit": [7, 11, 12], "solut": 7, "result": [7, 31, 64, 66, 67], "meant": [7, 34], "depend": [7, 8, 64, 66, 67], "level": [7, 45, 61, 67], "expertis": 7, "routin": 7, "yourself": [7, 66], "exist": [7, 63, 65, 67], "ad": [7, 31, 66, 67], "ones": 7, "modular": [7, 61], "build": [7, 61, 66], "block": [7, 19, 20, 21, 23, 61], "wandb": [7, 8, 52, 65], "log": [7, 45, 49, 50, 51, 52, 64, 65, 67], "fulli": 7, "nativ": [7, 59, 61, 66, 67], "pytorch": [7, 15, 32, 34, 51, 54, 56, 59, 60, 61, 66, 67], "correct": [7, 29, 30, 32, 43, 61, 63], "numer": [7, 61], "pariti": [7, 61], "verif": 7, "extens": [7, 61], "comparison": [7, 66, 67], "benchmark": [7, 56, 61, 64, 66], "limit": 7, "hidden": [7, 27], "behind": 7, "100": [7, 11, 12, 13, 14, 15, 53, 54, 66, 67], "flag": [7, 11, 12, 13, 14, 67], "prefer": [7, 61, 63], "over": [7, 35, 42, 61, 63, 64, 66, 67], "unnecessari": 7, "abstract": [7, 61, 65, 67], "No": [7, 61], "inherit": [7, 42, 61], "go": [7, 31, 61, 63, 64, 65, 67], "upon": 7, "figur": [7, 66, 67], "spectrum": 7, "decid": 7, "interact": [7, 59, 65], "start": [7, 8, 60, 61, 63, 64, 65], "paradigm": 7, "consist": [7, 65], "configur": [7, 11, 12, 13, 14, 15, 33, 61, 65, 66, 67], "paramet": [7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43, 44, 45, 47, 49, 50, 51, 52, 53, 54, 55, 56, 59, 61, 64, 65, 66, 67], "overrid": [7, 10, 64, 65, 67], "togeth": [7, 65, 66], "valid": [7, 60, 64, 65], "environ": [7, 60, 64, 65], "logic": [7, 40, 61, 65, 66], "api": [7, 8, 22, 25, 64, 65, 67], "closer": [7, 66], "monolith": [7, 61], "trainer": [7, 46], "A": [7, 8, 31, 34, 37, 40, 53, 58, 59, 62, 64, 66, 67], "wrapper": [7, 31, 66], "around": [7, 31, 54, 64, 66, 67], "extern": 7, "primarili": [7, 66], "eleutherai": [7, 61, 66], "har": [7, 61, 66], "control": [7, 11, 12, 13, 14, 56, 64], "multi": [7, 26], "stage": 7, "distil": 7, "oper": [7, 54, 56], "turn": 7, "dataload": [7, 11, 12, 13, 14], "applic": [7, 26, 40, 41, 52], "clean": [7, 11], "after": [7, 28, 29, 49, 50, 51, 52, 67], "process": [7, 34, 56, 65, 67], "group": [7, 26, 49, 50, 51, 52], "init_process_group": [7, 47], "backend": 7, "gloo": 7, "els": [7, 42, 61, 67], "nccl": 7, "fullfinetunerecipedistribut": 7, "cleanup": 7, "other": [7, 9, 11, 42, 63, 65, 66], "stuff": 7, "carri": 7, "relev": [7, 64, 66], "interfac": [7, 36], "metric": [7, 65], "logger": [7, 45, 49, 50, 51, 52, 65], "self": [7, 8, 19, 20, 21, 23, 26, 32, 33, 36, 63, 66, 67], "_devic": 7, "get_devic": 7, "_dtype": 7, "get_dtyp": 7, "ckpt_dict": 7, "wrap": [7, 54, 55], "_model": 7, "_setup_model": 7, "_token": [7, 63], "_setup_token": 7, "_optim": 7, "_setup_optim": 7, "_loss_fn": 7, "_setup_loss": 7, "_sampler": 7, "_dataload": 7, "_setup_data": 7, "backward": [7, 67], "zero_grad": 7, "curr_epoch": 7, "rang": [7, 56], "epochs_run": [7, 8], "total_epoch": [7, 8], "idx": 7, "batch": [7, 11, 12, 13, 14, 26, 28, 30, 31, 32, 33, 53, 61, 63, 65, 66], "enumer": 7, "_autocast": 7, "logit": 7, "label": [7, 11, 12, 15, 53], "total_training_step": 7, "_log_every_n_step": 7, "_metric_logg": 7, "log_dict": [7, 49, 50, 51, 52], "step": [7, 32, 35, 49, 50, 51, 52, 54, 59, 64, 66, 67], "learn": [7, 35, 61, 63, 65, 66, 67], "decor": [7, 10], "recipe_main": [7, 10], "none": [7, 8, 26, 30, 31, 32, 33, 39, 40, 41, 43, 44, 45, 49, 50, 51, 52, 55, 56, 64], "fullfinetunerecip": 7, "direct": 7, "wandblogg": [8, 66, 67], "workspac": 8, "seen": [8, 66, 67], "screenshot": 8, "below": [8, 30, 63, 66, 67], "packag": [8, 51, 52, 60], "pip": [8, 51, 52, 60, 64], "Then": [8, 65], "login": [8, 52], "built": [8, 63, 65, 67], "project": [8, 19, 20, 21, 23, 26, 27, 52, 59, 66, 67], "grab": 8, "tab": [8, 11, 12], "click": 8, "sampl": [8, 15, 63, 64], "desir": 8, "suggest": 8, "approach": [8, 63], "joinpath": 8, "_checkpoint": [8, 64], "_output_dir": [8, 40, 41], "torchtune_model_": 8, "with_suffix": 8, "wandb_at": 8, "artifact": 8, "type": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 37, 38, 40, 41, 44, 45, 46, 47, 54, 64, 66, 67], "descript": [8, 13], "whatev": 8, "metadata": 8, "seed_kei": 8, "epochs_kei": 8, "total_epochs_kei": 8, "max_steps_kei": 8, "max_steps_per_epoch": 8, "add_fil": 8, "log_artifact": 8, "field": [9, 11, 12, 13, 14], "num_lay": [9, 32], "32": [9, 66, 67], "num_head": [9, 26, 28, 30, 32], "num_kv_head": [9, 26, 28], "vocab_s": [9, 31], "must": [9, 11, 12, 13, 14, 15, 36, 42, 67], "return": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 26, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 47, 48, 53, 54, 56, 63, 66, 67], "nn": [9, 26, 27, 28, 32, 33, 34, 36, 38, 39, 55, 66, 67], "parsed_yaml": 9, "embed_dim": [9, 26, 30, 33, 66], "omegaconf": 9, "valueerror": [9, 15, 26, 32, 40, 41, 44, 56], "callabl": [10, 32], "main": [10, 11, 12, 13, 14, 26, 29, 30], "my_recip": 10, "With": [10, 64, 66, 67], "foo": 10, "bar": [10, 61, 65], "http": [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 29, 30, 35, 40, 41, 42, 45, 51, 52, 54, 56, 60], "huggingfac": [11, 12, 13, 14, 15, 35, 40, 41, 63], "co": [11, 12, 13, 14, 15, 40, 41], "yahma": 11, "data": [11, 12, 13, 14, 15, 49, 50, 51, 52, 63, 64, 67], "tatsu": [11, 12, 63], "lab": [11, 12, 63], "prompt": [11, 12, 13, 14, 15, 31, 32, 63, 64], "templat": [11, 12, 13, 14, 15], "codebas": [11, 12, 13, 14, 64], "com": [11, 12, 13, 14, 19, 20, 21, 26, 29, 30, 35, 60], "stanford_alpaca": [11, 12], "blob": [11, 12, 13, 14, 19, 20, 21, 26, 29, 30, 35], "761dc5bfbdeeffa89b8bff5d038781a4055f796a": [11, 12], "l31": [11, 12], "where": [11, 12, 13, 14, 26, 31, 32, 37, 63], "instruct": [11, 12, 59, 65, 66, 67], "mask": [11, 12, 13, 14, 26, 31, 33, 63], "ref": [11, 12, 52], "tloen": [11, 12, 19, 20, 21], "lora": [11, 12, 19, 20, 21, 22, 23, 25, 37, 59, 61, 65], "l49": [11, 12], "contribut": [11, 12, 13, 14], "replac": [11, 12, 13, 14, 34, 66], "version": [11, 26, 60, 67], "remov": 11, "hallucin": 11, "poorli": 11, "wrong": 11, "answer": [11, 64], "card": 11, "encod": [11, 12, 13, 14, 15, 31], "decod": [11, 12, 13, 14, 15, 31, 32], "whether": [11, 12, 13, 14, 15, 19, 20, 21, 23, 31, 34, 37, 44], "stanford": [11, 12, 63], "readm": [11, 12], "ov": [11, 12], "recommend": [11, 12, 51, 64, 67], "highest": [11, 12], "sequenc": [11, 12, 15, 26, 28, 30, 31, 32, 33, 53], "length": [11, 12, 15, 26, 28, 30, 31, 32, 33, 41, 53], "alpaca_d": [11, 12], "grammar": [13, 63], "its": [13, 14, 56, 63, 64, 66], "variant": [13, 14], "liweili": 13, "c4_200m": 13, "llama_recip": [13, 14], "src": [13, 14, 35], "l50": 13, "grammar_d": 13, "summar": [14, 63], "samsum": 14, "l13": 14, "dialogu": 14, "summari": 14, "samsum_d": 14, "1024": [15, 63], "chatdataset": 15, "represent": [15, 66, 67], "slimorca": [15, 63], "open": [15, 16, 63, 64], "orca": [15, 63], "dedup": [15, 63], "adher": 15, "chat": 15, "doesn": [15, 64], "prescrib": 15, "truncat": [15, 31], "least": [15, 66], "though": 15, "max": [15, 31, 32, 35, 66], "ds": 15, "10": [15, 53, 64, 67], "351": 15, "82": [15, 64], "391": 15, "221": 15, "220": 15, "193": 15, "12": 15, "471": 15, "gemma": 16, "transformerdecod": [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 66], "w": [16, 17, 18, 24, 51, 52, 64, 66, 67], "blog": 16, "technolog": 16, "develop": [16, 67], "instanti": [16, 17, 18, 19, 20, 21, 23, 24], "arxiv": [17, 18, 22, 25, 26, 29, 30], "org": [17, 18, 22, 25, 26, 29, 30, 42, 45, 51, 54, 56], "ab": [17, 18, 22, 25, 30], "2307": [17, 18], "09288": [17, 18], "lora_attn_modul": [19, 20, 21, 22, 23, 25, 66, 67], "liter": [19, 20, 21, 22, 23, 25], "q_proj": [19, 20, 21, 22, 23, 25, 26, 66, 67], "k_proj": [19, 20, 21, 22, 23, 25, 26, 66, 67], "v_proj": [19, 20, 21, 22, 23, 25, 26, 66, 67], "output_proj": [19, 20, 21, 22, 23, 25, 26, 66, 67], "apply_lora_to_mlp": [19, 20, 21, 22, 23, 25, 66], "apply_lora_to_output": [19, 20, 21, 22, 23, 25, 66], "lora_rank": [19, 20, 21, 22, 23, 25, 66], "lora_alpha": [19, 20, 21, 22, 23, 25, 66], "float": [19, 20, 21, 22, 23, 25, 26, 29, 35, 37, 49, 50, 51, 52, 66, 67], "16": [19, 20, 21, 22, 23, 25, 66, 67], "quantize_bas": [19, 20, 21, 22, 23, 25, 37, 67], "8bb8579e403dc78e37fe81ffbb253c413007323f": [19, 20, 21], "l41": [19, 20, 21], "l43": [19, 20, 21], "linear": [19, 20, 21, 22, 23, 25, 32, 36, 37, 66, 67], "attent": [19, 20, 21, 23, 26, 28, 30, 32, 33, 66, 67], "mlp": [19, 20, 21, 23, 32, 33, 66], "final": [19, 20, 21, 23, 27, 32, 64, 66, 67], "rank": [19, 20, 21, 23, 37, 46, 56, 65, 66, 67], "low": [19, 20, 21, 23, 37, 64, 66, 67], "approxim": [19, 20, 21, 23, 37, 66], "scale": [19, 20, 21, 23, 37, 66, 67], "factor": [19, 20, 21, 23, 37, 64], "lora_dropout": [20, 22], "05": [20, 22], "llama2_7b": [20, 66], "qlora": [22, 25, 59, 61, 66], "per": [22, 25, 28, 34, 67], "paper": [22, 25, 66, 67], "2305": [22, 25, 26], "14314": [22, 25], "lora_llama2_7b": [22, 66], "mistral": [23, 24, 25, 64, 65], "announc": 24, "lora_mistral_7b": 25, "head_dim": [26, 28, 30, 32], "pos_embed": [26, 66], "kv_cach": 26, "kvcach": [26, 32], "attn_dropout": [26, 32], "head": [26, 28, 30, 32], "queri": [26, 28, 32], "gqa": 26, "introduc": [26, 29, 37, 66, 67], "pdf": [26, 29], "13245v1": 26, "multihead": 26, "mha": [26, 32], "n": [26, 31, 58, 62, 63], "extrem": 26, "share": [26, 63], "mqa": 26, "credit": 26, "document": 26, "lightn": 26, "lit": 26, "gpt": [26, 64], "lit_gpt": 26, "v": [26, 32, 66], "k": [26, 66], "q": [26, 66], "n_kv_head": 26, "dimens": [26, 28, 30, 32, 37, 66, 67], "calcul": 26, "e": [26, 34, 36, 39, 60, 64, 66, 67], "g": [26, 36, 66, 67], "rotarypositionalembed": [26, 66], "cach": [26, 28, 30], "comput": [26, 27, 30, 32, 56, 64, 67], "rope": [26, 30], "dropout": [26, 37, 66, 67], "onto": 26, "scaled_dot_product_attent": 26, "input_po": [26, 30, 32, 33], "seq_length": [26, 33], "seq_len": [26, 30], "bigger": 26, "n_h": [26, 30], "num": [26, 30], "n_kv": 26, "kv": [26, 28, 32], "emb": [26, 32, 33], "h_d": [26, 30], "gate_proj": 27, "down_proj": 27, "up_proj": 27, "silu": 27, "feed": [27, 33], "network": [27, 66, 67], "deriv": [27, 32, 33], "fed": 27, "multipli": 27, "subclass": [27, 42], "although": [27, 66], "afterward": 27, "former": 27, "regist": [27, 34, 67], "hook": [27, 34, 67], "latter": 27, "max_batch_s": 28, "standalon": 28, "past": 28, "becaus": [28, 32, 64], "expand": 28, "dpython": [28, 34], "ep": 29, "1e": 29, "06": [29, 66], "root": [29, 51], "squar": 29, "1910": 29, "07467": 29, "verfic": [29, 30], "facebookresearch": [29, 30], "small": [29, 64], "avoid": [29, 56, 67], "divis": 29, "zero": [29, 64], "10000": 30, "rotari": 30, "propos": 30, "2104": 30, "09864": 30, "l450": 30, "upto": 30, "init": [30, 52, 67], "exceed": 30, "freq": 30, "recomput": 30, "geometr": 30, "progress": [30, 65], "rotat": 30, "angl": 30, "bsz": 30, "todo": 30, "made": [30, 64], "effici": [30, 59, 61, 64, 65, 66], "spm_model": 31, "sentencepieceprocessor": 31, "bos_id": 31, "eos_id": 31, "pad_id": 31, "sentencepiec": 31, "vocabulari": 31, "sentenc": 31, "pad": [31, 53], "non": 31, "from_fil": 31, "tokenized_text": 31, "hello": [31, 64], "world": [31, 46], "add_bo": 31, "add_eo": 31, "31587": 31, "29644": 31, "102": 31, "text": [31, 63, 64], "trim_leading_whitespac": 31, "prefix": 31, "unbatch": 31, "prepend": 31, "bo": 31, "append": 31, "eo": 31, "trim": 31, "lead": 31, "whitespac": 31, "underli": [31, 67], "s1": 31, "s2": 31, "due": [31, 66, 67], "classmethod": 31, "tokenize_messag": [31, 63], "messag": [31, 60, 63], "concaten": 31, "problem": 31, "known": [31, 63], "slice": 31, "tokenizer_path": 31, "role": [31, 63], "system": [31, 63], "assist": [31, 63], "respons": [31, 63, 64, 65], "separ": [31, 40, 65, 66, 67], "concat": 31, "1788": 31, "2643": 31, "13": [31, 64, 67], "1792": 31, "9508": 31, "465": 31, "22137": 31, "2933": 31, "join": 31, "attribut": 31, "transformerdecoderlay": 32, "norm": [32, 33], "move": 32, "space": 32, "check": [32, 44, 59, 65, 66], "belong": 32, "reduc": [32, 63, 66, 67], "statement": 32, "improv": [32, 64, 66], "readabl": [32, 64], "At": 32, "arang": 32, "prompt_length": 32, "causal_mask": 32, "m_": 32, "seq": 32, "attn": [33, 66, 67], "causalselfattent": [33, 66], "sa_norm": 33, "mlp_norm": 33, "ff": 33, "common_util": 34, "bfloat16": [34, 64, 65, 66], "offload_to_cpu": 34, "nf4": [34, 67], "restor": 34, "higher": [34, 67], "offload": [34, 67], "_register_state_dict_hook": 34, "m": 34, "mymodul": 34, "_after_": 34, "nf4tensor": [34, 67], "unquant": [34, 64, 67], "unus": 34, "num_warmup_step": 35, "num_training_step": 35, "num_cycl": 35, "last_epoch": 35, "lambdalr": 35, "rate": [35, 61, 65], "schedul": [35, 54, 65], "linearli": 35, "increas": [35, 66], "lr": 35, "decreas": [35, 66, 67], "cosin": 35, "remain": [35, 66], "v4": 35, "23": 35, "l104": 35, "warmup": [35, 54], "phase": 35, "total": [35, 46, 58, 62, 64, 66], "wave": 35, "half": 35, "index": [35, 53, 64], "last": 35, "lr_schedul": 35, "appropri": [35, 63, 67], "peft": [36, 37, 38, 39, 66, 67], "protocol": 36, "adapter_param": [36, 37, 38, 39], "correspond": [36, 38, 44, 65], "come": [36, 66], "proj": 36, "in_dim": [36, 37, 66, 67], "out_dim": [36, 37, 66, 67], "bia": [36, 37, 66, 67], "loralinear": [36, 66, 67], "alpha": [37, 66, 67], "use_bia": 37, "larg": [37, 67], "languag": [37, 66], "perturb": 37, "decomposit": [37, 66], "matric": [37, 66, 67], "trainabl": [37, 39, 66, 67], "mapsto": 37, "w_0x": 37, "r": [37, 66], "bax": 37, "probabl": [37, 64], "lora_a": [37, 66, 67], "lora_b": [37, 66, 67], "subset": 38, "map": [39, 40, 49, 50, 51, 52, 64, 66], "respect": [39, 63], "get_adapter_param": [39, 66], "few": [40, 63, 66, 67], "0001_of_0003": 40, "0002_of_0003": 40, "preserv": [40, 67], "weight_map": [40, 64], "intermediate_checkpoint": [40, 41], "parit": 40, "_weight_map": 40, "shard": 41, "wip": 41, "tunerecipeargpars": 42, "argpars": 42, "argumentpars": 42, "builtin": 42, "noth": 42, "treat": 42, "still": [42, 66, 67], "consult": 42, "doc": [42, 45, 51, 52, 54, 56], "info": [42, 65], "librari": [42, 45, 56, 59, 61, 67], "html": [42, 45, 51, 54, 56], "parse_known_arg": 42, "namespac": 42, "act": 42, "alwai": 42, "precid": 42, "parse_arg": 42, "intern": 42, "properti": [42, 66], "too": 42, "availab": 43, "machin": [43, 64], "distribut": [43, 47, 55, 56, 61, 65], "bf16": [44, 67], "request": [44, 63, 64], "inde": [44, 64], "kernel": 44, "runtimeerror": [44, 47], "float32": 44, "done": [44, 66, 67], "isn": 44, "hardwar": [44, 61, 64, 66], "stream": 45, "handler": 45, "aka": 46, "filenam": 49, "log_": 49, "unixtimestamp": 49, "txt": [49, 65], "thread": 49, "safe": 49, "resourc": [49, 50, 51, 52], "flush": [49, 50, 51, 52], "union": [49, 50, 51, 52, 56], "ndarrai": [49, 50, 51, 52], "scalar": [49, 50, 51, 52], "tag": [49, 50, 51, 52], "record": [49, 50, 51, 52], "payload": [49, 50, 51, 52], "dictionari": [49, 50, 51, 52, 64], "organize_log": 51, "tensorboard": 51, "stabl": [51, 54, 56, 60], "subdirectori": 51, "sub": 51, "compar": [51, 64, 66, 67], "logdir": 51, "startup": 51, "recurs": 51, "tree": [51, 63, 64], "tfevent": 51, "encount": 51, "frontend": 51, "organ": 51, "accordingli": 51, "my_log_dir": 51, "view": [51, 64, 65], "my_metr": [51, 52], "termin": [51, 52], "entiti": 52, "bias": 52, "my_project": 52, "my_ent": 52, "my_group": 52, "importerror": 52, "account": [52, 66, 67], "log_config": 52, "local": [52, 56, 60, 64, 65], "link": 52, "capecap": 52, "6053ofw0": 52, "torchtune_config_j67sb73v": 52, "padding_idx": 53, "ignore_idx": 53, "longest": 53, "integ": [53, 56], "tokenpair": 53, "collat": 53, "token_pair": 53, "torchtune_perf_trac": 54, "contextmanag": 54, "wait": 54, "trace": 54, "speed": [54, 67], "reduct": [54, 66], "context": [54, 63], "auto_wrap_polici": 55, "polici": 55, "debug_mod": 56, "pseudo": 56, "random": [56, 65], "commonli": [56, 64, 66, 67], "numpi": 56, "own": [56, 63, 64, 66], "determinist": 56, "global": 56, "warn": 56, "nondeterminist": 56, "addition": [56, 66], "cudnn": 56, "disabl": 56, "set_deterministic_debug_mod": 56, "algorithm": 56, "outsid": [56, 64, 66], "generated_examples_python": 57, "zip": 57, "galleri": [57, 62], "sphinx": 57, "000": [58, 62], "execut": [58, 62], "generated_exampl": 58, "mem": [58, 62], "mb": [58, 62], "topic": 59, "gentl": 59, "introduct": 59, "readi": 59, "maxim": [59, 61], "workflow": [59, 63, 65, 66], "requisit": 60, "proper": [60, 65], "host": [60, 65], "page": [60, 61, 65], "latest": [60, 65, 67], "confirm": 60, "And": [60, 64], "usag": [60, 64, 65, 67], "h": 60, "ls": [60, 64, 65], "cp": [60, 64, 65], "welcom": 60, "show": [60, 66], "exit": 60, "greatest": [60, 65], "contributor": 60, "cd": [60, 64], "On": [61, 66], "pointer": 61, "author": [61, 65], "emphas": 61, "aspect": 61, "simplic": 61, "component": 61, "reus": 61, "high": [61, 66], "prove": 61, "democrat": 61, "box": [61, 67], "zoo": 61, "varieti": [61, 66], "techniqu": [61, 64, 65, 66], "integr": [61, 64, 65, 66, 67], "excit": 61, "checkout": 61, "quickstart": 61, "attain": 61, "better": [61, 63, 64], "chekckpoint": 61, "hyperparamet": [61, 65, 66, 67], "embodi": 61, "philosophi": 61, "especi": [61, 64], "usabl": 61, "eluetherai": 61, "composit": 61, "hard": 61, "outlin": 61, "unecessari": 61, "never": 61, "thoroughli": 61, "unit": 61, "know": [63, 64, 66], "steer": 63, "wheel": 63, "publicli": 63, "great": [63, 64], "sever": 63, "wide": 63, "bootstrap": 63, "indic": 63, "iter": [63, 67], "knob": 63, "tweak": 63, "sai": [63, 65], "footprint": [63, 66], "could": [63, 66], "achiev": [63, 64, 66, 67], "256": [63, 64], "task": [63, 64, 66, 67], "fix": 63, "goal": 63, "flavor": 63, "It": [63, 67], "agnost": 63, "condit": 63, "respond": 63, "alpacainstructtempl": 63, "describ": 63, "further": [63, 66, 67], "classifi": 63, "anim": 63, "plant": 63, "miner": 63, "oak": 63, "copper": 63, "ore": 63, "eleph": 63, "instructtempl": 63, "instruct_dataset": 63, "mydataset": 63, "onthehub": 63, "customtempl": 63, "similar": [63, 64, 66, 67], "chatformat": 63, "quit": [63, 67], "similarli": 63, "chat_dataset": 63, "conversation_styl": 63, "sharegpt": 63, "chat_format": 63, "llama2chatformat": 63, "honest": 63, "am": [63, 64], "pari": 63, "capit": 63, "franc": 63, "stun": 63, "formatted_messag": 63, "inst": 63, "sy": 63, "nyou": 63, "incorpor": 63, "advanc": 63, "preferencedataset": 63, "rlhf": 63, "adjust": 63, "chosen": 63, "reject": 63, "chosen_messag": 63, "transformed_sampl": 63, "key_chosen": 63, "rejected_messag": 63, "key_reject": 63, "chosen_input_id": 63, "c_mask": 63, "chosen_label": 63, "np": 63, "cross_entropy_ignore_idx": 63, "rejected_input_id": 63, "r_mask": 63, "rejected_label": 63, "purpos": [63, 65], "stack_exchanged_paired_dataset": 63, "stackexchang": 63, "had": 63, "lvwerra": 63, "stack": 63, "exchang": 63, "stackexchangedpairedtempl": 63, "column_map": 63, "question": [63, 64], "response_j": 63, "response_k": 63, "data_dir": 63, "rl": 63, "favorit": [64, 66], "commun": 64, "seemlessli": 64, "beyond": [64, 67], "connect": 64, "larger": 64, "might": 64, "amount": 64, "natur": 64, "export": 64, "mobil": 64, "phone": 64, "leverag": [64, 67], "mode": 64, "lot": 64, "plai": 64, "freez": [64, 66], "percentag": 64, "learnabl": 64, "keep": [64, 66], "16gb": [64, 66], "rtx": 64, "3090": 64, "4090": 64, "peak": [64, 66, 67], "hour": 64, "full_finetune_single_devic": [64, 65], "7b_full_low_memori": [64, 65], "13b_full": [64, 65], "lora_finetune_single_devic": [64, 65, 66, 67], "7b_lora_single_devic": [64, 65, 66, 67], "7b_qlora_single_devic": [64, 65, 67], "473": 64, "98": [64, 67], "gb": [64, 66, 67], "50": 64, "484": 64, "01": [64, 65], "fact": [64, 66], "ident": 64, "third": 64, "smaller": [64, 66, 67], "But": [64, 66], "realli": 64, "eleuther_ev": 64, "eleuther_evalu": 64, "lm_eval": 64, "plan": 64, "copi": [64, 65, 67], "element": 64, "custom_eval_config": 64, "truthfulqa_mc2": [64, 66], "qa": 64, "measur": 64, "propens": 64, "shot": 64, "accuraci": [64, 66, 67], "baselin": [64, 66], "324": 64, "loglikelihood": 64, "195": 64, "121": 64, "27": 64, "second": [64, 66, 67], "197": 64, "acc": 64, "388": 64, "38": 64, "shown": 64, "489": 64, "48": [64, 67], "seem": 64, "custom_generation_config": 64, "kick": 64, "top_k": 64, "300": 64, "temperatur": 64, "interest": 64, "site": 64, "visit": 64, "bai": 64, "area": 64, "92": 64, "exploratorium": 64, "san": 64, "francisco": 64, "magazin": 64, "awesom": 64, "bridg": 64, "pretti": 64, "cool": 64, "96": [64, 67], "61": 64, "sec": 64, "25": 64, "83": 64, "99": [64, 66], "15": [64, 66, 67], "72": 64, "littl": 64, "saw": 64, "took": 64, "torchao": [64, 67], "bit": [64, 66, 67], "custom_quantization_config": 64, "68": 64, "19": [64, 67], "76": 64, "69": 64, "95": 64, "67": 64, "4w": 64, "unlik": 64, "won": 64, "engin": 64, "fullmodeltorchtunecheckpoint": 64, "int4weightonlyquant": 64, "groupsiz": 64, "did": [64, 67], "park": 64, "sit": 64, "top": [64, 67], "hill": 64, "beauti": 64, "62": 64, "17": [64, 66], "85": 64, "compil": [64, 67], "hood": [64, 67], "sped": 64, "almost": [64, 66], "3x": 64, "benefit": 64, "yet": 64, "fast": 64, "clone": [64, 66, 67], "assumpt": 64, "satisfi": 64, "new_dir": 64, "output_dict": 64, "sd_1": 64, "sd_2": 64, "dump": 64, "convert_hf_checkpoint": 64, "checkpoint_path": 64, "my": 64, "justin": 64, "school": 64, "math": 64, "teacher": 64, "ws": 64, "94": 64, "103": 64, "28": 64, "bandwidth": 64, "1391": 64, "84": 64, "thats": 64, "hopefulli": 64, "gave": 64, "launch": 65, "pretrain": [65, 66, 67], "gate": 65, "grant": 65, "minut": 65, "agreement": 65, "altern": 65, "opt": 65, "authent": 65, "hackabl": 65, "singularli": 65, "focus": 65, "technic": 65, "depth": 65, "why": [65, 66], "principl": 65, "minim": [65, 66, 67], "boilerpl": 65, "hold": 65, "substanti": [65, 66], "custom_config": 65, "replic": 65, "lorafinetunerecipesingledevic": 65, "lora_finetune_output": 65, "log_1713194212": 65, "sampler": 65, "52": 65, "3697006702423096": 65, "25880": [65, 67], "24": 65, "55": 65, "83it": 65, "were": 65, "monitor": 65, "tqdm": 65, "interv": 65, "e2": 65, "teach": 66, "straight": 66, "jump": 66, "neural": [66, 67], "unfamiliar": 66, "oppos": [66, 67], "momentum": 66, "adamw": 66, "arbitrari": 66, "min": 66, "relat": 66, "aghajanyan": 66, "et": 66, "al": 66, "hypothes": 66, "intrins": 66, "lower": 66, "down": [66, 67], "often": 66, "four": 66, "eight": 66, "practic": 66, "imag": 66, "simplifi": 66, "left": 66, "blue": 66, "extra": [66, 67], "rememb": 66, "approx": 66, "15m": 66, "8192": 66, "65k": 66, "p": [66, 67], "requires_grad": [66, 67], "frozen_out": [66, 67], "lora_out": [66, 67], "omit": 66, "construct": 66, "base_model": 66, "choos": 66, "lora_model": 66, "lora_llama_2_7b": [66, 67], "alon": 66, "in_featur": 66, "out_featur": 66, "inplac": 66, "feel": 66, "free": 66, "strict": 66, "whenev": 66, "validate_state_dict_for_lora": 66, "peft_util": 66, "set_trainable_param": 66, "fetch": 66, "lora_param": 66, "total_param": 66, "sum": 66, "numel": 66, "trainable_param": 66, "2f": 66, "6742609920": 66, "4194304": 66, "taken": [66, 67], "vram": 66, "nnode": 66, "nproc_per_nod": 66, "lora_finetune_distribut": 66, "7b_lora": 66, "my_model_checkpoint_path": [66, 67], "tokenizer_checkpoint": [66, 67], "my_tokenizer_checkpoint_path": [66, 67], "constraint": 66, "factori": 66, "benefici": 66, "long": 66, "impact": 66, "rel": 66, "minor": 66, "good": 66, "64": 66, "lora_experiment_1": 66, "smooth": [66, 67], "curv": [66, 67], "500": 66, "ran": 66, "commod": 66, "cogniz": 66, "ax": 66, "parallel": 66, "truthfulqa": 66, "previous": 66, "57": [66, 67], "475": 66, "87": 66, "508": 66, "128": 66, "86": 66, "504": 66, "04": 66, "514": 66, "lowest": 66, "absolut": 66, "4gb": 66, "coupl": [66, 67], "tradeoff": 66, "even": [66, 67], "potenti": 66, "enhanc": 67, "maintain": 67, "therebi": 67, "highli": 67, "part": 67, "vanilla": 67, "style": 67, "held": 67, "therefor": 67, "intermedi": 67, "bespok": 67, "normalfloat": 67, "8x": 67, "retain": 67, "vast": 67, "major": 67, "highlight": 67, "degrad": 67, "normatfloat": 67, "doubl": 67, "themselv": 67, "prune": 67, "deepdiv": 67, "idea": 67, "distinct": 67, "storag": 67, "datatyp": 67, "de": 67, "incur": 67, "consum": 67, "counterpart": 67, "set_default_devic": 67, "qlora_linear": 67, "memory_alloc": 67, "177": 67, "152": 67, "byte": 67, "del": 67, "empty_cach": 67, "lora_linear": 67, "081": 67, "344": 67, "qlora_llama2_7b": 67, "qlora_model": 67, "essenti": 67, "reparametrize_as_dtype_state_dict_post_hook": 67, "entir": 67, "stat": 67, "alloc": 67, "reserv": 67, "against": 67, "35": 67, "40": 67, "29": 67, "slow": 67, "slower": 67, "149": 67, "9157477021217346": 67, "02": 67, "08": 67, "14": 67, "15it": 67, "thing": 67, "nightli": 67, "200": 67, "hundr": 67, "228": 67, "8158286809921265": 67, "59": 67, "95it": 67, "exercis": 67, "manual": 67, "portion": 67, "augment": 67, "linear_nf4": 67, "to_nf4": 67, "linear_weight": 67, "autograd": 67, "regular": 67, "incom": 67, "variabl": 67}, "objects": {"torchtune.config": [[9, 0, 1, "", "instantiate"], [10, 0, 1, "", "parse"]], "torchtune.datasets": [[11, 0, 1, "", "alpaca_cleaned_dataset"], [12, 0, 1, "", "alpaca_dataset"], [13, 0, 1, "", "grammar_dataset"], [14, 0, 1, "", "samsum_dataset"], [15, 0, 1, "", "slimorca_dataset"]], "torchtune.models.gemma": [[16, 0, 1, "", "gemma_2b"]], "torchtune.models.llama2": [[17, 0, 1, "", "llama2_13b"], [18, 0, 1, "", "llama2_7b"], [19, 0, 1, "", "lora_llama2_13b"], [20, 0, 1, "", "lora_llama2_7b"], [21, 0, 1, "", "qlora_llama2_13b"], [22, 0, 1, "", "qlora_llama2_7b"]], "torchtune.models.mistral": [[23, 0, 1, "", "lora_mistral_7b"], [24, 0, 1, "", "mistral_7b"], [25, 0, 1, "", "qlora_mistral_7b"]], "torchtune.modules": [[26, 1, 1, "", "CausalSelfAttention"], [27, 1, 1, "", "FeedForward"], [28, 1, 1, "", "KVCache"], [29, 1, 1, "", "RMSNorm"], [30, 1, 1, "", "RotaryPositionalEmbeddings"], [31, 1, 1, "", "Tokenizer"], [32, 1, 1, "", "TransformerDecoder"], [33, 1, 1, "", "TransformerDecoderLayer"], [35, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[26, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[27, 2, 1, "", "forward"]], "torchtune.modules.RMSNorm": [[29, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[30, 2, 1, "", "forward"]], "torchtune.modules.Tokenizer": [[31, 2, 1, "", "decode"], [31, 2, 1, "", "encode"], [31, 2, 1, "", "from_file"], [31, 2, 1, "", "tokenize_messages"]], "torchtune.modules.TransformerDecoder": [[32, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoderLayer": [[33, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[34, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[36, 1, 1, "", "AdapterModule"], [37, 1, 1, "", "LoRALinear"], [38, 0, 1, "", "get_adapter_params"], [39, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[36, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[37, 2, 1, "", "adapter_params"], [37, 2, 1, "", "forward"]], "torchtune.utils": [[40, 1, 1, "", "FullModelHFCheckpointer"], [41, 1, 1, "", "FullModelMetaCheckpointer"], [42, 1, 1, "", "TuneRecipeArgumentParser"], [43, 0, 1, "", "get_device"], [44, 0, 1, "", "get_dtype"], [45, 0, 1, "", "get_logger"], [46, 0, 1, "", "get_world_size_and_rank"], [47, 0, 1, "", "init_distributed"], [48, 0, 1, "", "list_dtypes"], [53, 0, 1, "", "padded_collate"], [54, 0, 1, "", "profiler"], [55, 0, 1, "", "set_activation_checkpointing"], [56, 0, 1, "", "set_seed"]], "torchtune.utils.FullModelHFCheckpointer": [[40, 2, 1, "", "load_checkpoint"], [40, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[41, 2, 1, "", "load_checkpoint"], [41, 2, 1, "", "save_checkpoint"]], "torchtune.utils.TuneRecipeArgumentParser": [[42, 2, 1, "", "parse_known_args"]], "torchtune.utils.metric_logging": [[49, 1, 1, "", "DiskLogger"], [50, 1, 1, "", "StdoutLogger"], [51, 1, 1, "", "TensorBoardLogger"], [52, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[49, 2, 1, "", "close"], [49, 2, 1, "", "log"], [49, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[50, 2, 1, "", "close"], [50, 2, 1, "", "log"], [50, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[51, 2, 1, "", "close"], [51, 2, 1, "", "log"], [51, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[52, 2, 1, "", "close"], [52, 2, 1, "", "log"], [52, 2, 1, "", "log_config"], [52, 2, 1, "", "log_dict"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 59, 61, 64, 66, 67], "config": [0, 6, 7, 65], "dataset": [1, 63], "model": [2, 3, 8, 64, 65, 66], "llama2": [2, 64, 66, 67], "mistral": 2, "gemma": 2, "modul": 3, "compon": [3, 6], "build": [3, 67], "block": 3, "peft": 3, "util": [3, 4], "checkpoint": [4, 5, 8, 64], "distribut": 4, "reduc": 4, "precis": 4, "memori": [4, 66, 67], "manag": 4, "perform": [4, 66], "profil": [4, 54], "metric": [4, 8], "log": [4, 8], "data": 4, "miscellan": 4, "overview": [5, 61, 64], "format": [5, 63], "handl": 5, "differ": 5, "intermedi": 5, "vs": 5, "final": 5, "lora": [5, 64, 66, 67], "put": [5, 67], "thi": 5, "all": [5, 6, 67], "togeth": [5, 67], "about": 6, "where": 6, "do": 6, "paramet": 6, "live": 6, "write": 6, "configur": [6, 63], "us": [6, 7, 64, 67], "instanti": [6, 9], "referenc": 6, "other": [6, 64], "field": 6, "interpol": 6, "valid": 6, "your": [6, 7, 65], "best": 6, "practic": 6, "airtight": 6, "public": 6, "api": 6, "onli": 6, "command": 6, "line": 6, "overrid": 6, "what": [7, 61, 66, 67], "ar": 7, "recip": [7, 65, 66], "script": 7, "class": 7, "run": [7, 64], "cli": 7, "pars": [7, 10], "weight": 8, "bias": 8, "logger": 8, "w": 8, "b": 8, "alpaca_cleaned_dataset": 11, "alpaca_dataset": 12, "grammar_dataset": 13, "samsum_dataset": 14, "slimorca_dataset": 15, "gemma_2b": 16, "llama2_13b": 17, "llama2_7b": 18, "lora_llama2_13b": 19, "lora_llama2_7b": 20, "qlora_llama2_13b": 21, "qlora_llama2_7b": 22, "lora_mistral_7b": 23, "mistral_7b": 24, "qlora_mistral_7b": 25, "causalselfattent": 26, "todo": [26, 33], "feedforward": 27, "kvcach": 28, "rmsnorm": 29, "rotarypositionalembed": 30, "token": 31, "transformerdecod": 32, "transformerdecoderlay": 33, "reparametrize_as_dtype_state_dict_post_hook": 34, "get_cosine_schedule_with_warmup": 35, "adaptermodul": 36, "loralinear": 37, "get_adapter_param": 38, "set_trainable_param": 39, "fullmodelhfcheckpoint": 40, "fullmodelmetacheckpoint": 41, "tunerecipeargumentpars": 42, "get_devic": 43, "get_dtyp": 44, "get_logg": 45, "get_world_size_and_rank": 46, "init_distribut": 47, "list_dtyp": 48, "disklogg": 49, "stdoutlogg": 50, "tensorboardlogg": 51, "wandblogg": 52, "padded_col": 53, "set_activation_checkpoint": 55, "set_se": 56, "comput": [58, 62], "time": [58, 62], "welcom": 59, "document": 59, "get": 59, "start": 59, "tutori": 59, "instal": 60, "instruct": [60, 63], "via": 60, "pypi": 60, "git": 60, "clone": 60, "kei": 61, "concept": 61, "design": 61, "principl": 61, "fine": 63, "tune": 63, "custom": 63, "templat": 63, "chat": 63, "fulli": 63, "end": 64, "workflow": 64, "download": [64, 65], "7b": 64, "finetun": [64, 65, 66, 67], "evalu": 64, "eleutherai": 64, "s": 64, "eval": 64, "har": 64, "gener": 64, "speed": 64, "up": 64, "quantiz": 64, "librari": 64, "first": 65, "llm": 65, "select": 65, "modifi": 65, "train": 65, "next": 65, "step": 65, "how": 66, "doe": 66, "work": 66, "appli": 66, "trade": 66, "off": 66, "qlora": 67, "save": 67, "deep": 67, "dive": 67, "from": 67}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})