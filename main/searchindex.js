Search.setIndex({"docnames": ["api_ref_config", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "examples/checkpointer", "examples/configs", "examples/e2e_flow", "examples/finetune_llm", "examples/first_finetune_tutorial", "examples/lora_finetune", "examples/recipe_deepdive", "examples/wandb_logging", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.Tokenizer", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.argparse.TuneRecipeArgumentParser", "generated/torchtune.utils.collate.padded_collate", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.logging.get_logger", "generated/torchtune.utils.memory.set_activation_checkpointing", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.precision.get_autocast", "generated/torchtune.utils.precision.get_dtype", "generated/torchtune.utils.precision.get_gradient_scaler", "generated/torchtune.utils.precision.list_dtypes", "generated/torchtune.utils.seed.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times"], "filenames": ["api_ref_config.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "examples/checkpointer.rst", "examples/configs.rst", "examples/e2e_flow.rst", "examples/finetune_llm.rst", "examples/first_finetune_tutorial.rst", "examples/lora_finetune.rst", "examples/recipe_deepdive.rst", "examples/wandb_logging.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.Tokenizer.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.argparse.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.collate.padded_collate.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.logging.get_logger.rst", "generated/torchtune.utils.memory.set_activation_checkpointing.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.precision.get_autocast.rst", "generated/torchtune.utils.precision.get_dtype.rst", "generated/torchtune.utils.precision.get_gradient_scaler.rst", "generated/torchtune.utils.precision.list_dtypes.rst", "generated/torchtune.utils.seed.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst"], "titles": ["torchtune.config", "torchtune.datasets", "torchtune.models.llama2", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "Configs Deep-Dive", "End-to-End Workflow with torchtune", "LLM Full Finetuning Recipe", "Finetune your First LLM", "Finetuning Llama2 with LoRA", "Training Recipe Deep-Dive", "Logging to Weights &amp; Biases", "instantiate", "parse", "alpaca_cleaned_dataset", "alpaca_dataset", "grammar_dataset", "samsum_dataset", "slimorca_dataset", "llama2_7b", "lora_llama2", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "Tokenizer", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "padded_collate", "get_device", "get_world_size_and_rank", "init_distributed", "get_logger", "set_activation_checkpointing", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "get_autocast", "get_dtype", "get_gradient_scaler", "list_dtypes", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times"], "terms": {"These": [3, 5, 6, 7, 9, 10, 11, 13, 38], "ar": [3, 5, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 21, 28, 33, 36, 37, 50, 57, 58], "common": [3, 6, 10], "can": [3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 25, 26, 27, 36, 38, 47, 48, 56, 57, 58], "us": [3, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 29, 30, 36, 37, 38, 40, 45, 46, 47, 48, 49, 50, 51, 53, 56, 58], "all": [3, 6, 7, 8, 9, 10, 11, 22, 23, 28, 30, 36, 38, 54, 56, 58, 59], "offer": 4, "allow": [4, 47], "seamless": 4, "transit": 4, "between": [4, 5, 7, 10, 36], "format": [4, 7, 9, 15, 16, 17, 18, 19, 36, 37], "train": [4, 5, 7, 10, 12, 15, 16, 17, 18, 19, 22, 31, 36, 37, 49, 50, 51, 56, 58], "interoper": [4, 5, 7, 11, 58], "rest": 4, "ecosystem": [4, 5, 7, 9, 11, 58], "For": [4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 21, 22, 28, 38, 48, 53], "comprehens": 4, "overview": [4, 6, 9, 10, 12], "pleas": 4, "see": [4, 5, 7, 8, 9, 10, 12, 15, 24, 32, 38, 43, 48, 53, 57, 58], "deep": [4, 5, 8, 9, 10, 58], "dive": [4, 5, 8, 9, 10, 58], "enabl": [4, 6, 8, 9, 11, 12, 33, 53], "work": [4, 5, 7, 11, 38, 58], "set": [4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 26, 28, 35, 40, 44, 53, 58], "consumpt": 4, "dure": [4, 5, 7, 8, 10, 15, 16, 17, 18, 22, 24, 26, 28, 29], "variou": 4, "dataset": [4, 6, 7, 9, 10, 15, 16, 17, 18, 19, 58], "walk": [5, 7, 8, 9, 11, 47, 58], "you": [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 38, 47, 48, 56, 57, 58], "through": [5, 6, 7, 8, 9, 11, 23, 58], "design": [5, 11], "behavior": 5, "associ": [5, 6, 7, 10, 11], "util": [5, 6, 7, 8, 9, 11, 12, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 58], "what": [5, 6, 7, 9, 56], "cover": [5, 6, 7, 11], "how": [5, 6, 7, 8, 9, 11, 56], "we": [5, 6, 7, 8, 10, 11, 12, 15, 16, 22, 24, 26, 27, 28, 33, 36, 37, 50, 58], "them": [5, 6, 7, 8, 10, 23, 27, 30], "scenario": 5, "full": [5, 6, 9, 10, 11, 27, 36, 37, 56, 58], "finetun": [5, 6, 11, 15, 16, 52, 56, 58], "compos": 5, "compon": [5, 9, 10, 11, 58], "which": [5, 7, 10, 11, 15, 16, 17, 18, 21, 22, 26, 27, 28, 29, 31, 36, 37, 45, 50, 51, 57, 58], "plug": 5, "ani": [5, 6, 7, 8, 10, 11, 13, 14, 27, 30, 34, 35, 36, 37, 53], "recip": [5, 6, 7, 12, 13, 14, 17, 18, 23, 36, 37, 56, 57, 58], "evalu": [5, 9, 10, 11, 56, 58], "gener": [5, 10, 11, 19, 27, 53, 54, 56], "each": [5, 7, 9, 10, 11, 21, 22, 26, 27, 28, 53, 58], "support": [5, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 21, 22, 33, 37, 49, 50, 52, 58], "model": [5, 6, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 44, 56, 58], "make": [5, 6, 7, 9, 10, 11, 12, 22, 29, 58], "easi": [5, 9, 10, 11, 58], "understand": [5, 6, 9, 10, 11, 58], "debug": [5, 6, 11], "extend": [5, 11, 58], "befor": [5, 7, 28, 29, 33, 36], "let": [5, 6, 7, 9, 10, 12], "s": [5, 6, 8, 9, 10, 11, 12, 14, 21, 22, 26, 28, 29, 30, 32, 34, 36, 37, 40, 47, 58], "defin": [5, 6, 10, 11, 23, 32, 33, 34], "some": [5, 6, 7, 9, 10, 21, 34, 35, 56, 58], "concept": [5, 7], "In": [5, 6, 7, 8, 10, 11, 26, 33, 47, 48], "ll": [5, 6, 7, 9, 11, 58], "talk": 5, "about": [5, 7, 10, 11, 36, 48, 58], "take": [5, 6, 7, 9, 10, 11, 13, 23, 24, 30, 36, 38, 40], "close": [5, 10, 11, 45, 46, 47, 48], "look": [5, 6, 7, 8, 9, 10, 11, 47], "veri": [5, 7, 28], "simpli": [5, 6], "dictat": 5, "state_dict": [5, 10, 30, 36, 37], "store": [5, 10, 45, 48], "file": [5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 27, 36, 37, 38, 45, 48, 55, 58, 59], "disk": [5, 45], "weight": [5, 7, 9, 10, 11, 21, 22, 30, 32, 33, 36, 37, 48], "string": [5, 27, 32, 40, 50], "kei": [5, 6, 7, 10, 12, 21, 22, 24, 28, 35, 36], "identifi": 5, "state": [5, 7, 10, 11, 30, 34, 35, 36, 37], "dict": [5, 6, 11, 12, 13, 30, 34, 35, 36, 37, 42], "If": [5, 6, 9, 10, 15, 16, 17, 18, 19, 21, 22, 30, 33, 36, 37, 40, 42, 47, 48, 50, 53], "identif": 5, "don": [5, 6, 7, 8, 11, 53], "t": [5, 6, 7, 8, 11, 19, 50, 53], "match": [5, 7, 10], "up": [5, 9, 10, 11, 15, 16], "exactli": 5, "those": [5, 10], "definit": [5, 10], "either": [5, 10, 36], "run": [5, 6, 8, 9, 10, 12, 14, 21, 23, 24, 28, 30, 36, 37, 47, 48, 57, 58], "explicit": 5, "error": [5, 6, 15, 36, 53, 57], "load": [5, 7, 8, 10, 11, 36, 37, 38, 47], "rais": [5, 13, 19, 22, 28, 36, 37, 42, 48, 50, 53], "an": [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 28, 32, 34, 35, 36, 37, 48, 58], "except": 5, "wors": 5, "silent": [5, 23], "succe": 5, "infer": [5, 7, 22, 24, 26, 28, 29], "expect": [5, 6, 10, 13, 26, 48], "addit": [5, 6, 10, 11, 13, 36, 37, 42, 44, 45, 47, 48, 50, 58], "line": [5, 9, 11, 38], "also": [5, 6, 7, 9, 10, 11, 12, 13, 21, 22, 28, 33, 40, 48], "need": [5, 6, 7, 9, 10, 11, 12, 19, 22, 23, 28, 47, 48], "shape": [5, 22, 24, 26, 28, 29, 33], "valu": [5, 6, 8, 10, 19, 20, 21, 22, 24, 25, 28, 31, 36, 38, 45, 46, 47, 48, 53], "two": [5, 6, 7, 9, 10, 58], "popular": [5, 7, 9, 58], "llama2": [5, 6, 8, 9, 11, 13, 15, 16, 19, 20, 21, 23, 27, 28, 29, 56, 58], "meta": [5, 7, 9, 17, 18, 36, 37], "offici": [5, 9], "implement": [5, 8, 10, 11, 15, 16, 17, 18, 19, 23, 25, 26, 31, 32, 33, 36, 47, 58], "when": [5, 6, 7, 10, 11, 14, 28, 30, 31, 47], "download": [5, 10, 54, 57], "7b": [5, 8, 9, 10, 15, 16, 20, 36, 37], "from": [5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 23, 27, 28, 29, 31, 32, 34, 36, 37, 38, 47, 48, 55, 59], "llama": [5, 7, 8, 9, 17, 18, 25, 26, 36, 37], "websit": 5, "get": [5, 6, 7, 9, 10, 11, 27, 41, 43, 50, 58], "access": [5, 6, 7, 9, 11, 36], "singl": [5, 6, 7, 10, 13, 22, 36, 37], "pth": [5, 7, 8, 9], "inspect": [5, 7, 10], "content": [5, 27], "easili": [5, 6, 10, 58], "torch": [5, 7, 8, 9, 10, 24, 28, 30, 31, 40, 42, 44, 49, 50, 53], "import": [5, 6, 7, 9, 10, 13, 47, 48], "consolid": [5, 8, 9], "00": [5, 8, 9, 55, 59], "mmap": [5, 7], "true": [5, 6, 7, 8, 9, 10, 15, 16, 17, 18, 27, 30, 36, 37, 42, 47], "weights_onli": 5, "map_loc": [5, 7], "cpu": [5, 7, 11, 30, 50], "tensor": [5, 10, 22, 23, 24, 25, 26, 28, 29, 30, 33, 36, 39, 45, 46, 47, 48], "item": 5, "print": [5, 10, 15, 16, 17, 18, 19, 27], "f": [5, 7, 10, 12, 15, 16, 17, 18], "tok_embed": [5, 28], "size": [5, 7, 8, 11, 13, 15, 16, 17, 18, 20, 22, 24, 25, 26, 27, 28, 29, 41, 58], "32000": [5, 13], "4096": [5, 10, 13, 15, 16, 22, 26], "len": [5, 15, 16, 17, 18, 28], "292": 5, "The": [5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 25, 26, 27, 30, 31, 36, 38, 40, 43, 48, 50, 53, 58], "contain": [5, 7, 10, 22, 24, 26, 27, 28, 29, 32, 34, 35, 36, 37, 38, 39, 47], "includ": [5, 6, 7, 9, 10, 11, 33, 36, 37, 38, 58], "input": [5, 8, 10, 15, 16, 17, 18, 19, 22, 23, 25, 26, 27, 28, 29, 33, 36, 39, 53], "embed": [5, 21, 22, 24, 25, 26, 28], "tabl": [5, 10], "call": [5, 9, 10, 13, 23, 30, 38, 45, 46, 47, 48], "layer": [5, 10, 11, 21, 22, 28, 29, 33, 58], "token": [5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 21, 22, 26, 28, 29], "have": [5, 6, 7, 9, 10, 13, 22, 24, 32, 38, 47], "dim": [5, 22, 23, 25, 26, 28, 29], "hf": [5, 7, 9, 36], "most": [5, 6, 9, 10], "within": [5, 6, 7, 13, 19, 21, 23, 47, 53], "hug": [5, 7, 9, 15, 16, 17, 18, 19, 31, 58], "face": [5, 7, 9, 15, 16, 17, 18, 19, 31, 58], "hub": [5, 7, 9], "default": [5, 6, 7, 8, 10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 36, 37, 38, 39, 45, 50, 53], "everi": [5, 11, 23, 47], "config": [5, 7, 8, 10, 12, 13, 14, 22, 36, 38, 48, 58], "2": [5, 7, 8, 9, 10, 19, 22, 27, 36, 37, 39, 53], "repo": [5, 7, 36, 37], "first": [5, 6, 7, 10, 13, 28, 36, 38, 56, 58], "big": [5, 7], "split": [5, 7], "across": [5, 7, 11, 36, 47, 53], "bin": [5, 7], "To": [5, 6, 7, 8, 9, 10, 11, 36, 57, 58], "correctli": [5, 9, 11, 36, 57], "piec": 5, "one": [5, 7, 10, 11, 23, 27, 57], "pytorch_model": [5, 7], "00001": 5, "00002": 5, "embed_token": 5, "241": 5, "Not": 5, "onli": [5, 7, 8, 10, 12, 21, 22, 26, 27, 28, 29, 33, 34, 37, 38, 50, 57], "doe": [5, 7, 32, 36, 38], "fewer": [5, 22], "sinc": [5, 6, 7, 8, 13, 23, 36], "instead": [5, 7, 8, 11, 23, 24, 33], "mismatch": 5, "name": [5, 6, 7, 12, 32, 35, 36, 37, 38, 40, 45, 46, 47, 48], "caus": [5, 27], "try": [5, 6, 7, 10], "same": [5, 6, 7, 10, 21, 22, 24, 27, 29, 38, 48], "As": [5, 6, 7, 10, 11, 33, 58], "re": [5, 6, 7, 9, 10, 58], "care": [5, 7, 10, 23, 36], "like": [5, 6, 7, 8, 9, 10, 11, 12], "end": [5, 9, 11, 27, 56, 58], "number": [5, 10, 11, 15, 16, 19, 21, 22, 24, 28, 31, 36, 37, 41, 53], "just": [5, 9, 10, 58], "save": [5, 7, 10, 11, 12, 36, 37, 48], "less": [5, 7, 8, 9, 19], "prone": 5, "manag": [5, 49], "invari": 5, "accept": [5, 6, 9, 19, 27], "multipl": [5, 6, 11, 33, 45, 46, 47, 48], "sourc": [5, 6, 7, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54], "worri": 5, "explicitli": [5, 10, 32, 58], "convert": [5, 7, 9, 36, 39], "time": [5, 7, 27, 45, 47], "produc": 5, "back": [5, 10, 36], "origin": [5, 7, 10, 15, 16, 30, 33], "form": [5, 6, 11, 15], "One": [5, 7], "advantag": [5, 10], "being": [5, 36, 37, 40, 51], "should": [5, 6, 7, 9, 10, 11, 21, 22, 23, 32, 38, 45, 46, 47, 48, 57, 58], "abl": [5, 7, 9, 11], "fine": [5, 7, 8, 9, 10, 11, 15, 16, 56, 58], "tune": [5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 56, 57, 58], "post": 5, "tool": [5, 7, 9], "quantiz": [5, 21, 33, 56], "eval": [5, 58], "without": [5, 6, 7, 8, 10, 58], "code": [5, 11, 28, 54, 58], "chang": [5, 6, 7, 8, 9, 12], "OR": 5, "convers": [5, 7, 10, 36, 58], "script": [5, 7, 9, 12], "wai": [5, 6, 9, 57], "surround": [5, 11, 58], "load_checkpoint": [5, 11, 36, 37], "save_checkpoint": [5, 11, 12, 36, 37], "method": [5, 6, 7, 10, 11, 12, 14, 15, 16, 17, 18, 19, 30, 32, 34, 38, 58], "convertor": 5, "avail": [5, 7, 9, 10, 11, 38, 40, 58], "here": [5, 6, 7, 9, 10, 12, 25, 26], "three": [5, 9, 11], "hfcheckpoint": 5, "read": [5, 36, 37, 58], "write": [5, 9, 11, 36, 37, 45], "compat": [5, 9, 36], "transform": [5, 10, 11, 21, 28, 29, 31], "framework": [5, 11, 58], "mention": [5, 7], "abov": [5, 7, 10, 30], "assum": [5, 7, 10, 31, 34, 50], "checkpoint_dir": [5, 6, 7, 8, 9, 36, 37], "necessari": [5, 10, 19, 45, 46, 47, 48], "json": [5, 7, 36], "easiest": [5, 9], "sure": [5, 6, 7, 9, 10], "everyth": [5, 9, 11, 38, 58], "follow": [5, 7, 8, 9, 10, 11, 22, 31, 48, 56, 57], "flow": 5, "By": [5, 10], "ignor": [5, 22, 23], "safetensor": 5, "output": [5, 7, 9, 10, 15, 16, 17, 19, 21, 22, 23, 25, 26, 28, 29, 33, 35, 46, 57], "dir": [5, 7, 9], "output_dir": [5, 6, 7, 8, 9, 10, 36, 37], "specifi": [5, 6, 7, 9, 11, 13, 21, 22], "argument": [5, 6, 8, 9, 10, 13, 19, 22, 38, 42, 44, 45, 47, 48, 57], "snippet": 5, "explain": 5, "setup": [5, 6, 7, 10, 11, 28, 44], "_component_": [5, 6, 7, 8, 9, 10, 12, 13], "fullmodelhfcheckpoint": [5, 7], "directori": [5, 6, 7, 9, 36, 37, 45, 47, 48], "sort": [5, 36], "id": [5, 7, 15, 16, 19, 27, 36, 39], "so": [5, 6, 7, 9, 10, 36, 38, 58], "order": [5, 9, 11, 36, 47, 48], "matter": [5, 10, 36], "checkpoint_fil": [5, 6, 7, 8, 9, 10, 12, 36, 37], "restart": [5, 8], "previou": [5, 36, 37], "more": [5, 6, 7, 8, 9, 10, 11, 15, 24, 26, 38, 48, 53, 58], "next": 5, "section": [5, 7, 11, 56], "recipe_checkpoint": [5, 8, 9, 36, 37], "null": [5, 6, 8, 9, 49], "usual": [5, 7, 8, 10, 26, 36], "model_typ": [5, 7, 8, 9, 36, 37], "resume_from_checkpoint": [5, 8, 9, 36, 37], "fals": [5, 6, 7, 8, 9, 10, 15, 16, 17, 18, 19, 21, 22, 27, 33, 36, 37, 51], "requir": [5, 6, 19, 36, 47, 48, 53, 57], "param": [5, 10, 11, 33, 34, 35, 36], "directli": [5, 6, 7, 9, 10, 11, 13, 36], "help": [5, 7, 9, 28, 36, 38, 56, 58], "ensur": [5, 6, 19, 21, 22, 36, 50, 58], "out": [5, 6, 7, 8, 10, 11, 15, 16, 17, 18, 36, 37, 56, 58], "case": [5, 7, 10, 11, 12, 21, 22, 36, 45, 50, 51, 58], "discrep": [5, 36], "along": 5, "detail": [5, 7, 9, 10, 15, 24, 53], "found": [5, 6, 10, 12, 25, 26], "metacheckpoint": 5, "github": [5, 15, 16, 17, 18, 22, 25, 26, 31, 57], "repositori": [5, 7, 9], "fullmodelmetacheckpoint": [5, 8, 9], "torchtunecheckpoint": 5, "perform": [5, 7, 10, 23, 58], "current": [5, 7, 9, 21, 22, 26, 28, 29, 37, 41, 45, 47, 53, 57], "test": [5, 6, 11, 58], "complet": [5, 7, 9, 11], "written": [5, 6, 11, 36, 37, 45, 46, 47, 48, 58], "begin": [5, 8, 27], "partit": 5, "ha": [5, 7, 10, 27, 32, 34], "standard": [5, 7, 46, 58], "key_1": 5, "weight_1": 5, "key_2": 5, "weight_2": 5, "mid": 5, "chekpoint": 5, "middl": [5, 7], "inform": [5, 7, 8, 9, 48, 58], "subsequ": [5, 11], "recipe_st": [5, 36, 37], "pt": [5, 7, 12, 36, 37], "epoch": [5, 7, 8, 9, 10, 11, 12, 31, 36, 37], "optim": [5, 6, 7, 8, 9, 10, 11, 31], "etc": [5, 11, 36], "prevent": 5, "flood": 5, "overwritten": 5, "note": [5, 6, 7, 10, 27, 28, 32, 36, 38, 50, 53], "updat": [5, 6, 7, 8, 9, 10, 11], "hf_model_0001_0": [5, 7], "hf_model_0002_0": [5, 7], "both": [5, 7, 10], "adapt": [5, 7, 10, 32, 33, 34, 35, 36, 37], "merg": [5, 7, 13, 36], "would": [5, 6, 7, 10, 12, 28], "our": [5, 7, 10, 11, 58], "tutori": [5, 7, 8, 9, 58], "primari": [5, 6, 9, 11], "want": [5, 6, 8, 10, 11, 12, 13], "resum": [5, 11, 31, 36, 37], "initi": [5, 9, 10, 11, 14, 20, 27, 42], "frozen": [5, 10], "base": [5, 7, 10, 19, 21, 26, 31, 33, 35, 36, 38, 45, 49], "well": [5, 6, 7, 11, 58], "learnt": [5, 7], "someth": [5, 7, 8, 11, 12], "NOT": 5, "refer": [5, 6, 8, 10, 11, 25, 26, 49, 58], "adapter_checkpoint": [5, 36, 37], "adapter_0": [5, 7], "now": [5, 7, 9, 10, 27], "knowledg": 5, "creat": [5, 6, 7, 13, 15, 16, 17, 18, 20, 24, 31, 36, 37, 45, 47], "simpl": [5, 9, 11, 56], "forward": [5, 10, 11, 22, 23, 25, 26, 28, 29, 33], "13b": 5, "modeltyp": [5, 36, 37], "llama2_13b": 5, "right": [5, 7, 9, 10, 36], "pytorch_fil": 5, "00003": 5, "torchtune_sd": 5, "load_state_dict": [5, 10], "successfulli": 5, "vocab": [5, 13, 28], "70": 5, "x": [5, 10, 22, 23, 25, 26, 28, 29, 33], "randint": 5, "0": [5, 7, 9, 10, 11, 21, 22, 27, 28, 31, 33, 39, 47, 48, 53, 55, 59], "1": [5, 7, 8, 9, 10, 11, 19, 22, 27, 28, 31, 37, 39, 47, 48, 53], "no_grad": 5, "6": [5, 7, 25, 39], "3989": 5, "9": [5, 7], "0531": 5, "3": [5, 7, 8, 38, 39, 43], "2375": 5, "5": [5, 7, 8, 9, 31, 39], "2822": 5, "4": [5, 6, 7, 8, 19, 22, 39, 58], "4872": 5, "7469": 5, "8": [5, 7, 10, 15, 16, 17, 18], "6737": 5, "11": [5, 7], "0023": 5, "8235": 5, "6819": 5, "2424": 5, "0109": 5, "6915": 5, "7": [5, 39], "3618": 5, "1628": 5, "8594": 5, "5857": 5, "1151": 5, "7808": 5, "2322": 5, "8850": 5, "9604": 5, "7624": 5, "6040": 5, "3159": 5, "5849": 5, "8039": 5, "9322": 5, "2010": 5, "6824": 5, "8929": 5, "8465": 5, "3794": 5, "3500": 5, "6145": 5, "5931": 5, "do": [5, 7, 9, 10, 11, 48], "find": [5, 7, 9, 11, 12], "list": [5, 6, 9, 15, 16, 19, 21, 27, 32, 33, 36, 37, 38, 39, 43, 52], "builder": [5, 20], "hope": 5, "provid": [5, 6, 7, 9, 11, 13, 19, 28, 38, 58], "deeper": 5, "insight": [5, 7], "happi": [5, 7], "thi": [6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 19, 21, 22, 23, 26, 27, 28, 29, 30, 31, 32, 36, 37, 38, 40, 45, 47, 48, 53, 56, 58], "guid": [6, 8, 9, 10], "yaml": [6, 7, 9, 10, 11, 12, 13, 14, 38, 48, 58], "pars": [6, 9, 13, 38], "effect": 6, "cli": [6, 7, 9, 12, 14], "prerequisit": [6, 7, 9, 10], "Be": [6, 7, 9, 10], "familiar": [6, 7, 9, 10], "torchtun": [6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 57], "instal": [6, 7, 9, 10, 12, 47, 48, 56], "fundament": 6, "There": [6, 7, 10, 57], "entri": [6, 9, 11], "point": [6, 7, 8, 9, 10, 11], "locat": [6, 10], "thei": [6, 10, 11, 28, 38], "truth": [6, 7], "reproduc": 6, "overridden": [6, 23, 38], "quick": 6, "experiment": 6, "modifi": [6, 7, 10, 11, 12, 30, 58], "serv": [6, 10], "particular": [6, 19], "seed": [6, 9, 11, 12, 53], "shuffl": [6, 8, 9], "devic": [6, 7, 8, 9, 11, 40, 49, 50], "cuda": [6, 7, 8, 9, 40, 50], "dtype": [6, 7, 8, 9, 11, 24, 30, 49, 50, 52], "fp32": 6, "enable_fsdp": 6, "mani": [6, 7], "object": [6, 13, 22, 49, 51], "keyword": [6, 13, 19, 30], "loss": [6, 8, 9, 10, 11, 15, 16, 17, 18], "function": [6, 11, 13, 14, 22, 23, 30, 40, 41, 53, 58], "exampl": [6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 22, 27, 32, 36, 37, 39, 47, 48, 54, 55, 59], "subfield": 6, "dotpath": 6, "wish": 6, "exact": [6, 7, 13], "path": [6, 7, 8, 9, 10, 11, 12, 13, 27, 36, 37, 38], "normal": [6, 10, 25, 27, 28, 29], "python": [6, 7, 38, 43, 48, 53, 54], "alpaca_dataset": [6, 8, 9, 15], "custom": [6, 7, 9, 10, 11, 58], "train_on_input": [6, 8, 15, 16, 17, 18, 19], "onc": [6, 7, 9, 10], "ve": [6, 7, 10, 24], "instanc": [6, 10, 13, 15, 16, 21, 23, 27, 30, 34, 35], "cfg": [6, 11, 14], "automat": [6, 12, 13], "under": [6, 7], "preced": [6, 10, 13], "actual": [6, 12], "throw": 6, "notic": [6, 10], "miss": [6, 10], "posit": [6, 13, 22, 26, 28, 29], "anoth": [6, 7], "handl": [6, 7, 10, 14, 27], "def": [6, 10, 11, 12, 14], "dictconfig": [6, 11, 13, 14, 48], "arg": [6, 13, 28, 30, 32, 38, 46], "tupl": [6, 13, 19, 27, 30, 38, 39, 41], "kwarg": [6, 13, 30, 32, 38, 42, 44, 45, 46, 47, 48], "str": [6, 13, 27, 30, 32, 33, 34, 35, 36, 37, 38, 40, 43, 45, 46, 47, 48, 50, 52, 53], "mean": [6, 9, 10, 25], "pass": [6, 10, 13, 20, 21, 22, 23, 30, 42, 44, 47, 48, 50], "add": [6, 7, 10, 12, 38], "d": [6, 10, 22, 28, 29], "llama2_token": [6, 7, 8, 9], "tmp": [6, 7, 8, 9], "option": [6, 7, 9, 11, 20, 21, 22, 26, 27, 28, 29, 30, 36, 37, 40, 43, 44, 45, 48, 50, 53, 57, 58], "bool": [6, 15, 16, 17, 18, 19, 21, 27, 30, 33, 36, 37, 42, 47, 51], "max_seq_len": [6, 8, 13, 15, 16, 19, 21, 22, 24, 26, 27, 28], "int": [6, 10, 12, 15, 16, 19, 20, 21, 22, 24, 25, 26, 27, 28, 31, 33, 36, 37, 39, 41, 45, 46, 47, 48, 53], "512": [6, 8, 15, 16], "instructdataset": [6, 15, 16, 17, 18], "alreadi": [6, 7, 9, 10, 42], "overwrit": 6, "duplic": [6, 11, 58], "sometim": 6, "than": [6, 7, 9, 10, 19, 22], "resolv": 6, "alpaca": [6, 7, 8, 9, 10, 15, 16], "metric_logg": [6, 11, 12], "metric_log": [6, 12, 45, 46, 47, 48], "disklogg": 6, "log_dir": [6, 45, 47], "conveni": [6, 11], "quickli": 6, "verifi": [6, 9, 10, 40, 50], "properli": 6, "experi": [6, 10, 56, 58], "wa": [6, 7, 10], "7b_full": [6, 7, 9], "batch_siz": [6, 7, 8, 9, 15, 16, 17, 18, 22, 29], "discuss": [6, 10], "guidelin": 6, "while": [6, 7, 9, 11, 23, 58], "mai": [6, 9, 10], "tempt": 6, "put": [6, 9, 10, 11], "much": [6, 7, 10], "give": [6, 10], "maximum": [6, 8, 15, 16, 19, 20, 21, 22, 24, 26, 28], "flexibl": 6, "switch": 6, "encourag": 6, "clariti": 6, "significantli": 6, "easier": [6, 7, 9], "dont": 6, "slimorca_dataset": 6, "privat": 6, "typic": 6, "expos": [6, 9, 11], "parent": 6, "modul": [6, 10, 13, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 44, 53], "__init__": [6, 10, 11], "py": [6, 7, 14, 15, 16, 17, 18, 22, 24, 25, 26, 31], "guarante": 6, "stabil": [6, 58], "underscor": 6, "_alpaca": 6, "collect": [6, 9], "differ": [6, 7, 8, 10, 12, 27, 58], "itself": 6, "via": [6, 10, 12, 33], "pair": [6, 8, 39], "k1": [6, 11], "v1": [6, 11], "k2": [6, 11], "v2": [6, 11], "full_finetun": [6, 12], "gpu": [6, 7, 8, 9, 10], "full_finetune_distribut": [6, 7, 8, 9], "checkpoint": [6, 8, 9, 10, 11, 36, 37, 44, 48, 58], "home": 6, "my_model_checkpoint": 6, "file_1": 6, "file_2": 6, "class": [6, 9, 10, 12, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 45, 46, 47, 48], "assign": 6, "nest": 6, "dot": 6, "notat": [6, 22, 26, 28, 29], "my_config": 6, "your": [7, 10, 12, 13, 47, 48, 56, 58], "favorit": [7, 10], "llm": [7, 10, 11, 56, 58], "go": [7, 8, 9, 11, 27, 58], "over": [7, 10, 11, 31, 38, 58], "commun": 7, "seemlessli": 7, "type": [7, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 30, 33, 34, 36, 37, 41, 42, 43, 49, 50, 51], "beyond": 7, "connect": 7, "step": [7, 10, 11, 28, 31, 45, 46, 47, 48, 56], "larger": 7, "might": 7, "relev": [7, 10, 11], "techniqu": [7, 8, 10, 58], "depend": [7, 10, 11, 12], "factor": [7, 21, 33], "amount": 7, "natur": 7, "data": [7, 8, 15, 16, 17, 18, 19, 45, 46, 47, 48], "hardwar": [7, 10, 58], "task": [7, 10], "benchmark": [7, 11, 53, 58], "valid": [7, 9, 11], "qualiti": [7, 8, 11], "reason": [7, 11], "effici": [7, 8, 10, 26, 56, 58], "export": 7, "specif": [7, 9, 11, 13], "environ": [7, 9, 11], "mobil": 7, "phone": 7, "leverag": 7, "integr": [7, 9, 58], "mode": 7, "paramet": [7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 53, 56, 58], "especi": [7, 58], "lot": [7, 8], "memori": [7, 8, 10, 11, 15, 16, 44], "plai": 7, "freez": [7, 10], "small": [7, 25], "percentag": 7, "learnabl": 7, "keep": [7, 10], "gradient": [7, 10, 11, 51, 58], "low": [7, 10, 21, 33], "16gb": 7, "bfloat16": [7, 30], "rtx": 7, "3090": 7, "4090": 7, "With": [7, 10, 14], "peak": [7, 10], "usag": [7, 8, 57], "total": [7, 10, 31, 41, 55, 59], "around": [7, 10, 11, 27], "hour": 7, "ls": 7, "full_finetune_single_devic": 7, "7b_full_single_devic": 7, "7b_full_single_device_low_memori": 7, "mistral": 7, "13b_full": 7, "lora_finetune_single_devic": 7, "7b_lora_single_devic": 7, "7b_qlora_single_devic": 7, "7b_lora": [7, 10], "overrid": [7, 9, 11, 14], "start": [7, 9, 11, 58], "log": [7, 9, 11, 43, 45, 46, 47, 48], "_checkpoint": [7, 12], "473": 7, "98": 7, "gb": 7, "50": 7, "484": 7, "01": 7, "final": [7, 10, 21, 23, 28], "similar": [7, 10], "fact": [7, 10], "ident": 7, "third": 7, "smaller": [7, 10], "But": 7, "realli": 7, "eleuther_ev": 7, "its": [7, 10, 17, 18, 21, 53], "eleuther_evalu": 7, "plan": 7, "copi": [7, 9], "local": [7, 8, 9, 48, 53, 57], "element": 7, "cp": [7, 9], "custom_eval_config": 7, "truthfulqa_mc2": 7, "qa": 7, "measur": 7, "propens": 7, "answer": [7, 15], "question": 7, "zero": [7, 25], "shot": 7, "accuraci": 7, "respons": [7, 9, 27], "baselin": [7, 10], "324": 7, "loglikelihood": 7, "request": [7, 50], "195": 7, "121": 7, "27": 7, "second": 7, "197": 7, "acc": 7, "none": [7, 11, 12, 21, 22, 26, 27, 28, 29, 35, 36, 37, 40, 43, 44, 45, 46, 47, 48, 50, 53], "388": 7, "38": 7, "compar": [7, 10, 47], "shown": 7, "result": [7, 8, 9, 11, 27], "489": 7, "48": 7, "10": [7, 19, 39], "better": [7, 8, 9, 58], "great": 7, "seem": [7, 9], "meaning": [7, 11, 58], "text": [7, 27], "prompt": [7, 8, 15, 16, 17, 18, 19, 27, 28], "custom_generation_config": 7, "kick": 7, "off": [7, 11, 27], "sampl": [7, 12, 19], "top_k": 7, "300": 7, "temperatur": 7, "control": [7, 8, 11, 15, 16, 17, 18, 53], "probabl": [7, 21, 33], "comput": [7, 8, 21, 22, 23, 26, 28, 53], "recommend": [7, 15, 16, 47], "interest": 7, "site": 7, "visit": [7, 9], "bai": 7, "area": 7, "92": 7, "exploratorium": 7, "san": 7, "francisco": 7, "made": [7, 26], "magazin": 7, "awesom": 7, "And": [7, 8, 57], "bridg": 7, "pretti": 7, "cool": 7, "96": 7, "61": 7, "sec": 7, "25": 7, "83": 7, "99": [7, 10], "15": 7, "72": 7, "inde": [7, 50], "know": [7, 10], "littl": 7, "saw": 7, "took": 7, "commonli": [7, 10, 53], "torchao": 7, "api": [7, 9, 11, 12], "bit": [7, 10], "improv": [7, 28], "custom_quantization_config": 7, "68": 7, "19": 7, "76": 7, "69": 7, "13": [7, 27], "95": 7, "82": [7, 19], "67": 7, "4w": 7, "unlik": 7, "becaus": [7, 24, 28], "won": 7, "outsid": [7, 53], "engin": 7, "fullmodeltorchtunecheckpoint": 7, "int4weightonlyquant": 7, "groupsiz": 7, "256": 7, "did": 7, "unquant": [7, 30], "A": [7, 10, 11, 12, 27, 30, 33, 36, 39, 55, 56, 59], "park": 7, "sit": 7, "top": 7, "hill": 7, "tree": [7, 47], "beauti": 7, "view": [7, 47], "62": 7, "17": 7, "85": 7, "compil": 7, "hood": 7, "sped": 7, "almost": 7, "3x": 7, "benefit": 7, "doesn": [7, 19], "yet": 7, "mix": [7, 8, 11, 49, 51, 58], "codebas": [7, 15, 16, 17, 18], "gpt": [7, 22], "fast": 7, "clone": [7, 10, 57], "machin": [7, 40], "assumpt": 7, "map": [7, 35, 36, 45, 46, 47, 48], "i": [7, 8, 11, 30, 35], "e": [7, 8, 22, 30, 32, 35, 57], "satisfi": 7, "new_dir": 7, "dictionari": [7, 45, 46, 47, 48], "output_dict": 7, "weight_map": [7, 36], "sd_1": 7, "sd_2": 7, "open": [7, 19], "index": [7, 31, 39], "w": [7, 10, 20, 47, 48], "dump": 7, "structur": [7, 11], "cd": [7, 57], "readabl": [7, 28], "convert_hf_checkpoint": 7, "checkpoint_path": 7, "hello": [7, 27], "my": 7, "justin": 7, "am": 7, "school": 7, "math": 7, "teacher": 7, "ws": 7, "94": 7, "103": 7, "28": 7, "bandwidth": 7, "achiev": 7, "1391": 7, "84": 7, "thats": 7, "own": [7, 10, 53], "hopefulli": 7, "gave": 7, "supervis": 8, "learn": [8, 9, 10, 11, 31, 58], "given": [8, 10, 11, 13, 33, 40, 50, 58], "compris": 8, "label": [8, 11, 15, 16, 19, 39], "cross": 8, "entropi": 8, "expens": 8, "lora": [8, 15, 16, 21, 33, 56, 58], "higher": [8, 30], "precis": [8, 11, 30, 49, 50, 51, 52, 58], "distribut": [8, 9, 40, 42, 44, 53, 58], "fsdp": [8, 9, 11, 51, 58], "activ": [8, 9, 11, 23, 44, 58], "aspect": [8, 58], "llama2_7b": [8, 9, 10], "sgd": [8, 9], "lr": [8, 9, 31], "2e": 8, "nn": [8, 9, 10, 13, 22, 23, 24, 28, 29, 30, 32, 34, 35, 44], "crossentropyloss": [8, 9], "bf16": [8, 9, 50], "enable_activation_checkpoint": [8, 9], "launch": [8, 9], "tunecli": 8, "nnode": [8, 9, 10], "nproc_per_nod": [8, 9, 10], "stanford": [8, 15, 16], "relat": [8, 10], "mask": [8, 15, 16, 17, 18, 22, 27, 29], "truncat": [8, 19, 27], "after": [8, 11, 24, 25, 45, 46, 47, 48], "sequenc": [8, 15, 16, 19, 21, 22, 24, 26, 27, 28, 29, 39], "length": [8, 15, 16, 19, 21, 22, 24, 26, 27, 28, 29, 37, 39], "limit": [8, 11], "down": [8, 9, 10], "slower": 8, "tokenizer_checkpoint": [8, 10], "path_to_model_token": 8, "batch": [8, 11, 15, 16, 17, 18, 20, 22, 24, 26, 27, 28, 29, 39, 58], "global": [8, 53], "num_gpu": 8, "gradient_accumulation_step": 8, "correspond": [8, 10, 32, 34, 50], "accumul": [8, 11, 58], "previous": 8, "incomplet": 8, "adam": 8, "known": [8, 27], "process": [9, 11, 30, 53], "job": [9, 53], "latest": 9, "greatest": 9, "gate": 9, "grant": 9, "instruct": [9, 10, 15, 16, 56], "page": [9, 58], "host": 9, "minut": 9, "agreement": 9, "signup": 9, "author": [9, 58], "authent": 9, "Then": [9, 12], "command": [9, 10, 11, 38, 57], "other": [9, 10, 11, 13, 15, 38], "user": [9, 11, 21, 22, 27], "thought": [9, 11, 58], "pipelin": [9, 11, 58], "consist": [9, 11], "configur": [9, 10, 11, 15, 16, 17, 18, 19, 29, 58], "dataclass": 9, "core": [9, 11, 58], "logic": [9, 10, 11, 36, 58], "togeth": [9, 10, 11], "basic": 9, "hold": 9, "hyperparamet": [9, 10, 58], "metric": [9, 11], "logger": [9, 11, 43, 45, 46, 47, 48], "wandb": [9, 11, 12, 48], "new": [9, 10, 11, 45, 47], "exist": [9, 11], "Or": 9, "past": [9, 24], "It": 9, "alpaca_llama_full_finetun": 9, "good": [9, 10], "place": 9, "custom_config": 9, "random": [9, 53], "replic": 9, "lower": [9, 10], "sooner": 9, "rate": [9, 31, 58], "42": 9, "1e": [9, 21, 25], "proper": 9, "suit": [9, 11], "pytorch": [9, 10, 11, 19, 28, 30, 47, 49, 53, 56, 57, 58], "torchrun": 9, "therefor": 9, "immedi": 9, "indic": 9, "succesfulli": 9, "log_1707246452": 9, "txt": [9, 45], "manual": [9, 10], "rank": [9, 10, 21, 33, 41, 53], "sampler": 9, "7553404569625854": 9, "13000": 9, "03": 9, "closer": [9, 10, 11], "teach": 10, "show": 10, "straight": 10, "jump": 10, "trainabl": [10, 33, 35], "decomposit": [10, 33], "matric": [10, 33], "neural": 10, "network": [10, 23], "remain": [10, 31], "linear": [10, 21, 28, 32, 33], "project": [10, 12, 21, 22, 23, 48, 56], "self": [10, 11, 12, 21, 22, 28, 29, 32], "attent": [10, 21, 22, 24, 26, 28, 29], "unfamiliar": 10, "check": [10, 28, 50, 56], "approxim": [10, 21, 33], "oppos": 10, "due": [10, 27], "substanti": 10, "reduct": 10, "momentum": 10, "adamw": 10, "further": 10, "come": [10, 32], "primarili": [10, 11], "reduc": [10, 28], "replac": [10, 15, 16, 17, 18, 30], "arbitrari": 10, "in_dim": [10, 32, 33], "out_dim": [10, 32, 33], "could": 10, "high": [10, 58], "min": 10, "paper": 10, "aghajanyan": 10, "et": 10, "al": 10, "hypothes": 10, "intrins": 10, "dimens": [10, 21, 22, 24, 26, 28, 33], "properti": [10, 38], "b": [10, 11, 22, 26, 28, 29, 33, 48], "often": 10, "four": 10, "eight": 10, "practic": 10, "imag": 10, "below": [10, 26], "simplifi": 10, "represent": [10, 19], "left": 10, "blue": 10, "although": [10, 23], "introduc": [10, 22, 25, 33], "few": [10, 36], "extra": 10, "r": [10, 33], "rememb": 10, "q": [10, 22], "k": [10, 22], "v": [10, 22, 28], "approx": 10, "15m": 10, "8192": 10, "65k": 10, "minim": 10, "nativ": [10, 11, 56, 58], "loralinear": [10, 32], "alpha": [10, 33], "float": [10, 21, 22, 25, 31, 33, 45, 46, 47, 48], "dropout": [10, 21, 22, 33], "pretrain": 10, "bia": [10, 32, 33], "lora_a": [10, 33], "lora_b": [10, 33], "p": 10, "requires_grad": 10, "frozen_out": 10, "lora_out": 10, "scale": [10, 21, 33], "return": [10, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 39, 40, 41, 42, 43, 49, 50, 51, 52, 53], "omit": 10, "varieti": [10, 58], "construct": 10, "lora_llama2_7b": 10, "build": [10, 11, 58], "base_model": 10, "choos": 10, "q_proj": [10, 21, 22], "k_proj": [10, 21, 22], "v_proj": [10, 21, 22], "output_proj": [10, 21, 22], "lora_model": 10, "lora_attn_modul": [10, 21], "lora_llama_2_7b": 10, "alon": 10, "attn": [10, 29], "causalselfattent": [10, 29], "in_featur": 10, "out_featur": 10, "pos_embed": [10, 22], "rotarypositionalembed": [10, 22], "inplac": 10, "addition": [10, 53], "transformerdecod": [10, 20, 21], "feel": 10, "free": 10, "yourself": [10, 11], "why": 10, "wrapper": [10, 11, 27], "strict": 10, "whenev": 10, "peft": [10, 32, 33, 34, 35], "validate_state_dict_for_lora": 10, "peft_util": 10, "get_adapter_param": [10, 35], "set_trainable_param": 10, "fetch": 10, "lora_param": 10, "total_param": 10, "sum": 10, "numel": 10, "trainable_param": 10, "100": [10, 11, 15, 16, 17, 18, 19, 39], "2f": 10, "6742609920": 10, "4194304": 10, "06": [10, 25], "taken": 10, "vram": 10, "least": [10, 19], "23gb": 10, "lora_finetune_distribut": 10, "done": [10, 50], "ad": [10, 11, 27], "my_model_checkpoint_path": 10, "my_tokenizer_checkpoint_path": 10, "constraint": 10, "coupl": 10, "factori": 10, "lora_rank": [10, 21], "lora_alpha": [10, 21], "16": 10, "benefici": 10, "increas": [10, 31], "32": [10, 13], "max": [10, 19, 27, 28, 31], "long": 10, "embed_dim": [10, 13, 21, 22, 26, 29], "impact": 10, "rel": 10, "minor": 10, "64": 10, "lora_experiment_1": 10, "comparison": [10, 11], "smooth": 10, "curv": 10, "500": 10, "seen": 10, "figur": [10, 11], "wandblogg": [10, 12], "account": [10, 48], "separ": [10, 27, 36], "exercis": 10, "longer": 10, "target": [11, 58], "eg": [11, 28, 36, 58], "featur": [11, 12, 58], "appli": [11, 21, 22, 25, 26, 28, 29, 58], "famili": [11, 58], "complex": 11, "becom": 11, "harder": 11, "anticip": 11, "architectur": [11, 28], "methodolog": 11, "possibl": 11, "trade": 11, "vs": 11, "believ": 11, "best": 11, "fit": [11, 15, 16], "solut": 11, "meant": [11, 30], "level": [11, 43, 58], "expertis": 11, "routin": 11, "ones": 11, "modular": [11, 58], "block": [11, 21, 58], "fulli": 11, "correct": [11, 25, 26, 28, 40, 58], "numer": [11, 58], "pariti": [11, 58], "verif": 11, "extens": [11, 58], "hidden": [11, 23], "behind": 11, "flag": [11, 15, 16, 17, 18], "prefer": [11, 58], "unnecessari": 11, "abstract": [11, 58], "No": [11, 58], "inherit": [11, 38, 58], "upon": 11, "spectrum": 11, "decid": 11, "interact": [11, 56], "paradigm": 11, "monolith": [11, 58], "trainer": [11, 41], "extern": 11, "eleutherai": [11, 58], "har": [11, 58], "multi": [11, 22], "stage": 11, "distil": 11, "oper": [11, 53], "turn": 11, "dataload": [11, 15, 16, 17, 18], "applic": [11, 22, 36, 37, 48, 49], "clean": [11, 15], "group": [11, 22, 45, 46, 47, 48], "init_process_group": [11, 42], "backend": 11, "gloo": 11, "els": [11, 38, 58], "nccl": 11, "fullfinetunerecipedistribut": 11, "cleanup": 11, "stuff": 11, "carri": 11, "interfac": [11, 32], "_devic": 11, "get_devic": 11, "_dtype": 11, "get_dtyp": 11, "ckpt_dict": 11, "wrap": [11, 44], "_model": 11, "_setup_model": 11, "_token": 11, "_setup_token": 11, "_optim": 11, "_setup_optim": 11, "_loss_fn": 11, "_setup_loss": 11, "_sampler": 11, "_dataload": 11, "_setup_data": 11, "backward": 11, "zero_grad": 11, "curr_epoch": 11, "rang": [11, 53], "epochs_run": [11, 12], "total_epoch": [11, 12], "idx": 11, "enumer": 11, "_autocast": 11, "logit": 11, "total_training_step": 11, "_log_every_n_step": 11, "_metric_logg": 11, "log_dict": [11, 45, 46, 47, 48], "decor": [11, 14], "recipe_main": [11, 14], "fullfinetunerecip": 11, "direct": 11, "topic": [12, 56], "http": [12, 15, 16, 17, 18, 19, 20, 22, 25, 26, 31, 36, 37, 38, 43, 47, 48, 49, 53, 57], "ai": [12, 22, 48], "packag": [12, 47, 48, 57], "pip": [12, 47, 48, 57], "login": [12, 48], "built": 12, "grab": 12, "tab": [12, 15, 16], "click": 12, "workspac": 12, "capecap": [12, 48], "6053ofw0": [12, 48], "torchtune_config_j67sb73v": [12, 48], "desir": 12, "suggest": 12, "approach": 12, "joinpath": 12, "_output_dir": [12, 36, 37], "torchtune_model_": 12, "with_suffix": 12, "wandb_at": 12, "artifact": 12, "descript": [12, 17], "whatev": 12, "metadata": 12, "seed_kei": 12, "epochs_kei": 12, "total_epochs_kei": 12, "max_steps_kei": 12, "max_steps_per_epoch": 12, "add_fil": 12, "log_artifact": 12, "field": [13, 15, 16, 17, 18], "num_lay": [13, 21, 28], "num_head": [13, 21, 22, 24, 26, 28], "num_kv_head": [13, 21, 22, 24], "vocab_s": [13, 21, 27], "must": [13, 15, 16, 17, 18, 19, 32, 38], "parsed_yaml": 13, "omegaconf": 13, "valueerror": [13, 19, 22, 28, 36, 37, 50, 53], "callabl": [14, 28], "main": [14, 15, 16, 17, 18, 22, 25, 26], "my_recip": 14, "foo": 14, "bar": [14, 58], "huggingfac": [15, 16, 17, 18, 19, 31, 36, 37], "co": [15, 16, 17, 18, 19, 36, 37], "yahma": 15, "tatsu": [15, 16], "lab": [15, 16], "templat": [15, 16, 17, 18, 19], "com": [15, 16, 17, 18, 22, 25, 26, 31, 57], "stanford_alpaca": [15, 16], "blob": [15, 16, 17, 18, 22, 25, 26, 31], "761dc5bfbdeeffa89b8bff5d038781a4055f796a": [15, 16], "l31": [15, 16], "where": [15, 16, 17, 18, 22, 27, 28, 33], "ref": [15, 16, 48], "tloen": [15, 16], "l49": [15, 16], "contribut": [15, 16, 17, 18], "version": [15, 21, 22], "remov": 15, "hallucin": 15, "poorli": 15, "wrong": 15, "card": 15, "encod": [15, 16, 17, 18, 19, 27], "decod": [15, 16, 17, 18, 19, 21, 27, 28], "whether": [15, 16, 17, 18, 19, 21, 27, 30, 33, 50, 51], "readm": [15, 16], "ov": [15, 16], "highest": [15, 16], "alpaca_d": [15, 16], "grammar": 17, "variant": [17, 18], "liweili": 17, "c4_200m": 17, "llama_recip": [17, 18], "src": [17, 18, 31], "l50": 17, "grammar_d": 17, "summar": 18, "samsum": 18, "l13": 18, "dialogu": 18, "summari": 18, "samsum_d": 18, "1024": 19, "chatdataset": 19, "slimorca": 19, "orca": 19, "dedup": 19, "adher": 19, "chat": 19, "prescrib": 19, "though": 19, "ds": 19, "351": 19, "391": 19, "221": 19, "220": 19, "193": 19, "12": 19, "471": 19, "arxiv": [20, 22, 25, 26], "org": [20, 22, 25, 26, 38, 43, 47, 49, 53], "ab": [20, 26], "2307": 20, "09288": 20, "max_batch_s": [20, 24], "kvcach": [20, 21, 22, 28], "instanti": [20, 21], "liter": 21, "apply_lora_to_mlp": 21, "apply_lora_to_output": 21, "intermediate_dim": 21, "attn_dropout": [21, 22, 28], "norm_ep": 21, "05": 21, "lora_dropout": 21, "quantize_bas": [21, 33], "mlp": [21, 28, 29], "vocabulari": [21, 27], "queri": [21, 22, 24, 28], "head": [21, 22, 24, 26, 28], "mha": [21, 22, 28], "onto": [21, 22], "scaled_dot_product_attent": [21, 22], "intermedi": 21, "scale_hidden_dim_for_mlp": 21, "epsilon": 21, "rm": 21, "norm": [21, 28, 29], "subset": [21, 34], "head_dim": [22, 24, 26, 28], "kv_cach": 22, "gqa": 22, "pdf": [22, 25], "2305": 22, "13245v1": 22, "multihead": 22, "n": [22, 27, 55, 59], "extrem": 22, "share": 22, "mqa": 22, "credit": 22, "document": 22, "lightn": 22, "lit": 22, "lit_gpt": 22, "n_kv_head": 22, "calcul": 22, "g": [22, 32], "cach": [22, 24, 26], "rope": [22, 26], "input_po": [22, 26, 28, 29], "seq_length": [22, 29], "seq_len": [22, 26], "bigger": 22, "n_h": [22, 26], "num": [22, 26], "n_kv": 22, "kv": [22, 24, 28], "emb": [22, 28, 29], "h_d": [22, 26], "gate_proj": 23, "down_proj": 23, "up_proj": 23, "silu": 23, "feed": [23, 29], "deriv": [23, 28, 29], "fed": 23, "multipli": 23, "subclass": [23, 38], "afterward": 23, "former": 23, "regist": [23, 30], "hook": [23, 30], "latter": 23, "standalon": 24, "expand": 24, "per": [24, 30], "dpython": [24, 30, 49], "ep": 25, "root": [25, 47], "squar": 25, "1910": 25, "07467": 25, "verfic": [25, 26], "facebookresearch": [25, 26], "avoid": [25, 53], "divis": 25, "10000": 26, "rotari": 26, "propos": 26, "2104": 26, "09864": 26, "l450": 26, "upto": 26, "init": [26, 48], "exceed": 26, "freq": 26, "recomput": 26, "geometr": 26, "progress": 26, "rotat": 26, "angl": 26, "bsz": 26, "todo": 26, "spm_model": 27, "sentencepieceprocessor": 27, "bos_id": 27, "eos_id": 27, "pad_id": 27, "sentencepiec": 27, "sentenc": 27, "pad": [27, 39], "non": 27, "from_fil": 27, "tokenized_text": 27, "world": [27, 41], "add_bo": 27, "add_eo": 27, "31587": 27, "29644": 27, "102": 27, "trim_leading_whitespac": 27, "prefix": 27, "unbatch": 27, "prepend": 27, "bo": 27, "append": 27, "eo": 27, "trim": 27, "lead": 27, "whitespac": 27, "underli": 27, "s1": 27, "s2": 27, "classmethod": 27, "tokenize_messag": 27, "messag": 27, "concaten": 27, "problem": 27, "slice": 27, "tokenizer_path": 27, "role": 27, "system": 27, "assist": 27, "concat": 27, "1788": 27, "2643": 27, "1792": 27, "9508": 27, "465": 27, "22137": 27, "2933": 27, "join": 27, "attribut": 27, "transformerdecoderlay": 28, "move": 28, "space": 28, "belong": 28, "statement": 28, "At": 28, "arang": 28, "prompt_length": 28, "causal_mask": 28, "m_": 28, "seq": 28, "sa_norm": 29, "mlp_norm": 29, "ff": 29, "common_util": 30, "offload_to_cpu": 30, "nf4": 30, "restor": 30, "offload": 30, "_register_state_dict_hook": 30, "m": 30, "mymodul": 30, "_after_": 30, "nf4tensor": 30, "unus": 30, "num_warmup_step": 31, "num_training_step": 31, "num_cycl": 31, "last_epoch": 31, "lambdalr": 31, "schedul": 31, "linearli": 31, "decreas": 31, "cosin": 31, "v4": 31, "23": 31, "l104": 31, "warmup": 31, "phase": 31, "wave": 31, "half": [31, 49], "last": 31, "lr_schedul": 31, "appropri": 31, "protocol": 32, "adapter_param": [32, 33, 34, 35], "proj": 32, "use_bia": 33, "larg": 33, "languag": 33, "perturb": 33, "mapsto": 33, "w_0x": 33, "bax": 33, "respect": 35, "0001_of_0003": 36, "0002_of_0003": 36, "preserv": 36, "intermediate_checkpoint": [36, 37], "parit": 36, "_weight_map": 36, "shard": [37, 51], "wip": 37, "argpars": 38, "tunerecipeargpars": 38, "argumentpars": 38, "builtin": [38, 49], "noth": 38, "treat": 38, "still": 38, "consult": 38, "doc": [38, 43, 47, 48, 49, 53], "info": 38, "librari": [38, 43, 53, 56, 58], "html": [38, 43, 47, 49, 53], "parse_known_arg": 38, "namespac": 38, "act": 38, "alwai": 38, "precid": 38, "parse_arg": 38, "intern": 38, "too": 38, "collat": 39, "padding_idx": 39, "ignore_idx": 39, "longest": 39, "integ": [39, 53], "tokenpair": 39, "token_pair": 39, "availab": 40, "aka": 41, "runtimeerror": 42, "stream": 43, "handler": 43, "auto_wrap_polici": 44, "polici": 44, "filenam": 45, "log_": 45, "unixtimestamp": 45, "thread": 45, "safe": 45, "resourc": [45, 46, 47, 48], "flush": [45, 46, 47, 48], "union": [45, 46, 47, 48, 51, 53], "ndarrai": [45, 46, 47, 48], "scalar": [45, 46, 47, 48], "tag": [45, 46, 47, 48], "record": [45, 46, 47, 48], "payload": [45, 46, 47, 48], "organize_log": 47, "tensorboard": 47, "stabl": [47, 49, 53], "subdirectori": 47, "sub": 47, "logdir": 47, "startup": 47, "recurs": 47, "tfevent": 47, "encount": 47, "frontend": 47, "organ": 47, "accordingli": 47, "my_log_dir": 47, "my_metr": [47, 48], "termin": [47, 48], "entiti": 48, "bias": 48, "my_project": 48, "my_ent": 48, "my_group": 48, "importerror": 48, "log_config": 48, "link": 48, "contextmanag": 49, "intellig": 49, "determin": 49, "autocast": 49, "amp": 49, "otherwis": 49, "context": 49, "kernel": 50, "float32": 50, "isn": 50, "gradscal": 51, "shardedgradscal": 51, "scaler": 51, "awar": 51, "debug_mod": 53, "pseudo": 53, "numpi": 53, "determinist": 53, "warn": 53, "nondeterminist": 53, "cudnn": 53, "disabl": 53, "set_deterministic_debug_mod": 53, "algorithm": 53, "generated_examples_python": 54, "zip": 54, "galleri": [54, 59], "sphinx": 54, "000": [55, 59], "execut": [55, 59], "generated_exampl": 55, "mem": [55, 59], "mb": [55, 59], "gentl": 56, "introduct": 56, "workflow": 56, "readi": 56, "git": 57, "confirm": 57, "recipe_arg": 57, "On": 58, "pointer": 58, "emphas": 58, "simplic": 58, "component": 58, "reus": 58, "prove": 58, "democrat": 58, "box": 58, "zoo": 58, "excit": 58, "checkout": 58, "chekckpoint": 58, "embodi": 58, "philosophi": 58, "usabl": 58, "eluetherai": 58, "composit": 58, "hard": 58, "outlin": 58, "unecessari": 58, "never": 58, "thoroughli": 58, "unit": 58}, "objects": {"torchtune.config": [[13, 0, 1, "", "instantiate"], [14, 0, 1, "", "parse"]], "torchtune.datasets": [[15, 0, 1, "", "alpaca_cleaned_dataset"], [16, 0, 1, "", "alpaca_dataset"], [17, 0, 1, "", "grammar_dataset"], [18, 0, 1, "", "samsum_dataset"], [19, 0, 1, "", "slimorca_dataset"]], "torchtune.models.llama2": [[20, 0, 1, "", "llama2_7b"], [21, 0, 1, "", "lora_llama2"]], "torchtune.modules": [[22, 1, 1, "", "CausalSelfAttention"], [23, 1, 1, "", "FeedForward"], [24, 1, 1, "", "KVCache"], [25, 1, 1, "", "RMSNorm"], [26, 1, 1, "", "RotaryPositionalEmbeddings"], [27, 1, 1, "", "Tokenizer"], [28, 1, 1, "", "TransformerDecoder"], [29, 1, 1, "", "TransformerDecoderLayer"], [31, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[22, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[23, 2, 1, "", "forward"]], "torchtune.modules.RMSNorm": [[25, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[26, 2, 1, "", "forward"]], "torchtune.modules.Tokenizer": [[27, 2, 1, "", "decode"], [27, 2, 1, "", "encode"], [27, 2, 1, "", "from_file"], [27, 2, 1, "", "tokenize_messages"]], "torchtune.modules.TransformerDecoder": [[28, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoderLayer": [[29, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[30, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[32, 1, 1, "", "AdapterModule"], [33, 1, 1, "", "LoRALinear"], [34, 0, 1, "", "get_adapter_params"], [35, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[32, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[33, 2, 1, "", "adapter_params"], [33, 2, 1, "", "forward"]], "torchtune.utils": [[36, 1, 1, "", "FullModelHFCheckpointer"], [37, 1, 1, "", "FullModelMetaCheckpointer"], [40, 0, 1, "", "get_device"], [41, 0, 1, "", "get_world_size_and_rank"], [42, 0, 1, "", "init_distributed"]], "torchtune.utils.FullModelHFCheckpointer": [[36, 2, 1, "", "load_checkpoint"], [36, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[37, 2, 1, "", "load_checkpoint"], [37, 2, 1, "", "save_checkpoint"]], "torchtune.utils.argparse": [[38, 1, 1, "", "TuneRecipeArgumentParser"]], "torchtune.utils.argparse.TuneRecipeArgumentParser": [[38, 2, 1, "", "parse_known_args"]], "torchtune.utils.collate": [[39, 0, 1, "", "padded_collate"]], "torchtune.utils.logging": [[43, 0, 1, "", "get_logger"]], "torchtune.utils.memory": [[44, 0, 1, "", "set_activation_checkpointing"]], "torchtune.utils.metric_logging": [[45, 1, 1, "", "DiskLogger"], [46, 1, 1, "", "StdoutLogger"], [47, 1, 1, "", "TensorBoardLogger"], [48, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[45, 2, 1, "", "close"], [45, 2, 1, "", "log"], [45, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[46, 2, 1, "", "close"], [46, 2, 1, "", "log"], [46, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[47, 2, 1, "", "close"], [47, 2, 1, "", "log"], [47, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[48, 2, 1, "", "close"], [48, 2, 1, "", "log"], [48, 2, 1, "", "log_config"], [48, 2, 1, "", "log_dict"]], "torchtune.utils.precision": [[49, 0, 1, "", "get_autocast"], [50, 0, 1, "", "get_dtype"], [51, 0, 1, "", "get_gradient_scaler"], [52, 0, 1, "", "list_dtypes"]], "torchtune.utils.seed": [[53, 0, 1, "", "set_seed"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 7, 10, 56, 58], "config": [0, 6, 9, 11], "dataset": [1, 8], "model": [2, 3, 7, 8, 9, 10, 12], "llama2": [2, 7, 10], "modul": 3, "compon": [3, 6], "build": 3, "block": 3, "peft": 3, "util": [3, 4], "checkpoint": [4, 5, 7, 12], "distribut": 4, "reduc": 4, "precis": 4, "memori": 4, "manag": 4, "metric": [4, 12], "log": [4, 12], "data": 4, "miscellan": 4, "overview": [5, 7, 58], "format": 5, "handl": 5, "differ": 5, "intermedi": 5, "vs": 5, "final": 5, "lora": [5, 7, 10], "put": 5, "thi": 5, "all": 5, "togeth": 5, "deep": [6, 11], "dive": [6, 11], "where": 6, "do": 6, "paramet": 6, "live": 6, "write": 6, "configur": 6, "us": [6, 7, 11], "instanti": [6, 13], "referenc": 6, "other": [6, 7], "field": 6, "interpol": 6, "valid": 6, "your": [6, 9, 11], "best": 6, "practic": 6, "airtight": 6, "public": 6, "api": 6, "onli": 6, "command": 6, "line": 6, "overrid": 6, "end": 7, "workflow": 7, "download": [7, 9], "7b": 7, "finetun": [7, 8, 9, 10], "run": [7, 11], "evalu": 7, "eleutherai": 7, "s": 7, "eval": 7, "har": 7, "gener": 7, "speed": 7, "up": 7, "quantiz": 7, "librari": 7, "llm": [8, 9], "full": 8, "recip": [8, 9, 10, 11], "train": [8, 9, 11], "first": 9, "select": 9, "modifi": 9, "next": 9, "step": 9, "what": [10, 11, 58], "how": 10, "doe": 10, "work": 10, "appli": 10, "ar": 11, "script": 11, "class": 11, "cli": 11, "pars": [11, 14], "weight": 12, "bias": 12, "logger": 12, "w": 12, "b": 12, "alpaca_cleaned_dataset": 15, "alpaca_dataset": 16, "grammar_dataset": 17, "samsum_dataset": 18, "slimorca_dataset": 19, "llama2_7b": 20, "lora_llama2": 21, "causalselfattent": 22, "todo": [22, 29], "feedforward": 23, "kvcach": 24, "rmsnorm": 25, "rotarypositionalembed": 26, "token": 27, "transformerdecod": 28, "transformerdecoderlay": 29, "reparametrize_as_dtype_state_dict_post_hook": 30, "get_cosine_schedule_with_warmup": 31, "adaptermodul": 32, "loralinear": 33, "get_adapter_param": 34, "set_trainable_param": 35, "fullmodelhfcheckpoint": 36, "fullmodelmetacheckpoint": 37, "tunerecipeargumentpars": 38, "padded_col": 39, "get_devic": 40, "get_world_size_and_rank": 41, "init_distribut": 42, "get_logg": 43, "set_activation_checkpoint": 44, "disklogg": 45, "stdoutlogg": 46, "tensorboardlogg": 47, "wandblogg": 48, "get_autocast": 49, "get_dtyp": 50, "get_gradient_scal": 51, "list_dtyp": 52, "set_se": 53, "comput": [55, 59], "time": [55, 59], "welcom": 56, "document": 56, "get": 56, "start": 56, "tutori": 56, "instal": 57, "instruct": 57, "kei": 58, "concept": 58, "design": 58, "principl": 58}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})