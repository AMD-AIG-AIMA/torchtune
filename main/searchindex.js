Search.setIndex({"docnames": ["api_ref_config", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "examples/configs", "examples/finetune_llm", "examples/first_finetune_tutorial", "examples/lora_finetune", "examples/recipe_deepdive", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.datasets.SlimOrcaDataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.Tokenizer", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.low_precision.FrozenNF4Linear", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.utils.argparse.TuneArgumentParser", "generated/torchtune.utils.checkpoint.load_checkpoint", "generated/torchtune.utils.checkpoint.save_checkpoint", "generated/torchtune.utils.checkpointable_dataloader.CheckpointableDataLoader", "generated/torchtune.utils.collate.padded_collate", "generated/torchtune.utils.generation.GenerationUtils", "generated/torchtune.utils.generation.generate_from_prompt", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.logging.get_logger", "generated/torchtune.utils.memory.set_activation_checkpointing", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.precision.get_autocast", "generated/torchtune.utils.precision.get_dtype", "generated/torchtune.utils.precision.get_gradient_scaler", "generated/torchtune.utils.precision.list_dtypes", "generated/torchtune.utils.seed.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times"], "filenames": ["api_ref_config.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "examples/configs.rst", "examples/finetune_llm.rst", "examples/first_finetune_tutorial.rst", "examples/lora_finetune.rst", "examples/recipe_deepdive.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.datasets.SlimOrcaDataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.Tokenizer.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.low_precision.FrozenNF4Linear.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.utils.argparse.TuneArgumentParser.rst", "generated/torchtune.utils.checkpoint.load_checkpoint.rst", "generated/torchtune.utils.checkpoint.save_checkpoint.rst", "generated/torchtune.utils.checkpointable_dataloader.CheckpointableDataLoader.rst", "generated/torchtune.utils.collate.padded_collate.rst", "generated/torchtune.utils.generation.GenerationUtils.rst", "generated/torchtune.utils.generation.generate_from_prompt.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.logging.get_logger.rst", "generated/torchtune.utils.memory.set_activation_checkpointing.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.precision.get_autocast.rst", "generated/torchtune.utils.precision.get_dtype.rst", "generated/torchtune.utils.precision.get_gradient_scaler.rst", "generated/torchtune.utils.precision.list_dtypes.rst", "generated/torchtune.utils.seed.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst"], "titles": ["torchtune.config", "torchtune.datasets", "torchtune.models.llama2", "torchtune.modules", "torchtune.utils", "Configs Deep-Dive", "LLM Full Finetuning Recipe", "Finetune your First LLM", "Finetuning Llama2 with LoRA", "Training Recipe Deep-Dive", "instantiate", "parse", "SlimOrcaDataset", "alpaca_dataset", "grammar_dataset", "samsum_dataset", "llama2_7b", "lora_llama2", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "Tokenizer", "TransformerDecoder", "TransformerDecoderLayer", "get_cosine_schedule_with_warmup", "FrozenNF4Linear", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "TuneArgumentParser", "load_checkpoint", "save_checkpoint", "CheckpointableDataLoader", "padded_collate", "GenerationUtils", "generate_from_prompt", "get_device", "get_world_size_and_rank", "init_distributed", "get_logger", "set_activation_checkpointing", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "get_autocast", "get_dtype", "get_gradient_scaler", "list_dtypes", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the TorchTune Documentation", "Install Instructions", "TorchTune Overview", "Computation times"], "terms": {"thi": [5, 6, 7, 8, 9, 10, 12, 17, 18, 19, 22, 24, 26, 27, 28, 32, 33, 34, 35, 37, 39, 44, 46, 47, 52, 55, 57], "tutori": [5, 6, 7, 9, 57], "guid": [5, 6, 7, 8], "you": [5, 6, 7, 8, 9, 10, 32, 46, 47, 55, 56, 57], "through": [5, 6, 7, 9, 19, 57], "run": [5, 6, 7, 8, 11, 17, 19, 20, 27, 35, 46, 47, 56, 57], "recip": [5, 10, 11, 14, 15, 19, 55, 56, 57], "what": [5, 7, 55], "learn": [5, 6, 7, 8, 9, 26, 57], "how": [5, 6, 7, 9, 55], "yaml": [5, 7, 8, 9, 10, 11, 32, 57], "pars": [5, 7, 10, 32], "effect": 5, "cli": [5, 7, 11], "prerequisit": [5, 7, 8], "Be": [5, 7, 8], "familiar": [5, 7, 8], "overview": [5, 7, 8], "torchtun": [5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 56], "make": [5, 6, 7, 8, 9, 18, 25, 57], "sure": [5, 6, 7, 8], "instal": [5, 7, 8, 46, 47, 55], "understand": [5, 7, 8, 9, 57], "fundament": 5, "There": [5, 8, 56], "ar": [5, 6, 7, 8, 10, 13, 14, 15, 16, 17, 24, 27, 29, 34, 35, 37, 56, 57], "two": [5, 7, 8, 35, 57], "primari": [5, 7, 9], "entri": [5, 7, 9], "point": [5, 6, 7, 8, 9], "file": [5, 7, 8, 9, 10, 11, 23, 32, 33, 44, 54, 57, 58], "defin": [5, 8, 9, 19, 28, 29, 30], "all": [5, 6, 7, 8, 9, 18, 19, 32, 53, 55, 57, 58], "need": [5, 7, 8, 9, 12, 18, 19, 33, 46, 47], "within": [5, 10, 12, 19, 46, 52], "singl": [5, 8, 10, 18], "locat": [5, 8], "thei": [5, 8, 24, 32], "sourc": [5, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53], "truth": 5, "reproduc": 5, "The": [5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 21, 22, 23, 26, 32, 39, 42, 49, 52, 57], "can": [5, 6, 7, 8, 9, 10, 21, 22, 32, 33, 35, 46, 47, 55, 56, 57], "overridden": [5, 19, 32], "tune": [5, 6, 7, 8, 9, 11, 55, 56, 57], "quick": 5, "chang": [5, 6, 7], "experiment": 5, "without": [5, 6, 8, 57], "modifi": [5, 8, 9, 57], "serv": [5, 8], "expect": [5, 8, 10, 22, 33, 34, 47], "simpli": 5, "list": [5, 7, 12, 17, 23, 28, 29, 32, 36, 37, 38, 42, 51], "out": [5, 6, 8, 13, 14, 15, 34, 55, 57], "valu": [5, 6, 8, 12, 16, 17, 18, 20, 21, 24, 26, 32, 37, 44, 45, 46, 47, 52], "want": [5, 6, 8, 10], "particular": [5, 12], "seed": [5, 7, 9, 35, 52], "null": [5, 6, 7, 48], "shuffl": [5, 6, 7], "true": [5, 6, 7, 8, 13, 14, 15, 23, 27, 34, 37, 41, 46], "devic": [5, 6, 7, 9, 27, 37, 39, 48], "cuda": [5, 6, 7, 39], "dtype": [5, 6, 7, 9, 27, 48, 49, 51], "fp32": 5, "enable_fsdp": 5, "mani": 5, "requir": [5, 12, 46, 47, 52, 56], "specifi": [5, 7, 9, 10, 17, 18, 33, 34], "object": [5, 10, 18, 33, 34, 35, 48, 50], "associ": [5, 8, 9], "keyword": [5, 10, 12, 35], "argument": [5, 6, 7, 8, 10, 12, 18, 27, 32, 35, 41, 43, 44, 46, 47, 56], "model": [5, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 33, 34, 37, 38, 43, 55, 57], "dataset": [5, 7, 8, 12, 13, 14, 15, 35, 57], "optim": [5, 6, 7, 8, 9, 26, 33, 34], "loss": [5, 6, 7, 8, 9, 13, 14, 15], "function": [5, 10, 11, 18, 19, 33, 34, 37, 39, 40, 52, 57], "common": [5, 8], "exampl": [5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 18, 23, 28, 33, 34, 35, 36, 37, 46, 47, 53, 54, 58], "easili": [5, 8, 57], "_component_": [5, 6, 7, 8, 10], "subfield": 5, "In": [5, 6, 8, 9, 22, 29, 46, 47], "dotpath": 5, "wish": 5, "exact": [5, 10], "path": [5, 6, 7, 8, 9, 10, 23, 32, 33, 34], "would": [5, 8], "import": [5, 7, 8, 10, 46, 47], "normal": [5, 8, 21, 24, 25], "python": [5, 32, 42, 47, 52, 53], "For": [5, 6, 7, 8, 9, 17, 18, 32, 34, 47, 52], "alpaca_dataset": [5, 6, 7], "custom": [5, 7, 8, 9, 57], "train_on_input": [5, 6, 13, 14, 15], "fals": [5, 6, 7, 8, 13, 14, 15, 17, 18, 29, 34, 37, 50], "here": [5, 7, 8, 21, 22], "we": [5, 6, 8, 9, 18, 22, 29, 57], "default": [5, 6, 8, 12, 13, 14, 15, 16, 17, 18, 21, 23, 24, 25, 26, 27, 29, 32, 33, 36, 37, 52], "from": [5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 19, 23, 24, 25, 26, 28, 30, 32, 33, 35, 37, 38, 46, 47, 54, 58], "onc": [5, 7, 8], "ve": [5, 8], "creat": [5, 10, 13, 14, 15, 16, 26, 27, 35, 44, 46], "an": [5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 17, 18, 24, 28, 30, 31, 33, 35, 57], "instanc": [5, 8, 10, 13, 17, 19, 23, 30, 31], "s": [5, 6, 7, 8, 9, 11, 17, 18, 22, 24, 25, 28, 30, 33, 37, 39, 46, 55, 57], "setup": [5, 8, 9, 43], "like": [5, 6, 7, 8, 9], "so": [5, 7, 8, 32, 57], "access": [5, 7], "cfg": [5, 9, 11], "automat": [5, 10], "ani": [5, 6, 8, 9, 10, 11, 27, 30, 31, 33, 34, 35, 52], "under": [5, 9], "As": [5, 8, 9, 29, 35, 57], "written": [5, 9, 44, 45, 46, 47, 57], "preced": [5, 8, 10], "actual": 5, "throw": 5, "error": [5, 52, 56], "If": [5, 8, 9, 12, 13, 14, 15, 17, 18, 27, 29, 33, 34, 35, 37, 39, 41, 46, 47, 52], "look": [5, 6, 7, 8, 9, 46], "method": [5, 8, 9, 11, 12, 13, 14, 15, 28, 30, 32, 35, 57], "ll": [5, 7, 9, 57], "notic": [5, 8], "re": [5, 7, 8, 9, 57], "miss": [5, 8], "posit": [5, 10, 18, 20, 22, 24, 25], "token": [5, 6, 7, 8, 9, 12, 13, 14, 15, 17, 24, 37, 38], "sinc": [5, 6, 10, 19], "anoth": 5, "let": [5, 7, 8], "handl": [5, 8, 11, 33], "take": [5, 7, 8, 9, 10, 19, 32, 39], "def": [5, 8, 9, 11, 37], "dictconfig": [5, 9, 10, 11], "arg": [5, 9, 10, 24, 28, 32, 35, 45], "tupl": [5, 10, 12, 20, 32, 36, 37, 38, 40], "kwarg": [5, 10, 12, 27, 28, 32, 35, 41, 43, 44, 45, 46, 47], "dict": [5, 9, 10, 30, 31, 33, 34, 35, 41], "str": [5, 10, 23, 28, 29, 30, 31, 32, 33, 34, 38, 39, 42, 44, 45, 46, 47, 49, 51, 52], "also": [5, 7, 8, 9, 10, 17, 18, 27, 29, 39], "accept": [5, 12, 23], "when": [5, 8, 9, 11, 24, 26, 37, 46], "mean": [5, 7, 8, 21], "pass": [5, 8, 10, 12, 16, 17, 18, 19, 27, 33, 35, 37, 41, 43, 46, 47], "add": [5, 8, 32], "addit": [5, 8, 9, 10, 12, 27, 41, 43, 44, 46, 47, 57], "d": [5, 8, 18, 24, 25], "first": [5, 8, 10, 32, 55, 57], "llama2": [5, 6, 7, 9, 10, 12, 16, 17, 19, 24, 25, 55, 57], "llama2_token": [5, 6, 7], "tmp": [5, 6, 7, 34], "note": [5, 8, 27, 28, 32, 33, 52], "option": [5, 7, 9, 16, 17, 18, 24, 25, 27, 33, 34, 37, 39, 42, 43, 47, 49, 52, 56, 57], "bool": [5, 13, 14, 15, 17, 23, 29, 34, 37, 41, 46, 50], "use_clean": [5, 6, 13], "instructdataset": [5, 13, 14, 15], "alreadi": [5, 7, 8, 41], "don": [5, 6, 52], "t": [5, 6, 12, 35, 49, 52], "overwrit": 5, "duplic": [5, 57], "kei": [5, 8, 17, 18, 20, 31, 33, 34], "sometim": 5, "same": [5, 8, 17, 18, 25, 32, 35], "more": [5, 6, 7, 8, 9, 22, 32, 47, 52, 57], "than": [5, 7, 8, 12, 18, 20], "multipl": [5, 9, 29, 44, 45, 46, 47], "refer": [5, 6, 8, 9, 21, 22, 48, 57], "resolv": 5, "output_dir": [5, 6, 7, 8], "alpaca": [5, 6, 7, 8, 13], "finetun": [5, 9, 13, 51, 55, 57], "metric_logg": [5, 9], "util": [5, 6, 7, 9, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 57], "metric_log": [5, 44, 45, 46, 47], "disklogg": 5, "log_dir": [5, 44, 46], "provid": [5, 7, 9, 10, 12, 32, 35, 57], "conveni": [5, 9], "quickli": 5, "verifi": [5, 8, 39], "well": [5, 9, 57], "form": [5, 9], "properli": 5, "test": [5, 9, 57], "experi": [5, 8, 55, 57], "wa": [5, 8, 33], "found": [5, 8, 21, 22], "full_finetune_single_devic": 5, "batch_siz": [5, 6, 7, 13, 14, 15, 18, 25, 37], "4": [5, 6, 12, 18, 36, 57], "discuss": [5, 8], "some": [5, 7, 8, 17, 30, 31, 55, 57], "guidelin": 5, "get": [5, 7, 8, 9, 40, 42, 49, 57], "most": [5, 7, 8], "them": [5, 6, 8, 19], "while": [5, 7, 9, 19, 57], "mai": [5, 8], "tempt": 5, "put": [5, 7, 8, 9], "much": [5, 8], "give": [5, 8], "maximum": [5, 12, 16, 17, 18, 20, 22, 37], "flexibl": 5, "switch": 5, "encourag": 5, "includ": [5, 7, 8, 9, 29, 32, 34, 57], "ensur": [5, 12, 17, 18, 27, 57], "full": [5, 7, 8, 9, 27, 34, 55, 57], "clariti": 5, "significantli": 5, "easier": [5, 7], "debug": [5, 9], "dont": 5, "slimorca_dataset": 5, "privat": 5, "These": [5, 7, 8, 9, 10, 32], "typic": 5, "expos": [5, 7, 9], "parent": 5, "modul": [5, 8, 10, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 37, 43, 52], "__init__": [5, 8, 9], "py": [5, 7, 11, 13, 14, 15, 18, 21, 22, 26], "wai": [5, 7, 56], "guarante": 5, "stabil": [5, 57], "should": [5, 7, 8, 9, 17, 18, 19, 28, 32, 34, 35, 37, 44, 45, 46, 47, 56, 57], "underscor": 5, "_alpaca": 5, "collect": [5, 7], "try": [5, 8], "differ": [5, 6, 8, 57], "have": [5, 7, 8, 10, 18, 28, 32, 34, 46], "updat": [5, 6, 7, 8, 9, 20], "itself": 5, "To": [5, 6, 7, 8, 9, 56, 57], "enabl": [5, 6, 7, 9, 29, 52], "via": [5, 8, 27, 29], "pair": [5, 6, 36], "k1": [5, 9], "v1": [5, 9], "k2": [5, 9], "v2": [5, 9], "full_finetun": 5, "directori": [5, 7, 44, 46], "gpu": [5, 6, 7, 8], "full_finetune_distribut": [5, 6, 7], "checkpoint": [5, 6, 7, 8, 9, 33, 34, 35, 43, 57], "checkpoint_dir": [5, 6, 7], "home": 5, "my_model_checkpoint": 5, "checkpoint_fil": [5, 6, 7, 8], "file_1": 5, "file_2": 5, "class": [5, 7, 8, 12, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 35, 37, 44, 45, 46, 47], "assign": 5, "name": [5, 28, 31, 32, 39, 44, 45, 46, 47], "directli": [5, 7, 8, 10], "nest": 5, "dot": 5, "notat": [5, 18, 22, 24, 25], "slimorcadataset": 5, "set": [5, 6, 7, 8, 9, 12, 13, 14, 15, 22, 27, 31, 37, 39, 43, 52, 57], "my_config": 5, "fine": [6, 7, 8, 9, 55, 57], "paramet": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 52, 55, 57], "us": [6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 18, 21, 22, 24, 25, 27, 32, 33, 35, 38, 39, 44, 45, 46, 47, 48, 50, 52, 55, 57], "supervis": 6, "given": [6, 8, 9, 10, 20, 27, 29, 35, 39, 49, 57], "compris": 6, "input": [6, 8, 12, 13, 14, 15, 18, 19, 21, 22, 23, 24, 25, 27, 29, 36, 52], "label": [6, 9, 12, 36], "cross": 6, "entropi": 6, "usual": [6, 8, 22], "lot": 6, "expens": 6, "effici": [6, 8, 22, 55, 57], "techniqu": [6, 8, 57], "lora": [6, 13, 17, 29, 55, 57], "result": [6, 7, 9, 33], "higher": 6, "qualiti": [6, 9], "support": [6, 7, 9, 10, 13, 14, 15, 18, 20, 27, 29, 34, 35, 37, 48, 49, 51, 57], "mix": [6, 9, 48, 50, 57], "precis": [6, 9, 27, 48, 49, 50, 51, 57], "distribut": [6, 7, 34, 39, 41, 43, 52, 57], "fsdp": [6, 7, 9, 33, 34, 50, 57], "activ": [6, 7, 9, 19, 43, 57], "walk": [6, 7, 9, 46, 57], "aspect": [6, 57], "config": [6, 8, 10, 11, 18, 32, 57], "llama": [6, 7, 14, 15, 21, 22, 37], "7b": [6, 7, 8, 16], "someth": [6, 9], "llama2_7b": [6, 7, 8], "fullmodelmetacheckpoint": [6, 7], "consolid": [6, 7], "00": [6, 7, 54, 58], "pth": [6, 7], "recipe_checkpoint": [6, 7], "model_typ": [6, 7], "resume_from_checkpoint": [6, 7], "2": [6, 7, 8, 12, 18, 23, 36, 52], "epoch": [6, 7, 8, 9, 26, 35], "3": [6, 32, 36, 42], "torch": [6, 7, 8, 9, 26, 27, 37, 39, 41, 43, 48, 49, 52], "sgd": [6, 7], "lr": [6, 7, 26], "2e": 6, "5": [6, 7, 26, 36, 37], "nn": [6, 7, 8, 10, 18, 19, 20, 24, 25, 27, 28, 30, 31, 33, 37, 43], "crossentropyloss": [6, 7], "bf16": [6, 7, 27], "enable_activation_checkpoint": [6, 7], "launch": [6, 7, 9], "tunecli": [6, 9], "nnode": [6, 7, 8], "1": [6, 7, 8, 9, 12, 18, 23, 24, 26, 36, 37, 46, 47, 52], "nproc_per_nod": [6, 7, 8], "stanford": 6, "follow": [6, 7, 8, 9, 18, 26, 55, 56], "relat": [6, 8, 33], "data": [6, 12, 13, 14, 15, 35, 44, 45, 46, 47], "implement": [6, 8, 9, 12, 13, 14, 15, 19, 21, 22, 26, 28, 29, 35, 46, 57], "mask": [6, 13, 14, 15, 18, 24, 25], "prompt": [6, 13, 14, 15, 37, 38], "dure": [6, 8, 13, 14, 15, 20, 22, 37], "raw": 6, "clean": [6, 9, 13], "version": [6, 13, 17, 18], "between": [6, 8], "after": [6, 9, 21, 35, 44, 45, 46, 47], "everi": [6, 9, 19, 46], "good": [6, 7, 8], "practic": [6, 8], "help": [6, 7, 24, 32, 55, 57], "doe": [6, 28, 32, 33, 34, 37], "spuriou": 6, "pattern": 6, "sequenc": [6, 12, 17, 18, 20, 22, 24, 25, 36, 37], "onli": [6, 8, 9, 23, 24, 27, 29, 30, 32, 34, 35, 56], "i": [6, 9, 31, 33, 34, 37], "e": [6, 18, 28, 31, 33, 34, 56], "go": [6, 7, 57], "down": [6, 7, 8], "slower": 6, "tokenizer_checkpoint": [6, 8], "path_to_model_token": 6, "batch": [6, 9, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 35, 36, 37, 57], "size": [6, 9, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 40, 57], "local": [6, 7, 33, 34, 52, 56], "global": [6, 52], "comput": [6, 18, 19, 22, 27, 37, 52], "num_gpu": 6, "gradient_accumulation_step": 6, "correspond": [6, 8, 28, 30, 38, 49], "accumul": [6, 9, 57], "control": [6, 9, 13, 14, 15, 37, 52], "load": [6, 8, 9, 32, 33, 35, 46], "begin": [6, 23, 35], "previous": 6, "incomplet": 6, "restart": 6, "instead": [6, 19, 29], "adam": 6, "less": [6, 7, 12], "memori": [6, 8, 9, 27, 43], "known": 6, "better": [6, 7, 57], "And": [6, 56], "inform": [6, 7, 47, 57], "see": [6, 7, 8, 28, 32, 42, 47, 52, 56, 57], "deep": [6, 7, 8, 55, 57], "dive": [6, 7, 8, 55, 57], "process": [7, 9, 35, 52], "job": [7, 34, 52], "convert": [7, 36], "format": [7, 12, 13, 14, 15], "compat": 7, "integr": [7, 57], "huggingfac": [7, 12, 13, 14, 15, 26, 57], "hub": 7, "latest": 7, "greatest": 7, "weight": [7, 8, 9, 18, 27, 28, 29, 47], "meta": [7, 14, 15], "gate": 7, "grant": 7, "order": [7, 9, 46, 47], "instruct": [7, 8, 13, 55], "offici": 7, "page": [7, 57], "host": 7, "complet": [7, 9], "minut": 7, "author": [7, 57], "authent": 7, "easiest": 7, "do": [7, 8, 9, 47], "script": 7, "find": [7, 9], "Then": 7, "simpl": [7, 55], "repo": 7, "id": [7, 12, 23, 36, 37], "output": [7, 8, 13, 14, 17, 18, 19, 21, 22, 24, 25, 27, 29, 31, 34, 37, 45, 56], "dir": 7, "hf": 7, "command": [7, 8, 9, 32, 56], "other": [7, 8, 9, 10, 32, 33], "respons": [7, 38], "repositori": 7, "detail": [7, 8, 52], "user": [7, 9, 17, 18, 33], "thought": [7, 9, 57], "end": [7, 9, 23, 37, 57], "pipelin": [7, 9, 57], "evalu": [7, 8, 9, 57], "each": [7, 8, 9, 17, 18, 22, 37, 52, 57], "consist": [7, 9], "three": [7, 9], "compon": [7, 8, 9, 57], "configur": [7, 8, 9, 13, 14, 15, 25, 57], "line": [7, 9, 32], "overrid": [7, 9, 11, 27], "dataclass": [7, 9], "core": [7, 9, 57], "logic": [7, 8, 9, 57], "api": [7, 9, 37], "everyth": [7, 9, 32, 57], "togeth": [7, 8, 9], "valid": [7, 9], "up": [7, 8, 9], "environ": [7, 9], "correctli": [7, 9, 56], "avail": [7, 8, 32, 39, 57], "right": [7, 8, 35], "basic": 7, "hold": 7, "hyperparamet": [7, 8, 57], "metric": [7, 9], "logger": [7, 9, 42, 44, 45, 46, 47], "wandb": [7, 9, 47], "new": [7, 8, 9, 20, 44, 46], "current": [7, 18, 20, 22, 24, 25, 27, 34, 35, 37, 40, 44, 46, 52, 56], "exist": [7, 9], "copi": 7, "Or": 7, "visit": 7, "specif": [7, 9, 10], "past": [7, 20], "It": [7, 35], "call": [7, 8, 10, 19, 32, 33, 34, 37, 44, 45, 46, 47], "alpaca_llama_full_finetun": 7, "popular": [7, 57], "seem": 7, "place": 7, "start": [7, 57], "cp": 7, "custom_config": 7, "now": [7, 8, 23], "random": [7, 35, 37, 52], "replic": 7, "lower": [7, 8], "sooner": 7, "rate": [7, 26, 57], "42": 7, "1e": [7, 17, 21], "proper": 7, "suit": [7, 9], "just": [7, 8, 57], "tool": 7, "pytorch": [7, 8, 9, 12, 24, 27, 46, 48, 52, 55, 56, 57], "ecosystem": [7, 9, 57], "torchrun": [7, 9], "therefor": 7, "easi": [7, 8, 9, 57], "immedi": 7, "indic": [7, 33], "succesfulli": 7, "write": [7, 9, 34], "log": [7, 9, 37, 42, 44, 45, 46, 47], "log_1707246452": 7, "txt": 7, "manual": [7, 8], "rank": [7, 8, 17, 29, 34, 40, 52], "0": [7, 8, 9, 17, 18, 22, 24, 25, 26, 29, 34, 35, 36, 37, 46, 47, 52, 54, 58], "initi": [7, 8, 9, 11, 16, 23, 37, 41], "sampler": [7, 35], "7553404569625854": 7, "13000": 7, "03": 7, "closer": [7, 8, 9], "teach": 8, "about": [8, 9, 47, 57], "show": 8, "know": 8, "straight": 8, "your": [8, 10, 46, 47, 55, 57], "own": [8, 52], "jump": 8, "save": [8, 9, 27, 33, 34, 35], "download": [8, 53, 56], "adapt": [8, 28, 29, 30, 31], "base": [8, 12, 22, 26, 27, 31, 32, 35, 37, 44, 48], "trainabl": [8, 29, 31], "low": [8, 17, 29], "decomposit": [8, 29], "matric": [8, 29], "layer": [8, 17, 18, 24, 25, 27, 29, 57], "neural": 8, "network": [8, 19], "freez": [8, 27], "remain": [8, 26], "commonli": [8, 52], "transform": [8, 9, 17, 24, 25, 26, 33, 35, 37], "which": [8, 9, 13, 14, 15, 17, 18, 26, 34, 35, 37, 50, 56, 57], "case": [8, 9, 17, 18, 27, 50, 57], "linear": [8, 17, 24, 27, 28, 29], "project": [8, 17, 18, 19, 47, 55], "self": [8, 9, 17, 18, 25, 28], "attent": [8, 17, 18, 20, 22, 24, 25], "unfamiliar": 8, "check": [8, 24, 55], "definit": 8, "approxim": [8, 17, 29], "By": 8, "oppos": 8, "due": 8, "substanti": 8, "reduct": 8, "number": [8, 9, 12, 17, 18, 20, 24, 26, 37, 40, 52], "gradient": [8, 9, 27, 50, 57], "momentum": 8, "adamw": 8, "further": 8, "state": [8, 9, 30, 31, 33, 34, 35], "come": [8, 28], "primarili": [8, 9], "peak": 8, "its": [8, 13, 14, 15, 17, 27, 52], "forward": [8, 9, 18, 19, 21, 22, 24, 25, 27, 29, 37], "reduc": [8, 24], "replac": [8, 13, 14, 15], "gener": [8, 9, 12, 37, 38, 52, 53], "arbitrari": 8, "in_dim": [8, 27, 28, 29], "out_dim": [8, 27, 28, 29], "could": 8, "high": [8, 57], "min": 8, "paper": 8, "aghajanyan": 8, "et": 8, "al": 8, "hypothes": 8, "intrins": 8, "dimens": [8, 17, 18, 20, 22, 27, 29, 37], "llm": [8, 9, 37, 55, 57], "fact": 8, "advantag": 8, "properti": [8, 32], "origin": [8, 13, 29], "explicitli": [8, 28, 57], "train": [8, 13, 14, 15, 18, 26, 48, 50, 55, 57], "A": [8, 9, 23, 27, 29, 36, 54, 55, 58], "b": [8, 9, 18, 22, 24, 25, 29], "smaller": 8, "often": 8, "four": 8, "eight": 8, "back": 8, "imag": 8, "below": [8, 22], "simplifi": 8, "represent": [8, 12], "step": [8, 9, 26, 44, 45, 46, 47, 55], "left": 8, "compar": [8, 46], "blue": 8, "although": [8, 19], "introduc": [8, 18, 21, 29], "few": 8, "extra": 8, "r": [8, 29], "store": [8, 44], "rememb": 8, "4096": [8, 10, 18, 22], "q": [8, 18], "k": [8, 18, 20, 37], "v": [8, 18, 20, 24], "8": [8, 13, 14, 15, 37], "approx": 8, "15m": 8, "8192": 8, "65k": 8, "over": [8, 9, 26, 32, 57], "99": 8, "minim": 8, "nativ": [8, 9, 55, 57], "tensor": [8, 18, 19, 20, 21, 22, 24, 25, 27, 29, 36, 37, 44, 45, 46, 47], "loralinear": [8, 28], "int": [8, 12, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 36, 37, 38, 40, 44, 45, 46, 47, 52], "alpha": [8, 29], "float": [8, 17, 18, 21, 26, 29, 37, 44, 45, 46, 47], "dropout": [8, 17, 18, 29], "pretrain": 8, "bia": [8, 27, 28, 29], "param": [8, 9, 27, 29, 30, 31, 38], "lora_a": [8, 29], "lora_b": [8, 29], "p": [8, 37], "frozen": [8, 27], "requires_grad": 8, "x": [8, 18, 19, 21, 22, 24, 25, 29, 37], "frozen_out": 8, "lora_out": 8, "final": [8, 17, 19, 24], "scale": [8, 17, 29], "return": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 48, 49, 50, 51, 52], "around": [8, 9, 23], "omit": 8, "our": [8, 9, 57], "favorit": 8, "With": [8, 11], "varieti": [8, 57], "construct": [8, 35], "lora_llama2_7b": 8, "build": [8, 9, 57], "base_model": 8, "match": [8, 37], "those": 8, "choos": 8, "q_proj": [8, 17, 18], "k_proj": [8, 17, 18], "v_proj": [8, 17, 18], "output_proj": [8, 17, 18], "lora_model": 8, "lora_attn_modul": [8, 17], "lora_llama_2_7b": 8, "alon": 8, "inspect": 8, "bit": 8, "close": [8, 9, 44, 45, 46, 47], "print": [8, 12, 13, 14, 15, 23, 37], "attn": [8, 25], "causalselfattent": [8, 25], "in_featur": 8, "out_featur": 8, "pos_embed": [8, 18], "rotarypositionalembed": [8, 18], "inplac": 8, "contain": [8, 20, 28, 30, 31, 32, 33, 34, 36, 46], "addition": [8, 52], "type": [8, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 29, 30, 33, 37, 38, 40, 41, 42, 48, 49, 50], "both": 8, "transformerdecod": [8, 16, 17, 38], "feel": 8, "free": 8, "yourself": [8, 9], "why": 8, "matter": [8, 35], "wrapper": [8, 9, 23], "convers": [8, 57], "assum": [8, 26, 30, 33, 37], "ha": [8, 28, 30], "necessari": [8, 12, 44, 45, 46, 47], "load_state_dict": [8, 33, 35], "state_dict": [8, 34, 35], "strict": 8, "whenev": 8, "peft": [8, 28, 29, 30, 31], "validate_state_dict_for_lora": 8, "peft_util": 8, "get_adapter_param": [8, 31], "set_trainable_param": 8, "fetch": [8, 35], "lora_param": 8, "total": [8, 26, 40, 54, 58], "total_param": 8, "sum": 8, "numel": 8, "trainable_param": 8, "f": [8, 13, 14, 15], "100": [8, 9, 12, 13, 14, 15, 36], "2f": 8, "6742609920": 8, "4194304": 8, "06": [8, 21], "relev": [8, 9, 24], "taken": [8, 34], "care": [8, 19], "perform": [8, 19, 35, 57], "vram": 8, "least": [8, 12, 34], "23gb": 8, "lora_finetune_distribut": 8, "done": 8, "either": 8, "ad": [8, 9], "my_model_checkpoint_path": 8, "my_tokenizer_checkpoint_path": 8, "clone": [8, 56], "depend": [8, 9], "constraint": 8, "hardwar": [8, 57], "tabl": 8, "coupl": 8, "factori": 8, "lora_rank": [8, 17], "lora_alpha": [8, 17], "16": 8, "benefici": 8, "increas": [8, 26], "32": [8, 10], "max": [8, 12, 26], "long": 8, "keep": [8, 37], "embed_dim": [8, 10, 17, 18, 22, 25], "impact": 8, "rel": 8, "minor": 8, "64": 8, "lora_experiment_1": 8, "comparison": 8, "smooth": 8, "curv": 8, "baselin": 8, "500": 8, "seen": 8, "abov": 8, "figur": 8, "w": [8, 16, 46, 47], "wandblogg": 8, "similar": [8, 27], "account": [8, 47], "separ": 8, "exercis": 8, "task": 8, "longer": 8, "one": [8, 9, 19, 56], "design": 9, "structur": 9, "target": [9, 57], "eg": [9, 24, 57], "meaning": [9, 57], "featur": [9, 57], "appli": [9, 17, 18, 21, 22, 24, 25, 57], "famili": [9, 57], "complex": 9, "becom": 9, "harder": 9, "anticip": 9, "architectur": [9, 24], "methodolog": 9, "reason": 9, "possibl": 9, "trade": 9, "off": 9, "vs": 9, "believ": 9, "best": 9, "fit": 9, "solut": 9, "meant": [9, 27, 33], "extend": [9, 57], "level": [9, 42, 57], "expertis": 9, "routin": 9, "ones": 9, "modular": [9, 57], "block": [9, 17, 57], "wrap": [9, 43], "section": [9, 55], "work": [9, 32, 35, 57], "monolith": [9, 57], "trainer": [9, 35, 40], "flag": [9, 13, 14, 15], "extern": 9, "framework": [9, 57], "fulli": 9, "interoper": [9, 57], "surround": [9, 57], "eleutherai": [9, 57], "har": [9, 57], "subsequ": 9, "post": 9, "oper": [9, 27, 52], "quantiz": [9, 27], "export": 9, "etc": 9, "multi": [9, 18], "stage": 9, "distil": 9, "extract": 9, "turn": 9, "resum": [9, 26, 35], "dataload": [9, 13, 14, 15, 35], "applic": [9, 18, 47, 48], "hood": 9, "parser": 9, "tuneargumentpars": 9, "_": 9, "parse_known_arg": [9, 32], "var": 9, "recipe_param": 9, "fullfinetuneparam": 9, "env": 9, "variabl": 9, "group": [9, 18, 44, 45, 46, 47], "init_process_group": [9, 41], "backend": 9, "nccl": 9, "fullfinetunerecip": 9, "cleanup": 9, "stuff": 9, "carri": 9, "interfac": [9, 28, 37], "_devic": 9, "get_devic": 9, "_dtype": 9, "get_dtyp": 9, "ckpt_dict": [9, 33, 34], "load_checkpoint": 9, "ckpt_path": [9, 33], "model_checkpoint": 9, "befor": [9, 24, 25, 29, 35, 37], "_resume_from_checkpoint": 9, "_update_recipe_st": 9, "_model": 9, "_setup_model": 9, "_token": 9, "_setup_token": 9, "_optim": 9, "_setup_optim": 9, "_loss_fn": 9, "_setup_loss": 9, "_sampler": 9, "_dataload": 9, "_setup_data": 9, "backward": [9, 27], "across": [9, 46, 52], "zero_grad": 9, "curr_epoch": 9, "rang": [9, 35, 52], "epochs_run": 9, "total_epoch": 9, "idx": 9, "enumer": 9, "_autocast": 9, "logit": [9, 37], "total_training_step": 9, "_log_every_n_step": 9, "_metric_logg": 9, "log_dict": [9, 44, 45, 46, 47], "save_checkpoint": [9, 33], "decor": [9, 11], "recipe_main": [9, 11], "none": [9, 16, 17, 18, 24, 25, 27, 31, 33, 34, 37, 39, 42, 43, 44, 45, 46, 47, 49, 52], "abl": 9, "direct": 9, "field": [10, 13, 14, 15], "merg": 10, "num_lay": [10, 17, 24], "num_head": [10, 17, 18, 22], "num_kv_head": [10, 17, 18], "vocab_s": [10, 17, 23], "32000": 10, "vocab": [10, 24], "must": [10, 12, 13, 14, 15, 28, 32, 34], "parsed_yaml": 10, "max_seq_len": [10, 17, 18, 20, 22], "omegaconf": 10, "rais": [10, 12, 18, 20, 24, 27, 33, 34, 35, 41, 47, 49, 52], "valueerror": [10, 12, 18, 20, 35, 49, 52], "callabl": [11, 24, 34, 37], "main": [11, 13, 14, 15, 18, 21, 22], "my_recip": 11, "foo": 11, "bar": [11, 57], "slimorca": 12, "http": [12, 13, 14, 15, 16, 18, 21, 22, 26, 32, 42, 46, 47, 48, 52, 56], "co": [12, 13, 14, 15], "open": 12, "orca": 12, "dedup": 12, "hug": 12, "face": 12, "adher": 12, "chat": 12, "doesn": [12, 35], "prescrib": 12, "max_token_length": 12, "truncat": 12, "length": [12, 17, 18, 20, 22, 24, 25, 36, 37], "encod": [12, 13, 14, 15, 23, 37], "decod": [12, 13, 14, 15, 17, 23, 24, 37, 38], "though": [12, 27], "1024": 12, "ds": 12, "10": [12, 36], "sampl": [12, 37], "ouput": 12, "351": 12, "82": 12, "391": 12, "221": 12, "220": 12, "193": 12, "12": 12, "471": 12, "variant": [13, 14, 15], "tatsu": 13, "lab": 13, "templat": [13, 14, 15], "codebas": [13, 14, 15], "github": [13, 14, 15, 18, 21, 22, 26, 56], "com": [13, 14, 15, 18, 21, 22, 26, 56], "stanford_alpaca": 13, "blob": [13, 14, 15, 18, 21, 22, 26], "761dc5bfbdeeffa89b8bff5d038781a4055f796a": 13, "l31": 13, "where": [13, 14, 15, 18, 24, 27, 29, 37], "ref": [13, 47], "tloen": 13, "l49": 13, "contribut": [13, 14, 15], "yahma": 13, "whether": [13, 14, 15, 17, 23, 29, 37, 50], "alpaca_d": 13, "len": [13, 14, 15], "grammar": 14, "liweili": 14, "c4_200m": 14, "descript": 14, "llama_recip": [14, 15], "src": [14, 15, 26], "l50": 14, "grammar_d": 14, "summar": 15, "samsum": 15, "l13": 15, "dialogu": 15, "summari": 15, "samsum_d": 15, "max_batch_s": [16, 17, 20], "builder": 16, "arxiv": [16, 18, 21, 22], "org": [16, 18, 21, 22, 32, 42, 46, 48, 52], "ab": [16, 22], "2307": 16, "09288": 16, "kvcach": [16, 17, 18], "instanti": [16, 17], "liter": 17, "apply_lora_to_mlp": 17, "apply_lora_to_output": 17, "attn_dropout": [17, 18, 24], "norm_ep": 17, "05": 17, "lora_dropout": 17, "mlp": [17, 24, 25], "vocabulari": [17, 23], "queri": [17, 18], "head": [17, 18, 20, 22], "mha": [17, 18], "embed": [17, 18, 20, 21, 22, 24], "onto": [17, 18], "scaled_dot_product_attent": [17, 18], "epsilon": 17, "rm": 17, "norm": [17, 24, 25], "factor": [17, 29], "probabl": [17, 29, 37], "subset": [17, 30], "head_dim": [18, 20, 22], "kv_cach": 18, "gqa": 18, "pdf": [18, 21], "2305": 18, "13245v1": 18, "multihead": 18, "fewer": 18, "n": [18, 54, 58], "extrem": 18, "share": 18, "mqa": 18, "credit": 18, "document": 18, "lightn": 18, "ai": [18, 47], "lit": 18, "gpt": 18, "lit_gpt": 18, "n_kv_head": [18, 20], "calcul": 18, "g": [18, 28], "cach": [18, 20, 22, 37], "rope": [18, 22], "ignor": [18, 19, 33], "curr_po": [18, 20, 22, 24, 25, 37], "shape": [18, 22, 24, 25, 29], "seq_length": [18, 25], "boolean": 18, "seq_len": [18, 20, 22], "bigger": 18, "n_h": [18, 22], "num": [18, 22], "n_kv": 18, "kv": [18, 20, 37], "emb": [18, 24, 25], "dim": [18, 19, 21, 22, 24, 25], "h_d": [18, 22], "gate_proj": 19, "down_proj": 19, "up_proj": 19, "feed": [19, 25], "deriv": [19, 24, 25], "hidden": 19, "fed": 19, "multipli": 19, "subclass": [19, 32], "afterward": 19, "former": 19, "regist": 19, "hook": 19, "latter": 19, "silent": 19, "standalon": 20, "infer": [20, 22], "per": [20, 37], "bsz": [20, 22], "k_val": 20, "v_val": 20, "greater": 20, "ep": 21, "root": [21, 46], "squar": 21, "1910": 21, "07467": 21, "correct": [21, 22, 24, 39, 57], "verfic": [21, 22], "facebookresearch": [21, 22], "small": 21, "avoid": [21, 52], "divis": 21, "zero": 21, "6": [21, 36, 37], "10000": 22, "rotari": 22, "propos": 22, "2104": 22, "09864": 22, "l450": 22, "upto": 22, "init": [22, 47], "exceed": 22, "freq": 22, "recomput": 22, "geometr": 22, "progress": 22, "rotat": 22, "angl": 22, "defualt": 22, "todo": 22, "made": 22, "spm_model": 23, "sentencepieceprocessor": 23, "bos_id": 23, "eos_id": [23, 37], "pad_id": [23, 37], "sentencepiec": 23, "sentenc": 23, "pad": [23, 36, 37], "non": 23, "from_fil": 23, "tokenized_text": 23, "hello": 23, "world": [23, 40], "add_bo": 23, "add_eo": 23, "31587": 23, "29644": 23, "102": 23, "string": [23, 28, 33, 39, 49], "text": [23, 37], "unbatch": 23, "prepend": 23, "bo": 23, "append": 23, "eo": 23, "classmethod": 23, "tok_embed": 24, "transformerdecoderlay": 24, "move": 24, "space": 24, "belong": 24, "statement": 24, "code": [24, 53, 57], "improv": 24, "readabl": 24, "seq": [24, 25], "increment": [24, 37], "sa_norm": 25, "mlp_norm": 25, "ff": 25, "num_warmup_step": 26, "num_training_step": 26, "num_cycl": 26, "last_epoch": 26, "lambdalr": 26, "schedul": 26, "linearli": 26, "decreas": 26, "cosin": 26, "v4": 26, "23": 26, "l104": 26, "warmup": 26, "phase": 26, "wave": 26, "half": [26, 48], "index": [26, 36, 37], "last": 26, "lr_schedul": 26, "appropri": [26, 33], "low_precis": 27, "nf4tensor": 27, "qlora": 27, "bias": [27, 47], "alwai": [27, 32], "underli": 27, "dtypt": 27, "set_default_dtyp": 27, "get_default_devic": 27, "runtimeerror": [27, 33, 34, 41], "bfloat16": 27, "happen": 27, "nf4": 27, "protocol": 28, "adapter_param": [28, 29, 30, 31], "proj": 28, "use_bia": 29, "larg": 29, "languag": [29, 37], "perturb": 29, "mapsto": 29, "w_0x": 29, "bax": 29, "map": [31, 33, 35, 44, 45, 46, 47], "respect": [31, 33], "argpars": 32, "argumentpars": 32, "builtin": [32, 48], "noth": 32, "treat": 32, "still": 32, "els": [32, 57], "consult": 32, "doc": [32, 42, 46, 47, 48, 52], "info": 32, "librari": [32, 42, 52, 55, 57], "html": [32, 42, 46, 48, 52], "namespac": 32, "act": 32, "precid": 32, "parse_arg": 32, "intern": 32, "inherit": [32, 57], "too": 32, "tandem": 33, "At": 33, "minimum": [33, 37], "NOT": 33, "present": 33, "dictionari": [33, 34, 44, 45, 46, 47], "restor": [33, 35], "output_loc": 34, "model_key_filt": 34, "repres": 34, "awar": [34, 50], "fashion": 34, "unshard": 34, "even": 34, "shard": [34, 50], "filter": [34, 37], "intend": 34, "otherwis": [34, 48], "pt": 34, "checkpointable_dataload": 35, "whose": 35, "style": [35, 37], "distributedsampl": 35, "invok": 35, "iter": 35, "datalaod": 35, "set_epoch": 35, "rng": 35, "worker": 35, "impli": 35, "previou": 35, "max_epoch": 35, "current_epoch": 35, "collat": 36, "padding_idx": 36, "ignore_idx": 36, "longest": 36, "integ": [36, 52], "tokenpair": 36, "token_pair": 36, "7": [36, 37], "decoder_lm": 37, "signatur": 37, "pleas": 37, "incremental_decod": 37, "prompt_token": 37, "min_gen_len": 37, "max_gen_len": 37, "temperatur": 37, "top_p": 37, "9": 37, "top_k": 37, "keep_prompt": 37, "logprob": 37, "logits_accessor": 37, "cpu": 37, "top": 37, "threshold": 37, "nucleu": 37, "kept": 37, "max_gen_length": 37, "love": 37, "eat": 37, "20": 37, "ic": 37, "cream": 37, "availab": 39, "machin": 39, "being": [39, 50], "aka": 40, "stream": 42, "handler": 42, "auto_wrap_polici": 43, "polici": 43, "disk": 44, "thread": 44, "safe": 44, "time": [44, 46], "resourc": [44, 45, 46, 47], "flush": [44, 45, 46, 47], "union": [44, 45, 46, 47, 50, 52], "ndarrai": [44, 45, 46, 47], "scalar": [44, 45, 46, 47], "tag": [44, 45, 46, 47], "record": [44, 45, 46, 47], "payload": [44, 45, 46, 47], "standard": [45, 57], "organize_log": 46, "tensorboard": 46, "stabl": [46, 48, 52], "subdirectori": 46, "sub": 46, "allow": 46, "logdir": 46, "startup": 46, "recurs": 46, "tree": 46, "tfevent": 46, "encount": 46, "frontend": 46, "organ": 46, "accordingli": 46, "recommend": 46, "my_log_dir": 46, "view": 46, "my_metr": [46, 47], "packag": [46, 47, 56], "pip": [46, 47, 56], "termin": [46, 47], "entiti": 47, "my_project": 47, "my_ent": 47, "my_group": 47, "importerror": 47, "login": 47, "contextmanag": 48, "intellig": 48, "determin": 48, "autocast": 48, "amp": 48, "dpython": 48, "manag": 48, "context": 48, "isn": 49, "gradscal": 50, "shardedgradscal": 50, "scaler": 50, "debug_mod": 52, "pseudo": 52, "numpi": 52, "determinist": 52, "warn": 52, "nondeterminist": 52, "cudnn": 52, "benchmark": [52, 57], "disabl": 52, "set_deterministic_debug_mod": 52, "algorithm": 52, "outsid": 52, "generated_examples_python": 53, "zip": 53, "galleri": [53, 58], "sphinx": 53, "000": [54, 58], "execut": [54, 58], "generated_exampl": 54, "mem": [54, 58], "mb": [54, 58], "topic": 55, "gentl": 55, "introduct": 55, "readi": 55, "interact": 55, "git": 56, "cd": 56, "confirm": 56, "usag": 56, "recipe_arg": 56, "On": 57, "pointer": 57, "emphas": 57, "simplic": 57, "extens": 57, "component": 57, "reus": 57, "abstract": 57, "prove": 57, "democrat": 57, "box": 57, "zoo": 57, "eval": 57, "excit": 57, "checkout": 57, "chekckpoint": 57, "embodi": 57, "philosophi": 57, "especi": 57, "usabl": 57, "eluetherai": 57, "composit": 57, "hard": 57, "read": 57, "No": 57, "outlin": 57, "prefer": 57, "unecessari": 57, "never": 57, "thoroughli": 57, "unit": 57, "numer": 57, "pariti": 57}, "objects": {"torchtune.config": [[10, 0, 1, "", "instantiate"], [11, 0, 1, "", "parse"]], "torchtune.datasets": [[12, 1, 1, "", "SlimOrcaDataset"], [13, 0, 1, "", "alpaca_dataset"], [14, 0, 1, "", "grammar_dataset"], [15, 0, 1, "", "samsum_dataset"]], "torchtune.models.llama2": [[16, 0, 1, "", "llama2_7b"], [17, 0, 1, "", "lora_llama2"]], "torchtune.modules": [[18, 1, 1, "", "CausalSelfAttention"], [19, 1, 1, "", "FeedForward"], [20, 1, 1, "", "KVCache"], [21, 1, 1, "", "RMSNorm"], [22, 1, 1, "", "RotaryPositionalEmbeddings"], [23, 1, 1, "", "Tokenizer"], [24, 1, 1, "", "TransformerDecoder"], [25, 1, 1, "", "TransformerDecoderLayer"], [26, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[18, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[19, 2, 1, "", "forward"]], "torchtune.modules.KVCache": [[20, 2, 1, "", "update"]], "torchtune.modules.RMSNorm": [[21, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[22, 2, 1, "", "forward"]], "torchtune.modules.Tokenizer": [[23, 2, 1, "", "decode"], [23, 2, 1, "", "encode"], [23, 2, 1, "", "from_file"]], "torchtune.modules.TransformerDecoder": [[24, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoderLayer": [[25, 2, 1, "", "forward"]], "torchtune.modules.low_precision": [[27, 1, 1, "", "FrozenNF4Linear"]], "torchtune.modules.low_precision.FrozenNF4Linear": [[27, 2, 1, "", "forward"]], "torchtune.modules.peft": [[28, 1, 1, "", "AdapterModule"], [29, 1, 1, "", "LoRALinear"], [30, 0, 1, "", "get_adapter_params"], [31, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[28, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[29, 2, 1, "", "adapter_params"], [29, 2, 1, "", "forward"]], "torchtune.utils.argparse": [[32, 1, 1, "", "TuneArgumentParser"]], "torchtune.utils.argparse.TuneArgumentParser": [[32, 2, 1, "", "parse_known_args"]], "torchtune.utils.checkpoint": [[33, 0, 1, "", "load_checkpoint"], [34, 0, 1, "", "save_checkpoint"]], "torchtune.utils.checkpointable_dataloader": [[35, 1, 1, "", "CheckpointableDataLoader"]], "torchtune.utils.collate": [[36, 0, 1, "", "padded_collate"]], "torchtune.utils.generation": [[37, 1, 1, "", "GenerationUtils"], [38, 0, 1, "", "generate_from_prompt"]], "torchtune.utils.generation.GenerationUtils": [[37, 2, 1, "", "generate"]], "torchtune.utils": [[39, 0, 1, "", "get_device"], [40, 0, 1, "", "get_world_size_and_rank"], [41, 0, 1, "", "init_distributed"]], "torchtune.utils.logging": [[42, 0, 1, "", "get_logger"]], "torchtune.utils.memory": [[43, 0, 1, "", "set_activation_checkpointing"]], "torchtune.utils.metric_logging": [[44, 1, 1, "", "DiskLogger"], [45, 1, 1, "", "StdoutLogger"], [46, 1, 1, "", "TensorBoardLogger"], [47, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[44, 2, 1, "", "close"], [44, 2, 1, "", "log"], [44, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[45, 2, 1, "", "close"], [45, 2, 1, "", "log"], [45, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[46, 2, 1, "", "close"], [46, 2, 1, "", "log"], [46, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[47, 2, 1, "", "close"], [47, 2, 1, "", "log"], [47, 2, 1, "", "log_dict"]], "torchtune.utils.precision": [[48, 0, 1, "", "get_autocast"], [49, 0, 1, "", "get_dtype"], [50, 0, 1, "", "get_gradient_scaler"], [51, 0, 1, "", "list_dtypes"]], "torchtune.utils.seed": [[52, 0, 1, "", "set_seed"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 8, 55, 57], "config": [0, 5, 7, 9], "dataset": [1, 6], "model": [2, 3, 6, 7, 8], "llama2": [2, 8], "modul": 3, "compon": [3, 5], "build": 3, "block": 3, "low": 3, "precis": [3, 4], "peft": 3, "util": 4, "distribut": 4, "mix": 4, "memori": 4, "manag": 4, "metric": 4, "log": 4, "data": 4, "checkpoint": 4, "save": 4, "load": 4, "gener": 4, "miscellan": 4, "deep": [5, 9], "dive": [5, 9], "where": 5, "do": 5, "paramet": 5, "live": 5, "write": 5, "configur": 5, "us": [5, 9], "instanti": [5, 10], "referenc": 5, "other": 5, "field": 5, "interpol": 5, "valid": 5, "your": [5, 7, 9], "best": 5, "practic": 5, "airtight": 5, "public": 5, "api": 5, "onli": 5, "command": 5, "line": 5, "overrid": 5, "llm": [6, 7], "full": 6, "finetun": [6, 7, 8], "recip": [6, 7, 8, 9], "train": [6, 7, 9], "first": 7, "download": 7, "select": 7, "modifi": 7, "next": 7, "step": 7, "lora": 8, "what": [8, 9, 57], "how": 8, "doe": 8, "work": 8, "appli": 8, "ar": 9, "script": 9, "class": 9, "run": 9, "cli": 9, "pars": [9, 11], "slimorcadataset": 12, "alpaca_dataset": 13, "grammar_dataset": 14, "samsum_dataset": 15, "llama2_7b": 16, "lora_llama2": 17, "causalselfattent": 18, "todo": [18, 25], "feedforward": 19, "kvcach": 20, "rmsnorm": 21, "rotarypositionalembed": 22, "token": 23, "transformerdecod": 24, "transformerdecoderlay": 25, "get_cosine_schedule_with_warmup": 26, "frozennf4linear": 27, "adaptermodul": 28, "loralinear": 29, "get_adapter_param": 30, "set_trainable_param": 31, "tuneargumentpars": 32, "load_checkpoint": 33, "save_checkpoint": 34, "checkpointabledataload": 35, "padded_col": 36, "generationutil": 37, "generate_from_prompt": 38, "get_devic": 39, "get_world_size_and_rank": 40, "init_distribut": 41, "get_logg": 42, "set_activation_checkpoint": 43, "disklogg": 44, "stdoutlogg": 45, "tensorboardlogg": 46, "wandblogg": 47, "get_autocast": 48, "get_dtyp": 49, "get_gradient_scal": 50, "list_dtyp": 51, "set_se": 52, "comput": [54, 58], "time": [54, 58], "welcom": 55, "document": 55, "get": 55, "start": 55, "tutori": 55, "instal": 56, "instruct": 56, "overview": 57, "kei": 57, "concept": 57, "design": 57, "principl": 57}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})