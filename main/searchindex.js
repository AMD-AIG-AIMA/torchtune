Search.setIndex({"docnames": ["api_ref_config", "api_ref_data", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "deep_dives/checkpointer", "deep_dives/configs", "deep_dives/recipe_deepdive", "deep_dives/wandb_logging", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.config.validate", "generated/torchtune.data.AlpacaInstructTemplate", "generated/torchtune.data.ChatFormat", "generated/torchtune.data.ChatMLFormat", "generated/torchtune.data.GrammarErrorCorrectionTemplate", "generated/torchtune.data.InstructTemplate", "generated/torchtune.data.Llama2ChatFormat", "generated/torchtune.data.MistralChatFormat", "generated/torchtune.data.SummarizeTemplate", "generated/torchtune.data.validate_messages", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.models.gemma.gemma_2b", "generated/torchtune.models.llama2.llama2_13b", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2_13b", "generated/torchtune.models.llama2.lora_llama2_7b", "generated/torchtune.models.llama2.qlora_llama2_13b", "generated/torchtune.models.llama2.qlora_llama2_7b", "generated/torchtune.models.mistral.lora_mistral_7b", "generated/torchtune.models.mistral.mistral_7b", "generated/torchtune.models.mistral.qlora_mistral_7b", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.Tokenizer", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.TuneRecipeArgumentParser", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_dtype", "generated/torchtune.utils.get_logger", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.list_dtypes", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.padded_collate", "generated/torchtune.utils.profiler", "generated/torchtune.utils.set_activation_checkpointing", "generated/torchtune.utils.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times", "tutorials/datasets", "tutorials/e2e_flow", "tutorials/first_finetune_tutorial", "tutorials/lora_finetune", "tutorials/qlora_finetune"], "filenames": ["api_ref_config.rst", "api_ref_data.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "deep_dives/checkpointer.rst", "deep_dives/configs.rst", "deep_dives/recipe_deepdive.rst", "deep_dives/wandb_logging.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.config.validate.rst", "generated/torchtune.data.AlpacaInstructTemplate.rst", "generated/torchtune.data.ChatFormat.rst", "generated/torchtune.data.ChatMLFormat.rst", "generated/torchtune.data.GrammarErrorCorrectionTemplate.rst", "generated/torchtune.data.InstructTemplate.rst", "generated/torchtune.data.Llama2ChatFormat.rst", "generated/torchtune.data.MistralChatFormat.rst", "generated/torchtune.data.SummarizeTemplate.rst", "generated/torchtune.data.validate_messages.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.models.gemma.gemma_2b.rst", "generated/torchtune.models.llama2.llama2_13b.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2_13b.rst", "generated/torchtune.models.llama2.lora_llama2_7b.rst", "generated/torchtune.models.llama2.qlora_llama2_13b.rst", "generated/torchtune.models.llama2.qlora_llama2_7b.rst", "generated/torchtune.models.mistral.lora_mistral_7b.rst", "generated/torchtune.models.mistral.mistral_7b.rst", "generated/torchtune.models.mistral.qlora_mistral_7b.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.Tokenizer.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_dtype.rst", "generated/torchtune.utils.get_logger.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.list_dtypes.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.padded_collate.rst", "generated/torchtune.utils.profiler.rst", "generated/torchtune.utils.set_activation_checkpointing.rst", "generated/torchtune.utils.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst", "tutorials/datasets.rst", "tutorials/e2e_flow.rst", "tutorials/first_finetune_tutorial.rst", "tutorials/lora_finetune.rst", "tutorials/qlora_finetune.rst"], "titles": ["torchtune.config", "torchtune.data", "torchtune.datasets", "torchtune.models", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "All About Configs", "What Are Recipes?", "Logging to Weights &amp; Biases", "instantiate", "parse", "validate", "AlpacaInstructTemplate", "ChatFormat", "ChatMLFormat", "GrammarErrorCorrectionTemplate", "InstructTemplate", "Llama2ChatFormat", "MistralChatFormat", "SummarizeTemplate", "validate_messages", "alpaca_cleaned_dataset", "alpaca_dataset", "grammar_dataset", "samsum_dataset", "slimorca_dataset", "gemma_2b", "llama2_13b", "llama2_7b", "lora_llama2_13b", "lora_llama2_7b", "qlora_llama2_13b", "qlora_llama2_7b", "lora_mistral_7b", "mistral_7b", "qlora_mistral_7b", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "Tokenizer", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "get_device", "get_dtype", "get_logger", "get_world_size_and_rank", "init_distributed", "list_dtypes", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "padded_collate", "profiler", "set_activation_checkpointing", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times", "Configuring Datasets for Fine-Tuning", "End-to-End Workflow with torchtune", "Fine-Tune Your First LLM", "Finetuning Llama2 with LoRA", "Finetuning Llama2 with QLoRA"], "terms": {"all": [3, 4, 8, 12, 37, 38, 43, 45, 51, 53, 68, 70, 72, 73, 75, 76, 77], "from": [3, 6, 7, 8, 9, 10, 13, 16, 17, 18, 20, 22, 23, 24, 25, 27, 28, 29, 35, 38, 42, 43, 44, 46, 47, 49, 51, 52, 53, 62, 63, 69, 71, 73, 74, 75, 76, 77], "famili": [3, 8, 22, 23, 26, 72], "pre": [3, 18, 71], "train": [3, 5, 6, 8, 9, 18, 22, 23, 24, 25, 26, 37, 45, 46, 51, 52, 55, 65, 70, 72, 74, 75, 77, 78], "can": [3, 4, 6, 7, 8, 9, 10, 12, 22, 23, 40, 41, 42, 51, 53, 62, 63, 70, 71, 72, 74, 75, 76, 77, 78], "download": [3, 6, 68, 71, 77, 78], "hug": [3, 6, 22, 23, 24, 25, 26, 46, 72, 74, 76], "face": [3, 6, 22, 23, 24, 25, 26, 46, 72, 74, 76], "hub": [3, 6, 76], "follow": [3, 6, 8, 37, 46, 63, 70, 71, 74, 75, 76, 77, 78], "command": [3, 8, 9, 53, 71, 75, 76, 77, 78], "tune": [3, 6, 7, 8, 9, 11, 70, 71, 72, 75, 77, 78], "meta": [3, 6, 18, 51, 52, 75, 76], "llama": [3, 6, 18, 40, 41, 51, 52, 75, 76, 77], "2": [3, 6, 9, 21, 26, 37, 42, 51, 52, 64, 67, 75, 76, 77], "7b": [3, 6, 22, 23, 29, 31, 34, 35, 51, 52, 76, 77, 78], "hf": [3, 6, 51, 75, 76], "token": [3, 6, 7, 8, 22, 23, 24, 25, 26, 37, 41, 43, 44, 74, 75, 76, 77, 78], "access_token": 3, "ai": [3, 35, 37, 63], "mistralai": 3, "v0": 3, "1": [3, 6, 8, 26, 37, 42, 43, 46, 52, 62, 63, 64, 67, 75, 76, 77, 78], "googl": [3, 27], "2b": [3, 27], "ignor": [3, 6, 37, 38], "pattern": 3, "These": [4, 6, 7, 8, 10, 53, 74, 75, 76, 77, 78], "ar": [4, 6, 7, 9, 10, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 30, 31, 32, 33, 34, 36, 43, 48, 51, 52, 55, 72, 74, 75, 76, 77, 78], "common": [4, 7, 74, 77], "us": [4, 6, 9, 10, 11, 15, 18, 22, 23, 24, 25, 26, 37, 38, 40, 41, 42, 43, 44, 45, 51, 52, 53, 54, 55, 60, 61, 62, 63, 67, 70, 71, 72, 74, 76, 77], "offer": 5, "allow": [5, 62, 78], "seamless": 5, "transit": 5, "between": [5, 6, 51, 75, 77, 78], "format": [5, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 26, 51, 52, 75, 76, 77], "interoper": [5, 6, 8, 72, 75, 78], "rest": [5, 78], "ecosystem": [5, 6, 8, 72, 75, 78], "For": [5, 6, 7, 8, 22, 23, 37, 43, 53, 63, 67, 74, 75, 76, 77, 78], "comprehens": 5, "overview": [5, 7, 9, 76, 77, 78], "pleas": [5, 33, 36, 71, 78], "see": [5, 6, 9, 18, 19, 33, 36, 39, 47, 53, 56, 63, 65, 67, 71, 72, 74, 75, 76, 77, 78], "deep": [5, 6, 7, 8, 9, 72, 76], "dive": [5, 6, 7, 8, 9, 72, 76], "enabl": [5, 7, 8, 9, 30, 31, 32, 33, 34, 36, 48, 65, 67, 77, 78], "work": [5, 6, 8, 53, 72, 75, 78], "set": [5, 6, 7, 8, 9, 22, 23, 24, 25, 26, 41, 43, 50, 54, 66, 67, 72, 74, 75, 76, 77], "consumpt": 5, "dure": [5, 6, 22, 23, 24, 25, 37, 39, 41, 43, 44, 45, 75, 77, 78], "provid": [5, 6, 7, 8, 10, 15, 19, 26, 43, 53, 63, 72, 74, 75, 76], "debug": [5, 6, 7, 8], "your": [5, 9, 10, 62, 63, 70, 71, 72, 74, 77, 78], "finetun": [5, 6, 7, 8, 30, 31, 32, 59, 70, 72, 76], "job": [5, 9, 67, 76], "variou": [5, 17], "dataset": [5, 7, 13, 16, 17, 20, 22, 23, 24, 25, 26, 72, 76], "walk": [6, 8, 62, 72, 74, 75, 76, 78], "you": [6, 7, 8, 9, 10, 17, 18, 22, 23, 53, 62, 63, 70, 71, 72, 74, 75, 76, 77, 78], "through": [6, 7, 8, 9, 38, 72, 74, 75, 76, 78], "design": [6, 8], "behavior": [6, 74], "associ": [6, 7, 8, 75, 77], "util": [6, 7, 8, 9, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 72, 75, 76, 78], "what": [6, 7, 9, 18, 19, 24, 25, 70, 74, 75, 76], "cover": [6, 7, 8, 9, 75, 78], "how": [6, 7, 8, 9, 70, 74, 75, 76, 78], "we": [6, 7, 8, 9, 22, 23, 37, 39, 41, 42, 43, 48, 51, 52, 55, 72, 74, 75, 76, 77, 78], "them": [6, 7, 38, 42, 45, 74, 75, 77, 78], "scenario": 6, "full": [6, 7, 8, 33, 36, 42, 72, 77], "compos": 6, "compon": [6, 8, 12, 65, 72, 74, 76, 77, 78], "which": [6, 8, 22, 23, 24, 25, 30, 31, 32, 34, 37, 41, 42, 43, 44, 46, 51, 52, 55, 60, 63, 72, 74, 75, 76, 77, 78], "plug": 6, "ani": [6, 7, 8, 10, 11, 12, 13, 16, 17, 20, 42, 45, 49, 50, 51, 52, 67, 74, 75, 76, 77], "recip": [6, 7, 9, 10, 11, 38, 51, 52, 72, 74, 75, 78], "evalu": [6, 8, 70, 72, 76, 77, 78], "gener": [6, 8, 13, 16, 20, 26, 42, 67, 68, 70, 74, 77, 78], "each": [6, 8, 14, 17, 30, 31, 32, 34, 37, 41, 42, 43, 67, 72, 74, 75, 76, 77], "support": [6, 8, 9, 10, 19, 22, 23, 24, 25, 26, 37, 48, 52, 55, 59, 72, 74, 75, 76, 77, 78], "model": [6, 7, 8, 10, 15, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 65, 66, 70, 72, 74, 78], "make": [6, 7, 8, 9, 37, 44, 72, 75, 76, 77, 78], "easi": [6, 8, 72, 77], "understand": [6, 7, 8, 70, 72, 74, 77, 78], "extend": [6, 8, 72], "befor": [6, 21, 43, 44, 48, 51, 75], "let": [6, 7, 9, 74, 75, 76, 77, 78], "s": [6, 7, 8, 9, 11, 13, 14, 15, 18, 19, 21, 22, 23, 24, 25, 26, 30, 31, 32, 34, 37, 41, 43, 44, 45, 47, 49, 51, 52, 54, 62, 65, 72, 74, 76, 77, 78], "defin": [6, 7, 8, 38, 47, 48, 49, 76, 77], "some": [6, 7, 15, 49, 50, 70, 72, 75, 76, 77, 78], "concept": [6, 75, 76], "In": [6, 7, 8, 41, 48, 62, 63, 75, 77, 78], "ll": [6, 7, 8, 72, 74, 75, 76, 78], "talk": 6, "about": [6, 8, 51, 63, 72, 75, 76, 77, 78], "take": [6, 7, 8, 10, 38, 39, 45, 51, 53, 54, 74, 75, 76, 77, 78], "close": [6, 8, 60, 61, 62, 63, 77], "look": [6, 7, 8, 62, 74, 75, 76, 77], "veri": [6, 43, 75], "simpli": [6, 7, 74, 75, 78], "dictat": 6, "state_dict": [6, 45, 51, 52, 77, 78], "store": [6, 60, 63, 77, 78], "file": [6, 7, 8, 9, 10, 11, 42, 51, 52, 53, 60, 63, 65, 69, 72, 73, 74, 75, 76, 77, 78], "disk": [6, 60], "weight": [6, 8, 30, 31, 32, 33, 34, 36, 37, 45, 47, 48, 51, 52, 63, 70, 75, 76, 77, 78], "string": [6, 22, 23, 24, 25, 26, 42, 47, 54, 55], "kei": [6, 7, 9, 37, 39, 43, 50, 51, 75, 76, 77, 78], "identifi": 6, "state": [6, 8, 45, 49, 50, 51, 52, 75, 77, 78], "dict": [6, 7, 8, 9, 10, 13, 16, 17, 20, 45, 49, 50, 51, 52, 58], "If": [6, 7, 12, 13, 16, 17, 19, 20, 21, 22, 23, 24, 25, 26, 37, 45, 48, 51, 52, 54, 55, 58, 62, 63, 67, 71, 74, 75, 76, 77], "identif": 6, "don": [6, 7, 8, 63, 67, 75, 76, 78], "t": [6, 7, 8, 26, 55, 63, 67, 75, 76, 78], "match": [6, 75, 77], "up": [6, 8, 9, 22, 23, 74, 76, 77, 78], "exactli": 6, "those": [6, 77], "definit": [6, 77], "either": [6, 51, 77, 78], "run": [6, 7, 9, 11, 38, 39, 43, 45, 51, 52, 62, 63, 71, 72, 76, 77, 78], "explicit": 6, "error": [6, 7, 21, 51, 67], "load": [6, 8, 51, 52, 53, 62, 75, 77], "rais": [6, 10, 12, 19, 21, 26, 37, 43, 51, 52, 55, 58, 63, 67], "an": [6, 7, 8, 9, 10, 13, 21, 22, 23, 24, 25, 26, 37, 43, 47, 49, 50, 51, 52, 63, 72, 74, 75, 76, 77, 78], "except": [6, 19, 74], "wors": 6, "silent": [6, 38], "succe": 6, "infer": [6, 18, 37, 39, 41, 43, 44, 70, 75, 76, 78], "expect": [6, 7, 10, 13, 16, 17, 20, 41, 63, 74, 77], "addit": [6, 7, 8, 10, 51, 52, 55, 58, 60, 62, 63, 66, 72, 76, 77], "line": [6, 8, 53, 76], "also": [6, 7, 8, 9, 10, 37, 43, 48, 54, 63, 71, 74, 75, 76, 77, 78], "need": [6, 7, 8, 9, 17, 26, 37, 38, 43, 62, 63, 74, 75, 76, 77, 78], "shape": [6, 37, 39, 41, 43, 44, 48], "valu": [6, 7, 26, 27, 28, 29, 35, 37, 39, 40, 43, 46, 51, 53, 60, 61, 62, 63, 67, 76, 77], "two": [6, 7, 21, 72, 75, 76, 77, 78], "popular": [6, 72, 74, 75], "llama2": [6, 7, 8, 10, 18, 22, 23, 26, 28, 29, 30, 31, 32, 33, 38, 42, 43, 44, 70, 72, 76], "offici": [6, 18, 76], "implement": [6, 8, 22, 23, 24, 25, 26, 38, 40, 41, 46, 47, 48, 51, 62, 72, 77, 78], "when": [6, 7, 8, 11, 43, 45, 46, 62, 75, 77, 78], "websit": 6, "get": [6, 7, 8, 9, 42, 55, 56, 57, 72, 74, 75, 76, 77], "access": [6, 7, 8, 51, 75, 76], "singl": [6, 7, 10, 13, 14, 15, 16, 17, 18, 19, 20, 37, 51, 52, 75, 76, 77, 78], "pth": [6, 75], "inspect": [6, 75, 77, 78], "content": [6, 42, 74], "easili": [6, 7, 72, 74, 77, 78], "torch": [6, 39, 43, 45, 46, 54, 55, 58, 65, 66, 67, 75, 76, 77, 78], "import": [6, 7, 10, 62, 63, 74, 75, 76, 77, 78], "consolid": 6, "00": [6, 69, 73, 76], "mmap": [6, 75], "true": [6, 7, 22, 23, 24, 25, 32, 33, 36, 42, 45, 51, 52, 58, 62, 74, 75, 77, 78], "weights_onli": 6, "map_loc": [6, 75], "cpu": [6, 8, 45, 55, 75, 78], "tensor": [6, 37, 38, 39, 40, 41, 43, 44, 45, 48, 51, 60, 61, 62, 63, 64, 77, 78], "item": 6, "print": [6, 9, 22, 23, 24, 25, 26, 42, 74, 76, 77, 78], "f": [6, 9, 22, 23, 24, 25, 75, 77, 78], "tok_embed": [6, 43], "size": [6, 8, 10, 22, 23, 24, 25, 37, 39, 40, 41, 42, 43, 44, 57, 72, 74, 75, 76, 77], "32000": [6, 10, 77], "4096": [6, 10, 22, 23, 37, 41, 77], "len": [6, 22, 23, 24, 25, 43], "292": 6, "The": [6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 30, 31, 32, 40, 41, 42, 45, 46, 51, 53, 54, 55, 56, 63, 65, 67, 71, 72, 75, 76, 77, 78], "contain": [6, 37, 39, 41, 42, 43, 44, 47, 49, 50, 51, 52, 53, 62, 64, 75, 77], "includ": [6, 7, 8, 14, 17, 48, 51, 52, 53, 72, 75, 76, 77, 78], "input": [6, 13, 14, 17, 22, 23, 24, 26, 37, 38, 40, 41, 42, 43, 44, 48, 51, 64, 67, 74, 77, 78], "embed": [6, 37, 39, 40, 41, 43], "tabl": [6, 78], "call": [6, 10, 38, 45, 53, 60, 61, 62, 63, 77, 78], "layer": [6, 8, 30, 31, 32, 33, 34, 36, 37, 43, 44, 48, 72, 77, 78], "have": [6, 7, 10, 37, 39, 47, 53, 62, 65, 74, 75, 76, 77, 78], "dim": [6, 37, 38, 40, 41, 43, 44], "most": [6, 7, 76, 77, 78], "within": [6, 7, 10, 26, 38, 62, 67, 75, 77, 78], "default": [6, 7, 15, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 48, 51, 52, 53, 55, 60, 63, 64, 65, 67, 75, 77, 78], "everi": [6, 8, 38, 62, 78], "config": [6, 9, 10, 11, 12, 37, 51, 53, 63, 72, 74, 75, 77, 78], "repo": [6, 51, 52, 75], "first": [6, 7, 10, 21, 43, 51, 53, 70, 72, 75, 77, 78], "big": [6, 75], "split": [6, 74, 75], "across": [6, 8, 51, 62, 67, 75], "bin": [6, 75], "To": [6, 7, 8, 9, 51, 71, 72, 74, 75, 76, 77, 78], "correctli": [6, 8, 12, 51, 71, 76, 78], "piec": 6, "one": [6, 8, 21, 38, 42, 74, 75, 76, 78], "pytorch_model": [6, 75], "00001": 6, "00002": 6, "embed_token": 6, "241": 6, "Not": 6, "onli": [6, 9, 37, 41, 42, 43, 44, 48, 49, 52, 53, 55, 75, 76, 77, 78], "doe": [6, 19, 47, 51, 53, 75], "fewer": [6, 37], "sinc": [6, 7, 10, 38, 51, 75], "instead": [6, 8, 38, 39, 48, 75, 77], "mismatch": 6, "name": [6, 7, 9, 13, 16, 17, 20, 47, 50, 51, 52, 53, 54, 60, 61, 62, 63, 75], "caus": [6, 42], "try": [6, 7, 75, 76, 78], "same": [6, 7, 30, 31, 32, 37, 39, 42, 44, 53, 63, 75, 77, 78], "As": [6, 7, 8, 9, 48, 72, 75, 78], "re": [6, 7, 72, 75, 76, 77], "care": [6, 38, 51, 75, 77], "like": [6, 7, 8, 9, 74, 75, 76, 77], "end": [6, 8, 42, 70, 72, 77], "number": [6, 8, 22, 23, 26, 37, 39, 43, 46, 51, 52, 57, 67, 76, 77], "just": [6, 13, 72, 74, 76, 77], "save": [6, 8, 9, 45, 51, 52, 63, 70, 75, 77], "less": [6, 26, 75, 76, 78], "prone": 6, "manag": [6, 65], "invari": 6, "accept": [6, 7, 26, 42, 76, 78], "multipl": [6, 7, 8, 48, 60, 61, 62, 63, 76], "sourc": [6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 74, 75], "worri": [6, 76], "explicitli": [6, 47, 72, 77], "convert": [6, 51, 64, 75, 78], "time": [6, 42, 60, 62, 75, 78], "produc": [6, 78], "back": [6, 21, 51, 77, 78], "origin": [6, 22, 23, 45, 48, 74, 75, 77, 78], "form": [6, 7, 8, 21], "One": [6, 75], "advantag": [6, 77], "being": [6, 51, 52, 54, 78], "should": [6, 7, 8, 14, 17, 18, 19, 30, 31, 32, 34, 37, 38, 47, 53, 60, 61, 62, 63, 71, 72, 74, 75, 76, 77, 78], "abl": [6, 8, 74, 75, 76], "fine": [6, 8, 9, 70, 72, 75, 77], "post": [6, 78], "tool": [6, 75, 76], "quantiz": [6, 30, 31, 32, 33, 34, 36, 48, 70, 76, 78], "eval": [6, 70, 72], "without": [6, 7, 9, 72, 74, 75, 77], "code": [6, 8, 43, 68, 72, 74, 76], "chang": [6, 7, 9, 13, 74, 75, 76, 77, 78], "OR": 6, "convers": [6, 14, 15, 18, 19, 21, 26, 51, 72, 74, 75, 77, 78], "script": [6, 9, 75, 76], "wai": [6, 7, 74, 75, 76], "surround": [6, 8, 72], "load_checkpoint": [6, 8, 51, 52], "save_checkpoint": [6, 8, 9, 51, 52], "method": [6, 7, 8, 9, 11, 22, 23, 24, 25, 26, 45, 47, 49, 53, 72, 75, 77, 78], "convertor": 6, "avail": [6, 8, 53, 54, 55, 72, 75, 77], "here": [6, 7, 9, 15, 24, 40, 41, 74, 75, 76, 77, 78], "three": [6, 8, 76], "hfcheckpoint": 6, "read": [6, 51, 52, 72], "write": [6, 8, 51, 52, 60, 74, 76], "compat": [6, 51], "transform": [6, 8, 30, 31, 32, 34, 43, 44, 46, 77], "framework": [6, 8, 72], "mention": [6, 75, 78], "abov": [6, 45, 75, 77, 78], "assum": [6, 13, 16, 17, 20, 46, 49, 55, 75, 77], "checkpoint_dir": [6, 7, 51, 52, 75], "necessari": [6, 26, 60, 61, 62, 63, 77], "json": [6, 51, 65, 75], "easiest": [6, 75, 76], "sure": [6, 7, 75, 76, 77, 78], "everyth": [6, 8, 53, 72, 76], "flow": [6, 78], "By": [6, 77, 78], "safetensor": 6, "output": [6, 17, 22, 23, 24, 26, 30, 31, 32, 34, 37, 38, 40, 41, 43, 44, 48, 50, 61, 65, 71, 74, 75, 76, 77, 78], "dir": [6, 63, 75, 76], "output_dir": [6, 7, 51, 52, 65, 75, 77, 78], "specifi": [6, 7, 8, 10, 37, 63, 74, 75, 76, 78], "argument": [6, 7, 10, 17, 26, 33, 36, 37, 53, 58, 60, 62, 63, 66, 77], "snippet": 6, "explain": 6, "setup": [6, 7, 8, 43, 66, 75, 77, 78], "_component_": [6, 7, 9, 10, 74, 75, 77], "fullmodelhfcheckpoint": [6, 75], "directori": [6, 7, 51, 52, 60, 62, 63, 75, 76], "sort": [6, 51], "id": [6, 22, 23, 26, 42, 51, 64, 75], "so": [6, 7, 51, 53, 71, 72, 75, 76, 77, 78], "order": [6, 8, 51, 62, 63, 76], "matter": [6, 51, 77], "checkpoint_fil": [6, 7, 9, 51, 52, 75, 77, 78], "restart": 6, "previou": [6, 51, 52], "more": [6, 7, 8, 39, 41, 53, 63, 65, 67, 72, 74, 75, 76, 77, 78], "next": [6, 78], "section": [6, 8, 70, 75, 78], "recipe_checkpoint": [6, 51, 52], "null": [6, 7], "usual": [6, 41, 51, 63, 75, 77], "model_typ": [6, 51, 52, 75], "resume_from_checkpoint": [6, 51, 52], "fals": [6, 7, 22, 23, 24, 25, 26, 30, 31, 32, 33, 34, 36, 37, 42, 48, 51, 52, 65, 75, 77, 78], "requir": [6, 7, 26, 51, 62, 63, 67, 71, 74, 76, 78], "param": [6, 8, 30, 31, 32, 48, 49, 50, 51, 77, 78], "directli": [6, 7, 8, 10, 51, 74, 75, 76, 77, 78], "help": [6, 18, 43, 51, 53, 70, 71, 72, 74, 75, 76, 78], "ensur": [6, 7, 12, 21, 26, 37, 51, 55, 72, 76], "out": [6, 7, 8, 22, 23, 24, 25, 51, 52, 70, 72, 75, 76, 77, 78], "case": [6, 8, 9, 37, 51, 55, 60, 72, 74, 75, 77, 78], "discrep": [6, 51], "along": [6, 77], "detail": [6, 39, 65, 67, 75, 76, 77, 78], "found": [6, 7, 9, 40, 41, 77, 78], "metacheckpoint": 6, "github": [6, 30, 31, 32, 37, 40, 41, 46, 71, 76], "repositori": [6, 18, 75, 76], "fullmodelmetacheckpoint": 6, "torchtunecheckpoint": 6, "perform": [6, 38, 72, 75, 78], "current": [6, 37, 41, 43, 44, 52, 57, 60, 62, 67, 75, 76], "test": [6, 7, 8, 72], "complet": [6, 8, 74, 75, 76], "written": [6, 7, 8, 51, 52, 60, 61, 62, 63, 72], "begin": [6, 42, 78], "partit": [6, 78], "ha": [6, 42, 47, 49, 74, 75, 76, 77, 78], "standard": [6, 61, 72, 75], "key_1": 6, "weight_1": 6, "key_2": 6, "weight_2": 6, "mid": 6, "chekpoint": 6, "middl": [6, 75], "inform": [6, 63, 72, 75, 76], "subsequ": [6, 8], "recipe_st": [6, 51, 52], "pt": [6, 9, 51, 52, 75], "epoch": [6, 8, 9, 46, 51, 52, 75, 76], "optim": [6, 7, 8, 46, 75, 76, 77, 78], "etc": [6, 8, 51, 76], "prevent": 6, "flood": 6, "overwritten": 6, "note": [6, 7, 17, 42, 43, 47, 51, 65, 67, 74, 75, 77, 78], "updat": [6, 7, 8, 75, 76, 77, 78], "hf_model_0001_0": [6, 75], "hf_model_0002_0": [6, 75], "both": [6, 75, 77, 78], "adapt": [6, 47, 48, 49, 50, 51, 52, 75, 77, 78], "merg": [6, 10, 51, 75, 78], "would": [6, 7, 9, 43, 74, 75, 77, 78], "our": [6, 8, 72, 74, 75, 76, 77, 78], "tutori": [6, 72, 74, 75, 76, 77, 78], "primari": [6, 7, 8, 76], "want": [6, 7, 8, 9, 10, 71, 75, 76, 77], "resum": [6, 8, 46, 51, 52, 78], "initi": [6, 8, 11, 27, 28, 29, 35, 42, 58, 76, 77, 78], "frozen": [6, 77, 78], "base": [6, 26, 30, 31, 32, 33, 34, 36, 41, 46, 48, 50, 51, 53, 60, 70, 75, 76, 77, 78], "well": [6, 7, 8, 72, 74, 75, 78], "learnt": [6, 75], "someth": [6, 8, 9, 75], "NOT": 6, "refer": [6, 7, 8, 40, 41, 72, 77], "adapter_checkpoint": [6, 51, 52], "adapter_0": [6, 75], "now": [6, 42, 74, 75, 76, 77, 78], "knowledg": 6, "creat": [6, 7, 10, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 39, 46, 51, 52, 60, 62, 74, 75, 78], "simpl": [6, 8, 70, 76, 77, 78], "forward": [6, 8, 37, 38, 40, 41, 43, 44, 48, 77, 78], "13b": [6, 28, 30, 32], "modeltyp": [6, 51, 52], "llama2_13b": [6, 30, 32], "right": [6, 51, 75, 77], "pytorch_fil": 6, "00003": 6, "torchtune_sd": 6, "load_state_dict": [6, 77], "successfulli": [6, 76], "vocab": [6, 10, 43], "70": 6, "x": [6, 37, 38, 40, 41, 43, 44, 48, 77, 78], "randint": 6, "0": [6, 8, 31, 33, 37, 42, 43, 46, 48, 62, 63, 64, 67, 69, 73, 75, 76, 77, 78], "no_grad": 6, "6": [6, 40, 64, 75, 78], "3989": 6, "9": [6, 75, 78], "0531": 6, "3": [6, 53, 56, 64, 75, 76, 78], "2375": 6, "5": [6, 46, 64, 65, 75, 76], "2822": 6, "4": [6, 26, 37, 64, 72, 75, 77, 78], "4872": 6, "7469": 6, "8": [6, 22, 23, 24, 25, 30, 31, 32, 33, 34, 36, 75, 77, 78], "6737": 6, "11": [6, 75, 78], "0023": 6, "8235": 6, "6819": 6, "2424": 6, "0109": 6, "6915": 6, "7": [6, 64], "3618": 6, "1628": 6, "8594": 6, "5857": 6, "1151": 6, "7808": 6, "2322": 6, "8850": 6, "9604": 6, "7624": 6, "6040": 6, "3159": 6, "5849": 6, "8039": 6, "9322": 6, "2010": 6, "6824": 6, "8929": 6, "8465": 6, "3794": 6, "3500": 6, "6145": 6, "5931": 6, "do": [6, 8, 63, 74, 75, 76, 77], "find": [6, 8, 9, 75, 76, 77], "list": [6, 7, 14, 15, 18, 19, 21, 22, 23, 26, 30, 31, 32, 33, 34, 36, 42, 47, 48, 51, 52, 53, 56, 59, 64, 74, 76], "builder": [6, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 74, 78], "hope": 6, "deeper": [6, 76], "insight": [6, 75], "happi": [6, 75], "thi": [7, 8, 9, 10, 22, 23, 26, 37, 38, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 60, 62, 63, 65, 67, 70, 71, 72, 74, 75, 76, 77, 78], "guid": [7, 9, 72, 74, 76, 77], "yaml": [7, 8, 10, 11, 53, 63, 72, 75, 76, 77, 78], "pars": [7, 10, 53, 76], "effect": 7, "cli": [7, 9, 11, 71, 75, 76], "prerequisit": [7, 74, 75, 76, 77, 78], "Be": [7, 75, 76, 77, 78], "familiar": [7, 75, 76, 77, 78], "torchtun": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 71, 74, 76], "instal": [7, 9, 62, 63, 70, 75, 76, 77, 78], "fundament": 7, "There": [7, 14, 21, 75, 76, 77], "entri": [7, 8, 76], "point": [7, 8, 74, 75, 76, 77, 78], "locat": [7, 77, 78], "thei": [7, 8, 43, 53, 74, 77], "truth": [7, 75], "reproduc": 7, "overridden": [7, 38, 53], "quick": 7, "experiment": 7, "modifi": [7, 8, 9, 45, 72, 75, 77, 78], "serv": [7, 74, 77], "particular": [7, 26, 74, 77, 78], "seed": [7, 8, 9, 67, 76], "shuffl": 7, "devic": [7, 8, 54, 55, 75, 76, 77], "cuda": [7, 54, 55, 75, 78], "dtype": [7, 8, 39, 45, 55, 59, 75, 78], "fp32": [7, 78], "enable_fsdp": 7, "mani": [7, 74, 75], "object": [7, 10, 14, 15, 18, 19, 37, 74], "keyword": [7, 10, 26, 45], "loss": [7, 8, 22, 23, 24, 25, 76, 77, 78], "function": [7, 8, 10, 11, 37, 38, 45, 54, 57, 67, 72, 74, 78], "exampl": [7, 8, 9, 10, 11, 15, 18, 19, 22, 23, 24, 25, 26, 37, 42, 47, 51, 52, 62, 63, 64, 68, 69, 73, 74, 75, 77, 78], "subfield": 7, "dotpath": 7, "wish": 7, "exact": [7, 10, 75], "path": [7, 8, 9, 10, 22, 23, 24, 25, 26, 42, 51, 52, 53, 65, 75, 77], "normal": [7, 40, 42, 43, 44, 74, 77, 78], "python": [7, 53, 56, 63, 67, 68, 75], "alpaca_dataset": [7, 22, 74], "custom": [7, 8, 72, 75, 76, 77], "train_on_input": [7, 22, 23, 24, 25, 26, 74], "onc": [7, 75, 76, 77, 78], "ve": [7, 39, 74, 75, 77], "instanc": [7, 10, 38, 42, 45, 49, 50, 77], "cfg": [7, 8, 11, 12], "automat": [7, 9, 10, 75, 78], "under": [7, 75, 78], "preced": [7, 10, 77], "actual": [7, 9], "throw": 7, "notic": [7, 74, 77], "miss": [7, 77], "posit": [7, 10, 37, 41, 43, 44], "anoth": [7, 75], "handl": [7, 11, 42, 75, 77, 78], "def": [7, 8, 9, 11, 74, 77, 78], "dictconfig": [7, 8, 10, 11, 12, 63], "arg": [7, 10, 43, 45, 47, 53, 61], "tupl": [7, 10, 26, 42, 45, 53, 57, 64], "kwarg": [7, 10, 45, 47, 53, 58, 60, 61, 62, 63, 66], "str": [7, 10, 13, 16, 17, 20, 22, 23, 24, 25, 26, 42, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 59, 60, 61, 62, 63, 65, 67], "mean": [7, 40, 76, 77], "pass": [7, 10, 37, 38, 45, 55, 58, 62, 63, 66, 77, 78], "add": [7, 9, 53, 74, 75, 77, 78], "d": [7, 37, 43, 44, 74, 77], "llama2_token": [7, 75], "tmp": [7, 76], "option": [7, 8, 13, 16, 17, 20, 30, 31, 32, 34, 37, 41, 42, 43, 44, 45, 51, 52, 54, 55, 56, 60, 63, 65, 66, 67, 71, 72, 75], "bool": [7, 22, 23, 24, 25, 26, 30, 31, 32, 33, 34, 36, 42, 45, 48, 51, 52, 58, 62, 65, 78], "max_seq_len": [7, 10, 22, 23, 26, 37, 39, 41, 42, 43, 74], "int": [7, 9, 22, 23, 26, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 46, 48, 51, 52, 57, 60, 61, 62, 63, 64, 67, 74, 77, 78], "512": [7, 22, 23, 74, 78], "instructdataset": [7, 22, 23, 24, 25, 74], "alreadi": [7, 58, 75, 77], "overwrit": 7, "duplic": [7, 8, 72], "sometim": 7, "than": [7, 21, 26, 37, 75, 76, 77, 78], "resolv": [7, 76], "alpaca": [7, 13, 22, 23, 30, 31, 32, 74], "metric_logg": [7, 8, 9], "metric_log": [7, 9, 60, 61, 62, 63], "disklogg": 7, "log_dir": [7, 60, 62, 63], "conveni": [7, 8], "quickli": [7, 74], "verifi": [7, 54, 55, 76, 77], "properli": 7, "experi": [7, 63, 70, 72, 77], "wa": [7, 75, 77, 78], "cp": [7, 71, 75, 76], "7b_lora_single_devic": [7, 75, 76, 77, 78], "my_config": 7, "discuss": [7, 76, 77], "guidelin": 7, "while": [7, 8, 30, 31, 32, 38, 72, 75, 78], "mai": [7, 9, 65, 74, 76, 77], "tempt": 7, "put": [7, 8, 76, 77], "much": [7, 75, 77, 78], "give": [7, 77], "maximum": [7, 22, 23, 26, 37, 39, 41, 43], "flexibl": [7, 74], "switch": 7, "encourag": [7, 77], "clariti": 7, "significantli": 7, "easier": [7, 75, 76], "dont": 7, "slimorca_dataset": 7, "privat": 7, "typic": [7, 78], "expos": [7, 8, 74, 76], "parent": 7, "modul": [7, 10, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 66, 67, 76, 77, 78], "__init__": [7, 8, 77, 78], "py": [7, 30, 31, 32, 37, 39, 40, 41, 46, 75], "guarante": 7, "stabil": [7, 72, 78], "underscor": 7, "_alpaca": 7, "collect": [7, 76], "differ": [7, 9, 42, 72, 75, 77, 78], "itself": 7, "via": [7, 9, 48, 77, 78], "pair": [7, 64, 74], "k1": [7, 8], "v1": [7, 8], "k2": [7, 8], "v2": [7, 8], "lora_finetune_single_devic": [7, 75, 76, 77, 78], "checkpoint": [7, 8, 45, 51, 52, 63, 66, 72, 77, 78], "home": 7, "my_model_checkpoint": 7, "file_1": 7, "file_2": 7, "my_tokenizer_path": 7, "class": [7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 37, 38, 39, 40, 41, 42, 43, 44, 47, 48, 49, 50, 51, 52, 53, 60, 61, 62, 63, 74, 76, 77, 78], "assign": 7, "nest": 7, "dot": 7, "notat": [7, 37, 41, 43, 44], "core": [8, 72, 74, 76, 78], "i": [8, 18, 19, 45, 50, 74, 75, 78], "structur": [8, 14, 15, 18, 19, 74, 75], "new": [8, 35, 60, 62, 75, 76, 77, 78], "user": [8, 14, 15, 18, 19, 21, 37, 42, 74, 76], "thought": [8, 72, 76, 78], "target": [8, 72], "pipelin": [8, 72], "llm": [8, 70, 72, 74, 75, 77], "eg": [8, 43, 51, 72], "meaning": [8, 72, 75], "featur": [8, 9, 71, 72, 75, 76], "fsdp": [8, 72, 76], "activ": [8, 38, 66, 72, 78], "gradient": [8, 72, 75, 77, 78], "accumul": [8, 72], "mix": [8, 75], "precis": [8, 45, 55, 72, 76, 78], "appli": [8, 30, 31, 32, 33, 34, 36, 37, 40, 41, 43, 44, 72, 78], "given": [8, 10, 17, 21, 48, 54, 55, 72, 77], "complex": 8, "becom": [8, 71, 74], "harder": 8, "anticip": 8, "architectur": [8, 18, 19, 43, 74], "methodolog": 8, "reason": [8, 75], "possibl": 8, "trade": 8, "off": [8, 42, 75], "memori": [8, 22, 23, 45, 70, 72, 74, 75, 76], "vs": [8, 76], "qualiti": [8, 75, 77], "believ": 8, "best": 8, "suit": [8, 76], "specif": [8, 10, 74, 75, 78], "b": [8, 37, 41, 43, 44, 48, 63, 77, 78], "fit": [8, 22, 23], "solut": 8, "result": [8, 42, 75, 77, 78], "meant": [8, 45], "depend": [8, 9, 13, 75, 77, 78], "level": [8, 56, 72, 78], "expertis": 8, "routin": 8, "yourself": [8, 77], "exist": [8, 74, 75, 76, 78], "ad": [8, 42, 77, 78], "ones": 8, "modular": [8, 72], "build": [8, 72, 77], "block": [8, 30, 31, 32, 34, 72], "wandb": [8, 9, 63, 76], "log": [8, 56, 60, 61, 62, 63, 75, 76, 78], "fulli": 8, "nativ": [8, 70, 72, 77, 78], "pytorch": [8, 43, 45, 62, 65, 67, 70, 71, 72, 77, 78], "correct": [8, 16, 24, 40, 41, 43, 54, 72, 74], "numer": [8, 72], "pariti": [8, 72], "verif": 8, "extens": [8, 72], "comparison": [8, 77, 78], "benchmark": [8, 67, 72, 75, 77], "limit": 8, "hidden": [8, 38], "behind": 8, "100": [8, 22, 23, 24, 25, 26, 64, 65, 77, 78], "flag": [8, 22, 23, 24, 25, 78], "prefer": [8, 72, 74], "over": [8, 46, 53, 72, 74, 75, 77, 78], "unnecessari": 8, "abstract": [8, 14, 17, 72, 76, 78], "No": [8, 72], "inherit": [8, 53, 72], "go": [8, 18, 19, 42, 72, 74, 75, 76, 78], "upon": 8, "figur": [8, 77, 78], "spectrum": 8, "decid": 8, "interact": [8, 70, 76], "start": [8, 9, 71, 72, 74, 75, 76], "paradigm": 8, "consist": [8, 76], "configur": [8, 22, 23, 24, 25, 26, 44, 72, 76, 77, 78], "paramet": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 54, 55, 56, 58, 60, 61, 62, 63, 64, 65, 66, 67, 70, 72, 75, 76, 77, 78], "overrid": [8, 11, 75, 76, 78], "togeth": [8, 63, 76, 77], "valid": [8, 21, 71, 75, 76], "environ": [8, 71, 75, 76], "logic": [8, 51, 72, 76, 77], "api": [8, 9, 33, 36, 75, 76, 78], "closer": [8, 77], "monolith": [8, 72], "trainer": [8, 57], "A": [8, 9, 42, 45, 48, 51, 53, 64, 69, 70, 73, 75, 77, 78], "wrapper": [8, 42, 77], "around": [8, 42, 65, 75, 77, 78], "extern": 8, "primarili": [8, 77], "eleutherai": [8, 72, 77], "har": [8, 72, 77], "control": [8, 22, 23, 24, 25, 67, 75], "multi": [8, 37], "stage": 8, "distil": 8, "oper": [8, 65, 67], "turn": [8, 21], "dataload": [8, 22, 23, 24, 25], "applic": [8, 37, 51, 52, 63], "clean": [8, 9, 22], "after": [8, 39, 40, 60, 61, 62, 63, 78], "process": [8, 9, 45, 67, 76, 78], "group": [8, 37, 60, 61, 62, 63], "init_process_group": [8, 58], "backend": 8, "gloo": 8, "els": [8, 53, 63, 72, 78], "nccl": 8, "fullfinetunerecipedistribut": 8, "cleanup": 8, "other": [8, 10, 53, 74, 76, 77], "stuff": 8, "carri": 8, "relev": [8, 75, 77], "interfac": [8, 14, 17, 47], "metric": [8, 76], "logger": [8, 56, 60, 61, 62, 63, 76], "self": [8, 9, 30, 31, 32, 34, 37, 43, 44, 47, 74, 77, 78], "_devic": 8, "get_devic": 8, "_dtype": 8, "get_dtyp": 8, "ckpt_dict": 8, "wrap": [8, 65, 66], "_model": 8, "_setup_model": 8, "_token": [8, 74], "_setup_token": 8, "_optim": 8, "_setup_optim": 8, "_loss_fn": 8, "_setup_loss": 8, "_sampler": 8, "_dataload": 8, "_setup_data": 8, "backward": [8, 78], "zero_grad": 8, "curr_epoch": 8, "rang": [8, 67], "epochs_run": [8, 9], "total_epoch": [8, 9], "idx": 8, "batch": [8, 22, 23, 24, 25, 37, 39, 41, 42, 43, 44, 64, 72, 74, 76, 77], "enumer": 8, "_autocast": 8, "logit": 8, "label": [8, 22, 23, 26, 64], "total_training_step": 8, "_log_every_n_step": 8, "_metric_logg": 8, "log_dict": [8, 60, 61, 62, 63], "step": [8, 43, 46, 60, 61, 62, 63, 65, 70, 75, 77, 78], "learn": [8, 46, 72, 74, 76, 77, 78], "decor": [8, 11], "recipe_main": [8, 11], "none": [8, 9, 12, 13, 16, 17, 19, 20, 21, 37, 41, 42, 43, 44, 50, 51, 52, 54, 55, 56, 60, 61, 62, 63, 66, 67, 75], "fullfinetunerecip": 8, "direct": 8, "wandblogg": [9, 77, 78], "workspac": 9, "seen": [9, 77, 78], "screenshot": 9, "below": [9, 41, 74, 77, 78], "packag": [9, 62, 63, 71], "pip": [9, 62, 63, 71, 75], "Then": [9, 76], "login": [9, 63, 75], "built": [9, 74, 76, 78], "project": [9, 30, 31, 32, 34, 37, 38, 63, 70, 77, 78], "grab": 9, "tab": 9, "tip": 9, "straggler": 9, "background": 9, "crash": 9, "otherwis": 9, "exit": [9, 71], "resourc": [9, 60, 61, 62, 63], "kill": 9, "ps": 9, "aux": 9, "grep": 9, "awk": 9, "xarg": 9, "click": 9, "sampl": [9, 13, 14, 15, 16, 17, 18, 19, 20, 26, 74, 75], "desir": 9, "suggest": 9, "approach": [9, 74], "full_finetun": 9, "joinpath": 9, "_checkpoint": [9, 75], "_output_dir": [9, 51, 52], "torchtune_model_": 9, "with_suffix": 9, "wandb_at": 9, "artifact": 9, "type": [9, 10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 39, 40, 41, 42, 43, 44, 45, 48, 49, 51, 52, 55, 56, 57, 58, 65, 75, 77, 78], "descript": 9, "whatev": 9, "metadata": 9, "seed_kei": 9, "epochs_kei": 9, "total_epochs_kei": 9, "max_steps_kei": 9, "max_steps_per_epoch": 9, "add_fil": 9, "log_artifact": 9, "field": [10, 17, 22, 23, 24, 25], "omegaconf": 10, "num_lay": [10, 43], "32": [10, 77, 78], "num_head": [10, 37, 39, 41, 43], "num_kv_head": [10, 37, 39], "vocab_s": [10, 42], "must": [10, 22, 23, 24, 25, 26, 47, 53, 78], "return": [10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 37, 40, 41, 42, 43, 44, 46, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 59, 64, 65, 67, 74, 77, 78], "nn": [10, 37, 38, 39, 43, 44, 45, 47, 49, 50, 66, 77, 78], "parsed_yaml": 10, "embed_dim": [10, 37, 41, 44, 77], "valueerror": [10, 19, 21, 26, 37, 43, 51, 52, 55, 67], "callabl": [11, 43], "main": [11, 37, 40, 41, 75], "With": [11, 75, 77, 78], "my_recip": 11, "foo": 11, "bar": [11, 72, 76], "instanti": [12, 27, 28, 29, 30, 31, 32, 34, 35], "configerror": 12, "cannot": 12, "data": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 60, 61, 62, 63, 74, 75, 78], "prompt": [13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 42, 43, 74, 75], "templat": [13, 14, 16, 17, 20, 22, 23, 24, 25, 26], "style": [13, 22, 23, 26, 78], "slightli": 13, "instruct": [13, 15, 17, 19, 22, 23, 70, 76, 77, 78], "classmethod": [13, 14, 15, 16, 17, 18, 19, 20, 42], "map": [13, 16, 17, 20, 50, 51, 60, 61, 62, 63, 75, 77], "column_map": [13, 16, 17, 20, 74], "placehold": [13, 14, 16, 17, 20], "column": [13, 16, 17, 20], "ident": [13, 16, 17, 19, 20, 75], "chat": [14, 15, 18, 26], "role": [14, 42, 74], "system": [14, 15, 18, 19, 21, 42, 74], "assist": [14, 15, 18, 21, 42, 74], "messag": [14, 15, 18, 19, 21, 42, 71, 74], "accord": [14, 19], "openai": 15, "markup": 15, "languag": [15, 48, 77], "It": [15, 19, 74, 78], "huggingfac": [15, 46, 51, 52, 74, 75], "im_start": 15, "context": [15, 65, 74], "im_end": 15, "goe": 15, "respons": [15, 42, 74, 75, 76], "appropri": [15, 18, 19, 46, 74, 78], "tag": [15, 18, 19, 60, 61, 62, 63], "grammar": [16, 24, 74], "sentenc": [16, 42], "alwai": [17, 53], "human": 18, "taken": [18, 77, 78], "inst": [18, 19, 74], "sy": [18, 74], "respect": [18, 50, 74], "honest": [18, 74], "am": [18, 19, 74, 75], "pari": [18, 19, 74], "capit": [18, 19, 74], "franc": [18, 19, 74], "known": [18, 19, 42, 74], "its": [18, 19, 67, 74, 75, 77], "stun": [18, 19, 74], "mistral": [19, 34, 35, 36, 75, 76], "llama2chatformat": [19, 74], "summar": [20, 25, 74], "task": [20, 74, 75, 77, 78], "dialogu": [20, 25], "dialog": 20, "forth": 21, "consecut": 21, "come": [21, 47, 77], "empti": 21, "shorter": 21, "length": [21, 22, 23, 26, 37, 39, 41, 42, 43, 44, 52, 64], "min": [21, 77], "invalid": 21, "yahma": 22, "codebas": [22, 23, 24, 25, 75], "where": [22, 23, 24, 25, 37, 42, 43, 48, 74], "mask": [22, 23, 24, 25, 37, 42, 44, 74], "contribut": [22, 23, 24, 25], "replac": [22, 23, 24, 25, 45, 77], "encod": [22, 23, 24, 25, 26, 42], "decod": [22, 23, 24, 25, 26, 42, 43], "anyth": [22, 23, 24, 25, 26], "load_dataset": [22, 23, 24, 25, 26], "whether": [22, 23, 24, 25, 26, 30, 31, 32, 34, 42, 45, 48, 55], "recommend": [22, 23, 62, 75, 78], "highest": [22, 23], "sequenc": [22, 23, 26, 37, 39, 41, 42, 43, 44, 64], "alpaca_d": [22, 23], "batch_siz": [22, 23, 24, 25, 37, 44, 75], "tatsu": [23, 74], "lab": [23, 74], "liweili": 24, "c4_200m": 24, "variant": [24, 25], "mirror": [24, 25], "llama_recip": [24, 25], "grammar_d": 24, "samsum": 25, "summari": 25, "samsum_d": 25, "open": [26, 27, 74, 75], "orca": [26, 74], "slimorca": [26, 74], "dedup": [26, 74], "1024": [26, 74], "chatdataset": 26, "adher": 26, "doesn": [26, 75], "prescrib": 26, "truncat": [26, 42], "least": [26, 77], "though": 26, "max": [26, 42, 43, 46, 77], "ds": 26, "10": [26, 64, 75, 78], "351": 26, "82": [26, 75], "391": 26, "221": 26, "220": 26, "193": 26, "12": 26, "471": 26, "gemma": 27, "transformerdecod": [27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 77], "w": [27, 28, 29, 35, 62, 63, 75, 77, 78], "http": [27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 40, 41, 46, 51, 52, 53, 56, 62, 63, 65, 67, 71, 75], "blog": 27, "technolog": 27, "develop": [27, 78], "arxiv": [28, 29, 33, 36, 37, 40, 41], "org": [28, 29, 33, 36, 37, 40, 41, 53, 56, 62, 65, 67], "ab": [28, 29, 33, 36, 41], "2307": [28, 29], "09288": [28, 29], "lora_attn_modul": [30, 31, 32, 33, 34, 36, 77, 78], "liter": [30, 31, 32, 33, 34, 36], "q_proj": [30, 31, 32, 33, 34, 36, 37, 77, 78], "k_proj": [30, 31, 32, 33, 34, 36, 37, 77, 78], "v_proj": [30, 31, 32, 33, 34, 36, 37, 77, 78], "output_proj": [30, 31, 32, 33, 34, 36, 37, 77, 78], "apply_lora_to_mlp": [30, 31, 32, 33, 34, 36, 77], "apply_lora_to_output": [30, 31, 32, 33, 34, 36, 77], "lora_rank": [30, 31, 32, 33, 34, 36, 77], "lora_alpha": [30, 31, 32, 33, 34, 36, 77], "float": [30, 31, 32, 33, 34, 36, 37, 40, 46, 48, 60, 61, 62, 63, 77, 78], "16": [30, 31, 32, 33, 34, 36, 77, 78], "quantize_bas": [30, 31, 32, 33, 34, 36, 48, 78], "lora": [30, 31, 32, 33, 34, 36, 48, 70, 72, 76], "com": [30, 31, 32, 37, 40, 41, 46, 71], "tloen": [30, 31, 32], "blob": [30, 31, 32, 37, 40, 41, 46], "8bb8579e403dc78e37fe81ffbb253c413007323f": [30, 31, 32], "l41": [30, 31, 32], "l43": [30, 31, 32], "linear": [30, 31, 32, 33, 34, 36, 43, 47, 48, 77, 78], "attent": [30, 31, 32, 34, 37, 39, 41, 43, 44, 77, 78], "mlp": [30, 31, 32, 34, 43, 44, 77], "final": [30, 31, 32, 34, 38, 43, 75, 77, 78], "rank": [30, 31, 32, 34, 48, 57, 67, 76, 77, 78], "low": [30, 31, 32, 34, 48, 75, 77, 78], "approxim": [30, 31, 32, 34, 48, 77], "scale": [30, 31, 32, 34, 48, 77, 78], "factor": [30, 31, 32, 34, 48, 75], "lora_dropout": [31, 33], "05": [31, 33], "llama2_7b": [31, 77], "qlora": [33, 36, 45, 70, 72, 77], "per": [33, 36, 39, 45, 78], "paper": [33, 36, 77, 78], "2305": [33, 36, 37], "14314": [33, 36], "lora_llama2_7b": [33, 77], "announc": 35, "lora_mistral_7b": 36, "head_dim": [37, 39, 41, 43], "pos_embed": [37, 77], "kv_cach": 37, "kvcach": [37, 43], "attn_dropout": [37, 43], "head": [37, 39, 41, 43], "queri": [37, 39, 43], "gqa": 37, "introduc": [37, 40, 48, 77, 78], "pdf": [37, 40], "13245v1": 37, "version": [37, 71, 78], "multihead": 37, "mha": [37, 43], "n": [37, 42, 69, 73, 74], "extrem": 37, "share": [37, 74, 75], "mqa": 37, "credit": 37, "document": 37, "lightn": 37, "lit": 37, "gpt": [37, 75], "lit_gpt": 37, "v": [37, 43, 77], "k": [37, 77], "q": [37, 77], "n_kv_head": 37, "dimens": [37, 39, 41, 43, 48, 77, 78], "calcul": 37, "e": [37, 45, 47, 50, 71, 75, 77, 78], "g": [37, 47, 77, 78], "rotarypositionalembed": [37, 77], "cach": [37, 39, 41], "comput": [37, 38, 41, 43, 67, 75, 78], "rope": [37, 41], "dropout": [37, 48, 77, 78], "onto": 37, "scaled_dot_product_attent": 37, "input_po": [37, 41, 43, 44], "seq_length": [37, 44], "seq_len": [37, 41], "bigger": 37, "n_h": [37, 41], "num": [37, 41], "n_kv": 37, "kv": [37, 39, 43], "emb": [37, 43, 44], "h_d": [37, 41], "gate_proj": 38, "down_proj": 38, "up_proj": 38, "silu": 38, "feed": [38, 44], "network": [38, 77, 78], "deriv": [38, 43, 44], "fed": 38, "multipli": 38, "subclass": [38, 53], "although": [38, 77], "afterward": 38, "former": 38, "regist": [38, 45, 78], "hook": [38, 45, 78], "latter": 38, "max_batch_s": 39, "standalon": 39, "past": 39, "becaus": [39, 43, 75], "expand": 39, "dpython": [39, 45], "ep": 40, "1e": 40, "06": [40, 77], "root": [40, 62, 63], "squar": 40, "1910": 40, "07467": 40, "verfic": [40, 41], "facebookresearch": [40, 41], "small": [40, 75], "avoid": [40, 45, 67, 78], "divis": 40, "zero": [40, 75], "10000": 41, "rotari": 41, "propos": 41, "2104": 41, "09864": 41, "l450": 41, "upto": 41, "init": [41, 63, 78], "exceed": 41, "freq": 41, "recomput": 41, "geometr": 41, "progress": [41, 76], "rotat": 41, "angl": 41, "bsz": 41, "todo": 41, "made": [41, 75], "effici": [41, 70, 72, 75, 76, 77], "spm_model": 42, "sentencepieceprocessor": 42, "bos_id": 42, "eos_id": 42, "pad_id": 42, "sentencepiec": 42, "vocabulari": 42, "pad": [42, 64], "non": 42, "from_fil": 42, "tokenized_text": 42, "hello": [42, 75], "world": [42, 57, 75], "add_bo": 42, "add_eo": 42, "31587": 42, "29644": 42, "102": 42, "text": [42, 74, 75], "trim_leading_whitespac": 42, "prefix": 42, "unbatch": 42, "prepend": 42, "bo": 42, "append": 42, "eo": 42, "trim": 42, "lead": 42, "whitespac": 42, "underli": [42, 78], "s1": 42, "s2": 42, "due": [42, 77, 78], "tokenize_messag": [42, 74], "concaten": 42, "problem": 42, "slice": 42, "tokenizer_path": 42, "separ": [42, 51, 76, 77, 78], "concat": 42, "1788": 42, "2643": 42, "13": [42, 75, 78], "1792": 42, "9508": 42, "465": 42, "22137": 42, "2933": 42, "join": 42, "attribut": 42, "transformerdecoderlay": 43, "norm": [43, 44], "move": 43, "space": 43, "check": [43, 55, 70, 75, 76, 77], "belong": 43, "reduc": [43, 72, 74, 77, 78], "statement": 43, "improv": [43, 75, 77], "readabl": [43, 75], "At": 43, "arang": 43, "prompt_length": 43, "causal_mask": 43, "m_": 43, "seq": 43, "attn": [44, 77, 78], "causalselfattent": [44, 77], "sa_norm": 44, "mlp_norm": 44, "ff": 44, "common_util": 45, "bfloat16": [45, 75, 76, 77], "offload_to_cpu": 45, "nf4": [45, 78], "restor": 45, "higher": [45, 78], "offload": [45, 78], "increas": [45, 46, 77], "peak": [45, 75, 77, 78], "gpu": [45, 75, 76, 77, 78], "usag": [45, 71, 75, 76, 78], "_register_state_dict_hook": 45, "m": 45, "mymodul": 45, "_after_": 45, "nf4tensor": [45, 78], "unquant": [45, 75, 78], "unus": 45, "num_warmup_step": 46, "num_training_step": 46, "num_cycl": 46, "last_epoch": 46, "lambdalr": 46, "rate": [46, 72, 76], "schedul": [46, 65, 76], "linearli": 46, "lr": 46, "decreas": [46, 77, 78], "cosin": 46, "remain": [46, 77], "v4": 46, "23": 46, "src": 46, "l104": 46, "warmup": [46, 65], "phase": 46, "total": [46, 57, 69, 73, 75, 77], "wave": 46, "half": 46, "index": [46, 64, 75], "last": 46, "lr_schedul": 46, "peft": [47, 48, 49, 50, 77, 78], "protocol": 47, "adapter_param": [47, 48, 49, 50], "correspond": [47, 49, 55, 76], "proj": 47, "in_dim": [47, 48, 77, 78], "out_dim": [47, 48, 77, 78], "bia": [47, 48, 77, 78], "loralinear": [47, 77, 78], "alpha": [48, 77, 78], "use_bia": 48, "larg": [48, 78], "perturb": 48, "decomposit": [48, 77], "matric": [48, 77, 78], "trainabl": [48, 50, 77, 78], "mapsto": 48, "w_0x": 48, "r": [48, 77], "bax": 48, "probabl": [48, 75], "lora_a": [48, 77, 78], "lora_b": [48, 77, 78], "subset": 49, "get_adapter_param": [50, 77], "co": [51, 52, 75], "few": [51, 74, 77, 78], "0001_of_0003": 51, "0002_of_0003": 51, "preserv": [51, 78], "weight_map": [51, 75], "intermediate_checkpoint": [51, 52], "parit": 51, "_weight_map": 51, "shard": 52, "wip": 52, "argpars": 53, "argumentpars": 53, "builtin": 53, "said": 53, "noth": 53, "treat": 53, "still": [53, 77, 78], "consult": 53, "doc": [53, 56, 62, 63, 65, 67, 75], "info": [53, 76], "librari": [53, 56, 67, 70, 72, 78], "html": [53, 56, 62, 65, 67], "parse_known_arg": 53, "namespac": 53, "act": 53, "precid": 53, "parse_arg": 53, "intern": 53, "properti": [53, 77], "too": 53, "availab": 54, "machin": [54, 75], "distribut": [54, 58, 66, 67, 72, 76], "bf16": [55, 78], "request": [55, 74, 75], "inde": [55, 75], "kernel": 55, "runtimeerror": [55, 58], "float32": 55, "done": [55, 77, 78], "isn": 55, "hardwar": [55, 72, 75, 77], "stream": 56, "handler": 56, "aka": 57, "filenam": 60, "log_": 60, "unixtimestamp": 60, "txt": [60, 76], "thread": 60, "safe": 60, "flush": [60, 61, 62, 63], "union": [60, 61, 62, 63, 67], "ndarrai": [60, 61, 62, 63], "scalar": [60, 61, 62, 63], "record": [60, 61, 62, 63], "payload": [60, 61, 62, 63], "dictionari": [60, 61, 62, 63, 75], "organize_log": 62, "tensorboard": 62, "stabl": [62, 65, 67, 71], "subdirectori": 62, "sub": 62, "compar": [62, 75, 77, 78], "logdir": 62, "startup": 62, "recurs": 62, "tree": [62, 74, 75], "tfevent": 62, "encount": 62, "frontend": 62, "organ": 62, "accordingli": 62, "my_log_dir": 62, "view": [62, 75, 76], "my_metr": [62, 63], "termin": [62, 63], "entiti": 63, "bias": 63, "ref": 63, "sent": 63, "usernam": 63, "individu": 63, "my_project": 63, "my_ent": 63, "my_group": 63, "importerror": 63, "account": [63, 77, 78], "log_config": 63, "local": [63, 67, 71, 75, 76], "link": [63, 75], "capecap": 63, "6053ofw0": 63, "torchtune_config_j67sb73v": 63, "padding_idx": 64, "ignore_idx": 64, "longest": 64, "integ": [64, 67], "tokenpair": 64, "collat": 64, "token_pair": 64, "torchtune_perf_trac": 65, "contextmanag": 65, "wait": 65, "trace": 65, "speed": [65, 78], "reduct": [65, 77], "auto_wrap_polici": 66, "polici": 66, "debug_mod": 67, "pseudo": 67, "random": [67, 76], "commonli": [67, 75, 77, 78], "numpi": 67, "own": [67, 74, 75, 77], "determinist": 67, "global": 67, "warn": 67, "nondeterminist": 67, "addition": [67, 77], "cudnn": 67, "disabl": 67, "set_deterministic_debug_mod": 67, "algorithm": 67, "outsid": [67, 75, 77], "generated_examples_python": 68, "zip": 68, "galleri": [68, 73], "sphinx": 68, "000": [69, 73], "execut": [69, 73], "generated_exampl": 69, "mem": [69, 73], "mb": [69, 73], "topic": 70, "gentl": 70, "introduct": 70, "readi": 70, "maxim": [70, 72], "workflow": [70, 74, 76, 77], "requisit": 71, "proper": [71, 76], "host": [71, 76], "page": [71, 72, 76], "latest": [71, 76, 78], "confirm": 71, "And": [71, 75], "h": 71, "ls": [71, 75, 76], "welcom": 71, "show": [71, 77], "greatest": [71, 76], "contributor": 71, "cd": [71, 75], "On": [72, 77], "pointer": 72, "author": [72, 76, 78], "emphas": 72, "aspect": 72, "simplic": 72, "component": 72, "reus": 72, "high": [72, 77], "prove": 72, "democrat": 72, "box": [72, 78], "zoo": 72, "varieti": [72, 77], "techniqu": [72, 75, 76, 77], "integr": [72, 75, 76, 77, 78], "excit": 72, "checkout": 72, "quickstart": 72, "attain": 72, "better": [72, 74, 75], "chekckpoint": 72, "hyperparamet": [72, 76, 77, 78], "embodi": 72, "philosophi": 72, "especi": [72, 75], "usabl": 72, "composit": 72, "hard": 72, "outlin": 72, "unecessari": 72, "never": 72, "thoroughli": 72, "unit": 72, "know": [74, 75, 77], "steer": 74, "wheel": 74, "publicli": 74, "great": [74, 75], "sever": 74, "wide": 74, "bootstrap": 74, "indic": 74, "iter": [74, 78], "knob": 74, "tweak": 74, "sai": [74, 76], "footprint": [74, 77], "could": [74, 77], "achiev": [74, 75, 77, 78], "256": [74, 75], "fix": 74, "goal": 74, "flavor": 74, "agnost": 74, "condit": 74, "respond": 74, "alpacainstructtempl": 74, "describ": 74, "further": [74, 77, 78], "classifi": 74, "anim": 74, "plant": 74, "miner": 74, "oak": 74, "copper": 74, "ore": 74, "eleph": 74, "instructtempl": 74, "instruct_dataset": 74, "mydataset": 74, "onthehub": 74, "customtempl": 74, "similar": [74, 75, 77, 78], "chatformat": 74, "quit": [74, 78], "similarli": 74, "chat_dataset": 74, "conversation_styl": 74, "sharegpt": 74, "chat_format": 74, "formatted_messag": 74, "nyou": 74, "incorpor": 74, "advanc": 74, "preferencedataset": 74, "rlhf": 74, "adjust": 74, "chosen": 74, "reject": 74, "chosen_messag": 74, "transformed_sampl": 74, "key_chosen": 74, "rejected_messag": 74, "key_reject": 74, "chosen_input_id": 74, "c_mask": 74, "chosen_label": 74, "np": 74, "cross_entropy_ignore_idx": 74, "rejected_input_id": 74, "r_mask": 74, "rejected_label": 74, "purpos": [74, 76], "stack_exchanged_paired_dataset": 74, "had": 74, "lvwerra": 74, "stack": 74, "exchang": 74, "stackexchangedpairedtempl": 74, "question": [74, 75], "response_j": 74, "response_k": 74, "data_dir": 74, "rl": 74, "favorit": [75, 77], "commun": 75, "seemlessli": 75, "beyond": [75, 78], "connect": 75, "larger": 75, "might": 75, "amount": 75, "natur": 75, "export": 75, "mobil": 75, "phone": 75, "leverag": [75, 78], "mode": 75, "lot": 75, "plai": 75, "freez": [75, 77], "percentag": 75, "learnabl": 75, "keep": [75, 77], "16gb": [75, 77], "rtx": 75, "3090": 75, "4090": 75, "hour": 75, "full_finetune_single_devic": [75, 76], "7b_full_low_memori": [75, 76], "full_finetune_distribut": [75, 76], "7b_full": [75, 76], "13b_full": [75, 76], "7b_qlora_single_devic": [75, 76, 78], "473": 75, "98": [75, 78], "gb": [75, 77, 78], "50": 75, "484": 75, "01": [75, 76], "fact": [75, 77], "third": 75, "smaller": [75, 77, 78], "But": [75, 77], "realli": 75, "eleuther_ev": 75, "eleuther_evalu": 75, "lm_eval": 75, "plan": 75, "copi": [75, 76, 78], "element": 75, "custom_eval_config": 75, "truthfulqa_mc2": [75, 77], "measur": 75, "propens": 75, "answer": 75, "shot": 75, "accuraci": [75, 77, 78], "baselin": [75, 77], "324": 75, "loglikelihood": 75, "195": 75, "121": 75, "27": 75, "second": [75, 77, 78], "197": 75, "acc": 75, "388": 75, "38": 75, "shown": 75, "489": 75, "48": [75, 78], "seem": 75, "custom_generation_config": 75, "kick": 75, "top_k": 75, "300": 75, "temperatur": 75, "interest": 75, "site": 75, "visit": 75, "bai": 75, "area": 75, "92": 75, "exploratorium": 75, "san": 75, "francisco": 75, "magazin": 75, "awesom": 75, "bridg": 75, "pretti": 75, "cool": 75, "96": [75, 78], "61": 75, "sec": 75, "25": 75, "83": 75, "99": [75, 77], "15": [75, 77, 78], "72": 75, "littl": 75, "saw": 75, "took": 75, "torchao": [75, 78], "bit": [75, 77, 78], "custom_quantization_config": 75, "68": 75, "19": [75, 78], "76": 75, "69": 75, "95": 75, "67": 75, "4w": 75, "unlik": 75, "won": 75, "engin": 75, "fullmodeltorchtunecheckpoint": 75, "int4weightonlyquant": 75, "groupsiz": 75, "did": [75, 78], "park": 75, "sit": 75, "top": [75, 78], "hill": 75, "beauti": 75, "62": 75, "17": [75, 77], "85": 75, "compil": [75, 78], "hood": [75, 78], "sped": 75, "almost": [75, 77], "3x": 75, "benefit": 75, "yet": 75, "fast": 75, "clone": [75, 77, 78], "assumpt": 75, "satisfi": 75, "new_dir": 75, "output_dict": 75, "sd_1": 75, "sd_2": 75, "dump": 75, "convert_hf_checkpoint": 75, "checkpoint_path": 75, "my": 75, "justin": 75, "school": 75, "math": 75, "teacher": 75, "ws": 75, "94": 75, "103": 75, "28": 75, "bandwidth": 75, "1391": 75, "84": 75, "thats": 75, "seamlessli": 75, "authent": [75, 76], "hopefulli": 75, "gave": 75, "launch": 76, "pretrain": [76, 77, 78], "gate": 76, "grant": 76, "minut": 76, "agreement": 76, "altern": 76, "opt": 76, "hackabl": 76, "singularli": 76, "focus": 76, "technic": 76, "depth": 76, "why": [76, 77], "principl": 76, "minim": [76, 77, 78], "boilerpl": 76, "hold": 76, "substanti": [76, 77], "custom_config": 76, "replic": 76, "lorafinetunerecipesingledevic": 76, "lora_finetune_output": 76, "log_1713194212": 76, "sampler": 76, "52": 76, "3697006702423096": 76, "25880": [76, 78], "24": 76, "55": 76, "83it": 76, "were": 76, "monitor": 76, "tqdm": 76, "interv": 76, "e2": 76, "teach": 77, "straight": 77, "jump": 77, "neural": [77, 78], "unfamiliar": 77, "oppos": [77, 78], "momentum": 77, "adamw": 77, "arbitrari": 77, "relat": 77, "aghajanyan": 77, "et": 77, "al": 77, "hypothes": 77, "intrins": 77, "lower": 77, "down": [77, 78], "often": 77, "four": 77, "eight": 77, "practic": 77, "imag": 77, "simplifi": 77, "represent": [77, 78], "left": 77, "blue": 77, "extra": [77, 78], "rememb": 77, "approx": 77, "15m": 77, "8192": 77, "65k": 77, "p": [77, 78], "requires_grad": [77, 78], "frozen_out": [77, 78], "lora_out": [77, 78], "omit": 77, "construct": 77, "base_model": 77, "choos": 77, "lora_model": 77, "lora_llama_2_7b": [77, 78], "alon": 77, "in_featur": 77, "out_featur": 77, "inplac": 77, "feel": 77, "free": 77, "strict": 77, "whenev": 77, "validate_state_dict_for_lora": 77, "peft_util": 77, "set_trainable_param": 77, "fetch": 77, "lora_param": 77, "total_param": 77, "sum": 77, "numel": 77, "trainable_param": 77, "2f": 77, "6742609920": 77, "4194304": 77, "vram": 77, "nnode": 77, "nproc_per_nod": 77, "lora_finetune_distribut": 77, "7b_lora": 77, "my_model_checkpoint_path": [77, 78], "tokenizer_checkpoint": [77, 78], "my_tokenizer_checkpoint_path": [77, 78], "constraint": 77, "factori": 77, "benefici": 77, "long": 77, "impact": 77, "rel": 77, "minor": 77, "good": 77, "64": 77, "lora_experiment_1": 77, "smooth": [77, 78], "curv": [77, 78], "500": 77, "ran": 77, "commod": 77, "cogniz": 77, "ax": 77, "parallel": 77, "truthfulqa": 77, "previous": 77, "57": [77, 78], "475": 77, "87": 77, "508": 77, "128": 77, "86": 77, "504": 77, "04": 77, "514": 77, "lowest": 77, "absolut": 77, "4gb": 77, "coupl": [77, 78], "tradeoff": 77, "even": [77, 78], "potenti": 77, "enhanc": 78, "maintain": 78, "therebi": 78, "highli": 78, "part": 78, "vanilla": 78, "held": 78, "therefor": 78, "intermedi": 78, "bespok": 78, "normalfloat": 78, "8x": 78, "retain": 78, "vast": 78, "major": 78, "highlight": 78, "degrad": 78, "normatfloat": 78, "doubl": 78, "themselv": 78, "prune": 78, "deepdiv": 78, "idea": 78, "distinct": 78, "storag": 78, "datatyp": 78, "de": 78, "incur": 78, "consum": 78, "counterpart": 78, "set_default_devic": 78, "qlora_linear": 78, "memory_alloc": 78, "177": 78, "152": 78, "byte": 78, "del": 78, "empty_cach": 78, "lora_linear": 78, "081": 78, "344": 78, "qlora_llama2_7b": 78, "qlora_model": 78, "essenti": 78, "reparametrize_as_dtype_state_dict_post_hook": 78, "entir": 78, "stat": 78, "alloc": 78, "reserv": 78, "against": 78, "35": 78, "40": 78, "29": 78, "slow": 78, "slower": 78, "149": 78, "9157477021217346": 78, "02": 78, "08": 78, "14": 78, "15it": 78, "thing": 78, "nightli": 78, "200": 78, "hundr": 78, "228": 78, "8158286809921265": 78, "59": 78, "95it": 78, "exercis": 78, "manual": 78, "portion": 78, "augment": 78, "linear_nf4": 78, "to_nf4": 78, "linear_weight": 78, "autograd": 78, "regular": 78, "incom": 78, "variabl": 78}, "objects": {"torchtune.config": [[10, 0, 1, "", "instantiate"], [11, 0, 1, "", "parse"], [12, 0, 1, "", "validate"]], "torchtune.data": [[13, 1, 1, "", "AlpacaInstructTemplate"], [14, 1, 1, "", "ChatFormat"], [15, 1, 1, "", "ChatMLFormat"], [16, 1, 1, "", "GrammarErrorCorrectionTemplate"], [17, 1, 1, "", "InstructTemplate"], [18, 1, 1, "", "Llama2ChatFormat"], [19, 1, 1, "", "MistralChatFormat"], [20, 1, 1, "", "SummarizeTemplate"], [21, 0, 1, "", "validate_messages"]], "torchtune.data.AlpacaInstructTemplate": [[13, 2, 1, "", "format"]], "torchtune.data.ChatFormat": [[14, 2, 1, "", "format"]], "torchtune.data.ChatMLFormat": [[15, 2, 1, "", "format"]], "torchtune.data.GrammarErrorCorrectionTemplate": [[16, 2, 1, "", "format"]], "torchtune.data.InstructTemplate": [[17, 2, 1, "", "format"]], "torchtune.data.Llama2ChatFormat": [[18, 2, 1, "", "format"]], "torchtune.data.MistralChatFormat": [[19, 2, 1, "", "format"], [19, 3, 1, "", "system"]], "torchtune.data.SummarizeTemplate": [[20, 2, 1, "", "format"]], "torchtune.datasets": [[22, 0, 1, "", "alpaca_cleaned_dataset"], [23, 0, 1, "", "alpaca_dataset"], [24, 0, 1, "", "grammar_dataset"], [25, 0, 1, "", "samsum_dataset"], [26, 0, 1, "", "slimorca_dataset"]], "torchtune.models.gemma": [[27, 0, 1, "", "gemma_2b"]], "torchtune.models.llama2": [[28, 0, 1, "", "llama2_13b"], [29, 0, 1, "", "llama2_7b"], [30, 0, 1, "", "lora_llama2_13b"], [31, 0, 1, "", "lora_llama2_7b"], [32, 0, 1, "", "qlora_llama2_13b"], [33, 0, 1, "", "qlora_llama2_7b"]], "torchtune.models.mistral": [[34, 0, 1, "", "lora_mistral_7b"], [35, 0, 1, "", "mistral_7b"], [36, 0, 1, "", "qlora_mistral_7b"]], "torchtune.modules": [[37, 1, 1, "", "CausalSelfAttention"], [38, 1, 1, "", "FeedForward"], [39, 1, 1, "", "KVCache"], [40, 1, 1, "", "RMSNorm"], [41, 1, 1, "", "RotaryPositionalEmbeddings"], [42, 1, 1, "", "Tokenizer"], [43, 1, 1, "", "TransformerDecoder"], [44, 1, 1, "", "TransformerDecoderLayer"], [46, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[37, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[38, 2, 1, "", "forward"]], "torchtune.modules.RMSNorm": [[40, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[41, 2, 1, "", "forward"]], "torchtune.modules.Tokenizer": [[42, 2, 1, "", "decode"], [42, 2, 1, "", "encode"], [42, 2, 1, "", "from_file"], [42, 2, 1, "", "tokenize_messages"]], "torchtune.modules.TransformerDecoder": [[43, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoderLayer": [[44, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[45, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[47, 1, 1, "", "AdapterModule"], [48, 1, 1, "", "LoRALinear"], [49, 0, 1, "", "get_adapter_params"], [50, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[47, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[48, 2, 1, "", "adapter_params"], [48, 2, 1, "", "forward"]], "torchtune.utils": [[51, 1, 1, "", "FullModelHFCheckpointer"], [52, 1, 1, "", "FullModelMetaCheckpointer"], [53, 1, 1, "", "TuneRecipeArgumentParser"], [54, 0, 1, "", "get_device"], [55, 0, 1, "", "get_dtype"], [56, 0, 1, "", "get_logger"], [57, 0, 1, "", "get_world_size_and_rank"], [58, 0, 1, "", "init_distributed"], [59, 0, 1, "", "list_dtypes"], [64, 0, 1, "", "padded_collate"], [65, 0, 1, "", "profiler"], [66, 0, 1, "", "set_activation_checkpointing"], [67, 0, 1, "", "set_seed"]], "torchtune.utils.FullModelHFCheckpointer": [[51, 2, 1, "", "load_checkpoint"], [51, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[52, 2, 1, "", "load_checkpoint"], [52, 2, 1, "", "save_checkpoint"]], "torchtune.utils.TuneRecipeArgumentParser": [[53, 2, 1, "", "parse_known_args"]], "torchtune.utils.metric_logging": [[60, 1, 1, "", "DiskLogger"], [61, 1, 1, "", "StdoutLogger"], [62, 1, 1, "", "TensorBoardLogger"], [63, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[60, 2, 1, "", "close"], [60, 2, 1, "", "log"], [60, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[61, 2, 1, "", "close"], [61, 2, 1, "", "log"], [61, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[62, 2, 1, "", "close"], [62, 2, 1, "", "log"], [62, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[63, 2, 1, "", "close"], [63, 2, 1, "", "log"], [63, 2, 1, "", "log_config"], [63, 2, 1, "", "log_dict"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method", "3": "py:attribute"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 6, 70, 72, 75, 77, 78], "config": [0, 7, 8, 76], "data": [1, 5], "dataset": [2, 74], "model": [3, 4, 9, 75, 76, 77], "llama2": [3, 75, 77, 78], "mistral": 3, "gemma": 3, "modul": 4, "compon": [4, 7], "build": [4, 78], "block": 4, "peft": 4, "util": [4, 5], "checkpoint": [5, 6, 9, 75], "distribut": 5, "reduc": 5, "precis": 5, "memori": [5, 77, 78], "manag": 5, "perform": [5, 77], "profil": [5, 65], "metric": [5, 9], "log": [5, 9], "miscellan": 5, "overview": [6, 72, 75], "format": [6, 74], "handl": 6, "differ": 6, "intermedi": 6, "vs": 6, "final": 6, "lora": [6, 75, 77, 78], "put": [6, 78], "thi": 6, "all": [6, 7, 78], "togeth": [6, 78], "about": 7, "where": 7, "do": 7, "paramet": 7, "live": 7, "write": 7, "configur": [7, 74], "us": [7, 8, 75, 78], "instanti": [7, 10], "referenc": 7, "other": [7, 75], "field": 7, "interpol": 7, "valid": [7, 12], "your": [7, 8, 75, 76], "best": 7, "practic": 7, "airtight": 7, "public": 7, "api": 7, "onli": 7, "command": 7, "line": 7, "overrid": 7, "what": [8, 72, 77, 78], "ar": 8, "recip": [8, 76, 77], "script": 8, "class": 8, "run": [8, 75], "cli": 8, "pars": [8, 11], "weight": 9, "bias": 9, "logger": 9, "w": 9, "b": 9, "alpacainstructtempl": 13, "chatformat": 14, "chatmlformat": 15, "grammarerrorcorrectiontempl": 16, "instructtempl": 17, "llama2chatformat": 18, "mistralchatformat": 19, "summarizetempl": 20, "validate_messag": 21, "alpaca_cleaned_dataset": 22, "alpaca_dataset": 23, "grammar_dataset": 24, "samsum_dataset": 25, "slimorca_dataset": 26, "gemma_2b": 27, "llama2_13b": 28, "llama2_7b": 29, "lora_llama2_13b": 30, "lora_llama2_7b": 31, "qlora_llama2_13b": 32, "qlora_llama2_7b": 33, "lora_mistral_7b": 34, "mistral_7b": 35, "qlora_mistral_7b": 36, "causalselfattent": 37, "todo": [37, 44], "feedforward": 38, "kvcach": 39, "rmsnorm": 40, "rotarypositionalembed": 41, "token": 42, "transformerdecod": 43, "transformerdecoderlay": 44, "reparametrize_as_dtype_state_dict_post_hook": 45, "get_cosine_schedule_with_warmup": 46, "adaptermodul": 47, "loralinear": 48, "get_adapter_param": 49, "set_trainable_param": 50, "fullmodelhfcheckpoint": 51, "fullmodelmetacheckpoint": 52, "tunerecipeargumentpars": 53, "get_devic": 54, "get_dtyp": 55, "get_logg": 56, "get_world_size_and_rank": 57, "init_distribut": 58, "list_dtyp": 59, "disklogg": 60, "stdoutlogg": 61, "tensorboardlogg": 62, "wandblogg": 63, "padded_col": 64, "set_activation_checkpoint": 66, "set_se": 67, "comput": [69, 73], "time": [69, 73], "welcom": 70, "document": 70, "get": 70, "start": 70, "tutori": 70, "instal": 71, "instruct": [71, 74], "via": 71, "pypi": 71, "git": 71, "clone": 71, "kei": 72, "concept": 72, "design": 72, "principl": 72, "fine": [74, 76], "tune": [74, 76], "custom": 74, "templat": 74, "chat": 74, "fulli": 74, "end": 75, "workflow": 75, "download": [75, 76], "7b": 75, "finetun": [75, 77, 78], "evalu": 75, "eleutherai": 75, "s": 75, "eval": 75, "har": 75, "gener": 75, "speed": 75, "up": 75, "quantiz": 75, "librari": 75, "upload": 75, "hug": 75, "face": 75, "hub": 75, "first": 76, "llm": 76, "select": 76, "modifi": 76, "train": 76, "next": 76, "step": 76, "how": 77, "doe": 77, "work": 77, "appli": 77, "trade": 77, "off": 77, "qlora": 78, "save": 78, "deep": 78, "dive": 78, "from": 78}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})