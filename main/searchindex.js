Search.setIndex({"docnames": ["api_ref_config", "api_ref_data", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "deep_dives/checkpointer", "deep_dives/configs", "deep_dives/recipe_deepdive", "deep_dives/wandb_logging", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.config.validate", "generated/torchtune.data.AlpacaInstructTemplate", "generated/torchtune.data.ChatFormat", "generated/torchtune.data.ChatMLFormat", "generated/torchtune.data.GrammarErrorCorrectionTemplate", "generated/torchtune.data.InstructTemplate", "generated/torchtune.data.Llama2ChatFormat", "generated/torchtune.data.Message", "generated/torchtune.data.MistralChatFormat", "generated/torchtune.data.SummarizeTemplate", "generated/torchtune.data.sharegpt_to_llama2_messages", "generated/torchtune.data.validate_messages", "generated/torchtune.datasets.ChatDataset", "generated/torchtune.datasets.ConcatDataset", "generated/torchtune.datasets.InstructDataset", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.chat_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.instruct_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.models.gemma.gemma_2b", "generated/torchtune.models.llama2.llama2_13b", "generated/torchtune.models.llama2.llama2_70b", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2_13b", "generated/torchtune.models.llama2.lora_llama2_70b", "generated/torchtune.models.llama2.lora_llama2_7b", "generated/torchtune.models.llama2.qlora_llama2_13b", "generated/torchtune.models.llama2.qlora_llama2_7b", "generated/torchtune.models.llama3.llama3_70b", "generated/torchtune.models.llama3.llama3_8b", "generated/torchtune.models.llama3.lora_llama3_70b", "generated/torchtune.models.llama3.lora_llama3_8b", "generated/torchtune.models.llama3.qlora_llama3_8b", "generated/torchtune.models.mistral.lora_mistral_7b", "generated/torchtune.models.mistral.mistral_7b", "generated/torchtune.models.mistral.qlora_mistral_7b", "generated/torchtune.models.phi3.lora_phi3_mini", "generated/torchtune.models.phi3.phi3_mini", "generated/torchtune.models.phi3.qlora_phi3_mini", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.modules.tokenizers.SentencePieceTokenizer", "generated/torchtune.modules.tokenizers.TikTokenTokenizer", "generated/torchtune.utils.FSDPPolicyType", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.TuneRecipeArgumentParser", "generated/torchtune.utils.generate", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_dtype", "generated/torchtune.utils.get_full_finetune_fsdp_wrap_policy", "generated/torchtune.utils.get_logger", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.list_dtypes", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.padded_collate", "generated/torchtune.utils.profiler", "generated/torchtune.utils.set_activation_checkpointing", "generated/torchtune.utils.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times", "tutorials/chat", "tutorials/datasets", "tutorials/e2e_flow", "tutorials/first_finetune_tutorial", "tutorials/llama3", "tutorials/lora_finetune", "tutorials/qlora_finetune"], "filenames": ["api_ref_config.rst", "api_ref_data.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "deep_dives/checkpointer.rst", "deep_dives/configs.rst", "deep_dives/recipe_deepdive.rst", "deep_dives/wandb_logging.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.config.validate.rst", "generated/torchtune.data.AlpacaInstructTemplate.rst", "generated/torchtune.data.ChatFormat.rst", "generated/torchtune.data.ChatMLFormat.rst", "generated/torchtune.data.GrammarErrorCorrectionTemplate.rst", "generated/torchtune.data.InstructTemplate.rst", "generated/torchtune.data.Llama2ChatFormat.rst", "generated/torchtune.data.Message.rst", "generated/torchtune.data.MistralChatFormat.rst", "generated/torchtune.data.SummarizeTemplate.rst", "generated/torchtune.data.sharegpt_to_llama2_messages.rst", "generated/torchtune.data.validate_messages.rst", "generated/torchtune.datasets.ChatDataset.rst", "generated/torchtune.datasets.ConcatDataset.rst", "generated/torchtune.datasets.InstructDataset.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.chat_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.instruct_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.models.gemma.gemma_2b.rst", "generated/torchtune.models.llama2.llama2_13b.rst", "generated/torchtune.models.llama2.llama2_70b.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2_13b.rst", "generated/torchtune.models.llama2.lora_llama2_70b.rst", "generated/torchtune.models.llama2.lora_llama2_7b.rst", "generated/torchtune.models.llama2.qlora_llama2_13b.rst", "generated/torchtune.models.llama2.qlora_llama2_7b.rst", "generated/torchtune.models.llama3.llama3_70b.rst", "generated/torchtune.models.llama3.llama3_8b.rst", "generated/torchtune.models.llama3.lora_llama3_70b.rst", "generated/torchtune.models.llama3.lora_llama3_8b.rst", "generated/torchtune.models.llama3.qlora_llama3_8b.rst", "generated/torchtune.models.mistral.lora_mistral_7b.rst", "generated/torchtune.models.mistral.mistral_7b.rst", "generated/torchtune.models.mistral.qlora_mistral_7b.rst", "generated/torchtune.models.phi3.lora_phi3_mini.rst", "generated/torchtune.models.phi3.phi3_mini.rst", "generated/torchtune.models.phi3.qlora_phi3_mini.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.modules.tokenizers.SentencePieceTokenizer.rst", "generated/torchtune.modules.tokenizers.TikTokenTokenizer.rst", "generated/torchtune.utils.FSDPPolicyType.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.generate.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_dtype.rst", "generated/torchtune.utils.get_full_finetune_fsdp_wrap_policy.rst", "generated/torchtune.utils.get_logger.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.list_dtypes.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.padded_collate.rst", "generated/torchtune.utils.profiler.rst", "generated/torchtune.utils.set_activation_checkpointing.rst", "generated/torchtune.utils.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst", "tutorials/chat.rst", "tutorials/datasets.rst", "tutorials/e2e_flow.rst", "tutorials/first_finetune_tutorial.rst", "tutorials/llama3.rst", "tutorials/lora_finetune.rst", "tutorials/qlora_finetune.rst"], "titles": ["torchtune.config", "torchtune.data", "torchtune.datasets", "torchtune.models", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "All About Configs", "What Are Recipes?", "Logging to Weights &amp; Biases", "instantiate", "parse", "validate", "AlpacaInstructTemplate", "ChatFormat", "ChatMLFormat", "GrammarErrorCorrectionTemplate", "InstructTemplate", "Llama2ChatFormat", "Message", "MistralChatFormat", "SummarizeTemplate", "sharegpt_to_llama2_messages", "validate_messages", "ChatDataset", "ConcatDataset", "InstructDataset", "alpaca_cleaned_dataset", "alpaca_dataset", "chat_dataset", "grammar_dataset", "instruct_dataset", "samsum_dataset", "slimorca_dataset", "gemma_2b", "llama2_13b", "llama2_70b", "llama2_7b", "lora_llama2_13b", "lora_llama2_70b", "lora_llama2_7b", "qlora_llama2_13b", "qlora_llama2_7b", "llama3_70b", "llama3_8b", "lora_llama3_70b", "lora_llama3_8b", "qlora_llama3_8b", "lora_mistral_7b", "mistral_7b", "qlora_mistral_7b", "lora_phi3_mini", "phi3_mini", "qlora_phi3_mini", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "SentencePieceTokenizer", "TikTokenTokenizer", "torchtune.utils.FSDPPolicyType", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "generate", "get_device", "get_dtype", "get_full_finetune_fsdp_wrap_policy", "get_logger", "get_world_size_and_rank", "init_distributed", "list_dtypes", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "padded_collate", "profiler", "set_activation_checkpointing", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times", "Fine-tuning Llama3 with Chat Data", "Configuring Datasets for Fine-Tuning", "End-to-End Workflow with torchtune", "Fine-Tune Your First LLM", "Meta Llama3 in torchtune", "Finetuning Llama2 with LoRA", "Finetuning Llama2 with QLoRA"], "terms": {"support": [2, 6, 8, 9, 10, 20, 24, 26, 27, 28, 29, 30, 31, 32, 33, 52, 54, 64, 71, 75, 80, 93, 95, 96, 97, 98, 99, 100, 101], "sever": [2, 96], "wide": [2, 96], "us": [2, 4, 6, 9, 10, 11, 15, 18, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 54, 55, 57, 58, 59, 60, 61, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 81, 82, 83, 84, 88, 91, 92, 93, 96, 98, 99, 100], "help": [2, 6, 18, 59, 70, 72, 91, 92, 93, 95, 96, 97, 98, 99, 101], "quickli": [2, 7, 95, 96], "bootstrap": [2, 96], "your": [2, 5, 9, 10, 24, 83, 84, 91, 92, 93, 95, 96, 99, 100, 101], "fine": [2, 6, 8, 9, 91, 93, 97, 100], "tune": [2, 3, 6, 7, 8, 9, 11, 91, 92, 93, 97, 100, 101], "also": [2, 6, 7, 8, 9, 10, 29, 54, 59, 64, 74, 76, 84, 92, 95, 96, 97, 98, 99, 100, 101], "common": [2, 4, 7, 95, 96, 99, 100], "format": [2, 5, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 31, 33, 70, 71, 95, 97, 98, 99, 100], "like": [2, 6, 7, 8, 9, 24, 92, 95, 96, 97, 98, 100], "chat": [2, 14, 15, 18, 19, 22, 24, 29, 33], "model": [2, 6, 7, 8, 10, 15, 20, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 70, 71, 73, 76, 86, 87, 91, 93, 95, 96, 101], "instruct": [2, 3, 13, 15, 17, 19, 20, 26, 27, 28, 31, 52, 91, 95, 98, 100, 101], "These": [2, 4, 6, 7, 8, 10, 72, 95, 96, 97, 98, 99, 100, 101], "ar": [2, 4, 6, 7, 9, 10, 13, 16, 17, 18, 19, 20, 21, 23, 26, 27, 28, 29, 30, 31, 32, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 59, 64, 69, 70, 71, 73, 75, 92, 93, 95, 96, 97, 98, 99, 100, 101], "especi": [2, 93, 97], "specifi": [2, 6, 7, 8, 10, 29, 54, 69, 73, 76, 84, 87, 95, 96, 97, 98, 99, 101], "from": [2, 3, 6, 7, 8, 9, 10, 13, 16, 17, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 49, 55, 59, 60, 62, 63, 65, 67, 70, 71, 72, 73, 83, 84, 90, 92, 94, 96, 97, 98, 99, 100], "yaml": [2, 7, 8, 10, 11, 29, 31, 72, 84, 93, 95, 97, 98, 99, 100, 101], "config": [2, 6, 9, 10, 11, 12, 29, 31, 54, 70, 72, 84, 93, 95, 96, 97, 99, 100, 101], "represent": [2, 100, 101], "abov": [2, 6, 61, 92, 97, 99, 100, 101], "all": [3, 4, 8, 12, 24, 25, 29, 54, 55, 59, 61, 68, 70, 72, 89, 91, 93, 94, 95, 97, 98, 99, 100], "famili": [3, 8, 27, 28, 33, 93, 99], "download": [3, 6, 89, 92, 95, 99, 100, 101], "meta": [3, 6, 18, 70, 71, 95, 97, 98], "llama": [3, 6, 18, 24, 29, 57, 58, 70, 71, 95, 97, 98, 99, 100], "8b": [3, 44, 45, 46, 51, 95], "hf": [3, 6, 70, 95, 97, 98, 99], "token": [3, 6, 7, 8, 19, 24, 26, 27, 28, 29, 30, 31, 32, 33, 54, 58, 59, 60, 67, 68, 73, 76, 96, 97, 98, 99, 100, 101], "access_token": 3, "pre": [3, 18, 92, 95], "train": [3, 5, 6, 8, 9, 18, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 54, 61, 62, 70, 71, 75, 86, 91, 93, 95, 96, 97, 99, 100, 101], "can": [3, 4, 6, 7, 8, 9, 10, 12, 19, 24, 25, 26, 27, 28, 29, 31, 57, 58, 67, 69, 70, 72, 76, 83, 84, 87, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101], "hug": [3, 6, 24, 26, 27, 28, 29, 30, 31, 32, 33, 62, 93, 96, 98, 99], "face": [3, 6, 24, 26, 27, 28, 29, 30, 31, 32, 33, 62, 93, 96, 98, 99], "hub": [3, 6, 98], "follow": [3, 6, 8, 22, 24, 54, 62, 84, 91, 92, 96, 97, 98, 99, 100, 101], "command": [3, 8, 9, 72, 92, 95, 97, 98, 99, 100, 101], "2": [3, 6, 9, 23, 33, 54, 67, 70, 71, 85, 88, 95, 97, 98, 99, 100], "7b": [3, 6, 26, 27, 28, 31, 37, 40, 42, 48, 49, 70, 71, 95, 98, 99, 100, 101], "mini": [3, 51, 52, 53], "microsoft": [3, 52], "4k": [3, 52], "hf_token": 3, "ignor": [3, 6, 54, 55], "pattern": [3, 68], "ai": [3, 49, 54, 84, 95, 99], "mistralai": 3, "v0": 3, "1": [3, 6, 8, 33, 54, 59, 62, 67, 68, 71, 73, 83, 84, 85, 88, 95, 97, 98, 99, 100, 101], "googl": [3, 34], "2b": [3, 34], "offer": 5, "allow": [5, 25, 83, 101], "seamless": 5, "transit": 5, "between": [5, 6, 70, 97, 99, 100, 101], "interoper": [5, 6, 8, 93, 97, 101], "rest": [5, 95, 101], "ecosystem": [5, 6, 8, 93, 97, 99, 101], "For": [5, 6, 7, 8, 24, 25, 26, 27, 28, 29, 31, 54, 59, 72, 84, 87, 88, 92, 95, 96, 97, 98, 99, 100, 101], "comprehens": 5, "overview": [5, 7, 9, 98, 100, 101], "pleas": [5, 41, 42, 47, 50, 53, 69, 76, 87, 92, 101], "see": [5, 6, 9, 18, 20, 29, 33, 41, 42, 47, 50, 53, 56, 63, 69, 72, 76, 77, 84, 86, 87, 88, 92, 93, 95, 96, 97, 98, 99, 100, 101], "deep": [5, 6, 7, 8, 9, 93, 98, 99], "dive": [5, 6, 7, 8, 9, 93, 98, 99], "enabl": [5, 7, 8, 9, 25, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 64, 86, 88, 99, 100, 101], "work": [5, 6, 8, 72, 93, 97, 99, 101], "set": [5, 6, 7, 8, 9, 26, 27, 28, 30, 31, 32, 33, 58, 59, 66, 69, 74, 76, 87, 88, 93, 95, 96, 97, 98, 99, 100], "consumpt": [5, 25], "dure": [5, 6, 25, 26, 27, 28, 30, 32, 54, 56, 58, 59, 60, 61, 95, 97, 99, 100, 101], "provid": [5, 6, 7, 8, 10, 15, 20, 24, 25, 26, 33, 59, 72, 76, 84, 93, 95, 96, 97, 98, 99], "debug": [5, 6, 7, 8], "finetun": [5, 6, 7, 8, 38, 39, 40, 45, 46, 51, 80, 91, 93, 98, 99], "job": [5, 9, 88, 98], "variou": [5, 17], "dataset": [5, 7, 13, 16, 17, 19, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 93, 98, 99], "walk": [6, 8, 83, 93, 95, 96, 97, 98, 101], "you": [6, 7, 8, 9, 10, 17, 18, 24, 26, 27, 28, 31, 72, 73, 83, 84, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101], "through": [6, 7, 8, 9, 55, 93, 95, 96, 97, 98, 101], "design": [6, 8], "behavior": [6, 95, 96], "associ": [6, 7, 8, 73, 97, 100], "util": [6, 7, 8, 9, 10, 25, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 97, 98, 99, 101], "what": [6, 7, 9, 18, 20, 30, 32, 91, 95, 96, 97, 98, 99], "cover": [6, 7, 8, 9, 95, 97, 101], "how": [6, 7, 8, 9, 69, 87, 91, 95, 96, 97, 98, 99, 101], "we": [6, 7, 8, 9, 26, 27, 28, 31, 54, 56, 58, 59, 64, 67, 70, 71, 73, 75, 93, 95, 96, 97, 98, 99, 100, 101], "them": [6, 7, 24, 25, 26, 31, 33, 55, 61, 67, 95, 96, 97, 100, 101], "scenario": [6, 25], "full": [6, 7, 8, 41, 42, 47, 50, 53, 67, 93, 99, 100], "compos": 6, "compon": [6, 8, 12, 86, 93, 96, 98, 100, 101], "which": [6, 8, 25, 26, 27, 28, 30, 32, 38, 39, 40, 45, 46, 48, 51, 54, 58, 59, 60, 62, 67, 70, 71, 75, 81, 84, 87, 93, 95, 96, 97, 98, 99, 100, 101], "plug": 6, "ani": [6, 7, 8, 10, 11, 12, 13, 16, 17, 21, 22, 24, 26, 29, 31, 61, 65, 66, 67, 70, 71, 73, 88, 95, 96, 97, 98, 99, 100], "recip": [6, 7, 9, 10, 11, 55, 70, 71, 93, 95, 96, 97, 99, 101], "evalu": [6, 8, 91, 93, 98, 100, 101], "gener": [6, 8, 13, 16, 21, 24, 26, 33, 67, 88, 89, 91, 95, 96, 100, 101], "each": [6, 8, 14, 17, 25, 38, 39, 40, 45, 46, 48, 51, 54, 58, 59, 67, 68, 88, 93, 96, 97, 98, 99, 100], "make": [6, 7, 8, 9, 54, 60, 93, 97, 98, 99, 100, 101], "easi": [6, 8, 93, 100], "understand": [6, 7, 8, 91, 93, 95, 96, 100, 101], "extend": [6, 8, 93], "befor": [6, 23, 26, 59, 60, 64, 70, 97], "let": [6, 7, 9, 95, 96, 97, 98, 99, 100, 101], "s": [6, 7, 8, 9, 10, 11, 13, 14, 15, 18, 20, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 38, 39, 40, 45, 46, 48, 51, 54, 56, 58, 59, 60, 61, 63, 65, 68, 69, 70, 71, 74, 76, 83, 86, 87, 93, 95, 96, 98, 100, 101], "defin": [6, 7, 8, 55, 63, 64, 65, 98, 100], "some": [6, 7, 15, 65, 66, 91, 93, 95, 97, 98, 100, 101], "concept": [6, 97, 98], "In": [6, 7, 8, 24, 58, 64, 69, 83, 84, 95, 97, 99, 100, 101], "ll": [6, 7, 8, 68, 73, 93, 95, 96, 97, 98, 99, 101], "talk": 6, "about": [6, 8, 70, 84, 93, 95, 97, 98, 99, 100, 101], "take": [6, 7, 8, 10, 55, 56, 61, 70, 72, 74, 95, 96, 97, 98, 99, 100, 101], "close": [6, 8, 81, 82, 83, 84, 100], "look": [6, 7, 8, 83, 92, 95, 96, 97, 98, 99, 100], "veri": [6, 25, 59, 97], "simpli": [6, 7, 95, 96, 97, 99, 101], "dictat": 6, "state_dict": [6, 61, 70, 71, 100, 101], "store": [6, 25, 81, 84, 100, 101], "file": [6, 7, 8, 9, 10, 11, 67, 68, 70, 71, 72, 81, 84, 86, 90, 93, 94, 95, 96, 97, 98, 99, 100, 101], "disk": [6, 81], "weight": [6, 8, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 54, 61, 63, 64, 70, 71, 84, 91, 95, 97, 98, 99, 100, 101], "string": [6, 24, 26, 27, 28, 29, 30, 31, 32, 33, 63, 67, 68, 74, 75], "kei": [6, 7, 9, 24, 26, 31, 33, 54, 56, 59, 66, 70, 97, 98, 100, 101], "identifi": 6, "state": [6, 8, 61, 65, 66, 70, 71, 97, 99, 100, 101], "dict": [6, 7, 8, 9, 10, 13, 16, 17, 19, 21, 22, 24, 26, 29, 31, 61, 65, 66, 70, 71, 79], "If": [6, 7, 12, 13, 16, 17, 20, 21, 23, 24, 26, 27, 28, 30, 31, 32, 33, 54, 61, 64, 70, 71, 73, 74, 75, 76, 79, 83, 84, 88, 92, 95, 96, 97, 98, 99, 100], "don": [6, 7, 8, 84, 88, 95, 97, 98, 99, 101], "t": [6, 7, 8, 33, 68, 75, 84, 88, 95, 97, 98, 99, 101], "match": [6, 24, 26, 31, 33, 92, 97, 99, 100], "up": [6, 8, 9, 26, 27, 28, 31, 95, 96, 98, 99, 100, 101], "exactli": 6, "those": [6, 100], "definit": [6, 100], "either": [6, 70, 73, 87, 100, 101], "run": [6, 7, 9, 11, 55, 56, 59, 61, 70, 71, 83, 84, 92, 93, 95, 98, 99, 100, 101], "explicit": 6, "error": [6, 7, 23, 70, 88], "load": [6, 8, 24, 25, 26, 70, 71, 72, 83, 95, 97, 99, 100], "rais": [6, 10, 12, 20, 23, 29, 33, 54, 56, 59, 70, 71, 75, 79, 84, 88], "an": [6, 7, 8, 9, 10, 13, 19, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 54, 59, 63, 65, 66, 69, 70, 71, 76, 84, 93, 95, 96, 97, 98, 99, 100, 101], "except": [6, 19, 20, 96], "wors": 6, "silent": [6, 55], "succe": 6, "infer": [6, 18, 24, 54, 56, 58, 59, 60, 91, 95, 97, 98, 99, 101], "expect": [6, 7, 10, 13, 16, 17, 21, 24, 26, 29, 31, 58, 84, 95, 96, 100], "addit": [6, 7, 8, 10, 24, 26, 29, 31, 69, 70, 71, 75, 76, 79, 81, 83, 84, 87, 93, 95, 98, 100], "line": [6, 8, 72, 98, 99], "need": [6, 7, 8, 9, 17, 24, 33, 54, 55, 59, 83, 84, 92, 95, 96, 97, 98, 99, 100, 101], "shape": [6, 54, 56, 58, 59, 60, 64, 73], "valu": [6, 7, 22, 33, 34, 35, 36, 37, 43, 44, 49, 54, 56, 57, 59, 62, 70, 72, 73, 81, 82, 83, 84, 88, 98, 99, 100], "two": [6, 7, 23, 93, 97, 98, 99, 100, 101], "popular": [6, 93, 96, 97], "llama2": [6, 7, 8, 10, 18, 22, 24, 26, 27, 28, 31, 33, 35, 36, 37, 38, 39, 40, 41, 42, 55, 59, 60, 67, 91, 93, 98, 99], "offici": [6, 18, 95, 98, 99], "implement": [6, 8, 24, 26, 27, 28, 29, 30, 31, 32, 33, 55, 57, 58, 62, 63, 64, 70, 83, 93, 100, 101], "when": [6, 7, 8, 11, 19, 25, 59, 61, 62, 73, 76, 83, 97, 99, 100, 101], "websit": 6, "get": [6, 7, 8, 9, 24, 67, 75, 77, 78, 92, 93, 95, 96, 97, 98, 100], "access": [6, 7, 8, 25, 70, 97, 98], "singl": [6, 7, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 25, 54, 70, 71, 95, 96, 97, 98, 99, 100, 101], "pth": [6, 97, 99], "inspect": [6, 97, 100, 101], "content": [6, 19, 22, 24, 67, 95, 96], "easili": [6, 7, 93, 96, 100, 101], "torch": [6, 25, 56, 59, 61, 62, 73, 74, 75, 79, 86, 87, 88, 97, 98, 99, 100, 101], "import": [6, 7, 10, 29, 83, 84, 95, 96, 97, 98, 100, 101], "consolid": [6, 99], "00": [6, 90, 94, 98, 99], "mmap": [6, 97], "true": [6, 7, 19, 26, 27, 28, 29, 30, 32, 41, 42, 47, 50, 53, 61, 67, 68, 69, 70, 71, 76, 79, 83, 95, 96, 97, 99, 100, 101], "weights_onli": 6, "map_loc": [6, 97], "cpu": [6, 8, 61, 75, 92, 97, 101], "tensor": [6, 54, 55, 56, 57, 58, 59, 60, 61, 64, 70, 73, 81, 82, 83, 84, 85, 100, 101], "item": 6, "print": [6, 9, 25, 27, 28, 30, 32, 33, 67, 73, 95, 96, 98, 100, 101], "f": [6, 9, 27, 28, 30, 32, 95, 97, 100, 101], "tok_embed": [6, 59], "size": [6, 8, 10, 27, 28, 30, 32, 54, 56, 57, 58, 59, 60, 78, 93, 96, 97, 98, 99, 100], "32000": [6, 10, 100], "4096": [6, 10, 26, 27, 28, 31, 54, 58, 100], "len": [6, 25, 27, 28, 30, 32, 59], "292": 6, "The": [6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 30, 32, 33, 38, 39, 40, 45, 46, 51, 57, 58, 61, 62, 67, 68, 69, 70, 72, 74, 75, 77, 84, 86, 88, 92, 93, 95, 96, 97, 98, 99, 100, 101], "contain": [6, 19, 25, 54, 56, 58, 59, 60, 63, 65, 66, 67, 68, 70, 71, 72, 83, 85, 95, 97, 99, 100], "includ": [6, 7, 8, 14, 17, 64, 70, 71, 72, 93, 95, 97, 98, 99, 100, 101], "input": [6, 13, 14, 17, 24, 26, 27, 28, 29, 30, 31, 33, 54, 55, 57, 58, 59, 60, 64, 67, 70, 85, 88, 95, 96, 100, 101], "embed": [6, 54, 56, 57, 58, 59, 76, 95, 99], "tabl": [6, 95, 101], "call": [6, 10, 19, 55, 61, 72, 81, 82, 83, 84, 95, 100, 101], "layer": [6, 8, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 54, 59, 60, 64, 69, 76, 93, 99, 100, 101], "have": [6, 7, 10, 54, 56, 63, 72, 76, 83, 86, 92, 95, 96, 97, 98, 99, 100, 101], "dim": [6, 54, 55, 57, 58, 59, 60], "most": [6, 7, 68, 95, 98, 100, 101], "within": [6, 7, 10, 24, 33, 55, 73, 83, 88, 97, 99, 100, 101], "default": [6, 7, 15, 19, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 51, 54, 55, 57, 58, 59, 60, 61, 62, 64, 67, 68, 70, 71, 72, 73, 75, 81, 84, 85, 86, 88, 92, 97, 99, 100, 101], "everi": [6, 8, 55, 83, 92, 101], "repo": [6, 70, 71, 97], "first": [6, 7, 10, 23, 56, 59, 68, 70, 72, 91, 93, 95, 97, 99, 100, 101], "big": [6, 97], "split": [6, 95, 96, 97], "across": [6, 8, 25, 70, 83, 88, 97, 99], "bin": [6, 97], "To": [6, 7, 8, 9, 70, 92, 93, 95, 96, 97, 98, 99, 100, 101], "correctli": [6, 8, 12, 70, 92, 95, 98, 101], "piec": 6, "one": [6, 8, 23, 55, 67, 95, 96, 97, 98, 99, 101], "pytorch_model": [6, 97], "00001": 6, "00002": 6, "embed_token": 6, "241": 6, "Not": 6, "onli": [6, 9, 19, 54, 58, 59, 60, 64, 65, 67, 71, 72, 73, 75, 76, 97, 98, 99, 100, 101], "doe": [6, 20, 24, 52, 63, 70, 72, 95, 97], "fewer": [6, 54], "sinc": [6, 7, 10, 55, 70, 95, 97, 99], "instead": [6, 8, 29, 31, 55, 56, 64, 97, 99, 100], "mismatch": 6, "name": [6, 7, 9, 13, 16, 17, 21, 24, 26, 29, 31, 33, 63, 66, 68, 70, 71, 72, 73, 74, 81, 82, 83, 84, 95, 97, 99], "caus": [6, 67], "try": [6, 7, 95, 97, 98, 99, 101], "same": [6, 7, 38, 39, 40, 45, 46, 51, 54, 56, 60, 67, 72, 76, 84, 95, 97, 99, 100, 101], "As": [6, 7, 8, 9, 64, 93, 97, 99, 101], "re": [6, 7, 68, 93, 95, 97, 98, 99, 100], "care": [6, 55, 70, 97, 99, 100], "end": [6, 8, 19, 25, 68, 91, 93, 95, 99, 100], "number": [6, 8, 24, 26, 27, 28, 29, 31, 33, 54, 56, 59, 62, 70, 71, 73, 78, 88, 98, 100], "just": [6, 13, 93, 95, 96, 98, 99, 100], "save": [6, 8, 9, 61, 70, 71, 76, 84, 91, 95, 97, 99, 100], "less": [6, 33, 97, 98, 99, 101], "prone": 6, "manag": [6, 25, 86, 95], "invari": 6, "accept": [6, 7, 33, 67, 69, 98, 101], "multipl": [6, 7, 8, 19, 24, 25, 64, 81, 82, 83, 84, 96, 98, 99], "sourc": [6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 97], "worri": [6, 95, 98], "explicitli": [6, 63, 93, 100], "convert": [6, 22, 24, 70, 85, 95, 97, 101], "time": [6, 67, 81, 83, 95, 97, 99, 101], "produc": [6, 101], "back": [6, 23, 70, 100, 101], "origin": [6, 27, 28, 61, 64, 95, 96, 97, 99, 100, 101], "form": [6, 7, 8, 23], "One": [6, 97], "advantag": [6, 100], "being": [6, 70, 71, 74, 101], "should": [6, 7, 8, 14, 17, 18, 19, 20, 22, 29, 31, 38, 39, 40, 45, 46, 48, 51, 54, 55, 63, 69, 72, 81, 82, 83, 84, 92, 93, 96, 97, 98, 99, 100, 101], "abl": [6, 8, 96, 97, 98, 99], "post": [6, 101], "tool": [6, 97, 98], "quantiz": [6, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 64, 91, 98, 101], "eval": [6, 91, 93], "without": [6, 7, 9, 92, 93, 95, 96, 97, 100], "code": [6, 8, 59, 89, 93, 96, 98], "chang": [6, 7, 9, 13, 92, 96, 97, 98, 99, 100, 101], "OR": 6, "convers": [6, 14, 15, 18, 20, 22, 23, 24, 29, 33, 70, 93, 95, 96, 97, 99, 100, 101], "script": [6, 9, 97, 98, 99], "wai": [6, 7, 24, 95, 96, 97, 98, 99], "surround": [6, 8, 93], "load_checkpoint": [6, 8, 70, 71], "save_checkpoint": [6, 8, 9, 70, 71], "method": [6, 7, 8, 9, 11, 24, 26, 27, 28, 29, 30, 31, 32, 33, 61, 63, 65, 72, 92, 93, 97, 99, 100, 101], "convertor": 6, "avail": [6, 8, 72, 74, 75, 93, 97, 99, 100], "here": [6, 7, 9, 15, 30, 57, 58, 95, 96, 97, 98, 99, 100, 101], "three": [6, 8, 98], "hfcheckpoint": 6, "read": [6, 70, 71, 93], "write": [6, 8, 70, 71, 81, 95, 96, 98], "compat": [6, 70], "transform": [6, 8, 24, 26, 38, 39, 40, 45, 46, 48, 51, 59, 60, 62, 87, 100], "framework": [6, 8, 93], "mention": [6, 97, 101], "assum": [6, 13, 16, 17, 21, 26, 31, 62, 65, 68, 75, 97, 100], "checkpoint_dir": [6, 7, 70, 71, 97, 99], "necessari": [6, 33, 81, 82, 83, 84, 95, 100], "json": [6, 70, 86, 97], "easiest": [6, 97, 98], "sure": [6, 7, 97, 98, 99, 100, 101], "everyth": [6, 8, 72, 93, 98], "flow": [6, 24, 26, 101], "By": [6, 99, 100, 101], "safetensor": 6, "output": [6, 17, 27, 28, 30, 33, 38, 39, 40, 45, 46, 48, 51, 54, 55, 57, 58, 59, 60, 64, 66, 73, 76, 82, 86, 92, 95, 96, 97, 98, 99, 100, 101], "dir": [6, 84, 92, 97, 98, 99], "output_dir": [6, 7, 70, 71, 86, 97, 99, 100, 101], "argument": [6, 7, 10, 17, 24, 26, 29, 31, 33, 41, 42, 47, 50, 53, 54, 69, 72, 76, 79, 81, 83, 84, 87, 95, 99, 100], "snippet": [6, 96], "explain": 6, "setup": [6, 7, 8, 59, 87, 97, 100, 101], "_component_": [6, 7, 9, 10, 29, 95, 96, 97, 99, 100], "fullmodelhfcheckpoint": [6, 97], "directori": [6, 7, 70, 71, 81, 83, 84, 97, 98, 99], "sort": [6, 70], "id": [6, 24, 26, 27, 28, 29, 31, 33, 67, 68, 70, 73, 85, 95, 97], "so": [6, 7, 70, 72, 92, 93, 95, 97, 98, 99, 100, 101], "order": [6, 8, 70, 83, 84, 98], "matter": [6, 70, 100], "checkpoint_fil": [6, 7, 9, 70, 71, 97, 99, 100, 101], "restart": 6, "previou": [6, 70, 71], "more": [6, 7, 8, 29, 33, 56, 58, 69, 72, 84, 86, 87, 88, 93, 96, 97, 98, 99, 100, 101], "next": [6, 73, 99, 101], "section": [6, 8, 91, 97, 99, 101], "recipe_checkpoint": [6, 70, 71], "null": [6, 7], "usual": [6, 58, 70, 84, 97, 100], "model_typ": [6, 70, 71, 97, 99], "resume_from_checkpoint": [6, 70, 71], "fals": [6, 7, 19, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 54, 64, 67, 68, 70, 71, 86, 95, 96, 97, 99, 100, 101], "requir": [6, 7, 25, 33, 70, 83, 84, 88, 92, 95, 96, 98, 101], "param": [6, 8, 38, 39, 40, 45, 46, 51, 64, 65, 66, 70, 100, 101], "directli": [6, 7, 8, 10, 29, 31, 69, 70, 96, 97, 98, 99, 100, 101], "ensur": [6, 7, 12, 23, 33, 54, 70, 75, 93, 98], "out": [6, 7, 8, 24, 26, 27, 28, 29, 30, 32, 70, 71, 91, 93, 95, 97, 98, 99, 100, 101], "case": [6, 8, 9, 19, 54, 70, 75, 81, 87, 93, 95, 96, 97, 99, 100, 101], "discrep": [6, 70], "along": [6, 99, 100], "detail": [6, 29, 33, 56, 69, 76, 86, 88, 97, 98, 99, 100, 101], "found": [6, 7, 9, 57, 58, 100, 101], "metacheckpoint": 6, "github": [6, 10, 38, 39, 40, 45, 46, 51, 54, 57, 58, 62, 92, 98], "repositori": [6, 18, 97, 98], "fullmodelmetacheckpoint": [6, 99], "torchtunecheckpoint": 6, "perform": [6, 55, 73, 93, 95, 97, 99, 101], "current": [6, 52, 54, 56, 58, 59, 60, 71, 76, 78, 81, 83, 88, 97, 98, 99], "test": [6, 7, 8, 93, 95], "complet": [6, 8, 95, 96, 97, 98, 99], "written": [6, 7, 8, 70, 71, 81, 82, 83, 84, 93], "begin": [6, 67, 68, 95, 99, 101], "partit": [6, 101], "ha": [6, 63, 65, 67, 96, 97, 98, 99, 100, 101], "standard": [6, 82, 93, 95, 97, 99], "key_1": 6, "weight_1": 6, "key_2": 6, "weight_2": 6, "mid": 6, "chekpoint": 6, "middl": [6, 97], "inform": [6, 19, 84, 87, 93, 97, 98, 99], "subsequ": [6, 8], "recipe_st": [6, 70, 71], "pt": [6, 9, 70, 71, 97, 99], "epoch": [6, 8, 9, 62, 70, 71, 95, 97, 98, 99], "optim": [6, 7, 8, 25, 52, 62, 95, 97, 98, 99, 100, 101], "etc": [6, 8, 70, 98], "prevent": 6, "flood": 6, "overwritten": 6, "note": [6, 7, 17, 19, 59, 63, 67, 70, 86, 88, 95, 96, 97, 100, 101], "updat": [6, 7, 8, 56, 92, 95, 97, 98, 99, 100, 101], "hf_model_0001_0": [6, 97], "hf_model_0002_0": [6, 97], "both": [6, 25, 97, 100, 101], "adapt": [6, 63, 64, 65, 66, 70, 71, 95, 97, 100, 101], "merg": [6, 10, 70, 97, 99, 101], "would": [6, 7, 9, 59, 92, 95, 96, 97, 100, 101], "our": [6, 8, 93, 95, 96, 97, 98, 100, 101], "tutori": [6, 87, 93, 95, 96, 97, 98, 99, 100, 101], "primari": [6, 7, 8, 98], "want": [6, 7, 8, 9, 10, 24, 73, 92, 95, 97, 98, 99, 100], "resum": [6, 8, 62, 70, 71, 101], "initi": [6, 8, 11, 25, 34, 35, 36, 37, 43, 44, 49, 79, 98, 100, 101], "frozen": [6, 100, 101], "base": [6, 10, 26, 33, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 58, 62, 64, 66, 70, 72, 76, 81, 91, 95, 97, 98, 99, 100, 101], "well": [6, 7, 8, 93, 96, 97, 99, 101], "learnt": [6, 95, 97], "someth": [6, 8, 9, 95, 97], "NOT": 6, "refer": [6, 7, 8, 57, 58, 93, 100], "adapter_checkpoint": [6, 70, 71], "adapter_0": [6, 97], "now": [6, 67, 95, 96, 97, 98, 99, 100, 101], "knowledg": 6, "creat": [6, 7, 10, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 56, 62, 69, 70, 71, 81, 83, 95, 96, 97, 99, 101], "simpl": [6, 8, 91, 98, 100, 101], "forward": [6, 8, 54, 55, 57, 58, 59, 60, 64, 99, 100, 101], "13b": [6, 35, 38, 41], "modeltyp": [6, 70, 71], "llama2_13b": [6, 38], "right": [6, 70, 97, 99, 100], "pytorch_fil": 6, "00003": 6, "torchtune_sd": 6, "load_state_dict": [6, 100], "successfulli": [6, 98], "vocab": [6, 10, 59, 99], "70": [6, 43], "x": [6, 54, 55, 57, 58, 59, 60, 64, 73, 100, 101], "randint": 6, "0": [6, 8, 38, 39, 40, 41, 42, 54, 59, 62, 64, 67, 73, 83, 84, 85, 88, 90, 94, 95, 97, 98, 99, 100, 101], "no_grad": 6, "6": [6, 57, 85, 97, 101], "3989": 6, "9": [6, 97, 101], "0531": 6, "3": [6, 51, 52, 68, 72, 77, 85, 95, 97, 98, 99, 101], "2375": 6, "5": [6, 62, 85, 86, 97, 98, 99], "2822": 6, "4": [6, 33, 54, 85, 93, 97, 99, 100, 101], "4872": 6, "7469": 6, "8": [6, 27, 28, 30, 32, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 97, 100, 101], "6737": 6, "11": [6, 97, 99, 101], "0023": 6, "8235": 6, "6819": 6, "2424": 6, "0109": 6, "6915": 6, "7": [6, 85], "3618": 6, "1628": 6, "8594": 6, "5857": 6, "1151": 6, "7808": 6, "2322": 6, "8850": 6, "9604": 6, "7624": 6, "6040": 6, "3159": 6, "5849": 6, "8039": 6, "9322": 6, "2010": 6, "6824": 6, "8929": 6, "8465": 6, "3794": 6, "3500": 6, "6145": 6, "5931": 6, "do": [6, 8, 24, 26, 31, 33, 84, 95, 96, 97, 98, 99, 100], "find": [6, 8, 9, 97, 98, 100], "list": [6, 7, 14, 15, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31, 33, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 63, 64, 67, 68, 70, 71, 72, 73, 77, 80, 85, 95, 96, 98, 99], "builder": [6, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 95, 96, 101], "hope": 6, "deeper": [6, 98], "insight": [6, 97], "happi": [6, 97], "thi": [7, 8, 9, 10, 19, 24, 25, 26, 27, 28, 29, 31, 33, 52, 54, 55, 58, 59, 60, 61, 62, 63, 67, 69, 70, 71, 72, 73, 74, 75, 81, 83, 84, 86, 87, 88, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101], "guid": [7, 9, 93, 95, 96, 98, 100], "pars": [7, 10, 68, 72, 95, 98], "effect": 7, "cli": [7, 9, 11, 92, 97, 98], "prerequisit": [7, 95, 96, 97, 98, 99, 100, 101], "Be": [7, 95, 97, 98, 99, 100, 101], "familiar": [7, 95, 97, 98, 99, 100, 101], "torchtun": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 92, 95, 96, 98], "instal": [7, 9, 83, 84, 91, 97, 98, 99, 100, 101], "fundament": 7, "There": [7, 14, 23, 95, 97, 98, 99, 100], "entri": [7, 8, 98], "point": [7, 8, 22, 96, 97, 98, 99, 100, 101], "locat": [7, 99, 100, 101], "thei": [7, 8, 19, 25, 59, 72, 95, 96, 100], "truth": [7, 97, 99], "reproduc": 7, "overridden": [7, 55, 72], "quick": [7, 25], "experiment": 7, "modifi": [7, 8, 9, 61, 93, 97, 99, 100, 101], "serv": [7, 69, 96, 100], "particular": [7, 24, 25, 33, 69, 96, 100, 101], "seed": [7, 8, 9, 88, 98], "shuffl": 7, "devic": [7, 8, 74, 75, 95, 97, 98, 99, 100], "cuda": [7, 74, 75, 92, 97, 101], "dtype": [7, 8, 56, 59, 61, 75, 80, 97, 101], "fp32": [7, 101], "enable_fsdp": 7, "mani": [7, 96, 97], "object": [7, 10, 14, 15, 18, 20, 54, 69, 95, 96], "keyword": [7, 10, 24, 26, 29, 31, 33, 61, 95], "loss": [7, 8, 26, 27, 28, 30, 32, 98, 100, 101], "function": [7, 8, 10, 11, 24, 54, 55, 61, 69, 73, 74, 78, 88, 93, 95, 96, 101], "exampl": [7, 8, 9, 10, 11, 15, 18, 20, 25, 26, 27, 28, 29, 30, 31, 32, 33, 54, 63, 67, 69, 70, 71, 73, 83, 84, 85, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101], "subfield": 7, "dotpath": 7, "wish": 7, "exact": [7, 10, 97], "path": [7, 8, 9, 10, 24, 26, 27, 28, 29, 30, 31, 32, 33, 67, 68, 70, 71, 72, 86, 95, 97, 99, 100], "normal": [7, 24, 57, 59, 60, 67, 95, 96, 100, 101], "python": [7, 68, 72, 77, 84, 88, 89, 97], "alpaca_dataset": [7, 27, 96], "custom": [7, 8, 24, 26, 29, 31, 87, 93, 97, 98, 99, 100], "train_on_input": [7, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 96], "onc": [7, 97, 98, 99, 100, 101], "ve": [7, 56, 68, 95, 96, 97, 99, 100], "instanc": [7, 10, 25, 55, 61, 65, 66, 100], "cfg": [7, 8, 11, 12], "automat": [7, 9, 10, 29, 97, 101], "under": [7, 97, 99, 101], "preced": [7, 10, 96, 99, 100], "actual": [7, 9, 24, 95], "throw": 7, "notic": [7, 95, 96, 100], "miss": [7, 100], "posit": [7, 10, 54, 56, 58, 59, 60, 99], "anoth": [7, 97], "handl": [7, 11, 19, 25, 67, 95, 97, 100, 101], "def": [7, 8, 9, 11, 69, 95, 96, 100, 101], "dictconfig": [7, 8, 10, 11, 12, 84], "arg": [7, 10, 59, 61, 63, 72, 82], "tupl": [7, 10, 25, 33, 56, 61, 67, 68, 69, 72, 78, 85], "kwarg": [7, 10, 61, 63, 72, 79, 81, 82, 83, 84, 87], "str": [7, 10, 13, 16, 17, 19, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 61, 63, 64, 65, 66, 67, 68, 70, 71, 72, 74, 75, 77, 80, 81, 82, 83, 84, 86, 88, 95], "mean": [7, 57, 95, 98, 100], "pass": [7, 10, 24, 25, 26, 29, 31, 54, 55, 61, 69, 75, 76, 79, 83, 84, 87, 95, 100, 101], "add": [7, 9, 24, 68, 72, 96, 97, 99, 100, 101], "d": [7, 19, 54, 56, 59, 60, 68, 95, 96, 100], "llama2_token": [7, 97], "tmp": [7, 95, 98, 99], "option": [7, 8, 13, 16, 17, 21, 24, 26, 29, 31, 33, 38, 39, 40, 45, 46, 48, 51, 54, 58, 59, 60, 61, 67, 68, 70, 71, 73, 74, 75, 77, 81, 84, 86, 88, 92, 93, 97], "bool": [7, 19, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 61, 64, 67, 68, 69, 70, 71, 76, 79, 83, 86, 87, 101], "max_seq_len": [7, 10, 24, 26, 27, 28, 29, 31, 33, 54, 56, 58, 59, 67, 68, 95, 96], "int": [7, 9, 24, 25, 26, 27, 28, 29, 31, 33, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 54, 56, 57, 58, 59, 62, 64, 67, 68, 69, 70, 71, 73, 76, 78, 81, 82, 83, 84, 85, 87, 88, 95, 96, 100, 101], "512": [7, 27, 28, 96, 101], "instructdataset": [7, 27, 28, 30, 31, 32, 96], "alreadi": [7, 79, 92, 97, 100], "overwrit": [7, 92], "duplic": [7, 8, 93], "sometim": 7, "than": [7, 23, 33, 54, 56, 69, 95, 97, 98, 99, 100, 101], "resolv": [7, 98], "alpaca": [7, 13, 27, 28, 38, 39, 40, 45, 46, 51, 96], "metric_logg": [7, 8, 9], "metric_log": [7, 9, 81, 82, 83, 84], "disklogg": 7, "log_dir": [7, 81, 83, 84], "conveni": [7, 8], "verifi": [7, 74, 75, 76, 95, 98, 100], "properli": 7, "experi": [7, 84, 91, 93, 95, 99, 100], "wa": [7, 95, 97, 99, 100, 101], "cp": [7, 92, 95, 97, 98, 99], "7b_lora_single_devic": [7, 97, 98, 100, 101], "my_config": 7, "discuss": [7, 98, 100], "guidelin": 7, "while": [7, 8, 38, 39, 40, 45, 46, 51, 55, 93, 97, 101], "mai": [7, 9, 76, 86, 95, 96, 98, 100], "tempt": 7, "put": [7, 8, 98, 100], "much": [7, 97, 99, 100, 101], "give": [7, 100], "maximum": [7, 24, 26, 27, 28, 29, 31, 33, 54, 56, 58, 59, 68], "flexibl": [7, 25, 96], "switch": 7, "encourag": [7, 100], "clariti": 7, "significantli": 7, "easier": [7, 97, 98], "dont": 7, "slimorca_dataset": 7, "privat": 7, "typic": [7, 101], "expos": [7, 8, 95, 96, 98], "parent": 7, "modul": [7, 10, 33, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 76, 87, 88, 95, 98, 100, 101], "__init__": [7, 8, 100, 101], "py": [7, 10, 38, 39, 40, 45, 46, 51, 54, 56, 57, 58, 62, 97, 99], "guarante": 7, "stabil": [7, 93, 101], "underscor": 7, "_alpaca": 7, "collect": [7, 73, 98], "differ": [7, 9, 24, 25, 26, 67, 93, 95, 97, 99, 100, 101], "itself": 7, "via": [7, 9, 29, 64, 100, 101], "pair": [7, 85, 96], "k1": [7, 8], "v1": [7, 8], "k2": [7, 8], "v2": [7, 8], "lora_finetune_single_devic": [7, 95, 97, 98, 99, 100, 101], "checkpoint": [7, 8, 61, 68, 70, 71, 84, 87, 93, 99, 100, 101], "home": 7, "my_model_checkpoint": 7, "file_1": 7, "file_2": 7, "my_tokenizer_path": 7, "class": [7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 29, 31, 33, 54, 55, 56, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 70, 71, 72, 81, 82, 83, 84, 95, 96, 98, 100, 101], "assign": 7, "nest": 7, "dot": 7, "notat": [7, 54, 58, 59, 60], "core": [8, 93, 96, 98, 101], "i": [8, 18, 20, 61, 66, 68, 73, 96, 97, 99, 101], "structur": [8, 14, 15, 18, 20, 24, 95, 96, 97], "new": [8, 49, 81, 83, 95, 97, 98, 99, 100, 101], "user": [8, 14, 15, 18, 19, 20, 22, 23, 24, 54, 67, 95, 96, 98], "thought": [8, 93, 98, 101], "target": [8, 93], "pipelin": [8, 93], "llm": [8, 91, 93, 96, 97, 100], "eg": [8, 59, 70, 93], "meaning": [8, 93, 97], "featur": [8, 9, 92, 93, 97, 98], "fsdp": [8, 69, 76, 93, 98, 99], "activ": [8, 55, 87, 93, 101], "gradient": [8, 93, 97, 99, 100, 101], "accumul": [8, 93], "mix": [8, 97], "precis": [8, 61, 75, 93, 98, 101], "appli": [8, 24, 26, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 54, 57, 58, 59, 60, 87, 93, 101], "given": [8, 10, 17, 23, 64, 73, 74, 75, 93, 100], "complex": 8, "becom": [8, 92, 96], "harder": 8, "anticip": 8, "architectur": [8, 18, 20, 59, 96], "methodolog": 8, "reason": [8, 73, 97], "possibl": [8, 24, 29, 96], "trade": 8, "off": [8, 67, 97], "memori": [8, 25, 26, 27, 28, 31, 61, 76, 91, 93, 96, 97, 98, 99], "vs": [8, 98], "qualiti": [8, 97, 100], "believ": 8, "best": [8, 95], "suit": [8, 98], "specif": [8, 10, 76, 95, 96, 97, 101], "b": [8, 54, 56, 58, 59, 60, 64, 84, 100, 101], "fit": [8, 24, 26, 27, 28, 31], "solut": 8, "result": [8, 67, 97, 99, 100, 101], "meant": [8, 61], "depend": [8, 9, 13, 97, 100, 101], "level": [8, 77, 93, 101], "expertis": 8, "routin": 8, "yourself": [8, 99, 100], "exist": [8, 92, 96, 97, 98, 99, 101], "ad": [8, 67, 95, 100, 101], "ones": 8, "modular": [8, 93], "build": [8, 29, 31, 93, 99, 100], "block": [8, 38, 39, 40, 45, 46, 48, 51, 93], "wandb": [8, 9, 84, 98], "log": [8, 77, 81, 82, 83, 84, 97, 98, 99, 101], "fulli": [8, 25], "nativ": [8, 91, 93, 100, 101], "pytorch": [8, 59, 61, 69, 83, 86, 87, 88, 91, 92, 93, 99, 100, 101], "correct": [8, 16, 30, 57, 58, 59, 74, 93, 95, 96], "numer": [8, 93], "pariti": [8, 93], "verif": 8, "extens": [8, 93], "comparison": [8, 100, 101], "benchmark": [8, 88, 93, 97, 99, 100], "limit": 8, "hidden": [8, 55], "behind": 8, "100": [8, 26, 27, 28, 30, 32, 33, 73, 85, 86, 100, 101], "flag": [8, 26, 27, 28, 30, 32, 69, 76, 101], "prefer": [8, 93, 96], "over": [8, 62, 72, 93, 96, 97, 99, 100, 101], "unnecessari": 8, "abstract": [8, 14, 17, 93, 98, 101], "No": [8, 93], "inherit": [8, 72, 93], "go": [8, 18, 20, 67, 93, 96, 97, 98, 101], "upon": [8, 25, 99], "figur": [8, 100, 101], "spectrum": 8, "decid": 8, "interact": [8, 91, 98], "start": [8, 9, 25, 68, 92, 93, 95, 96, 97, 98], "paradigm": 8, "consist": [8, 98], "configur": [8, 26, 27, 28, 29, 30, 31, 32, 33, 60, 93, 95, 98, 99, 100, 101], "paramet": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 51, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 79, 81, 82, 83, 84, 85, 86, 87, 88, 91, 93, 95, 96, 97, 98, 99, 100, 101], "overrid": [8, 11, 97, 98, 99, 101], "togeth": [8, 84, 98, 100], "valid": [8, 23, 92, 97, 98], "environ": [8, 92, 97, 98], "logic": [8, 70, 93, 98, 100], "api": [8, 9, 41, 42, 47, 50, 53, 95, 97, 98, 99, 101], "closer": [8, 100], "monolith": [8, 93], "trainer": [8, 78], "A": [8, 9, 22, 25, 61, 64, 67, 68, 69, 70, 72, 85, 90, 91, 94, 95, 97, 100, 101], "wrapper": [8, 67, 68, 100], "around": [8, 24, 67, 68, 86, 95, 97, 100, 101], "extern": 8, "primarili": [8, 25, 100], "eleutherai": [8, 93, 100], "har": [8, 93, 100], "control": [8, 26, 27, 28, 30, 32, 88, 97], "multi": [8, 24, 54, 99], "stage": 8, "distil": 8, "oper": [8, 25, 86, 88], "turn": [8, 19, 23, 24, 68, 95], "dataload": [8, 27, 28, 30, 32], "applic": [8, 54, 70, 71, 84], "clean": [8, 9, 27], "after": [8, 56, 57, 81, 82, 83, 84, 95, 101], "process": [8, 9, 61, 88, 98, 101], "group": [8, 54, 81, 82, 83, 84, 99], "init_process_group": [8, 79], "backend": 8, "gloo": 8, "els": [8, 72, 84, 93, 101], "nccl": 8, "fullfinetunerecipedistribut": 8, "cleanup": 8, "other": [8, 10, 25, 72, 76, 96, 98, 99, 100], "stuff": 8, "carri": 8, "relev": [8, 19, 97, 100], "interfac": [8, 14, 17, 25, 63], "metric": [8, 98], "logger": [8, 77, 81, 82, 83, 84, 98], "self": [8, 9, 38, 39, 40, 45, 46, 48, 51, 54, 59, 60, 63, 96, 100, 101], "_devic": 8, "get_devic": 8, "_dtype": 8, "get_dtyp": 8, "ckpt_dict": 8, "wrap": [8, 69, 76, 86, 87, 95], "_model": 8, "_setup_model": 8, "_token": [8, 96], "_setup_token": 8, "_optim": 8, "_setup_optim": 8, "_loss_fn": 8, "_setup_loss": 8, "_sampler": 8, "_dataload": 8, "_setup_data": 8, "backward": [8, 101], "zero_grad": 8, "curr_epoch": 8, "rang": [8, 88, 99], "epochs_run": [8, 9], "total_epoch": [8, 9], "idx": 8, "batch": [8, 27, 28, 30, 32, 54, 56, 58, 59, 60, 67, 85, 93, 96, 98, 99, 100], "enumer": 8, "_autocast": 8, "logit": [8, 73], "label": [8, 24, 26, 27, 28, 29, 31, 33, 85], "global_step": 8, "_log_every_n_step": 8, "_metric_logg": 8, "log_dict": [8, 81, 82, 83, 84], "step": [8, 59, 62, 68, 81, 82, 83, 84, 86, 91, 97, 100, 101], "learn": [8, 25, 62, 93, 95, 96, 98, 99, 100, 101], "decor": [8, 11], "recipe_main": [8, 11], "none": [8, 9, 12, 13, 16, 17, 20, 21, 23, 24, 26, 29, 31, 54, 56, 58, 59, 60, 66, 67, 68, 70, 71, 73, 74, 75, 77, 81, 82, 83, 84, 87, 88, 95, 97], "fullfinetunerecip": 8, "direct": [8, 92], "wandblogg": [9, 100, 101], "workspac": 9, "seen": [9, 100, 101], "screenshot": 9, "below": [9, 58, 69, 96, 99, 100, 101], "packag": [9, 83, 84, 92], "pip": [9, 83, 84, 92, 97, 99], "Then": [9, 98], "login": [9, 84, 97], "built": [9, 92, 95, 96, 98, 101], "project": [9, 38, 39, 40, 45, 46, 48, 51, 54, 55, 76, 84, 91, 100, 101], "grab": [9, 99], "tab": 9, "tip": 9, "straggler": 9, "background": 9, "crash": 9, "otherwis": [9, 95], "exit": [9, 92], "resourc": [9, 81, 82, 83, 84], "kill": 9, "ps": 9, "aux": 9, "grep": 9, "awk": 9, "xarg": 9, "click": 9, "sampl": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 31, 33, 73, 95, 96, 97], "desir": [9, 24, 95], "suggest": 9, "approach": [9, 25, 96], "full_finetun": 9, "joinpath": 9, "_checkpoint": [9, 97], "_output_dir": [9, 70, 71], "torchtune_model_": 9, "with_suffix": 9, "wandb_at": 9, "artifact": 9, "type": [9, 10, 11, 19, 22, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 51, 52, 54, 56, 57, 58, 59, 60, 61, 64, 65, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79, 86, 87, 97, 100, 101], "descript": [9, 29, 33], "whatev": 9, "metadata": 9, "seed_kei": 9, "epochs_kei": 9, "total_epochs_kei": 9, "max_steps_kei": 9, "max_steps_per_epoch": 9, "add_fil": 9, "log_artifact": 9, "field": [10, 17, 19, 22, 24, 27, 28, 30, 32], "hydra": 10, "facebook": 10, "research": 10, "http": [10, 24, 26, 29, 31, 34, 35, 36, 37, 38, 39, 40, 41, 42, 45, 46, 47, 49, 50, 51, 52, 53, 54, 57, 58, 62, 69, 70, 71, 72, 77, 83, 84, 86, 87, 88, 92, 97], "com": [10, 38, 39, 40, 45, 46, 51, 54, 57, 58, 62, 92], "facebookresearch": [10, 57, 58], "blob": [10, 38, 39, 40, 45, 46, 51, 54, 57, 58, 62], "main": [10, 11, 54, 57, 58, 92, 97, 99], "_intern": 10, "_instantiate2": 10, "l148": 10, "omegaconf": 10, "num_lay": [10, 59], "32": [10, 99, 100, 101], "num_head": [10, 54, 56, 58, 59], "num_kv_head": [10, 54, 56], "vocab_s": 10, "must": [10, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 63, 68, 72, 101], "return": [10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 51, 52, 54, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 85, 86, 88, 95, 96, 100, 101], "nn": [10, 54, 55, 56, 59, 60, 61, 63, 65, 66, 69, 87, 100, 101], "parsed_yaml": 10, "embed_dim": [10, 54, 58, 60, 100], "valueerror": [10, 20, 23, 29, 33, 54, 56, 59, 70, 71, 75, 88], "callabl": [11, 24, 26, 59, 69, 73, 76, 87], "With": [11, 97, 100, 101], "my_recip": 11, "foo": 11, "bar": [11, 93, 98], "instanti": [12, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 46, 48, 49, 51, 52], "configerror": 12, "cannot": [12, 99], "data": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 81, 82, 83, 84, 96, 97, 101], "prompt": [13, 14, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 59, 67, 73, 96, 97, 99], "templat": [13, 14, 16, 17, 21, 24, 26, 27, 28, 30, 31, 32, 33], "style": [13, 27, 28, 29, 33, 101], "slightli": 13, "classmethod": [13, 14, 15, 16, 17, 18, 19, 20, 21], "map": [13, 16, 17, 21, 22, 24, 25, 26, 31, 33, 66, 70, 81, 82, 83, 84, 95, 97, 100], "column_map": [13, 16, 17, 21, 24, 26, 31, 33, 96], "placehold": [13, 14, 16, 17, 21, 24, 26, 31, 33], "column": [13, 16, 17, 21, 24, 26, 31, 33, 95], "ident": [13, 16, 17, 20, 21, 26, 31, 97], "role": [14, 19, 22, 24, 67, 95, 96], "system": [14, 15, 18, 19, 20, 22, 23, 24, 67, 95, 96], "assist": [14, 15, 18, 19, 22, 23, 24, 67, 73, 95, 96], "messag": [14, 15, 18, 20, 22, 23, 24, 29, 67, 68, 92, 95, 96], "accord": [14, 20, 95], "openai": 15, "markup": 15, "languag": [15, 64, 73, 100], "It": [15, 20, 95, 96, 101], "huggingfac": [15, 24, 26, 29, 31, 52, 62, 70, 71, 96, 97], "im_start": 15, "context": [15, 52, 86, 96], "im_end": 15, "goe": 15, "respons": [15, 67, 96, 97, 98, 99], "appropri": [15, 18, 20, 25, 62, 96, 101], "tag": [15, 18, 20, 24, 68, 81, 82, 83, 84, 95], "grammar": [16, 30, 96], "sentenc": 16, "alwai": [17, 72], "human": [18, 22, 95], "taken": [18, 100, 101], "inst": [18, 20, 24, 95, 96], "sy": [18, 95, 96], "respect": [18, 25, 66, 95, 96], "honest": [18, 95, 96], "am": [18, 20, 95, 96, 97, 99], "pari": [18, 20, 96], "capit": [18, 20, 96], "franc": [18, 20, 96], "known": [18, 20, 67, 96], "its": [18, 20, 88, 96, 97, 99, 100], "stun": [18, 20, 96], "liter": [19, 38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53], "mask": [19, 26, 27, 28, 30, 32, 54, 60, 67, 68, 95, 96], "ipython": 19, "eot": 19, "dataclass": [19, 95], "repres": [19, 95], "individu": [19, 84, 87, 95, 96], "tiktoken": [19, 68, 99], "special": [19, 24, 68], "variabl": [19, 24, 25, 26, 31, 33, 101], "writer": 19, "whether": [19, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 38, 39, 40, 45, 46, 48, 51, 61, 64, 67, 68, 69, 75, 95], "correspond": [19, 63, 65, 75, 98, 99], "consecut": [19, 23], "from_dict": [19, 95], "construct": [19, 100], "dictionari": [19, 81, 82, 83, 84, 97], "mistral": [20, 24, 48, 49, 50, 95, 97, 98], "llama2chatformat": [20, 33, 95, 96], "summar": [21, 32, 95, 96], "task": [21, 25, 95, 96, 97, 99, 100, 101], "dialogu": [21, 32, 95], "dialog": 21, "adher": [22, 33], "sharegpt": [22, 29, 96], "gpt": [22, 54, 97], "remain": [22, 62, 100], "unmask": 22, "forth": 23, "come": [23, 63, 100], "empti": 23, "shorter": 23, "length": [23, 25, 26, 27, 28, 31, 33, 52, 54, 56, 58, 59, 60, 67, 68, 71, 85], "min": [23, 100], "invalid": 23, "convert_to_messag": [24, 95], "chat_format": [24, 29, 33, 95, 96], "chatformat": [24, 29, 33, 96], "load_dataset_kwarg": [24, 26, 29, 31], "multiturn": [24, 95], "foreach": 24, "prepar": [24, 95], "truncat": [24, 26, 31, 33, 67, 68], "encod": [24, 26, 27, 28, 29, 30, 31, 32, 33, 67, 68, 95], "decod": [24, 26, 27, 28, 29, 30, 31, 32, 33, 59, 67, 68, 73, 95], "anyth": [24, 26, 27, 28, 29, 30, 31, 32, 33], "load_dataset": [24, 26, 27, 28, 29, 30, 31, 32, 33, 95], "co": [24, 26, 29, 31, 52, 70, 71, 97], "doc": [24, 26, 29, 31, 69, 72, 77, 83, 84, 86, 88, 97], "en": [24, 26, 29, 31], "package_refer": [24, 26, 29, 31], "loading_method": [24, 26, 29, 31], "text": [24, 67, 68, 95, 96, 97], "extra": [24, 92, 100, 101], "still": [24, 72, 100, 101], "llama3": [24, 43, 44, 45, 46, 47, 73, 76, 91], "where": [24, 25, 27, 28, 30, 32, 54, 59, 64, 67, 96], "unless": 24, "check": [24, 29, 59, 75, 91, 95, 97, 98, 100], "concaten": [25, 67, 96], "sub": [25, 83], "unifi": 25, "were": [25, 95, 98], "simplifi": [25, 100], "simultan": 25, "intern": [25, 72], "aggreg": 25, "transpar": 25, "index": [25, 62, 85, 92, 95, 97], "howev": [25, 92], "constitu": 25, "might": [25, 97], "larg": [25, 64, 101], "comput": [25, 54, 55, 58, 59, 88, 97, 101], "cumul": 25, "maintain": [25, 101], "indic": [25, 69, 95, 96], "deleg": 25, "retriev": [25, 76], "lead": [25, 67], "high": [25, 93, 100], "scale": [25, 38, 39, 40, 45, 46, 48, 51, 64, 73, 100, 101], "consid": 25, "strategi": 25, "stream": [25, 77], "demand": 25, "deriv": [25, 55, 59, 60], "_dataset": 25, "_len": 25, "total": [25, 62, 78, 90, 94, 97, 99, 100], "combin": [25, 96], "_index": 25, "lookup": 25, "dataset1": 25, "mycustomdataset": 25, "params1": 25, "dataset2": 25, "params2": 25, "concat_dataset": 25, "data_point": 25, "1500": 25, "element": [25, 68, 97], "focus": [25, 98], "enhanc": [25, 101], "divers": 25, "machin": [25, 74, 97], "instructtempl": [26, 96], "contribut": [26, 27, 28, 30, 32], "replac": [26, 27, 28, 30, 32, 61, 100], "disabl": [26, 31, 88], "recommend": [26, 27, 28, 31, 83, 95, 97, 101], "highest": [26, 27, 28, 31], "sequenc": [26, 27, 28, 31, 33, 54, 56, 58, 59, 60, 67, 68, 85, 95], "yahma": 27, "codebas": [27, 28, 30, 32, 97], "alpaca_d": [27, 28], "batch_siz": [27, 28, 30, 32, 54, 56, 59, 60, 97], "tatsu": [28, 96], "lab": [28, 96], "conversation_styl": [29, 96], "chatdataset": [29, 33, 95], "made": [29, 31, 58, 97], "friendli": [29, 31, 73, 95], "huggingfaceh4": 29, "no_robot": 29, "chatmlformat": 29, "2096": 29, "accomplish": 29, "liweili": 30, "c4_200m": 30, "variant": [30, 32], "mirror": [30, 32], "llama_recip": [30, 32], "grammar_d": 30, "samsum": [32, 96], "summari": [32, 96], "samsum_d": 32, "_util": 33, "open": [33, 34, 96, 97], "orca": [33, 96], "slimorca": [33, 96], "dedup": [33, 96], "_chat_format": 33, "1024": [33, 96], "doesn": [33, 97], "prescrib": 33, "least": [33, 99, 100], "though": [33, 95], "max": [33, 59, 62, 67, 100], "ds": 33, "10": [33, 85, 97, 99, 101], "351": 33, "82": [33, 97], "391": 33, "221": 33, "220": 33, "193": 33, "12": [33, 92], "471": 33, "gemma": 34, "gemmatransformerdecod": 34, "w": [34, 35, 36, 37, 43, 44, 49, 83, 84, 95, 97, 100, 101], "blog": 34, "technolog": 34, "develop": [34, 101], "transformerdecod": [35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 73, 100], "arxiv": [35, 36, 37, 41, 42, 47, 50, 53, 54, 57, 58], "org": [35, 36, 37, 41, 42, 47, 50, 53, 54, 57, 58, 69, 72, 77, 83, 86, 87, 88, 92], "ab": [35, 36, 37, 41, 42, 47, 50, 53, 58], "2307": [35, 36, 37], "09288": [35, 36, 37], "70b": [36, 39, 43, 45, 99], "lora_attn_modul": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 100, 101], "q_proj": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 54, 100, 101], "k_proj": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 54, 100, 101], "v_proj": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 54, 100, 101], "output_proj": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 54, 100, 101], "apply_lora_to_mlp": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 100], "apply_lora_to_output": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 100], "lora_rank": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 100], "lora_alpha": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 100], "float": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 54, 57, 62, 64, 73, 81, 82, 83, 84, 100, 101], "16": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 100, 101], "lora_dropout": [38, 39, 40, 41, 42], "05": [38, 39, 40, 41, 42], "quantize_bas": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 64, 101], "lora": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 64, 91, 93, 95, 98, 99], "tloen": [38, 39, 40, 45, 46, 51], "8bb8579e403dc78e37fe81ffbb253c413007323f": [38, 39, 40, 45, 46, 51], "l41": [38, 39, 40, 45, 46, 51], "l43": [38, 39, 40, 45, 46, 51], "linear": [38, 39, 40, 41, 42, 45, 46, 47, 48, 50, 51, 53, 59, 63, 64, 100, 101], "attent": [38, 39, 40, 45, 46, 48, 51, 52, 54, 56, 58, 59, 60, 99, 100, 101], "mlp": [38, 39, 40, 45, 46, 48, 51, 59, 60, 99, 100], "final": [38, 39, 40, 45, 46, 48, 51, 55, 59, 68, 97, 99, 100, 101], "rank": [38, 39, 40, 45, 46, 48, 51, 64, 78, 88, 98, 100, 101], "low": [38, 39, 40, 45, 46, 48, 51, 64, 97, 100, 101], "approxim": [38, 39, 40, 45, 46, 48, 51, 64, 100], "factor": [38, 39, 40, 45, 46, 48, 51, 64, 97], "llama2_70b": 39, "llama2_7b": [40, 100], "qlora": [41, 42, 47, 50, 53, 61, 91, 93, 99, 100], "per": [41, 42, 47, 50, 53, 56, 61, 99, 101], "paper": [41, 42, 47, 50, 53, 100, 101], "2305": [41, 42, 47, 50, 53, 54], "14314": [41, 42, 47, 50, 53], "lora_llama2_13b": 41, "lora_llama2_7b": [42, 100], "llama3_70b": 45, "llama3_8b": [46, 73, 99], "lora_llama3_8b": 47, "announc": 49, "lora_mistral_7b": 50, "phi3": [51, 52, 53], "phi3_mini": 51, "ref": [52, 84], "phi": 52, "128k": 52, "nor": 52, "slide": 52, "window": 52, "lora_phi3_mini": 53, "head_dim": [54, 56, 58, 59], "pos_embed": [54, 100], "kv_cach": 54, "kvcach": [54, 59], "attn_dropout": [54, 59], "head": [54, 56, 58, 59, 99], "queri": [54, 56, 59, 99], "gqa": 54, "introduc": [54, 57, 64, 95, 100, 101], "pdf": [54, 57], "13245v1": 54, "version": [54, 73, 92, 99, 101], "multihead": 54, "mha": [54, 59], "n": [54, 67, 68, 90, 94, 95, 96], "extrem": 54, "share": [54, 96, 97], "mqa": 54, "credit": 54, "document": [54, 69, 76], "lightn": 54, "lit": 54, "lit_gpt": 54, "v": [54, 59, 100], "k": [54, 100], "q": [54, 100], "n_kv_head": 54, "dimens": [54, 56, 58, 59, 64, 99, 100, 101], "calcul": [54, 59, 99], "e": [54, 61, 63, 66, 92, 97, 99, 100, 101], "g": [54, 63, 99, 100, 101], "rotarypositionalembed": [54, 100], "cach": [54, 56, 58, 59, 92], "rope": [54, 58], "dropout": [54, 64, 100, 101], "onto": 54, "scaled_dot_product_attent": 54, "input_po": [54, 56, 58, 59, 60], "seq_length": [54, 60, 73], "seq_len": [54, 58], "bigger": 54, "n_h": [54, 58], "num": [54, 58], "n_kv": 54, "kv": [54, 56, 59], "emb": [54, 59, 60], "h_d": [54, 58], "gate_proj": 55, "down_proj": 55, "up_proj": 55, "silu": 55, "feed": [55, 60], "network": [55, 100, 101], "fed": [55, 95], "multipli": 55, "subclass": [55, 72], "although": [55, 100], "afterward": 55, "former": 55, "regist": [55, 61, 101], "hook": [55, 61, 101], "latter": 55, "standalon": 56, "past": 56, "becaus": [56, 59, 95, 97, 99], "expand": 56, "dpython": [56, 59, 61], "reset": [56, 59], "zero": [56, 57, 97, 99], "k_val": 56, "v_val": 56, "h": [56, 92], "longer": 56, "ep": 57, "1e": 57, "06": [57, 100], "root": [57, 83, 84], "squar": 57, "1910": 57, "07467": 57, "verfic": [57, 58], "small": [57, 97], "avoid": [57, 61, 88, 101], "divis": 57, "10000": 58, "rotari": [58, 99], "propos": 58, "2104": 58, "09864": 58, "l450": 58, "upto": 58, "init": [58, 84, 101], "exceed": 58, "freq": 58, "recomput": 58, "geometr": 58, "progress": [58, 98], "rotat": 58, "angl": 58, "bsz": [58, 73], "todo": 58, "effici": [58, 76, 91, 93, 97, 98, 100], "transformerdecoderlay": 59, "norm": [59, 60], "move": 59, "space": 59, "belong": 59, "reduc": [59, 93, 96, 100, 101], "statement": 59, "improv": [59, 76, 97, 99, 100], "readabl": [59, 97], "At": 59, "arang": 59, "prompt_length": 59, "causal_mask": 59, "m_": 59, "seq": 59, "reset_cach": 59, "setup_cach": 59, "attn": [60, 100, 101], "causalselfattent": [60, 100], "sa_norm": 60, "mlp_norm": 60, "ff": 60, "common_util": 61, "bfloat16": [61, 97, 98, 99, 100], "offload_to_cpu": 61, "nf4": [61, 101], "restor": 61, "higher": [61, 99, 101], "offload": [61, 101], "increas": [61, 62, 99, 100], "peak": [61, 97, 99, 100, 101], "gpu": [61, 97, 98, 99, 100, 101], "usag": [61, 92, 97, 98, 99, 101], "_register_state_dict_hook": 61, "m": [61, 68, 73, 95], "mymodul": 61, "_after_": 61, "nf4tensor": [61, 101], "unquant": [61, 97, 101], "unus": 61, "num_warmup_step": 62, "num_training_step": 62, "num_cycl": 62, "last_epoch": 62, "lambdalr": 62, "rate": [62, 93, 98], "schedul": [62, 86, 98], "linearli": 62, "lr": 62, "decreas": [62, 100, 101], "cosin": 62, "v4": 62, "23": [62, 99], "src": 62, "l104": 62, "warmup": [62, 86], "phase": 62, "wave": 62, "half": 62, "last": 62, "lr_schedul": 62, "peft": [63, 64, 65, 66, 100, 101], "protocol": 63, "adapter_param": [63, 64, 65, 66], "proj": 63, "in_dim": [63, 64, 100, 101], "out_dim": [63, 64, 100, 101], "bia": [63, 64, 100, 101], "loralinear": [63, 100, 101], "alpha": [64, 100, 101], "use_bia": 64, "perturb": 64, "decomposit": [64, 100], "matric": [64, 100, 101], "trainabl": [64, 66, 100, 101], "mapsto": 64, "w_0x": 64, "r": [64, 68, 100], "bax": 64, "probabl": [64, 73, 97], "lora_a": [64, 100, 101], "lora_b": [64, 100, 101], "subset": 65, "get_adapter_param": [66, 100], "sentencepieceprocessor": 67, "pretrain": [67, 68, 95, 98, 100, 101], "non": 67, "spm_model": [67, 95], "tokenized_text": 67, "hello": [67, 95, 97, 99], "world": [67, 78, 97], "add_bo": [67, 68, 95], "add_eo": [67, 68, 95], "31587": 67, "29644": 67, "102": 67, "trim_leading_whitespac": 67, "prefix": 67, "unbatch": 67, "prepend": [67, 68], "bo": [67, 68, 95], "append": [67, 92], "eo": [67, 68, 95], "trim": 67, "whitespac": 67, "underli": [67, 101], "sentencepiec": [67, 99], "s1": 67, "s2": 67, "due": [67, 100, 101], "tokenize_messag": [67, 68, 95, 96], "problem": 67, "slice": 67, "tokenizer_path": 67, "separ": [67, 70, 95, 98, 99, 100, 101], "concat": 67, "1788": 67, "2643": 67, "13": [67, 97, 99, 101], "1792": 67, "9508": 67, "465": 67, "22137": 67, "2933": 67, "join": 67, "attribut": 67, "llama3_tiktoken": 68, "p": [68, 69, 100, 101], "l": 68, "all_special_token": 68, "bos_token": 68, "begin_of_text": [68, 95], "eos_token": 68, "end_of_text": 68, "start_header_id": [68, 95], "end_header_id": [68, 95], "step_id": 68, "eom_id": 68, "eot_id": [68, 95], "python_tag": 68, "identif": 68, "regex": 68, "second": [68, 97, 99, 100, 101], "uniqu": 68, "256": [68, 96, 97, 99], "header": [68, 95], "token_id": 68, "truncate_at_eo": 68, "tokenize_head": 68, "datatyp": [69, 101], "polici": [69, 76, 87], "denot": 69, "boolean": 69, "integ": [69, 85, 88], "auto_wrap_polici": [69, 76, 87], "submodul": 69, "obei": 69, "contract": 69, "get_fsdp_polici": 69, "modules_to_wrap": [69, 76], "min_num_param": 69, "my_fsdp_polici": 69, "recurs": [69, 83], "isinst": 69, "sum": [69, 100], "numel": [69, 100], "1000": 69, "functool": 69, "partial": 69, "stabl": [69, 83, 86, 88, 92], "html": [69, 72, 77, 83, 86, 87, 88], "alia": 69, "few": [70, 96, 99, 100, 101], "0001_of_0003": 70, "0002_of_0003": 70, "preserv": [70, 101], "weight_map": [70, 97], "intermediate_checkpoint": [70, 71], "parit": 70, "_weight_map": 70, "shard": [71, 99], "wip": 71, "argpars": 72, "argumentpars": 72, "builtin": 72, "said": 72, "noth": 72, "treat": [72, 95], "consult": 72, "info": [72, 98], "librari": [72, 77, 88, 91, 93, 101], "parse_known_arg": 72, "namespac": 72, "act": 72, "precid": 72, "parse_arg": 72, "properti": [72, 100], "too": [72, 99], "max_generated_token": 73, "pad_id": 73, "temperatur": [73, 97], "top_k": [73, 97], "stop_token": 73, "custom_generate_next_token": 73, "condit": [73, 96], "pad": [73, 85], "predict": 73, "prune": [73, 101], "stop": 73, "compil": [73, 97, 99, 101], "generate_next_token": 73, "llama3_token": [73, 99], "hi": [73, 95], "my": [73, 95, 97, 99], "jeremi": 73, "availab": 74, "distribut": [74, 79, 87, 88, 93, 98, 99], "bf16": [75, 101], "request": [75, 96, 97], "inde": [75, 97], "kernel": 75, "runtimeerror": [75, 79], "float32": 75, "done": [75, 100, 101], "isn": 75, "hardwar": [75, 93, 97, 100], "memory_efficient_fsdp_wrap": 76, "maxim": [76, 91, 93], "been": [76, 99], "workload": 76, "15": [76, 95, 97, 100, 101], "alongsid": 76, "ac": 76, "fullyshardeddataparallel": 76, "const": 76, "fsdppolicytyp": 76, "handler": 77, "aka": 78, "filenam": 81, "log_": 81, "unixtimestamp": 81, "txt": [81, 98], "thread": 81, "safe": 81, "flush": [81, 82, 83, 84], "union": [81, 82, 83, 84, 87, 88], "ndarrai": [81, 82, 83, 84], "scalar": [81, 82, 83, 84], "record": [81, 82, 83, 84], "payload": [81, 82, 83, 84], "organize_log": 83, "tensorboard": 83, "subdirectori": 83, "compar": [83, 97, 100, 101], "logdir": 83, "startup": 83, "tree": [83, 96, 97], "tfevent": 83, "encount": 83, "frontend": 83, "organ": 83, "accordingli": 83, "my_log_dir": 83, "view": [83, 97, 98], "my_metr": [83, 84], "termin": [83, 84], "entiti": 84, "bias": 84, "sent": 84, "usernam": 84, "my_project": 84, "my_ent": 84, "my_group": 84, "importerror": 84, "account": [84, 100, 101], "log_config": 84, "local": [84, 88, 92, 95, 97, 98], "link": [84, 97], "capecap": 84, "6053ofw0": 84, "torchtune_config_j67sb73v": 84, "padding_idx": 85, "ignore_idx": 85, "longest": 85, "tokenpair": 85, "collat": 85, "token_pair": 85, "torchtune_perf_trac": 86, "contextmanag": 86, "wait": 86, "trace": 86, "speed": [86, 99, 101], "reduct": [86, 100], "acwrappolicytyp": 87, "describ": [87, 96], "author": [87, 93, 98, 101], "intermedi": [87, 99, 101], "fsdp_adavnced_tutori": 87, "debug_mod": 88, "pseudo": 88, "random": [88, 98], "commonli": [88, 97, 100, 101], "numpi": 88, "own": [88, 95, 96, 97, 100], "determinist": 88, "global": 88, "warn": 88, "nondeterminist": 88, "addition": [88, 100], "cudnn": 88, "set_deterministic_debug_mod": 88, "algorithm": 88, "outsid": [88, 97, 99, 100], "generated_examples_python": 89, "zip": 89, "galleri": [89, 94], "sphinx": 89, "000": [90, 94, 99], "execut": [90, 94], "generated_exampl": 90, "mem": [90, 94], "mb": [90, 94], "topic": 91, "gentl": 91, "introduct": 91, "readi": [91, 95], "workflow": [91, 96, 98, 100], "requisit": 92, "proper": [92, 98], "host": [92, 98], "page": [92, 93, 98, 99], "latest": [92, 98, 101], "confirm": 92, "And": [92, 97, 99], "ls": [92, 97, 98, 99], "welcom": 92, "show": [92, 95, 100], "greatest": [92, 98], "contributor": 92, "cd": [92, 97], "even": [92, 95, 99, 100, 101], "commit": 92, "branch": 92, "url": 92, "whl": 92, "therebi": [92, 101], "forc": 92, "reinstal": 92, "opt": [92, 98], "suffix": 92, "cu121": 92, "On": [93, 100], "pointer": 93, "emphas": 93, "aspect": 93, "simplic": 93, "component": 93, "reus": 93, "prove": 93, "democrat": 93, "box": [93, 101], "zoo": 93, "varieti": [93, 100], "techniqu": [93, 97, 98, 100], "integr": [93, 97, 98, 99, 100, 101], "excit": 93, "checkout": 93, "quickstart": 93, "attain": 93, "better": [93, 95, 96, 97], "chekckpoint": 93, "hyperparamet": [93, 98, 100, 101], "embodi": 93, "philosophi": 93, "usabl": 93, "composit": 93, "hard": 93, "outlin": 93, "unecessari": 93, "never": 93, "thoroughli": 93, "unit": 93, "know": [95, 96, 97, 99, 100], "align": 95, "intend": 95, "nice": 95, "meet": 95, "overhaul": 95, "entir": [95, 101], "sai": [95, 96, 98], "accompani": 95, "who": 95, "influenti": 95, "hip": 95, "hop": 95, "artist": [95, 99], "2pac": 95, "rakim": 95, "c": 95, "na": 95, "flavor": [95, 96], "certain": 95, "msg": 95, "formatted_messag": [95, 96], "nyou": [95, 96], "nwho": 95, "sentencepiecetoken": 95, "why": [95, 98, 100], "user_messag": 95, "518": 95, "25580": 95, "29962": 95, "3532": 95, "14816": 95, "29903": 95, "6778": 95, "piece_to_id": 95, "reserv": [95, 101], "vector": 95, "place": 95, "manual": [95, 101], "529": 95, "29879": 95, "29958": 95, "tiktokentoken": 95, "nhere": 95, "_encode_special_token": 95, "128000": 95, "128009": 95, "part": [95, 101], "pure": 95, "That": 95, "won": [95, 97, 99], "mess": 95, "govern": 95, "prime": 95, "strictli": 95, "summarizetempl": [95, 96], "lightweight": 95, "ask": 95, "untouch": 95, "nsummari": 95, "long": [95, 100], "robust": 95, "enough": 95, "csv": 95, "question": [95, 96, 97, 99], "answer": [95, 97, 99], "onlin": 95, "forum": 95, "panda": 95, "pd": 95, "df": 95, "read_csv": 95, "your_fil": 95, "nrow": 95, "tolist": 95, "row": 95, "iloc": 95, "gp": 95, "receiv": 95, "commun": [95, 97], "satellit": 95, "thing": [95, 101], "message_convert": 95, "input_msg": 95, "output_msg": 95, "assistant_messag": 95, "But": [95, 97, 99, 100], "mistralchatformat": 95, "custom_dataset": 95, "2048": 95, "data_fil": 95, "honor": 95, "copi": [95, 97, 98, 99, 101], "8b_lora_single_devic": [95, 99], "launch": [95, 98], "custom_8b_lora_single_devic": 95, "steer": 96, "wheel": 96, "publicli": 96, "great": [96, 97], "iter": [96, 101], "knob": 96, "tweak": 96, "footprint": [96, 100], "could": [96, 100], "achiev": [96, 97, 99, 100, 101], "concatdataset": 96, "instruct_dataset": 96, "vicgal": 96, "gpt4": 96, "alpacainstructtempl": 96, "demonstr": 96, "fix": 96, "goal": 96, "agnost": 96, "respond": 96, "further": [96, 100, 101], "classifi": 96, "anim": 96, "plant": 96, "miner": 96, "oak": 96, "copper": 96, "ore": 96, "eleph": 96, "mydataset": 96, "onthehub": 96, "customtempl": 96, "similar": [96, 97, 99, 100, 101], "quit": [96, 101], "similarli": 96, "chat_dataset": 96, "incorpor": 96, "advanc": 96, "preferencedataset": 96, "rlhf": 96, "adjust": 96, "chosen": 96, "reject": 96, "chosen_messag": 96, "transformed_sampl": 96, "key_chosen": 96, "rejected_messag": 96, "key_reject": 96, "chosen_input_id": 96, "c_mask": 96, "chosen_label": 96, "np": 96, "cross_entropy_ignore_idx": 96, "rejected_input_id": 96, "r_mask": 96, "rejected_label": 96, "purpos": [96, 98, 99], "stack_exchanged_paired_dataset": 96, "had": 96, "lvwerra": 96, "stack": 96, "exchang": 96, "stackexchangedpairedtempl": 96, "response_j": 96, "response_k": 96, "data_dir": 96, "rl": 96, "favorit": [97, 99, 100], "seemlessli": 97, "beyond": [97, 101], "connect": 97, "larger": [97, 99], "amount": 97, "natur": 97, "export": 97, "mobil": 97, "phone": 97, "leverag": [97, 99, 101], "mode": 97, "lot": 97, "plai": 97, "freez": [97, 100], "percentag": 97, "learnabl": 97, "keep": [97, 100], "16gb": [97, 100], "rtx": 97, "3090": 97, "4090": 97, "hour": 97, "full_finetune_single_devic": [97, 98], "7b_full_low_memori": [97, 98], "full_finetune_distribut": [97, 98], "7b_full": [97, 98], "13b_full": [97, 98], "7b_qlora_single_devic": [97, 98, 101], "473": 97, "98": [97, 101], "gb": [97, 99, 100, 101], "50": 97, "484": 97, "01": [97, 98], "fact": [97, 99, 100], "third": 97, "smaller": [97, 99, 100, 101], "realli": 97, "eleuther_ev": [97, 99], "eleuther_evalu": [97, 99], "lm_eval": [97, 99], "plan": 97, "custom_eval_config": [97, 99], "truthfulqa_mc2": [97, 99, 100], "measur": [97, 99], "propens": [97, 99], "shot": [97, 99], "accuraci": [97, 99, 100, 101], "baselin": [97, 100], "324": 97, "loglikelihood": 97, "195": 97, "121": 97, "27": 97, "197": 97, "acc": 97, "388": 97, "38": 97, "shown": 97, "489": 97, "48": [97, 101], "seem": 97, "custom_generation_config": [97, 99], "kick": 97, "300": 97, "interest": 97, "site": 97, "visit": 97, "bai": 97, "area": 97, "92": [97, 99], "exploratorium": 97, "san": 97, "francisco": 97, "magazin": 97, "awesom": 97, "bridg": 97, "pretti": 97, "cool": 97, "96": [97, 101], "61": 97, "sec": [97, 99], "25": 97, "83": 97, "99": [97, 100], "72": 97, "littl": 97, "saw": 97, "took": [97, 99], "torchao": [97, 99, 101], "bit": [97, 99, 100, 101], "custom_quantization_config": [97, 99], "68": 97, "19": [97, 99, 101], "76": 97, "69": 97, "95": [97, 99], "67": 97, "4w": [97, 99], "unlik": [97, 99], "engin": [97, 99], "fullmodeltorchtunecheckpoint": [97, 99], "int4weightonlyquant": [97, 99], "groupsiz": [97, 99], "did": [97, 99, 101], "park": 97, "sit": 97, "top": [97, 101], "hill": 97, "beauti": 97, "62": [97, 99], "17": [97, 100], "85": 97, "hood": [97, 101], "sped": 97, "almost": [97, 99, 100], "3x": [97, 99], "benefit": 97, "yet": 97, "fast": 97, "clone": [97, 100, 101], "assumpt": 97, "satisfi": 97, "new_dir": 97, "output_dict": 97, "sd_1": 97, "sd_2": 97, "dump": 97, "convert_hf_checkpoint": 97, "checkpoint_path": 97, "justin": 97, "school": 97, "math": 97, "teacher": 97, "ws": 97, "94": [97, 99], "103": 97, "28": 97, "bandwidth": [97, 99], "1391": 97, "84": 97, "thats": 97, "seamlessli": 97, "authent": [97, 98], "hopefulli": 97, "gave": 97, "gate": 98, "grant": 98, "minut": 98, "agreement": 98, "altern": 98, "hackabl": 98, "singularli": 98, "technic": 98, "depth": 98, "principl": 98, "minim": [98, 100, 101], "boilerpl": 98, "hold": 98, "substanti": [98, 100], "custom_config": 98, "replic": 98, "lorafinetunerecipesingledevic": 98, "lora_finetune_output": 98, "log_1713194212": 98, "sampler": 98, "52": 98, "3697006702423096": 98, "25880": [98, 101], "24": [98, 99], "55": 98, "83it": 98, "monitor": 98, "tqdm": 98, "interv": 98, "e2": 98, "releas": 99, "focu": 99, "128": [99, 100], "theta": 99, "gain": 99, "illustr": 99, "basic": 99, "observ": 99, "18": 99, "consum": [99, 101], "vram": [99, 100], "overal": 99, "nproc_per_nod": [99, 100], "lora_finetune_distribut": [99, 100], "8b_lora": 99, "8b_qlora_single_devic": 99, "alloc": [99, 101], "coupl": [99, 100, 101], "122": 99, "sarah": 99, "busi": 99, "mum": 99, "young": 99, "children": 99, "live": 99, "north": 99, "east": 99, "england": 99, "135": 99, "88": 99, "138": 99, "346": 99, "09": 99, "139": 99, "31": 99, "far": 99, "drill": 99, "90": 99, "93": 99, "91": 99, "104": 99, "four": [99, 100], "again": 99, "jake": 99, "disciplin": 99, "passion": 99, "draw": 99, "paint": 99, "57": [99, 100, 101], "speedup": 99, "broader": 99, "teach": 100, "straight": 100, "jump": 100, "neural": [100, 101], "unfamiliar": 100, "oppos": [100, 101], "momentum": 100, "adamw": 100, "arbitrari": 100, "relat": 100, "aghajanyan": 100, "et": 100, "al": 100, "hypothes": 100, "intrins": 100, "lower": 100, "down": [100, 101], "often": 100, "eight": 100, "practic": 100, "imag": 100, "left": 100, "blue": 100, "rememb": 100, "approx": 100, "15m": 100, "8192": 100, "65k": 100, "requires_grad": [100, 101], "frozen_out": [100, 101], "lora_out": [100, 101], "omit": 100, "base_model": 100, "choos": 100, "lora_model": 100, "lora_llama_2_7b": [100, 101], "alon": 100, "in_featur": 100, "out_featur": 100, "inplac": 100, "feel": 100, "free": 100, "strict": 100, "whenev": 100, "validate_state_dict_for_lora": 100, "peft_util": 100, "set_trainable_param": 100, "fetch": 100, "lora_param": 100, "total_param": 100, "trainable_param": 100, "2f": 100, "6742609920": 100, "4194304": 100, "nnode": 100, "7b_lora": 100, "my_model_checkpoint_path": [100, 101], "tokenizer_checkpoint": [100, 101], "my_tokenizer_checkpoint_path": [100, 101], "constraint": 100, "factori": 100, "benefici": 100, "impact": 100, "rel": 100, "minor": 100, "good": 100, "64": 100, "lora_experiment_1": 100, "smooth": [100, 101], "curv": [100, 101], "500": 100, "ran": 100, "commod": 100, "cogniz": 100, "ax": 100, "parallel": 100, "truthfulqa": 100, "previous": 100, "475": 100, "87": 100, "508": 100, "86": 100, "504": 100, "04": 100, "514": 100, "lowest": 100, "absolut": 100, "4gb": 100, "tradeoff": 100, "potenti": 100, "highli": 101, "vanilla": 101, "held": 101, "therefor": 101, "bespok": 101, "normalfloat": 101, "8x": 101, "retain": 101, "vast": 101, "major": 101, "highlight": 101, "degrad": 101, "normatfloat": 101, "doubl": 101, "themselv": 101, "deepdiv": 101, "idea": 101, "distinct": 101, "storag": 101, "de": 101, "incur": 101, "counterpart": 101, "set_default_devic": 101, "qlora_linear": 101, "memory_alloc": 101, "177": 101, "152": 101, "byte": 101, "del": 101, "empty_cach": 101, "lora_linear": 101, "081": 101, "344": 101, "qlora_llama2_7b": 101, "qlora_model": 101, "essenti": 101, "reparametrize_as_dtype_state_dict_post_hook": 101, "stat": 101, "against": 101, "35": 101, "40": 101, "29": 101, "slow": 101, "slower": 101, "149": 101, "9157477021217346": 101, "02": 101, "08": 101, "14": 101, "15it": 101, "nightli": 101, "200": 101, "hundr": 101, "228": 101, "8158286809921265": 101, "59": 101, "95it": 101, "exercis": 101, "portion": 101, "augment": 101, "linear_nf4": 101, "to_nf4": 101, "linear_weight": 101, "autograd": 101, "regular": 101, "incom": 101}, "objects": {"torchtune.config": [[10, 0, 1, "", "instantiate"], [11, 0, 1, "", "parse"], [12, 0, 1, "", "validate"]], "torchtune.data": [[13, 1, 1, "", "AlpacaInstructTemplate"], [14, 1, 1, "", "ChatFormat"], [15, 1, 1, "", "ChatMLFormat"], [16, 1, 1, "", "GrammarErrorCorrectionTemplate"], [17, 1, 1, "", "InstructTemplate"], [18, 1, 1, "", "Llama2ChatFormat"], [19, 1, 1, "", "Message"], [20, 1, 1, "", "MistralChatFormat"], [21, 1, 1, "", "SummarizeTemplate"], [22, 0, 1, "", "sharegpt_to_llama2_messages"], [23, 0, 1, "", "validate_messages"]], "torchtune.data.AlpacaInstructTemplate": [[13, 2, 1, "", "format"]], "torchtune.data.ChatFormat": [[14, 2, 1, "", "format"]], "torchtune.data.ChatMLFormat": [[15, 2, 1, "", "format"]], "torchtune.data.GrammarErrorCorrectionTemplate": [[16, 2, 1, "", "format"]], "torchtune.data.InstructTemplate": [[17, 2, 1, "", "format"]], "torchtune.data.Llama2ChatFormat": [[18, 2, 1, "", "format"]], "torchtune.data.Message": [[19, 2, 1, "", "from_dict"]], "torchtune.data.MistralChatFormat": [[20, 2, 1, "", "format"], [20, 3, 1, "", "system"]], "torchtune.data.SummarizeTemplate": [[21, 2, 1, "", "format"]], "torchtune.datasets": [[24, 1, 1, "", "ChatDataset"], [25, 1, 1, "", "ConcatDataset"], [26, 1, 1, "", "InstructDataset"], [27, 0, 1, "", "alpaca_cleaned_dataset"], [28, 0, 1, "", "alpaca_dataset"], [29, 0, 1, "", "chat_dataset"], [30, 0, 1, "", "grammar_dataset"], [31, 0, 1, "", "instruct_dataset"], [32, 0, 1, "", "samsum_dataset"], [33, 0, 1, "", "slimorca_dataset"]], "torchtune.models.gemma": [[34, 0, 1, "", "gemma_2b"]], "torchtune.models.llama2": [[35, 0, 1, "", "llama2_13b"], [36, 0, 1, "", "llama2_70b"], [37, 0, 1, "", "llama2_7b"], [38, 0, 1, "", "lora_llama2_13b"], [39, 0, 1, "", "lora_llama2_70b"], [40, 0, 1, "", "lora_llama2_7b"], [41, 0, 1, "", "qlora_llama2_13b"], [42, 0, 1, "", "qlora_llama2_7b"]], "torchtune.models.llama3": [[43, 0, 1, "", "llama3_70b"], [44, 0, 1, "", "llama3_8b"], [45, 0, 1, "", "lora_llama3_70b"], [46, 0, 1, "", "lora_llama3_8b"], [47, 0, 1, "", "qlora_llama3_8b"]], "torchtune.models.mistral": [[48, 0, 1, "", "lora_mistral_7b"], [49, 0, 1, "", "mistral_7b"], [50, 0, 1, "", "qlora_mistral_7b"]], "torchtune.models.phi3": [[51, 0, 1, "", "lora_phi3_mini"], [52, 0, 1, "", "phi3_mini"], [53, 0, 1, "", "qlora_phi3_mini"]], "torchtune.modules": [[54, 1, 1, "", "CausalSelfAttention"], [55, 1, 1, "", "FeedForward"], [56, 1, 1, "", "KVCache"], [57, 1, 1, "", "RMSNorm"], [58, 1, 1, "", "RotaryPositionalEmbeddings"], [59, 1, 1, "", "TransformerDecoder"], [60, 1, 1, "", "TransformerDecoderLayer"], [62, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[54, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[55, 2, 1, "", "forward"]], "torchtune.modules.KVCache": [[56, 2, 1, "", "reset"], [56, 2, 1, "", "update"]], "torchtune.modules.RMSNorm": [[57, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[58, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoder": [[59, 2, 1, "", "forward"], [59, 2, 1, "", "reset_caches"], [59, 2, 1, "", "setup_caches"]], "torchtune.modules.TransformerDecoderLayer": [[60, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[61, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[63, 1, 1, "", "AdapterModule"], [64, 1, 1, "", "LoRALinear"], [65, 0, 1, "", "get_adapter_params"], [66, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[63, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[64, 2, 1, "", "adapter_params"], [64, 2, 1, "", "forward"]], "torchtune.modules.tokenizers": [[67, 1, 1, "", "SentencePieceTokenizer"], [68, 1, 1, "", "TikTokenTokenizer"]], "torchtune.modules.tokenizers.SentencePieceTokenizer": [[67, 2, 1, "", "decode"], [67, 2, 1, "", "encode"], [67, 2, 1, "", "tokenize_messages"]], "torchtune.modules.tokenizers.TikTokenTokenizer": [[68, 2, 1, "", "decode"], [68, 2, 1, "", "encode"], [68, 2, 1, "", "tokenize_message"], [68, 2, 1, "", "tokenize_messages"]], "torchtune.utils": [[69, 4, 1, "", "FSDPPolicyType"], [70, 1, 1, "", "FullModelHFCheckpointer"], [71, 1, 1, "", "FullModelMetaCheckpointer"], [72, 1, 1, "", "TuneRecipeArgumentParser"], [73, 0, 1, "", "generate"], [74, 0, 1, "", "get_device"], [75, 0, 1, "", "get_dtype"], [76, 0, 1, "", "get_full_finetune_fsdp_wrap_policy"], [77, 0, 1, "", "get_logger"], [78, 0, 1, "", "get_world_size_and_rank"], [79, 0, 1, "", "init_distributed"], [80, 0, 1, "", "list_dtypes"], [85, 0, 1, "", "padded_collate"], [86, 0, 1, "", "profiler"], [87, 0, 1, "", "set_activation_checkpointing"], [88, 0, 1, "", "set_seed"]], "torchtune.utils.FullModelHFCheckpointer": [[70, 2, 1, "", "load_checkpoint"], [70, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[71, 2, 1, "", "load_checkpoint"], [71, 2, 1, "", "save_checkpoint"]], "torchtune.utils.TuneRecipeArgumentParser": [[72, 2, 1, "", "parse_known_args"]], "torchtune.utils.metric_logging": [[81, 1, 1, "", "DiskLogger"], [82, 1, 1, "", "StdoutLogger"], [83, 1, 1, "", "TensorBoardLogger"], [84, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[81, 2, 1, "", "close"], [81, 2, 1, "", "log"], [81, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[82, 2, 1, "", "close"], [82, 2, 1, "", "log"], [82, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[83, 2, 1, "", "close"], [83, 2, 1, "", "log"], [83, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[84, 2, 1, "", "close"], [84, 2, 1, "", "log"], [84, 2, 1, "", "log_config"], [84, 2, 1, "", "log_dict"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:data"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "data", "Python data"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 6, 69, 91, 93, 97, 99, 100, 101], "config": [0, 7, 8, 98], "data": [1, 5, 95], "instruct": [1, 92, 96, 99], "templat": [1, 95, 96], "chat": [1, 95, 96], "format": [1, 6, 96], "type": 1, "convert": 1, "helper": 1, "func": 1, "dataset": [2, 95, 96], "exampl": 2, "gener": [2, 73, 97, 99], "builder": 2, "class": [2, 8], "model": [3, 4, 9, 97, 98, 99, 100], "llama3": [3, 95, 99], "llama2": [3, 95, 97, 100, 101], "phi": 3, "3": 3, "mistral": 3, "gemma": 3, "modul": 4, "compon": [4, 7], "build": [4, 92, 101], "block": 4, "token": [4, 95], "peft": 4, "util": [4, 5, 69], "checkpoint": [5, 6, 9, 97], "distribut": 5, "reduc": 5, "precis": 5, "memori": [5, 100, 101], "manag": 5, "perform": [5, 100], "profil": [5, 86], "metric": [5, 9], "log": [5, 9], "miscellan": 5, "overview": [6, 93, 97], "handl": 6, "differ": 6, "intermedi": 6, "vs": 6, "final": 6, "lora": [6, 97, 100, 101], "put": [6, 101], "thi": 6, "all": [6, 7, 101], "togeth": [6, 101], "about": 7, "where": 7, "do": 7, "paramet": 7, "live": 7, "write": 7, "configur": [7, 96], "us": [7, 8, 95, 97, 101], "instanti": [7, 10], "referenc": 7, "other": [7, 97], "field": 7, "interpol": 7, "valid": [7, 12], "your": [7, 8, 97, 98], "best": 7, "practic": 7, "airtight": 7, "public": 7, "api": 7, "onli": 7, "command": 7, "line": 7, "overrid": 7, "what": [8, 93, 100, 101], "ar": 8, "recip": [8, 98, 100], "script": 8, "run": [8, 97], "cli": 8, "pars": [8, 11], "weight": 9, "bias": 9, "logger": 9, "w": 9, "b": 9, "alpacainstructtempl": 13, "chatformat": 14, "chatmlformat": 15, "grammarerrorcorrectiontempl": 16, "instructtempl": 17, "llama2chatformat": 18, "messag": 19, "mistralchatformat": 20, "summarizetempl": 21, "sharegpt_to_llama2_messag": 22, "validate_messag": 23, "chatdataset": 24, "concatdataset": 25, "instructdataset": 26, "alpaca_cleaned_dataset": 27, "alpaca_dataset": 28, "chat_dataset": 29, "grammar_dataset": 30, "instruct_dataset": 31, "samsum_dataset": 32, "slimorca_dataset": 33, "gemma_2b": 34, "llama2_13b": 35, "llama2_70b": 36, "llama2_7b": 37, "lora_llama2_13b": 38, "lora_llama2_70b": 39, "lora_llama2_7b": 40, "qlora_llama2_13b": 41, "qlora_llama2_7b": 42, "llama3_70b": 43, "llama3_8b": 44, "lora_llama3_70b": 45, "lora_llama3_8b": 46, "qlora_llama3_8b": 47, "lora_mistral_7b": 48, "mistral_7b": 49, "qlora_mistral_7b": 50, "lora_phi3_mini": 51, "phi3_mini": 52, "qlora_phi3_mini": 53, "causalselfattent": 54, "todo": [54, 60], "feedforward": 55, "kvcach": 56, "rmsnorm": 57, "rotarypositionalembed": 58, "transformerdecod": 59, "transformerdecoderlay": 60, "reparametrize_as_dtype_state_dict_post_hook": 61, "get_cosine_schedule_with_warmup": 62, "adaptermodul": 63, "loralinear": 64, "get_adapter_param": 65, "set_trainable_param": 66, "sentencepiecetoken": 67, "tiktokentoken": 68, "fsdppolicytyp": 69, "fullmodelhfcheckpoint": 70, "fullmodelmetacheckpoint": 71, "tunerecipeargumentpars": 72, "get_devic": 74, "get_dtyp": 75, "get_full_finetune_fsdp_wrap_polici": 76, "get_logg": 77, "get_world_size_and_rank": 78, "init_distribut": 79, "list_dtyp": 80, "disklogg": 81, "stdoutlogg": 82, "tensorboardlogg": 83, "wandblogg": 84, "padded_col": 85, "set_activation_checkpoint": 87, "set_se": 88, "comput": [90, 94], "time": [90, 94], "welcom": 91, "document": 91, "get": [91, 99], "start": 91, "tutori": 91, "instal": 92, "via": [92, 99], "pypi": 92, "git": 92, "clone": 92, "nightli": 92, "kei": 93, "concept": 93, "design": 93, "principl": 93, "fine": [95, 96, 98, 99], "tune": [95, 96, 98, 99], "chang": 95, "from": [95, 101], "prompt": 95, "special": 95, "when": 95, "should": 95, "i": 95, "custom": [95, 96], "fulli": 96, "end": 97, "workflow": 97, "download": [97, 98], "7b": 97, "finetun": [97, 100, 101], "evalu": [97, 99], "eleutherai": [97, 99], "s": [97, 99], "eval": [97, 99], "har": [97, 99], "speed": 97, "up": 97, "quantiz": [97, 99], "librari": 97, "upload": 97, "hug": 97, "face": 97, "hub": 97, "first": 98, "llm": 98, "select": 98, "modifi": 98, "train": 98, "next": 98, "step": 98, "meta": 99, "8b": 99, "access": 99, "text": 99, "our": 99, "faster": 99, "how": 100, "doe": 100, "work": 100, "appli": 100, "trade": 100, "off": 100, "qlora": 101, "save": 101, "deep": 101, "dive": 101}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})