Search.setIndex({"docnames": ["api_ref_config", "api_ref_data", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "deep_dives/checkpointer", "deep_dives/configs", "deep_dives/recipe_deepdive", "deep_dives/wandb_logging", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.config.validate", "generated/torchtune.data.AlpacaInstructTemplate", "generated/torchtune.data.ChatFormat", "generated/torchtune.data.ChatMLFormat", "generated/torchtune.data.GrammarErrorCorrectionTemplate", "generated/torchtune.data.InstructTemplate", "generated/torchtune.data.Llama2ChatFormat", "generated/torchtune.data.MistralChatFormat", "generated/torchtune.data.SummarizeTemplate", "generated/torchtune.data.validate_messages", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.chat_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.instruct_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.models.gemma.gemma_2b", "generated/torchtune.models.llama2.llama2_13b", "generated/torchtune.models.llama2.llama2_70b", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2_13b", "generated/torchtune.models.llama2.lora_llama2_70b", "generated/torchtune.models.llama2.lora_llama2_7b", "generated/torchtune.models.llama2.qlora_llama2_13b", "generated/torchtune.models.llama2.qlora_llama2_7b", "generated/torchtune.models.llama3.llama3_70b", "generated/torchtune.models.llama3.llama3_8b", "generated/torchtune.models.llama3.lora_llama3_70b", "generated/torchtune.models.llama3.lora_llama3_8b", "generated/torchtune.models.llama3.qlora_llama3_8b", "generated/torchtune.models.mistral.lora_mistral_7b", "generated/torchtune.models.mistral.mistral_7b", "generated/torchtune.models.mistral.qlora_mistral_7b", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.modules.tokenizers.SentencePieceTokenizer", "generated/torchtune.modules.tokenizers.TikTokenTokenizer", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.TuneRecipeArgumentParser", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_dtype", "generated/torchtune.utils.get_logger", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.list_dtypes", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.padded_collate", "generated/torchtune.utils.profiler", "generated/torchtune.utils.set_activation_checkpointing", "generated/torchtune.utils.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times", "tutorials/datasets", "tutorials/e2e_flow", "tutorials/first_finetune_tutorial", "tutorials/llama3", "tutorials/lora_finetune", "tutorials/qlora_finetune"], "filenames": ["api_ref_config.rst", "api_ref_data.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "deep_dives/checkpointer.rst", "deep_dives/configs.rst", "deep_dives/recipe_deepdive.rst", "deep_dives/wandb_logging.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.config.validate.rst", "generated/torchtune.data.AlpacaInstructTemplate.rst", "generated/torchtune.data.ChatFormat.rst", "generated/torchtune.data.ChatMLFormat.rst", "generated/torchtune.data.GrammarErrorCorrectionTemplate.rst", "generated/torchtune.data.InstructTemplate.rst", "generated/torchtune.data.Llama2ChatFormat.rst", "generated/torchtune.data.MistralChatFormat.rst", "generated/torchtune.data.SummarizeTemplate.rst", "generated/torchtune.data.validate_messages.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.chat_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.instruct_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.models.gemma.gemma_2b.rst", "generated/torchtune.models.llama2.llama2_13b.rst", "generated/torchtune.models.llama2.llama2_70b.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2_13b.rst", "generated/torchtune.models.llama2.lora_llama2_70b.rst", "generated/torchtune.models.llama2.lora_llama2_7b.rst", "generated/torchtune.models.llama2.qlora_llama2_13b.rst", "generated/torchtune.models.llama2.qlora_llama2_7b.rst", "generated/torchtune.models.llama3.llama3_70b.rst", "generated/torchtune.models.llama3.llama3_8b.rst", "generated/torchtune.models.llama3.lora_llama3_70b.rst", "generated/torchtune.models.llama3.lora_llama3_8b.rst", "generated/torchtune.models.llama3.qlora_llama3_8b.rst", "generated/torchtune.models.mistral.lora_mistral_7b.rst", "generated/torchtune.models.mistral.mistral_7b.rst", "generated/torchtune.models.mistral.qlora_mistral_7b.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.modules.tokenizers.SentencePieceTokenizer.rst", "generated/torchtune.modules.tokenizers.TikTokenTokenizer.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_dtype.rst", "generated/torchtune.utils.get_logger.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.list_dtypes.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.padded_collate.rst", "generated/torchtune.utils.profiler.rst", "generated/torchtune.utils.set_activation_checkpointing.rst", "generated/torchtune.utils.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst", "tutorials/datasets.rst", "tutorials/e2e_flow.rst", "tutorials/first_finetune_tutorial.rst", "tutorials/llama3.rst", "tutorials/lora_finetune.rst", "tutorials/qlora_finetune.rst"], "titles": ["torchtune.config", "torchtune.data", "torchtune.datasets", "torchtune.models", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "All About Configs", "What Are Recipes?", "Logging to Weights &amp; Biases", "instantiate", "parse", "validate", "AlpacaInstructTemplate", "ChatFormat", "ChatMLFormat", "GrammarErrorCorrectionTemplate", "InstructTemplate", "Llama2ChatFormat", "MistralChatFormat", "SummarizeTemplate", "validate_messages", "alpaca_cleaned_dataset", "alpaca_dataset", "chat_dataset", "grammar_dataset", "instruct_dataset", "samsum_dataset", "slimorca_dataset", "gemma_2b", "llama2_13b", "llama2_70b", "llama2_7b", "lora_llama2_13b", "lora_llama2_70b", "lora_llama2_7b", "qlora_llama2_13b", "qlora_llama2_7b", "llama3_70b", "llama3_8b", "lora_llama3_70b", "lora_llama3_8b", "qlora_llama3_8b", "lora_mistral_7b", "mistral_7b", "qlora_mistral_7b", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "SentencePieceTokenizer", "TikTokenTokenizer", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "get_device", "get_dtype", "get_logger", "get_world_size_and_rank", "init_distributed", "list_dtypes", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "padded_collate", "profiler", "set_activation_checkpointing", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times", "Configuring Datasets for Fine-Tuning", "End-to-End Workflow with torchtune", "Fine-Tune Your First LLM", "Llama3 in torchtune", "Finetuning Llama2 with LoRA", "Finetuning Llama2 with QLoRA"], "terms": {"support": [2, 6, 8, 9, 10, 19, 22, 23, 24, 25, 26, 27, 28, 46, 56, 62, 65, 69, 82, 84, 85, 86, 87, 88, 89], "sever": [2, 84], "wide": [2, 84], "us": [2, 4, 6, 9, 10, 11, 15, 18, 22, 23, 24, 25, 26, 27, 28, 46, 47, 49, 50, 51, 52, 53, 59, 60, 61, 62, 63, 64, 65, 70, 71, 72, 73, 77, 80, 81, 82, 84, 86, 87, 88], "help": [2, 6, 18, 51, 61, 63, 80, 81, 82, 84, 85, 86, 87, 89], "quickli": [2, 7, 84], "bootstrap": [2, 84], "your": [2, 5, 9, 10, 72, 73, 80, 81, 82, 84, 87, 88, 89], "fine": [2, 6, 8, 9, 80, 82, 85, 88], "tune": [2, 3, 6, 7, 8, 9, 11, 80, 81, 82, 85, 88, 89], "also": [2, 6, 7, 8, 9, 10, 46, 51, 56, 64, 73, 81, 84, 85, 86, 87, 88, 89], "common": [2, 4, 7, 84, 87, 88], "format": [2, 5, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 28, 61, 62, 85, 86, 87, 88], "like": [2, 6, 7, 8, 9, 81, 84, 85, 86, 88], "chat": [2, 14, 15, 18, 24, 28], "model": [2, 6, 7, 8, 10, 15, 19, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 61, 62, 75, 76, 80, 82, 84, 89], "instruct": [2, 13, 15, 17, 19, 22, 23, 26, 80, 86, 87, 88, 89], "all": [3, 4, 8, 12, 46, 47, 51, 53, 60, 61, 63, 78, 80, 82, 83, 85, 86, 87, 88], "from": [3, 6, 7, 8, 9, 10, 13, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 44, 47, 51, 52, 54, 55, 57, 59, 61, 62, 63, 72, 73, 79, 81, 83, 84, 85, 86, 87, 88], "famili": [3, 8, 22, 23, 28, 82, 87], "download": [3, 6, 78, 81, 87, 88, 89], "meta": [3, 6, 18, 61, 62, 85, 86, 87], "llama": [3, 6, 18, 24, 49, 50, 61, 62, 85, 86, 87, 88], "3": [3, 6, 60, 63, 66, 74, 85, 86, 87, 89], "8b": [3, 39, 40, 41], "hf": [3, 6, 61, 85, 86, 87], "token": [3, 6, 7, 8, 22, 23, 24, 25, 26, 27, 28, 46, 50, 51, 52, 59, 60, 84, 85, 86, 87, 88, 89], "access_token": 3, "pre": [3, 18, 81], "train": [3, 5, 6, 8, 9, 18, 22, 23, 24, 25, 26, 27, 28, 46, 53, 54, 61, 62, 65, 75, 80, 82, 84, 85, 87, 88, 89], "can": [3, 4, 6, 7, 8, 9, 10, 12, 22, 23, 26, 49, 50, 59, 61, 63, 72, 73, 80, 81, 82, 84, 85, 86, 87, 88, 89], "hug": [3, 6, 22, 23, 24, 25, 26, 27, 28, 54, 82, 84, 86, 87], "face": [3, 6, 22, 23, 24, 25, 26, 27, 28, 54, 82, 84, 86, 87], "hub": [3, 6, 86], "follow": [3, 6, 8, 46, 54, 73, 80, 81, 84, 85, 86, 87, 88, 89], "command": [3, 8, 9, 63, 81, 85, 86, 87, 88, 89], "2": [3, 6, 9, 21, 28, 46, 59, 61, 62, 74, 77, 85, 86, 87, 88], "7b": [3, 6, 22, 23, 26, 32, 35, 43, 44, 61, 62, 86, 87, 88, 89], "ai": [3, 44, 46, 73, 87], "mistralai": 3, "v0": 3, "1": [3, 6, 8, 28, 46, 51, 54, 59, 60, 62, 72, 73, 74, 77, 85, 86, 87, 88, 89], "googl": [3, 29], "2b": [3, 29], "ignor": [3, 6, 46, 47], "pattern": [3, 60], "These": [4, 6, 7, 8, 10, 63, 84, 85, 86, 87, 88, 89], "ar": [4, 6, 7, 9, 10, 13, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 51, 56, 61, 62, 65, 81, 82, 84, 85, 86, 87, 88, 89], "offer": 5, "allow": [5, 72, 89], "seamless": 5, "transit": 5, "between": [5, 6, 61, 85, 87, 88, 89], "interoper": [5, 6, 8, 82, 85, 89], "rest": [5, 89], "ecosystem": [5, 6, 8, 82, 85, 87, 89], "For": [5, 6, 7, 8, 22, 23, 26, 46, 51, 63, 73, 77, 81, 84, 85, 86, 87, 88, 89], "comprehens": 5, "overview": [5, 7, 9, 86, 88, 89], "pleas": [5, 37, 42, 45, 81, 89], "see": [5, 6, 9, 18, 19, 24, 28, 37, 42, 45, 48, 55, 63, 66, 73, 75, 77, 81, 82, 84, 85, 86, 87, 88, 89], "deep": [5, 6, 7, 8, 9, 82, 86, 87], "dive": [5, 6, 7, 8, 9, 82, 86, 87], "enabl": [5, 7, 8, 9, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 56, 75, 77, 87, 88, 89], "work": [5, 6, 8, 63, 82, 85, 87, 89], "set": [5, 6, 7, 8, 9, 22, 23, 25, 26, 27, 28, 50, 51, 58, 64, 76, 77, 82, 84, 85, 86, 87, 88], "consumpt": 5, "dure": [5, 6, 22, 23, 25, 27, 46, 48, 50, 51, 52, 53, 85, 87, 88, 89], "provid": [5, 6, 7, 8, 10, 15, 19, 28, 51, 63, 73, 82, 84, 85, 86, 87], "debug": [5, 6, 7, 8], "finetun": [5, 6, 7, 8, 33, 34, 35, 36, 40, 41, 69, 80, 82, 86, 87], "job": [5, 9, 77, 86], "variou": [5, 17], "dataset": [5, 7, 13, 16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 82, 86, 87], "walk": [6, 8, 72, 82, 84, 85, 86, 89], "you": [6, 7, 8, 9, 10, 17, 18, 22, 23, 26, 63, 72, 73, 80, 81, 82, 84, 85, 86, 87, 88, 89], "through": [6, 7, 8, 9, 47, 82, 84, 85, 86, 89], "design": [6, 8], "behavior": [6, 84], "associ": [6, 7, 8, 85, 88], "util": [6, 7, 8, 9, 10, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 85, 86, 87, 89], "what": [6, 7, 9, 18, 19, 25, 27, 80, 84, 85, 86, 87], "cover": [6, 7, 8, 9, 85, 89], "how": [6, 7, 8, 9, 80, 84, 85, 86, 87, 89], "we": [6, 7, 8, 9, 22, 23, 26, 46, 48, 50, 51, 56, 59, 61, 62, 65, 82, 84, 85, 86, 87, 88, 89], "them": [6, 7, 26, 28, 47, 53, 59, 84, 85, 88, 89], "scenario": 6, "full": [6, 7, 8, 37, 42, 45, 59, 82, 87, 88], "compos": 6, "compon": [6, 8, 12, 75, 82, 84, 86, 88, 89], "which": [6, 8, 22, 23, 25, 27, 33, 34, 35, 36, 40, 41, 43, 46, 50, 51, 52, 54, 59, 61, 62, 65, 70, 73, 82, 84, 85, 86, 87, 88, 89], "plug": 6, "ani": [6, 7, 8, 10, 11, 12, 13, 16, 17, 20, 24, 26, 53, 57, 58, 59, 61, 62, 77, 84, 85, 86, 87, 88], "recip": [6, 7, 9, 10, 11, 47, 61, 62, 82, 84, 85, 87, 89], "evalu": [6, 8, 80, 82, 86, 88, 89], "gener": [6, 8, 13, 16, 20, 28, 59, 77, 78, 80, 84, 88, 89], "each": [6, 8, 14, 17, 33, 34, 35, 36, 40, 41, 43, 46, 50, 51, 59, 60, 77, 82, 84, 85, 86, 87, 88], "make": [6, 7, 8, 9, 46, 52, 82, 85, 86, 87, 88, 89], "easi": [6, 8, 82, 88], "understand": [6, 7, 8, 80, 82, 84, 88, 89], "extend": [6, 8, 82], "befor": [6, 21, 51, 52, 56, 61, 85], "let": [6, 7, 9, 84, 85, 86, 87, 88, 89], "s": [6, 7, 8, 9, 10, 11, 13, 14, 15, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 33, 34, 35, 36, 40, 41, 43, 46, 50, 51, 52, 53, 55, 57, 60, 61, 62, 64, 72, 75, 82, 84, 86, 88, 89], "defin": [6, 7, 8, 47, 55, 56, 57, 86, 88], "some": [6, 7, 15, 57, 58, 80, 82, 85, 86, 88, 89], "concept": [6, 85, 86], "In": [6, 7, 8, 50, 56, 72, 73, 85, 87, 88, 89], "ll": [6, 7, 8, 60, 82, 84, 85, 86, 87, 89], "talk": 6, "about": [6, 8, 61, 73, 82, 85, 86, 87, 88, 89], "take": [6, 7, 8, 10, 47, 48, 53, 61, 63, 64, 84, 85, 86, 87, 88, 89], "close": [6, 8, 70, 71, 72, 73, 88], "look": [6, 7, 8, 72, 81, 84, 85, 86, 87, 88], "veri": [6, 51, 85], "simpli": [6, 7, 84, 85, 87, 89], "dictat": 6, "state_dict": [6, 53, 61, 62, 88, 89], "store": [6, 70, 73, 88, 89], "file": [6, 7, 8, 9, 10, 11, 59, 60, 61, 62, 63, 70, 73, 75, 79, 82, 83, 84, 85, 86, 87, 88, 89], "disk": [6, 70], "weight": [6, 8, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 53, 55, 56, 61, 62, 73, 80, 85, 86, 87, 88, 89], "string": [6, 22, 23, 24, 25, 26, 27, 28, 55, 59, 60, 64, 65], "kei": [6, 7, 9, 26, 28, 46, 48, 51, 58, 61, 85, 86, 88, 89], "identifi": 6, "state": [6, 8, 53, 57, 58, 61, 62, 85, 87, 88, 89], "dict": [6, 7, 8, 9, 10, 13, 16, 17, 20, 24, 26, 53, 57, 58, 61, 62, 68], "If": [6, 7, 12, 13, 16, 17, 19, 20, 21, 22, 23, 25, 26, 27, 28, 46, 53, 56, 61, 62, 64, 65, 68, 72, 73, 77, 81, 84, 85, 86, 87, 88], "don": [6, 7, 8, 73, 77, 85, 86, 87, 89], "t": [6, 7, 8, 28, 60, 65, 73, 77, 85, 86, 87, 89], "match": [6, 26, 28, 81, 85, 87, 88], "up": [6, 8, 9, 22, 23, 26, 84, 86, 87, 88, 89], "exactli": 6, "those": [6, 88], "definit": [6, 88], "either": [6, 61, 88, 89], "run": [6, 7, 9, 11, 47, 48, 51, 53, 61, 62, 72, 73, 81, 82, 86, 87, 88, 89], "explicit": 6, "error": [6, 7, 21, 61, 77], "load": [6, 8, 61, 62, 63, 72, 85, 87, 88], "rais": [6, 10, 12, 19, 21, 24, 28, 46, 51, 61, 62, 65, 68, 73, 77], "an": [6, 7, 8, 9, 10, 13, 21, 22, 23, 24, 25, 26, 27, 28, 46, 51, 55, 57, 58, 61, 62, 73, 82, 84, 85, 86, 87, 88, 89], "except": [6, 19, 84], "wors": 6, "silent": [6, 47], "succe": 6, "infer": [6, 18, 46, 48, 50, 51, 52, 80, 85, 86, 87, 89], "expect": [6, 7, 10, 13, 16, 17, 20, 24, 26, 50, 73, 84, 88], "addit": [6, 7, 8, 10, 24, 26, 61, 62, 65, 68, 70, 72, 73, 76, 82, 86, 88], "line": [6, 8, 63, 86, 87], "need": [6, 7, 8, 9, 17, 28, 46, 47, 51, 72, 73, 81, 84, 85, 86, 87, 88, 89], "shape": [6, 46, 48, 50, 51, 52, 56], "valu": [6, 7, 28, 29, 30, 31, 32, 38, 39, 44, 46, 48, 49, 51, 54, 61, 63, 70, 71, 72, 73, 77, 86, 87, 88], "two": [6, 7, 21, 82, 85, 86, 87, 88, 89], "popular": [6, 82, 84, 85], "llama2": [6, 7, 8, 10, 18, 22, 23, 26, 28, 30, 31, 32, 33, 34, 35, 36, 37, 47, 51, 52, 59, 80, 82, 86, 87], "offici": [6, 18, 86, 87], "implement": [6, 8, 22, 23, 24, 25, 26, 27, 28, 47, 49, 50, 54, 55, 56, 61, 72, 82, 88, 89], "when": [6, 7, 8, 11, 51, 53, 54, 72, 85, 87, 88, 89], "websit": 6, "get": [6, 7, 8, 9, 59, 65, 66, 67, 81, 82, 84, 85, 86, 88], "access": [6, 7, 8, 61, 85, 86], "singl": [6, 7, 10, 13, 14, 15, 16, 17, 18, 19, 20, 46, 61, 62, 85, 86, 87, 88, 89], "pth": [6, 85, 87], "inspect": [6, 85, 88, 89], "content": [6, 59, 84], "easili": [6, 7, 82, 84, 88, 89], "torch": [6, 48, 51, 53, 54, 64, 65, 68, 75, 76, 77, 85, 86, 87, 88, 89], "import": [6, 7, 10, 72, 73, 84, 85, 86, 88, 89], "consolid": [6, 87], "00": [6, 79, 83, 86, 87], "mmap": [6, 85], "true": [6, 7, 22, 23, 25, 27, 36, 37, 42, 45, 53, 59, 60, 61, 62, 68, 72, 84, 85, 87, 88, 89], "weights_onli": 6, "map_loc": [6, 85], "cpu": [6, 8, 53, 65, 81, 85, 89], "tensor": [6, 46, 47, 48, 49, 50, 51, 52, 53, 56, 61, 70, 71, 72, 73, 74, 88, 89], "item": 6, "print": [6, 9, 22, 23, 25, 27, 28, 59, 84, 86, 88, 89], "f": [6, 9, 22, 23, 25, 27, 85, 88, 89], "tok_embed": [6, 51], "size": [6, 8, 10, 22, 23, 25, 27, 46, 48, 49, 50, 51, 52, 67, 82, 84, 85, 86, 87, 88], "32000": [6, 10, 88], "4096": [6, 10, 22, 23, 26, 46, 50, 88], "len": [6, 22, 23, 25, 27, 51], "292": 6, "The": [6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 27, 28, 33, 34, 35, 36, 40, 41, 49, 50, 53, 54, 59, 60, 61, 63, 64, 65, 66, 73, 75, 77, 81, 82, 85, 86, 87, 88, 89], "contain": [6, 46, 48, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 63, 72, 74, 85, 87, 88], "includ": [6, 7, 8, 14, 17, 56, 61, 62, 63, 82, 85, 86, 87, 88, 89], "input": [6, 13, 14, 17, 22, 23, 24, 25, 26, 28, 46, 47, 49, 50, 51, 52, 56, 59, 61, 74, 77, 84, 88, 89], "embed": [6, 46, 48, 49, 50, 51, 87], "tabl": [6, 89], "call": [6, 10, 47, 53, 63, 70, 71, 72, 73, 88, 89], "layer": [6, 8, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 51, 52, 56, 82, 87, 88, 89], "have": [6, 7, 10, 46, 48, 55, 63, 72, 75, 81, 84, 85, 86, 87, 88, 89], "dim": [6, 46, 47, 49, 50, 51, 52], "most": [6, 7, 60, 86, 88, 89], "within": [6, 7, 10, 28, 47, 72, 77, 85, 87, 88, 89], "default": [6, 7, 15, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 56, 59, 60, 61, 62, 63, 65, 70, 73, 74, 75, 77, 81, 85, 87, 88, 89], "everi": [6, 8, 47, 72, 81, 89], "config": [6, 9, 10, 11, 12, 24, 26, 46, 61, 63, 73, 82, 84, 85, 87, 88, 89], "repo": [6, 61, 62, 85], "first": [6, 7, 10, 21, 51, 60, 61, 63, 80, 82, 85, 87, 88, 89], "big": [6, 85], "split": [6, 84, 85], "across": [6, 8, 61, 72, 77, 85, 87], "bin": [6, 85], "To": [6, 7, 8, 9, 61, 81, 82, 84, 85, 86, 87, 88, 89], "correctli": [6, 8, 12, 61, 81, 86, 89], "piec": 6, "one": [6, 8, 21, 47, 59, 84, 85, 86, 87, 89], "pytorch_model": [6, 85], "00001": 6, "00002": 6, "embed_token": 6, "241": 6, "Not": 6, "onli": [6, 9, 46, 50, 51, 52, 56, 57, 59, 62, 63, 65, 85, 86, 87, 88, 89], "doe": [6, 19, 55, 61, 63, 85], "fewer": [6, 46], "sinc": [6, 7, 10, 47, 61, 85, 87], "instead": [6, 8, 24, 26, 47, 48, 56, 85, 87, 88], "mismatch": 6, "name": [6, 7, 9, 13, 16, 17, 20, 24, 26, 28, 55, 58, 60, 61, 62, 63, 64, 70, 71, 72, 73, 85, 87], "caus": [6, 59], "try": [6, 7, 85, 86, 87, 89], "same": [6, 7, 33, 34, 35, 36, 40, 41, 46, 48, 52, 59, 63, 73, 85, 87, 88, 89], "As": [6, 7, 8, 9, 56, 82, 85, 87, 89], "re": [6, 7, 60, 82, 85, 86, 87, 88], "care": [6, 47, 61, 85, 87, 88], "end": [6, 8, 60, 80, 82, 87, 88], "number": [6, 8, 22, 23, 24, 26, 28, 46, 48, 51, 54, 61, 62, 67, 77, 86, 88], "just": [6, 13, 82, 84, 86, 87, 88], "save": [6, 8, 9, 53, 61, 62, 73, 80, 85, 87, 88], "less": [6, 28, 85, 86, 87, 89], "prone": 6, "manag": [6, 75], "invari": 6, "accept": [6, 7, 28, 59, 86, 89], "multipl": [6, 7, 8, 56, 70, 71, 72, 73, 86, 87], "sourc": [6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 84, 85], "worri": [6, 86], "explicitli": [6, 55, 82, 88], "convert": [6, 61, 74, 85, 89], "time": [6, 59, 70, 72, 85, 87, 89], "produc": [6, 89], "back": [6, 21, 61, 88, 89], "origin": [6, 22, 23, 53, 56, 84, 85, 87, 88, 89], "form": [6, 7, 8, 21], "One": [6, 85], "advantag": [6, 88], "being": [6, 61, 62, 64, 89], "should": [6, 7, 8, 14, 17, 18, 19, 24, 26, 33, 34, 35, 36, 40, 41, 43, 46, 47, 55, 63, 70, 71, 72, 73, 81, 82, 84, 85, 86, 87, 88, 89], "abl": [6, 8, 84, 85, 86, 87], "post": [6, 89], "tool": [6, 85, 86], "quantiz": [6, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 56, 80, 86, 89], "eval": [6, 80, 82], "without": [6, 7, 9, 81, 82, 84, 85, 88], "code": [6, 8, 51, 78, 82, 84, 86], "chang": [6, 7, 9, 13, 81, 84, 85, 86, 87, 88, 89], "OR": 6, "convers": [6, 14, 15, 18, 19, 21, 24, 28, 61, 82, 84, 85, 87, 88, 89], "script": [6, 9, 85, 86, 87], "wai": [6, 7, 84, 85, 86, 87], "surround": [6, 8, 82], "load_checkpoint": [6, 8, 61, 62], "save_checkpoint": [6, 8, 9, 61, 62], "method": [6, 7, 8, 9, 11, 22, 23, 24, 25, 26, 27, 28, 53, 55, 57, 63, 81, 82, 85, 87, 88, 89], "convertor": 6, "avail": [6, 8, 63, 64, 65, 82, 85, 87, 88], "here": [6, 7, 9, 15, 25, 49, 50, 84, 85, 86, 87, 88, 89], "three": [6, 8, 86], "hfcheckpoint": 6, "read": [6, 61, 62, 82], "write": [6, 8, 61, 62, 70, 84, 86], "compat": [6, 61], "transform": [6, 8, 33, 34, 35, 36, 40, 41, 43, 51, 52, 54, 88], "framework": [6, 8, 82], "mention": [6, 85, 89], "abov": [6, 53, 81, 85, 87, 88, 89], "assum": [6, 13, 16, 17, 20, 26, 54, 57, 60, 65, 85, 88], "checkpoint_dir": [6, 7, 61, 62, 85, 87], "necessari": [6, 28, 70, 71, 72, 73, 88], "json": [6, 61, 75, 85], "easiest": [6, 85, 86], "sure": [6, 7, 85, 86, 87, 88, 89], "everyth": [6, 8, 63, 82, 86], "flow": [6, 89], "By": [6, 87, 88, 89], "safetensor": 6, "output": [6, 17, 22, 23, 25, 28, 33, 34, 35, 36, 40, 41, 43, 46, 47, 49, 50, 51, 52, 56, 58, 71, 75, 81, 84, 85, 86, 87, 88, 89], "dir": [6, 73, 81, 85, 86, 87], "output_dir": [6, 7, 61, 62, 75, 85, 87, 88, 89], "specifi": [6, 7, 8, 10, 24, 46, 73, 84, 85, 86, 87, 89], "argument": [6, 7, 10, 17, 24, 26, 28, 37, 42, 45, 46, 63, 68, 70, 72, 73, 76, 87, 88], "snippet": 6, "explain": 6, "setup": [6, 7, 8, 51, 76, 85, 88, 89], "_component_": [6, 7, 9, 10, 84, 85, 87, 88], "fullmodelhfcheckpoint": [6, 85], "directori": [6, 7, 61, 62, 70, 72, 73, 85, 86, 87], "sort": [6, 61], "id": [6, 22, 23, 24, 26, 28, 59, 60, 61, 74, 85], "so": [6, 7, 61, 63, 81, 82, 85, 86, 87, 88, 89], "order": [6, 8, 61, 72, 73, 86], "matter": [6, 61, 88], "checkpoint_fil": [6, 7, 9, 61, 62, 85, 87, 88, 89], "restart": 6, "previou": [6, 61, 62], "more": [6, 7, 8, 24, 28, 48, 50, 63, 73, 75, 77, 82, 84, 85, 86, 87, 88, 89], "next": [6, 87, 89], "section": [6, 8, 80, 85, 87, 89], "recipe_checkpoint": [6, 61, 62], "null": [6, 7], "usual": [6, 50, 61, 73, 85, 88], "model_typ": [6, 61, 62, 85, 87], "resume_from_checkpoint": [6, 61, 62], "fals": [6, 7, 22, 23, 24, 25, 26, 27, 28, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 56, 59, 60, 61, 62, 75, 85, 87, 88, 89], "requir": [6, 7, 28, 61, 72, 73, 77, 81, 84, 86, 89], "param": [6, 8, 33, 34, 35, 36, 40, 41, 56, 57, 58, 61, 88, 89], "directli": [6, 7, 8, 10, 24, 26, 61, 84, 85, 86, 87, 88, 89], "ensur": [6, 7, 12, 21, 28, 46, 61, 65, 82, 86], "out": [6, 7, 8, 22, 23, 25, 27, 61, 62, 80, 82, 85, 86, 87, 88, 89], "case": [6, 8, 9, 46, 61, 65, 70, 82, 84, 85, 87, 88, 89], "discrep": [6, 61], "along": [6, 87, 88], "detail": [6, 24, 28, 48, 75, 77, 85, 86, 87, 88, 89], "found": [6, 7, 9, 49, 50, 88, 89], "metacheckpoint": 6, "github": [6, 10, 33, 34, 35, 36, 40, 41, 46, 49, 50, 54, 81, 86], "repositori": [6, 18, 85, 86], "fullmodelmetacheckpoint": [6, 87], "torchtunecheckpoint": 6, "perform": [6, 47, 82, 85, 87, 89], "current": [6, 46, 50, 51, 52, 62, 67, 70, 72, 77, 85, 86, 87], "test": [6, 7, 8, 81, 82], "complet": [6, 8, 84, 85, 86, 87], "written": [6, 7, 8, 61, 62, 70, 71, 72, 73, 82], "begin": [6, 59, 60, 87, 89], "partit": [6, 89], "ha": [6, 55, 57, 59, 84, 85, 86, 87, 88, 89], "standard": [6, 71, 82, 85, 87], "key_1": 6, "weight_1": 6, "key_2": 6, "weight_2": 6, "mid": 6, "chekpoint": 6, "middl": [6, 85], "inform": [6, 73, 82, 85, 86, 87], "subsequ": [6, 8], "recipe_st": [6, 61, 62], "pt": [6, 9, 61, 62, 85, 87], "epoch": [6, 8, 9, 54, 61, 62, 85, 86, 87], "optim": [6, 7, 8, 54, 85, 86, 87, 88, 89], "etc": [6, 8, 61, 86], "prevent": 6, "flood": 6, "overwritten": 6, "note": [6, 7, 17, 51, 55, 59, 61, 75, 77, 84, 85, 88, 89], "updat": [6, 7, 8, 81, 85, 86, 87, 88, 89], "hf_model_0001_0": [6, 85], "hf_model_0002_0": [6, 85], "both": [6, 85, 88, 89], "adapt": [6, 55, 56, 57, 58, 61, 62, 85, 88, 89], "merg": [6, 10, 61, 85, 87, 89], "would": [6, 7, 9, 51, 81, 84, 85, 88, 89], "our": [6, 8, 82, 84, 85, 86, 88, 89], "tutori": [6, 82, 84, 85, 86, 87, 88, 89], "primari": [6, 7, 8, 86], "want": [6, 7, 8, 9, 10, 81, 85, 86, 87, 88], "resum": [6, 8, 54, 61, 62, 89], "initi": [6, 8, 11, 29, 30, 31, 32, 38, 39, 44, 68, 86, 88, 89], "frozen": [6, 88, 89], "base": [6, 10, 28, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 50, 54, 56, 58, 61, 63, 70, 80, 85, 86, 87, 88, 89], "well": [6, 7, 8, 82, 84, 85, 87, 89], "learnt": [6, 85], "someth": [6, 8, 9, 85], "NOT": 6, "refer": [6, 7, 8, 49, 50, 82, 88], "adapter_checkpoint": [6, 61, 62], "adapter_0": [6, 85], "now": [6, 59, 84, 85, 86, 87, 88, 89], "knowledg": 6, "creat": [6, 7, 10, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 54, 61, 62, 70, 72, 84, 85, 87, 89], "simpl": [6, 8, 80, 86, 88, 89], "forward": [6, 8, 46, 47, 49, 50, 51, 52, 56, 87, 88, 89], "13b": [6, 30, 33, 36], "modeltyp": [6, 61, 62], "llama2_13b": [6, 33, 36], "right": [6, 61, 85, 87, 88], "pytorch_fil": 6, "00003": 6, "torchtune_sd": 6, "load_state_dict": [6, 88], "successfulli": [6, 86], "vocab": [6, 10, 51, 87], "70": [6, 31, 38], "x": [6, 46, 47, 49, 50, 51, 52, 56, 88, 89], "randint": 6, "0": [6, 8, 34, 35, 37, 46, 51, 54, 56, 59, 72, 73, 74, 77, 79, 83, 85, 86, 87, 88, 89], "no_grad": 6, "6": [6, 49, 74, 85, 89], "3989": 6, "9": [6, 85, 89], "0531": 6, "2375": 6, "5": [6, 54, 74, 75, 85, 86, 87], "2822": 6, "4": [6, 28, 46, 74, 82, 85, 87, 88, 89], "4872": 6, "7469": 6, "8": [6, 22, 23, 25, 27, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 85, 88, 89], "6737": 6, "11": [6, 85, 87, 89], "0023": 6, "8235": 6, "6819": 6, "2424": 6, "0109": 6, "6915": 6, "7": [6, 74], "3618": 6, "1628": 6, "8594": 6, "5857": 6, "1151": 6, "7808": 6, "2322": 6, "8850": 6, "9604": 6, "7624": 6, "6040": 6, "3159": 6, "5849": 6, "8039": 6, "9322": 6, "2010": 6, "6824": 6, "8929": 6, "8465": 6, "3794": 6, "3500": 6, "6145": 6, "5931": 6, "do": [6, 8, 26, 28, 73, 84, 85, 86, 87, 88], "find": [6, 8, 9, 85, 86, 88], "list": [6, 7, 14, 15, 18, 19, 21, 22, 23, 24, 26, 28, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 55, 56, 59, 60, 61, 62, 63, 66, 69, 74, 84, 86, 87], "builder": [6, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 84, 89], "hope": 6, "deeper": [6, 86], "insight": [6, 85], "happi": [6, 85], "thi": [7, 8, 9, 10, 22, 23, 24, 26, 28, 46, 47, 50, 51, 52, 53, 54, 55, 59, 61, 62, 63, 64, 65, 70, 72, 73, 75, 77, 80, 81, 82, 84, 85, 86, 87, 88, 89], "guid": [7, 9, 82, 84, 86, 88], "yaml": [7, 8, 10, 11, 24, 26, 63, 73, 82, 85, 86, 87, 88, 89], "pars": [7, 10, 60, 63, 86], "effect": 7, "cli": [7, 9, 11, 81, 85, 86], "prerequisit": [7, 84, 85, 86, 87, 88, 89], "Be": [7, 85, 86, 87, 88, 89], "familiar": [7, 85, 86, 87, 88, 89], "torchtun": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 81, 84, 86], "instal": [7, 9, 72, 73, 80, 85, 86, 87, 88, 89], "fundament": 7, "There": [7, 14, 21, 85, 86, 87, 88], "entri": [7, 8, 86], "point": [7, 8, 84, 85, 86, 87, 88, 89], "locat": [7, 87, 88, 89], "thei": [7, 8, 51, 63, 84, 88], "truth": [7, 85, 87], "reproduc": 7, "overridden": [7, 47, 63], "quick": 7, "experiment": 7, "modifi": [7, 8, 9, 53, 82, 85, 87, 88, 89], "serv": [7, 84, 88], "particular": [7, 28, 84, 88, 89], "seed": [7, 8, 9, 77, 86], "shuffl": 7, "devic": [7, 8, 64, 65, 85, 86, 87, 88], "cuda": [7, 64, 65, 81, 85, 89], "dtype": [7, 8, 48, 53, 65, 69, 85, 89], "fp32": [7, 89], "enable_fsdp": 7, "mani": [7, 84, 85], "object": [7, 10, 14, 15, 18, 19, 46, 84], "keyword": [7, 10, 24, 26, 28, 53], "loss": [7, 8, 22, 23, 25, 27, 86, 88, 89], "function": [7, 8, 10, 11, 46, 47, 53, 64, 67, 77, 82, 84, 89], "exampl": [7, 8, 9, 10, 11, 15, 18, 19, 22, 23, 25, 26, 27, 28, 46, 55, 59, 61, 62, 72, 73, 74, 78, 79, 81, 83, 84, 85, 87, 88, 89], "subfield": 7, "dotpath": 7, "wish": 7, "exact": [7, 10, 85], "path": [7, 8, 9, 10, 22, 23, 24, 25, 26, 27, 28, 59, 60, 61, 62, 63, 75, 85, 87, 88], "normal": [7, 49, 51, 52, 59, 84, 88, 89], "python": [7, 60, 63, 66, 73, 77, 78, 85], "alpaca_dataset": [7, 22, 84], "custom": [7, 8, 24, 26, 82, 85, 86, 87, 88], "train_on_input": [7, 22, 23, 24, 25, 26, 27, 28, 84], "onc": [7, 85, 86, 87, 88, 89], "ve": [7, 48, 60, 84, 85, 87, 88], "instanc": [7, 10, 47, 53, 57, 58, 88], "cfg": [7, 8, 11, 12], "automat": [7, 9, 10, 24, 85, 89], "under": [7, 85, 87, 89], "preced": [7, 10, 87, 88], "actual": [7, 9], "throw": 7, "notic": [7, 84, 88], "miss": [7, 88], "posit": [7, 10, 46, 50, 51, 52, 87], "anoth": [7, 85], "handl": [7, 11, 59, 85, 88, 89], "def": [7, 8, 9, 11, 84, 88, 89], "dictconfig": [7, 8, 10, 11, 12, 73], "arg": [7, 10, 51, 53, 55, 63, 71], "tupl": [7, 10, 28, 53, 59, 60, 63, 67, 74], "kwarg": [7, 10, 53, 55, 63, 68, 70, 71, 72, 73, 76], "str": [7, 10, 13, 16, 17, 20, 22, 23, 24, 25, 26, 27, 28, 53, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 69, 70, 71, 72, 73, 75, 77], "mean": [7, 49, 86, 88], "pass": [7, 10, 24, 26, 46, 47, 53, 65, 68, 72, 73, 76, 88, 89], "add": [7, 9, 60, 63, 84, 85, 87, 88, 89], "d": [7, 46, 51, 52, 60, 84, 88], "llama2_token": [7, 85], "tmp": [7, 86, 87], "option": [7, 8, 13, 16, 17, 20, 24, 26, 28, 33, 34, 35, 36, 40, 41, 43, 46, 50, 51, 52, 53, 59, 60, 61, 62, 64, 65, 66, 70, 73, 75, 76, 77, 81, 82, 85], "bool": [7, 22, 23, 24, 25, 26, 27, 28, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 53, 56, 59, 60, 61, 62, 68, 72, 75, 89], "max_seq_len": [7, 10, 22, 23, 24, 26, 28, 46, 48, 50, 51, 59, 60, 84], "int": [7, 9, 22, 23, 24, 26, 28, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 48, 49, 50, 51, 54, 56, 59, 60, 61, 62, 67, 70, 71, 72, 73, 74, 77, 84, 88, 89], "512": [7, 22, 23, 84, 89], "instructdataset": [7, 22, 23, 25, 26, 27, 84], "alreadi": [7, 68, 81, 85, 88], "overwrit": [7, 81], "duplic": [7, 8, 82], "sometim": 7, "than": [7, 21, 28, 46, 85, 86, 87, 88, 89], "resolv": [7, 86], "alpaca": [7, 13, 22, 23, 33, 34, 35, 36, 40, 41, 84], "metric_logg": [7, 8, 9], "metric_log": [7, 9, 70, 71, 72, 73], "disklogg": 7, "log_dir": [7, 70, 72, 73], "conveni": [7, 8], "verifi": [7, 64, 65, 86, 88], "properli": 7, "experi": [7, 73, 80, 82, 87, 88], "wa": [7, 85, 87, 88, 89], "cp": [7, 81, 85, 86, 87], "7b_lora_single_devic": [7, 85, 86, 88, 89], "my_config": 7, "discuss": [7, 86, 88], "guidelin": 7, "while": [7, 8, 33, 34, 35, 36, 40, 41, 47, 82, 85, 89], "mai": [7, 9, 75, 84, 86, 88], "tempt": 7, "put": [7, 8, 86, 88], "much": [7, 85, 87, 88, 89], "give": [7, 88], "maximum": [7, 22, 23, 24, 26, 28, 46, 48, 50, 51, 60], "flexibl": [7, 84], "switch": 7, "encourag": [7, 88], "clariti": 7, "significantli": 7, "easier": [7, 85, 86], "dont": 7, "slimorca_dataset": 7, "privat": 7, "typic": [7, 89], "expos": [7, 8, 84, 86], "parent": 7, "modul": [7, 10, 28, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 76, 77, 86, 88, 89], "__init__": [7, 8, 88, 89], "py": [7, 10, 33, 34, 35, 36, 40, 41, 46, 48, 49, 50, 54, 85, 87], "guarante": 7, "stabil": [7, 82, 89], "underscor": 7, "_alpaca": 7, "collect": [7, 86], "differ": [7, 9, 59, 82, 85, 87, 88, 89], "itself": 7, "via": [7, 9, 56, 88, 89], "pair": [7, 74, 84], "k1": [7, 8], "v1": [7, 8], "k2": [7, 8], "v2": [7, 8], "lora_finetune_single_devic": [7, 85, 86, 87, 88, 89], "checkpoint": [7, 8, 53, 60, 61, 62, 73, 76, 82, 87, 88, 89], "home": 7, "my_model_checkpoint": 7, "file_1": 7, "file_2": 7, "my_tokenizer_path": 7, "class": [7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 24, 26, 28, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 62, 63, 70, 71, 72, 73, 84, 86, 88, 89], "assign": 7, "nest": 7, "dot": 7, "notat": [7, 46, 50, 51, 52], "core": [8, 82, 84, 86, 89], "i": [8, 18, 19, 53, 58, 60, 84, 85, 87, 89], "structur": [8, 14, 15, 18, 19, 84, 85], "new": [8, 44, 70, 72, 85, 86, 87, 88, 89], "user": [8, 14, 15, 18, 19, 21, 46, 59, 84, 86], "thought": [8, 82, 86, 89], "target": [8, 82], "pipelin": [8, 82], "llm": [8, 80, 82, 84, 85, 88], "eg": [8, 51, 61, 82], "meaning": [8, 82, 85], "featur": [8, 9, 81, 82, 85, 86], "fsdp": [8, 82, 86, 87], "activ": [8, 47, 76, 82, 89], "gradient": [8, 82, 85, 87, 88, 89], "accumul": [8, 82], "mix": [8, 85], "precis": [8, 53, 65, 82, 86, 89], "appli": [8, 33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 49, 50, 51, 52, 82, 89], "given": [8, 10, 17, 21, 56, 64, 65, 82, 88], "complex": 8, "becom": [8, 81, 84], "harder": 8, "anticip": 8, "architectur": [8, 18, 19, 51, 84], "methodolog": 8, "reason": [8, 85], "possibl": 8, "trade": 8, "off": [8, 59, 85], "memori": [8, 22, 23, 26, 53, 80, 82, 84, 85, 86, 87], "vs": [8, 86], "qualiti": [8, 85, 88], "believ": 8, "best": 8, "suit": [8, 86], "specif": [8, 10, 84, 85, 89], "b": [8, 46, 50, 51, 52, 56, 73, 88, 89], "fit": [8, 22, 23, 26], "solut": 8, "result": [8, 59, 85, 87, 88, 89], "meant": [8, 53], "depend": [8, 9, 13, 85, 88, 89], "level": [8, 66, 82, 89], "expertis": 8, "routin": 8, "yourself": [8, 87, 88], "exist": [8, 81, 84, 85, 86, 87, 89], "ad": [8, 59, 88, 89], "ones": 8, "modular": [8, 82], "build": [8, 24, 26, 82, 87, 88], "block": [8, 33, 34, 35, 36, 40, 41, 43, 82], "wandb": [8, 9, 73, 86], "log": [8, 66, 70, 71, 72, 73, 85, 86, 87, 89], "fulli": 8, "nativ": [8, 80, 82, 88, 89], "pytorch": [8, 51, 53, 72, 75, 77, 80, 81, 82, 87, 88, 89], "correct": [8, 16, 25, 49, 50, 51, 64, 82, 84], "numer": [8, 82], "pariti": [8, 82], "verif": 8, "extens": [8, 82], "comparison": [8, 88, 89], "benchmark": [8, 77, 82, 85, 87, 88], "limit": 8, "hidden": [8, 47], "behind": 8, "100": [8, 22, 23, 25, 27, 28, 74, 75, 88, 89], "flag": [8, 22, 23, 25, 27, 89], "prefer": [8, 82, 84], "over": [8, 54, 63, 82, 84, 85, 87, 88, 89], "unnecessari": 8, "abstract": [8, 14, 17, 82, 86, 89], "No": [8, 82], "inherit": [8, 63, 82], "go": [8, 18, 19, 59, 82, 84, 85, 86, 89], "upon": [8, 87], "figur": [8, 88, 89], "spectrum": 8, "decid": 8, "interact": [8, 80, 86], "start": [8, 9, 60, 81, 82, 84, 85, 86], "paradigm": 8, "consist": [8, 86], "configur": [8, 22, 23, 24, 25, 26, 27, 28, 52, 82, 86, 87, 88, 89], "paramet": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 68, 70, 71, 72, 73, 74, 75, 76, 77, 80, 82, 85, 86, 87, 88, 89], "overrid": [8, 11, 85, 86, 87, 89], "togeth": [8, 73, 86, 88], "valid": [8, 21, 81, 85, 86], "environ": [8, 81, 85, 86], "logic": [8, 61, 82, 86, 88], "api": [8, 9, 37, 42, 45, 85, 86, 87, 89], "closer": [8, 88], "monolith": [8, 82], "trainer": [8, 67], "A": [8, 9, 53, 56, 59, 60, 61, 63, 74, 79, 80, 83, 85, 88, 89], "wrapper": [8, 59, 60, 88], "around": [8, 59, 60, 75, 85, 88, 89], "extern": 8, "primarili": [8, 88], "eleutherai": [8, 82, 88], "har": [8, 82, 88], "control": [8, 22, 23, 25, 27, 77, 85], "multi": [8, 46, 87], "stage": 8, "distil": 8, "oper": [8, 75, 77], "turn": [8, 21, 60], "dataload": [8, 22, 23, 25, 27], "applic": [8, 46, 61, 62, 73], "clean": [8, 9, 22], "after": [8, 48, 49, 70, 71, 72, 73, 89], "process": [8, 9, 53, 77, 86, 89], "group": [8, 46, 70, 71, 72, 73, 87], "init_process_group": [8, 68], "backend": 8, "gloo": 8, "els": [8, 63, 73, 82, 89], "nccl": 8, "fullfinetunerecipedistribut": 8, "cleanup": 8, "other": [8, 10, 63, 84, 86, 87, 88], "stuff": 8, "carri": 8, "relev": [8, 85, 88], "interfac": [8, 14, 17, 55], "metric": [8, 86], "logger": [8, 66, 70, 71, 72, 73, 86], "self": [8, 9, 33, 34, 35, 36, 40, 41, 43, 46, 51, 52, 55, 84, 88, 89], "_devic": 8, "get_devic": 8, "_dtype": 8, "get_dtyp": 8, "ckpt_dict": 8, "wrap": [8, 75, 76], "_model": 8, "_setup_model": 8, "_token": [8, 84], "_setup_token": 8, "_optim": 8, "_setup_optim": 8, "_loss_fn": 8, "_setup_loss": 8, "_sampler": 8, "_dataload": 8, "_setup_data": 8, "backward": [8, 89], "zero_grad": 8, "curr_epoch": 8, "rang": [8, 77, 87], "epochs_run": [8, 9], "total_epoch": [8, 9], "idx": 8, "batch": [8, 22, 23, 25, 27, 46, 48, 50, 51, 52, 59, 74, 82, 84, 86, 87, 88], "enumer": 8, "_autocast": 8, "logit": 8, "label": [8, 22, 23, 24, 26, 28, 74], "total_training_step": 8, "_log_every_n_step": 8, "_metric_logg": 8, "log_dict": [8, 70, 71, 72, 73], "step": [8, 51, 54, 60, 70, 71, 72, 73, 75, 80, 85, 88, 89], "learn": [8, 54, 82, 84, 86, 87, 88, 89], "decor": [8, 11], "recipe_main": [8, 11], "none": [8, 9, 12, 13, 16, 17, 19, 20, 21, 24, 26, 46, 50, 51, 52, 58, 59, 60, 61, 62, 64, 65, 66, 70, 71, 72, 73, 76, 77, 85], "fullfinetunerecip": 8, "direct": [8, 81], "wandblogg": [9, 88, 89], "workspac": 9, "seen": [9, 88, 89], "screenshot": 9, "below": [9, 50, 84, 87, 88, 89], "packag": [9, 72, 73, 81], "pip": [9, 72, 73, 81, 85, 87], "Then": [9, 86], "login": [9, 73, 85], "built": [9, 81, 84, 86, 89], "project": [9, 33, 34, 35, 36, 40, 41, 43, 46, 47, 73, 80, 88, 89], "grab": [9, 87], "tab": 9, "tip": 9, "straggler": 9, "background": 9, "crash": 9, "otherwis": 9, "exit": [9, 81], "resourc": [9, 70, 71, 72, 73], "kill": 9, "ps": 9, "aux": 9, "grep": 9, "awk": 9, "xarg": 9, "click": 9, "sampl": [9, 13, 14, 15, 16, 17, 18, 19, 20, 26, 28, 84, 85], "desir": 9, "suggest": 9, "approach": [9, 84], "full_finetun": 9, "joinpath": 9, "_checkpoint": [9, 85], "_output_dir": [9, 61, 62], "torchtune_model_": 9, "with_suffix": 9, "wandb_at": 9, "artifact": 9, "type": [9, 10, 11, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 46, 48, 49, 50, 51, 52, 53, 56, 57, 59, 60, 61, 62, 65, 66, 67, 68, 75, 85, 88, 89], "descript": [9, 24, 28], "whatev": 9, "metadata": 9, "seed_kei": 9, "epochs_kei": 9, "total_epochs_kei": 9, "max_steps_kei": 9, "max_steps_per_epoch": 9, "add_fil": 9, "log_artifact": 9, "field": [10, 17, 22, 23, 25, 27], "hydra": 10, "facebook": 10, "research": 10, "http": [10, 24, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 44, 45, 46, 49, 50, 54, 61, 62, 63, 66, 72, 73, 75, 77, 81, 85], "com": [10, 33, 34, 35, 36, 40, 41, 46, 49, 50, 54, 81], "facebookresearch": [10, 49, 50], "blob": [10, 33, 34, 35, 36, 40, 41, 46, 49, 50, 54], "main": [10, 11, 46, 49, 50, 81, 85, 87], "_intern": 10, "_instantiate2": 10, "l148": 10, "omegaconf": 10, "num_lay": [10, 51], "32": [10, 87, 88, 89], "num_head": [10, 46, 48, 50, 51], "num_kv_head": [10, 46, 48], "vocab_s": 10, "must": [10, 22, 23, 24, 25, 26, 27, 28, 55, 60, 63, 89], "return": [10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44, 46, 49, 50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 74, 75, 77, 84, 88, 89], "nn": [10, 46, 47, 48, 51, 52, 53, 55, 57, 58, 76, 88, 89], "parsed_yaml": 10, "embed_dim": [10, 46, 50, 52, 88], "valueerror": [10, 19, 21, 24, 28, 46, 51, 61, 62, 65, 77], "callabl": [11, 51], "With": [11, 85, 88, 89], "my_recip": 11, "foo": 11, "bar": [11, 82, 86], "instanti": [12, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 43, 44], "configerror": 12, "cannot": [12, 87], "data": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 70, 71, 72, 73, 84, 85, 89], "prompt": [13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 51, 59, 84, 85, 87], "templat": [13, 14, 16, 17, 20, 22, 23, 25, 26, 27, 28], "style": [13, 22, 23, 24, 28, 89], "slightli": 13, "classmethod": [13, 14, 15, 16, 17, 18, 19, 20], "map": [13, 16, 17, 20, 26, 28, 58, 61, 70, 71, 72, 73, 85, 88], "column_map": [13, 16, 17, 20, 26, 28, 84], "placehold": [13, 14, 16, 17, 20, 26, 28], "column": [13, 16, 17, 20, 26, 28], "ident": [13, 16, 17, 19, 20, 26, 85], "role": [14, 59, 84], "system": [14, 15, 18, 19, 21, 59, 84], "assist": [14, 15, 18, 21, 59, 84], "messag": [14, 15, 18, 19, 21, 24, 59, 60, 81, 84], "accord": [14, 19], "openai": 15, "markup": 15, "languag": [15, 56, 88], "It": [15, 19, 84, 89], "huggingfac": [15, 24, 26, 54, 61, 62, 84, 85], "im_start": 15, "context": [15, 75, 84], "im_end": 15, "goe": 15, "respons": [15, 59, 84, 85, 86, 87], "appropri": [15, 18, 19, 54, 84, 89], "tag": [15, 18, 19, 60, 70, 71, 72, 73], "grammar": [16, 25, 84], "sentenc": 16, "alwai": [17, 63], "human": 18, "taken": [18, 88, 89], "inst": [18, 19, 84], "sy": [18, 84], "respect": [18, 58, 84], "honest": [18, 84], "am": [18, 19, 84, 85, 87], "pari": [18, 19, 84], "capit": [18, 19, 84], "franc": [18, 19, 84], "known": [18, 19, 59, 84], "its": [18, 19, 77, 84, 85, 87, 88], "stun": [18, 19, 84], "mistral": [19, 43, 44, 45, 85, 86], "llama2chatformat": [19, 28, 84], "summar": [20, 27, 84], "task": [20, 84, 85, 87, 88, 89], "dialogu": [20, 27], "dialog": 20, "forth": 21, "consecut": 21, "come": [21, 55, 88], "empti": 21, "shorter": 21, "length": [21, 22, 23, 26, 28, 46, 48, 50, 51, 52, 59, 60, 62, 74], "min": [21, 88], "invalid": 21, "yahma": 22, "codebas": [22, 23, 25, 27, 85], "where": [22, 23, 25, 27, 46, 51, 56, 59, 84], "mask": [22, 23, 25, 27, 46, 52, 59, 60, 84], "contribut": [22, 23, 25, 27], "replac": [22, 23, 25, 27, 53, 88], "encod": [22, 23, 24, 25, 26, 27, 28, 59, 60], "decod": [22, 23, 24, 25, 26, 27, 28, 51, 59, 60], "anyth": [22, 23, 24, 25, 26, 27, 28], "load_dataset": [22, 23, 24, 25, 26, 27, 28], "whether": [22, 23, 24, 25, 26, 27, 28, 33, 34, 35, 36, 40, 41, 43, 53, 56, 59, 60, 65], "recommend": [22, 23, 26, 72, 85, 89], "highest": [22, 23, 26], "sequenc": [22, 23, 26, 28, 46, 48, 50, 51, 52, 59, 60, 74], "alpaca_d": [22, 23], "batch_siz": [22, 23, 25, 27, 46, 52, 85], "tatsu": [23, 84], "lab": [23, 84], "conversation_styl": [24, 84], "chat_format": [24, 28, 84], "load_dataset_kwarg": [24, 26], "chatdataset": [24, 28], "made": [24, 26, 50, 85], "friendli": [24, 26], "co": [24, 26, 61, 62, 85], "doc": [24, 26, 63, 66, 72, 73, 75, 77, 85], "en": [24, 26], "package_refer": [24, 26], "loading_method": [24, 26], "sharegpt": [24, 84], "chatformat": [24, 28, 84], "liweili": 25, "c4_200m": 25, "variant": [25, 27], "mirror": [25, 27], "llama_recip": [25, 27], "grammar_d": 25, "variabl": [26, 28, 89], "disabl": [26, 77], "truncat": [26, 28, 59, 60], "samsum": 27, "summari": 27, "samsum_d": 27, "_util": 28, "open": [28, 29, 84, 85], "orca": [28, 84], "slimorca": [28, 84], "dedup": [28, 84], "_chat_format": 28, "1024": [28, 84], "adher": 28, "doesn": [28, 85], "prescrib": 28, "least": [28, 87, 88], "though": 28, "max": [28, 51, 54, 59, 88], "ds": 28, "10": [28, 74, 85, 87, 89], "351": 28, "82": [28, 85], "391": 28, "221": 28, "220": 28, "193": 28, "12": [28, 81], "471": 28, "gemma": 29, "gemmatransformerdecod": 29, "w": [29, 30, 31, 32, 38, 39, 44, 72, 73, 85, 88, 89], "blog": 29, "technolog": 29, "develop": [29, 89], "transformerdecod": [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 88], "arxiv": [30, 31, 32, 37, 42, 45, 46, 49, 50], "org": [30, 31, 32, 37, 42, 45, 46, 49, 50, 63, 66, 72, 75, 77, 81], "ab": [30, 31, 32, 37, 42, 45, 50], "2307": [30, 31, 32], "09288": [30, 31, 32], "lora_attn_modul": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 88, 89], "liter": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45], "q_proj": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 88, 89], "k_proj": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 88, 89], "v_proj": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 88, 89], "output_proj": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 88, 89], "apply_lora_to_mlp": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 88], "apply_lora_to_output": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 88], "lora_rank": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 88], "lora_alpha": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 88], "float": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 49, 54, 56, 70, 71, 72, 73, 88, 89], "16": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 88, 89], "quantize_bas": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 56, 89], "lora": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 56, 80, 82, 86, 87], "tloen": [33, 34, 35, 36, 40, 41], "8bb8579e403dc78e37fe81ffbb253c413007323f": [33, 34, 35, 36, 40, 41], "l41": [33, 34, 35, 36, 40, 41], "l43": [33, 34, 35, 36, 40, 41], "linear": [33, 34, 35, 36, 37, 40, 41, 42, 43, 45, 51, 55, 56, 88, 89], "attent": [33, 34, 35, 36, 40, 41, 43, 46, 48, 50, 51, 52, 87, 88, 89], "mlp": [33, 34, 35, 36, 40, 41, 43, 51, 52, 87, 88], "final": [33, 34, 35, 36, 40, 41, 43, 47, 51, 60, 85, 87, 88, 89], "rank": [33, 34, 35, 36, 40, 41, 43, 56, 67, 77, 86, 88, 89], "low": [33, 34, 35, 36, 40, 41, 43, 56, 85, 88, 89], "approxim": [33, 34, 35, 36, 40, 41, 43, 56, 88], "scale": [33, 34, 35, 36, 40, 41, 43, 56, 88, 89], "factor": [33, 34, 35, 36, 40, 41, 43, 56, 85], "lora_dropout": [34, 35, 37], "05": [34, 35, 37], "70b": [34, 38, 40], "llama2_7b": [34, 35, 88], "qlora": [37, 42, 45, 53, 80, 82, 87, 88], "per": [37, 42, 45, 48, 53, 87, 89], "paper": [37, 42, 45, 88, 89], "2305": [37, 42, 45, 46], "14314": [37, 42, 45], "lora_llama2_7b": [37, 88], "llama3": [38, 39, 40, 41, 42, 80], "llama3_70b": 40, "llama3_8b": [41, 87], "lora_llama3_8b": 42, "announc": 44, "lora_mistral_7b": 45, "head_dim": [46, 48, 50, 51], "pos_embed": [46, 88], "kv_cach": 46, "kvcach": [46, 51], "attn_dropout": [46, 51], "head": [46, 48, 50, 51, 87], "queri": [46, 48, 51, 87], "gqa": 46, "introduc": [46, 49, 56, 88, 89], "pdf": [46, 49], "13245v1": 46, "version": [46, 81, 87, 89], "multihead": 46, "mha": [46, 51], "n": [46, 59, 60, 79, 83, 84], "extrem": 46, "share": [46, 84, 85], "mqa": 46, "credit": 46, "document": 46, "lightn": 46, "lit": 46, "gpt": [46, 85], "lit_gpt": 46, "v": [46, 51, 88], "k": [46, 88], "q": [46, 88], "n_kv_head": 46, "dimens": [46, 48, 50, 51, 56, 87, 88, 89], "calcul": [46, 87], "e": [46, 53, 55, 58, 81, 85, 87, 88, 89], "g": [46, 55, 87, 88, 89], "rotarypositionalembed": [46, 88], "cach": [46, 48, 50, 81], "comput": [46, 47, 50, 51, 77, 85, 89], "rope": [46, 50], "dropout": [46, 56, 88, 89], "onto": 46, "scaled_dot_product_attent": 46, "input_po": [46, 50, 51, 52], "seq_length": [46, 52], "seq_len": [46, 50], "bigger": 46, "n_h": [46, 50], "num": [46, 50], "n_kv": 46, "kv": [46, 48, 51], "emb": [46, 51, 52], "h_d": [46, 50], "gate_proj": 47, "down_proj": 47, "up_proj": 47, "silu": 47, "feed": [47, 52], "network": [47, 88, 89], "deriv": [47, 51, 52], "fed": 47, "multipli": 47, "subclass": [47, 63], "although": [47, 88], "afterward": 47, "former": 47, "regist": [47, 53, 89], "hook": [47, 53, 89], "latter": 47, "max_batch_s": 48, "standalon": 48, "past": 48, "becaus": [48, 51, 85, 87], "expand": 48, "dpython": [48, 53], "ep": 49, "1e": 49, "06": [49, 88], "root": [49, 72, 73], "squar": 49, "1910": 49, "07467": 49, "verfic": [49, 50], "small": [49, 85], "avoid": [49, 53, 77, 89], "divis": 49, "zero": [49, 85, 87], "10000": 50, "rotari": [50, 87], "propos": 50, "2104": 50, "09864": 50, "l450": 50, "upto": 50, "init": [50, 73, 89], "exceed": 50, "freq": 50, "recomput": 50, "geometr": 50, "progress": [50, 86], "rotat": 50, "angl": 50, "bsz": 50, "todo": 50, "effici": [50, 80, 82, 85, 86, 88], "transformerdecoderlay": 51, "norm": [51, 52], "move": 51, "space": 51, "check": [51, 65, 80, 85, 86, 88], "belong": 51, "reduc": [51, 82, 84, 88, 89], "statement": 51, "improv": [51, 85, 87, 88], "readabl": [51, 85], "At": 51, "arang": 51, "prompt_length": 51, "causal_mask": 51, "m_": 51, "seq": 51, "attn": [52, 88, 89], "causalselfattent": [52, 88], "sa_norm": 52, "mlp_norm": 52, "ff": 52, "common_util": 53, "bfloat16": [53, 85, 86, 87, 88], "offload_to_cpu": 53, "nf4": [53, 89], "restor": 53, "higher": [53, 87, 89], "offload": [53, 89], "increas": [53, 54, 87, 88], "peak": [53, 85, 87, 88, 89], "gpu": [53, 85, 86, 87, 88, 89], "usag": [53, 81, 85, 86, 87, 89], "_register_state_dict_hook": 53, "m": [53, 60], "mymodul": 53, "_after_": 53, "nf4tensor": [53, 89], "unquant": [53, 85, 89], "unus": 53, "num_warmup_step": 54, "num_training_step": 54, "num_cycl": 54, "last_epoch": 54, "lambdalr": 54, "rate": [54, 82, 86], "schedul": [54, 75, 86], "linearli": 54, "lr": 54, "decreas": [54, 88, 89], "cosin": 54, "remain": [54, 88], "v4": 54, "23": [54, 87], "src": 54, "l104": 54, "warmup": [54, 75], "phase": 54, "total": [54, 67, 79, 83, 85, 87, 88], "wave": 54, "half": 54, "index": [54, 74, 81, 85], "last": 54, "lr_schedul": 54, "peft": [55, 56, 57, 58, 88, 89], "protocol": 55, "adapter_param": [55, 56, 57, 58], "correspond": [55, 57, 65, 86, 87], "proj": 55, "in_dim": [55, 56, 88, 89], "out_dim": [55, 56, 88, 89], "bia": [55, 56, 88, 89], "loralinear": [55, 88, 89], "alpha": [56, 88, 89], "use_bia": 56, "larg": [56, 89], "perturb": 56, "decomposit": [56, 88], "matric": [56, 88, 89], "trainabl": [56, 58, 88, 89], "mapsto": 56, "w_0x": 56, "r": [56, 60, 88], "bax": 56, "probabl": [56, 85], "lora_a": [56, 88, 89], "lora_b": [56, 88, 89], "subset": 57, "get_adapter_param": [58, 88], "sentencepieceprocessor": 59, "pretrain": [59, 60, 86, 88, 89], "non": 59, "spm_model": 59, "tokenized_text": 59, "hello": [59, 85, 87], "world": [59, 67, 85], "add_bo": [59, 60], "add_eo": [59, 60], "31587": 59, "29644": 59, "102": 59, "text": [59, 60, 84, 85], "trim_leading_whitespac": 59, "prefix": 59, "unbatch": 59, "prepend": [59, 60], "bo": [59, 60], "append": [59, 81], "eo": [59, 60], "trim": 59, "lead": 59, "whitespac": 59, "underli": [59, 89], "sentencepiec": [59, 87], "s1": 59, "s2": 59, "due": [59, 88, 89], "tokenize_messag": [59, 60, 84], "concaten": 59, "problem": 59, "slice": 59, "tokenizer_path": 59, "separ": [59, 61, 86, 87, 88, 89], "concat": 59, "1788": 59, "2643": 59, "13": [59, 85, 87, 89], "1792": 59, "9508": 59, "465": 59, "22137": 59, "2933": 59, "join": 59, "attribut": 59, "llama3_tiktoken": 60, "p": [60, 88, 89], "l": 60, "all_special_token": 60, "bos_token": 60, "begin_of_text": 60, "eos_token": 60, "end_of_text": 60, "start_header_id": 60, "end_header_id": 60, "step_id": 60, "eom_id": 60, "eot_id": 60, "python_tag": 60, "tiktoken": [60, 87], "identif": 60, "regex": 60, "special": 60, "element": [60, 85], "second": [60, 85, 87, 88, 89], "uniqu": 60, "256": [60, 84, 85, 87], "header": 60, "token_id": 60, "truncate_at_eo": 60, "tokenize_head": 60, "few": [61, 84, 87, 88, 89], "0001_of_0003": 61, "0002_of_0003": 61, "preserv": [61, 89], "weight_map": [61, 85], "intermediate_checkpoint": [61, 62], "parit": 61, "_weight_map": 61, "shard": [62, 87], "wip": 62, "argpars": 63, "argumentpars": 63, "builtin": 63, "said": 63, "noth": 63, "treat": 63, "still": [63, 88, 89], "consult": 63, "info": [63, 86], "librari": [63, 66, 77, 80, 82, 89], "html": [63, 66, 72, 75, 77], "parse_known_arg": 63, "namespac": 63, "act": 63, "precid": 63, "parse_arg": 63, "intern": 63, "properti": [63, 88], "too": [63, 87], "availab": 64, "machin": [64, 85], "distribut": [64, 68, 76, 77, 82, 86, 87], "bf16": [65, 89], "request": [65, 84, 85], "inde": [65, 85], "kernel": 65, "runtimeerror": [65, 68], "float32": 65, "done": [65, 88, 89], "isn": 65, "hardwar": [65, 82, 85, 88], "stream": 66, "handler": 66, "aka": 67, "filenam": 70, "log_": 70, "unixtimestamp": 70, "txt": [70, 86], "thread": 70, "safe": 70, "flush": [70, 71, 72, 73], "union": [70, 71, 72, 73, 77], "ndarrai": [70, 71, 72, 73], "scalar": [70, 71, 72, 73], "record": [70, 71, 72, 73], "payload": [70, 71, 72, 73], "dictionari": [70, 71, 72, 73, 85], "organize_log": 72, "tensorboard": 72, "stabl": [72, 75, 77, 81], "subdirectori": 72, "sub": 72, "compar": [72, 85, 88, 89], "logdir": 72, "startup": 72, "recurs": 72, "tree": [72, 84, 85], "tfevent": 72, "encount": 72, "frontend": 72, "organ": 72, "accordingli": 72, "my_log_dir": 72, "view": [72, 85, 86], "my_metr": [72, 73], "termin": [72, 73], "entiti": 73, "bias": 73, "ref": 73, "sent": 73, "usernam": 73, "individu": 73, "my_project": 73, "my_ent": 73, "my_group": 73, "importerror": 73, "account": [73, 88, 89], "log_config": 73, "local": [73, 77, 81, 85, 86], "link": [73, 85], "capecap": 73, "6053ofw0": 73, "torchtune_config_j67sb73v": 73, "padding_idx": 74, "ignore_idx": 74, "pad": 74, "longest": 74, "integ": [74, 77], "tokenpair": 74, "collat": 74, "token_pair": 74, "torchtune_perf_trac": 75, "contextmanag": 75, "wait": 75, "trace": 75, "speed": [75, 87, 89], "reduct": [75, 88], "auto_wrap_polici": 76, "polici": 76, "debug_mod": 77, "pseudo": 77, "random": [77, 86], "commonli": [77, 85, 88, 89], "numpi": 77, "own": [77, 84, 85, 88], "determinist": 77, "global": 77, "warn": 77, "nondeterminist": 77, "addition": [77, 88], "cudnn": 77, "set_deterministic_debug_mod": 77, "algorithm": 77, "outsid": [77, 85, 87, 88], "generated_examples_python": 78, "zip": 78, "galleri": [78, 83], "sphinx": 78, "000": [79, 83, 87], "execut": [79, 83], "generated_exampl": 79, "mem": [79, 83], "mb": [79, 83], "topic": 80, "gentl": 80, "introduct": 80, "readi": 80, "maxim": [80, 82], "workflow": [80, 84, 86, 88], "requisit": 81, "proper": [81, 86], "host": [81, 86], "page": [81, 82, 86, 87], "latest": [81, 86, 89], "confirm": 81, "And": [81, 85, 87], "h": 81, "ls": [81, 85, 86, 87], "welcom": 81, "show": [81, 88], "greatest": [81, 86], "contributor": 81, "cd": [81, 85], "even": [81, 87, 88, 89], "commit": 81, "branch": 81, "extra": [81, 88, 89], "url": 81, "whl": 81, "therebi": [81, 89], "howev": 81, "forc": 81, "reinstal": 81, "opt": [81, 86], "suffix": 81, "cu121": 81, "On": [82, 88], "pointer": 82, "author": [82, 86, 89], "emphas": 82, "aspect": 82, "simplic": 82, "component": 82, "reus": 82, "high": [82, 88], "prove": 82, "democrat": 82, "box": [82, 89], "zoo": 82, "varieti": [82, 88], "techniqu": [82, 85, 86, 88], "integr": [82, 85, 86, 87, 88, 89], "excit": 82, "checkout": 82, "quickstart": 82, "attain": 82, "better": [82, 84, 85], "chekckpoint": 82, "hyperparamet": [82, 86, 88, 89], "embodi": 82, "philosophi": 82, "especi": [82, 85], "usabl": 82, "composit": 82, "hard": 82, "outlin": 82, "unecessari": 82, "never": 82, "thoroughli": 82, "unit": 82, "know": [84, 85, 87, 88], "steer": 84, "wheel": 84, "publicli": 84, "great": [84, 85], "indic": 84, "iter": [84, 89], "knob": 84, "tweak": 84, "sai": [84, 86], "footprint": [84, 88], "could": [84, 88], "achiev": [84, 85, 87, 88, 89], "fix": 84, "goal": 84, "flavor": 84, "agnost": 84, "condit": 84, "respond": 84, "alpacainstructtempl": 84, "describ": 84, "further": [84, 88, 89], "classifi": 84, "anim": 84, "plant": 84, "miner": 84, "oak": 84, "copper": 84, "ore": 84, "eleph": 84, "instructtempl": 84, "instruct_dataset": 84, "mydataset": 84, "onthehub": 84, "customtempl": 84, "similar": [84, 85, 87, 88, 89], "quit": [84, 89], "similarli": 84, "chat_dataset": 84, "formatted_messag": 84, "nyou": 84, "incorpor": 84, "advanc": 84, "preferencedataset": 84, "rlhf": 84, "adjust": 84, "chosen": 84, "reject": 84, "chosen_messag": 84, "transformed_sampl": 84, "key_chosen": 84, "rejected_messag": 84, "key_reject": 84, "chosen_input_id": 84, "c_mask": 84, "chosen_label": 84, "np": 84, "cross_entropy_ignore_idx": 84, "rejected_input_id": 84, "r_mask": 84, "rejected_label": 84, "purpos": [84, 86, 87], "stack_exchanged_paired_dataset": 84, "had": 84, "lvwerra": 84, "stack": 84, "exchang": 84, "stackexchangedpairedtempl": 84, "question": [84, 85, 87], "response_j": 84, "response_k": 84, "data_dir": 84, "rl": 84, "favorit": [85, 87, 88], "commun": 85, "seemlessli": 85, "beyond": [85, 89], "connect": 85, "larger": [85, 87], "might": 85, "amount": 85, "natur": 85, "export": 85, "mobil": 85, "phone": 85, "leverag": [85, 87, 89], "mode": 85, "lot": 85, "plai": 85, "freez": [85, 88], "percentag": 85, "learnabl": 85, "keep": [85, 88], "16gb": [85, 88], "rtx": 85, "3090": 85, "4090": 85, "hour": 85, "full_finetune_single_devic": [85, 86], "7b_full_low_memori": [85, 86], "full_finetune_distribut": [85, 86], "7b_full": [85, 86], "13b_full": [85, 86], "7b_qlora_single_devic": [85, 86, 89], "473": 85, "98": [85, 89], "gb": [85, 87, 88, 89], "50": 85, "484": 85, "01": [85, 86], "fact": [85, 87, 88], "third": 85, "smaller": [85, 87, 88, 89], "But": [85, 87, 88], "realli": 85, "eleuther_ev": [85, 87], "eleuther_evalu": [85, 87], "lm_eval": [85, 87], "plan": 85, "copi": [85, 86, 87, 89], "custom_eval_config": [85, 87], "truthfulqa_mc2": [85, 87, 88], "measur": [85, 87], "propens": [85, 87], "answer": [85, 87], "shot": [85, 87], "accuraci": [85, 87, 88, 89], "baselin": [85, 88], "324": 85, "loglikelihood": 85, "195": 85, "121": 85, "27": 85, "197": 85, "acc": 85, "388": 85, "38": 85, "shown": 85, "489": 85, "48": [85, 89], "seem": 85, "custom_generation_config": [85, 87], "kick": 85, "top_k": 85, "300": 85, "temperatur": 85, "interest": 85, "site": 85, "visit": 85, "bai": 85, "area": 85, "92": [85, 87], "exploratorium": 85, "san": 85, "francisco": 85, "magazin": 85, "awesom": 85, "bridg": 85, "pretti": 85, "cool": 85, "96": [85, 89], "61": 85, "sec": [85, 87], "25": 85, "83": 85, "99": [85, 88], "15": [85, 88, 89], "72": 85, "littl": 85, "saw": 85, "took": [85, 87], "torchao": [85, 87, 89], "bit": [85, 87, 88, 89], "custom_quantization_config": [85, 87], "68": 85, "19": [85, 87, 89], "76": 85, "69": 85, "95": [85, 87], "67": 85, "4w": [85, 87], "unlik": [85, 87], "won": [85, 87], "engin": [85, 87], "fullmodeltorchtunecheckpoint": [85, 87], "int4weightonlyquant": [85, 87], "groupsiz": [85, 87], "did": [85, 87, 89], "park": 85, "sit": 85, "top": [85, 89], "hill": 85, "beauti": 85, "62": [85, 87], "17": [85, 88], "85": 85, "compil": [85, 87, 89], "hood": [85, 89], "sped": 85, "almost": [85, 87, 88], "3x": [85, 87], "benefit": 85, "yet": 85, "fast": 85, "clone": [85, 88, 89], "assumpt": 85, "satisfi": 85, "new_dir": 85, "output_dict": 85, "sd_1": 85, "sd_2": 85, "dump": 85, "convert_hf_checkpoint": 85, "checkpoint_path": 85, "my": [85, 87], "justin": 85, "school": 85, "math": 85, "teacher": 85, "ws": 85, "94": [85, 87], "103": 85, "28": 85, "bandwidth": [85, 87], "1391": 85, "84": 85, "thats": 85, "seamlessli": 85, "authent": [85, 86], "hopefulli": 85, "gave": 85, "launch": 86, "gate": 86, "grant": 86, "minut": 86, "agreement": 86, "altern": 86, "hackabl": 86, "singularli": 86, "focus": 86, "technic": 86, "depth": 86, "why": [86, 88], "principl": 86, "minim": [86, 88, 89], "boilerpl": 86, "hold": 86, "substanti": [86, 88], "custom_config": 86, "replic": 86, "lorafinetunerecipesingledevic": 86, "lora_finetune_output": 86, "log_1713194212": 86, "sampler": 86, "52": 86, "3697006702423096": 86, "25880": [86, 89], "24": [86, 87], "55": 86, "83it": 86, "were": 86, "monitor": 86, "tqdm": 86, "interv": 86, "e2": 86, "releas": 87, "128": [87, 88], "intermedi": [87, 89], "theta": 87, "gain": 87, "illustr": 87, "basic": 87, "8b_lora_single_devic": 87, "observ": 87, "18": 87, "consum": [87, 89], "vram": [87, 88], "overal": 87, "nproc_per_nod": [87, 88], "lora_finetune_distribut": [87, 88], "8b_lora": 87, "8b_qlora_single_devic": 87, "alloc": [87, 89], "coupl": [87, 88, 89], "llama3_token": 87, "122": 87, "sarah": 87, "busi": 87, "mum": 87, "young": 87, "children": 87, "live": 87, "north": 87, "east": 87, "england": 87, "135": 87, "88": 87, "138": 87, "346": 87, "09": 87, "139": 87, "31": 87, "been": 87, "far": 87, "drill": 87, "90": 87, "93": 87, "91": 87, "104": 87, "four": [87, 88], "again": 87, "jake": 87, "disciplin": 87, "artist": 87, "passion": 87, "draw": 87, "paint": 87, "57": [87, 88, 89], "speedup": 87, "broader": 87, "teach": 88, "straight": 88, "jump": 88, "neural": [88, 89], "unfamiliar": 88, "oppos": [88, 89], "momentum": 88, "adamw": 88, "arbitrari": 88, "relat": 88, "aghajanyan": 88, "et": 88, "al": 88, "hypothes": 88, "intrins": 88, "lower": 88, "down": [88, 89], "often": 88, "eight": 88, "practic": 88, "imag": 88, "simplifi": 88, "represent": [88, 89], "left": 88, "blue": 88, "rememb": 88, "approx": 88, "15m": 88, "8192": 88, "65k": 88, "requires_grad": [88, 89], "frozen_out": [88, 89], "lora_out": [88, 89], "omit": 88, "construct": 88, "base_model": 88, "choos": 88, "lora_model": 88, "lora_llama_2_7b": [88, 89], "alon": 88, "in_featur": 88, "out_featur": 88, "inplac": 88, "feel": 88, "free": 88, "strict": 88, "whenev": 88, "validate_state_dict_for_lora": 88, "peft_util": 88, "set_trainable_param": 88, "fetch": 88, "lora_param": 88, "total_param": 88, "sum": 88, "numel": 88, "trainable_param": 88, "2f": 88, "6742609920": 88, "4194304": 88, "nnode": 88, "7b_lora": 88, "my_model_checkpoint_path": [88, 89], "tokenizer_checkpoint": [88, 89], "my_tokenizer_checkpoint_path": [88, 89], "constraint": 88, "factori": 88, "benefici": 88, "long": 88, "impact": 88, "rel": 88, "minor": 88, "good": 88, "64": 88, "lora_experiment_1": 88, "smooth": [88, 89], "curv": [88, 89], "500": 88, "ran": 88, "commod": 88, "cogniz": 88, "ax": 88, "parallel": 88, "truthfulqa": 88, "previous": 88, "475": 88, "87": 88, "508": 88, "86": 88, "504": 88, "04": 88, "514": 88, "lowest": 88, "absolut": 88, "4gb": 88, "tradeoff": 88, "potenti": 88, "enhanc": 89, "maintain": 89, "highli": 89, "part": 89, "vanilla": 89, "held": 89, "therefor": 89, "bespok": 89, "normalfloat": 89, "8x": 89, "retain": 89, "vast": 89, "major": 89, "highlight": 89, "degrad": 89, "normatfloat": 89, "doubl": 89, "themselv": 89, "prune": 89, "deepdiv": 89, "idea": 89, "distinct": 89, "storag": 89, "datatyp": 89, "de": 89, "incur": 89, "counterpart": 89, "set_default_devic": 89, "qlora_linear": 89, "memory_alloc": 89, "177": 89, "152": 89, "byte": 89, "del": 89, "empty_cach": 89, "lora_linear": 89, "081": 89, "344": 89, "qlora_llama2_7b": 89, "qlora_model": 89, "essenti": 89, "reparametrize_as_dtype_state_dict_post_hook": 89, "entir": 89, "stat": 89, "reserv": 89, "against": 89, "35": 89, "40": 89, "29": 89, "slow": 89, "slower": 89, "149": 89, "9157477021217346": 89, "02": 89, "08": 89, "14": 89, "15it": 89, "thing": 89, "nightli": 89, "200": 89, "hundr": 89, "228": 89, "8158286809921265": 89, "59": 89, "95it": 89, "exercis": 89, "manual": 89, "portion": 89, "augment": 89, "linear_nf4": 89, "to_nf4": 89, "linear_weight": 89, "autograd": 89, "regular": 89, "incom": 89}, "objects": {"torchtune.config": [[10, 0, 1, "", "instantiate"], [11, 0, 1, "", "parse"], [12, 0, 1, "", "validate"]], "torchtune.data": [[13, 1, 1, "", "AlpacaInstructTemplate"], [14, 1, 1, "", "ChatFormat"], [15, 1, 1, "", "ChatMLFormat"], [16, 1, 1, "", "GrammarErrorCorrectionTemplate"], [17, 1, 1, "", "InstructTemplate"], [18, 1, 1, "", "Llama2ChatFormat"], [19, 1, 1, "", "MistralChatFormat"], [20, 1, 1, "", "SummarizeTemplate"], [21, 0, 1, "", "validate_messages"]], "torchtune.data.AlpacaInstructTemplate": [[13, 2, 1, "", "format"]], "torchtune.data.ChatFormat": [[14, 2, 1, "", "format"]], "torchtune.data.ChatMLFormat": [[15, 2, 1, "", "format"]], "torchtune.data.GrammarErrorCorrectionTemplate": [[16, 2, 1, "", "format"]], "torchtune.data.InstructTemplate": [[17, 2, 1, "", "format"]], "torchtune.data.Llama2ChatFormat": [[18, 2, 1, "", "format"]], "torchtune.data.MistralChatFormat": [[19, 2, 1, "", "format"], [19, 3, 1, "", "system"]], "torchtune.data.SummarizeTemplate": [[20, 2, 1, "", "format"]], "torchtune.datasets": [[22, 0, 1, "", "alpaca_cleaned_dataset"], [23, 0, 1, "", "alpaca_dataset"], [24, 0, 1, "", "chat_dataset"], [25, 0, 1, "", "grammar_dataset"], [26, 0, 1, "", "instruct_dataset"], [27, 0, 1, "", "samsum_dataset"], [28, 0, 1, "", "slimorca_dataset"]], "torchtune.models.gemma": [[29, 0, 1, "", "gemma_2b"]], "torchtune.models.llama2": [[30, 0, 1, "", "llama2_13b"], [31, 0, 1, "", "llama2_70b"], [32, 0, 1, "", "llama2_7b"], [33, 0, 1, "", "lora_llama2_13b"], [34, 0, 1, "", "lora_llama2_70b"], [35, 0, 1, "", "lora_llama2_7b"], [36, 0, 1, "", "qlora_llama2_13b"], [37, 0, 1, "", "qlora_llama2_7b"]], "torchtune.models.llama3": [[38, 0, 1, "", "llama3_70b"], [39, 0, 1, "", "llama3_8b"], [40, 0, 1, "", "lora_llama3_70b"], [41, 0, 1, "", "lora_llama3_8b"], [42, 0, 1, "", "qlora_llama3_8b"]], "torchtune.models.mistral": [[43, 0, 1, "", "lora_mistral_7b"], [44, 0, 1, "", "mistral_7b"], [45, 0, 1, "", "qlora_mistral_7b"]], "torchtune.modules": [[46, 1, 1, "", "CausalSelfAttention"], [47, 1, 1, "", "FeedForward"], [48, 1, 1, "", "KVCache"], [49, 1, 1, "", "RMSNorm"], [50, 1, 1, "", "RotaryPositionalEmbeddings"], [51, 1, 1, "", "TransformerDecoder"], [52, 1, 1, "", "TransformerDecoderLayer"], [54, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[46, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[47, 2, 1, "", "forward"]], "torchtune.modules.RMSNorm": [[49, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[50, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoder": [[51, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoderLayer": [[52, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[53, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[55, 1, 1, "", "AdapterModule"], [56, 1, 1, "", "LoRALinear"], [57, 0, 1, "", "get_adapter_params"], [58, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[55, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[56, 2, 1, "", "adapter_params"], [56, 2, 1, "", "forward"]], "torchtune.modules.tokenizers": [[59, 1, 1, "", "SentencePieceTokenizer"], [60, 1, 1, "", "TikTokenTokenizer"]], "torchtune.modules.tokenizers.SentencePieceTokenizer": [[59, 2, 1, "", "decode"], [59, 2, 1, "", "encode"], [59, 2, 1, "", "tokenize_messages"]], "torchtune.modules.tokenizers.TikTokenTokenizer": [[60, 2, 1, "", "decode"], [60, 2, 1, "", "encode"], [60, 2, 1, "", "tokenize_message"], [60, 2, 1, "", "tokenize_messages"]], "torchtune.utils": [[61, 1, 1, "", "FullModelHFCheckpointer"], [62, 1, 1, "", "FullModelMetaCheckpointer"], [63, 1, 1, "", "TuneRecipeArgumentParser"], [64, 0, 1, "", "get_device"], [65, 0, 1, "", "get_dtype"], [66, 0, 1, "", "get_logger"], [67, 0, 1, "", "get_world_size_and_rank"], [68, 0, 1, "", "init_distributed"], [69, 0, 1, "", "list_dtypes"], [74, 0, 1, "", "padded_collate"], [75, 0, 1, "", "profiler"], [76, 0, 1, "", "set_activation_checkpointing"], [77, 0, 1, "", "set_seed"]], "torchtune.utils.FullModelHFCheckpointer": [[61, 2, 1, "", "load_checkpoint"], [61, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[62, 2, 1, "", "load_checkpoint"], [62, 2, 1, "", "save_checkpoint"]], "torchtune.utils.TuneRecipeArgumentParser": [[63, 2, 1, "", "parse_known_args"]], "torchtune.utils.metric_logging": [[70, 1, 1, "", "DiskLogger"], [71, 1, 1, "", "StdoutLogger"], [72, 1, 1, "", "TensorBoardLogger"], [73, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[70, 2, 1, "", "close"], [70, 2, 1, "", "log"], [70, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[71, 2, 1, "", "close"], [71, 2, 1, "", "log"], [71, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[72, 2, 1, "", "close"], [72, 2, 1, "", "log"], [72, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[73, 2, 1, "", "close"], [73, 2, 1, "", "log"], [73, 2, 1, "", "log_config"], [73, 2, 1, "", "log_dict"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method", "3": "py:attribute"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 6, 80, 82, 85, 87, 88, 89], "config": [0, 7, 8, 86], "data": [1, 5], "dataset": [2, 84], "exampl": 2, "gener": [2, 85, 87], "builder": 2, "model": [3, 4, 9, 85, 86, 87, 88], "llama3": [3, 87], "llama2": [3, 85, 88, 89], "mistral": 3, "gemma": 3, "modul": 4, "compon": [4, 7], "build": [4, 81, 89], "block": 4, "token": 4, "peft": 4, "util": [4, 5], "checkpoint": [5, 6, 9, 85], "distribut": 5, "reduc": 5, "precis": 5, "memori": [5, 88, 89], "manag": 5, "perform": [5, 88], "profil": [5, 75], "metric": [5, 9], "log": [5, 9], "miscellan": 5, "overview": [6, 82, 85], "format": [6, 84], "handl": 6, "differ": 6, "intermedi": 6, "vs": 6, "final": 6, "lora": [6, 85, 88, 89], "put": [6, 89], "thi": 6, "all": [6, 7, 89], "togeth": [6, 89], "about": 7, "where": 7, "do": 7, "paramet": 7, "live": 7, "write": 7, "configur": [7, 84], "us": [7, 8, 85, 89], "instanti": [7, 10], "referenc": 7, "other": [7, 85], "field": 7, "interpol": 7, "valid": [7, 12], "your": [7, 8, 85, 86], "best": 7, "practic": 7, "airtight": 7, "public": 7, "api": 7, "onli": 7, "command": 7, "line": 7, "overrid": 7, "what": [8, 82, 88, 89], "ar": 8, "recip": [8, 86, 88], "script": 8, "class": 8, "run": [8, 85], "cli": 8, "pars": [8, 11], "weight": 9, "bias": 9, "logger": 9, "w": 9, "b": 9, "alpacainstructtempl": 13, "chatformat": 14, "chatmlformat": 15, "grammarerrorcorrectiontempl": 16, "instructtempl": 17, "llama2chatformat": 18, "mistralchatformat": 19, "summarizetempl": 20, "validate_messag": 21, "alpaca_cleaned_dataset": 22, "alpaca_dataset": 23, "chat_dataset": 24, "grammar_dataset": 25, "instruct_dataset": 26, "samsum_dataset": 27, "slimorca_dataset": 28, "gemma_2b": 29, "llama2_13b": 30, "llama2_70b": 31, "llama2_7b": 32, "lora_llama2_13b": 33, "lora_llama2_70b": 34, "lora_llama2_7b": 35, "qlora_llama2_13b": 36, "qlora_llama2_7b": 37, "llama3_70b": 38, "llama3_8b": 39, "lora_llama3_70b": 40, "lora_llama3_8b": 41, "qlora_llama3_8b": 42, "lora_mistral_7b": 43, "mistral_7b": 44, "qlora_mistral_7b": 45, "causalselfattent": 46, "todo": [46, 52], "feedforward": 47, "kvcach": 48, "rmsnorm": 49, "rotarypositionalembed": 50, "transformerdecod": 51, "transformerdecoderlay": 52, "reparametrize_as_dtype_state_dict_post_hook": 53, "get_cosine_schedule_with_warmup": 54, "adaptermodul": 55, "loralinear": 56, "get_adapter_param": 57, "set_trainable_param": 58, "sentencepiecetoken": 59, "tiktokentoken": 60, "fullmodelhfcheckpoint": 61, "fullmodelmetacheckpoint": 62, "tunerecipeargumentpars": 63, "get_devic": 64, "get_dtyp": 65, "get_logg": 66, "get_world_size_and_rank": 67, "init_distribut": 68, "list_dtyp": 69, "disklogg": 70, "stdoutlogg": 71, "tensorboardlogg": 72, "wandblogg": 73, "padded_col": 74, "set_activation_checkpoint": 76, "set_se": 77, "comput": [79, 83], "time": [79, 83], "welcom": 80, "document": 80, "get": [80, 87], "start": 80, "tutori": 80, "instal": 81, "instruct": [81, 84], "via": [81, 87], "pypi": 81, "git": 81, "clone": 81, "nightli": 81, "kei": 82, "concept": 82, "design": 82, "principl": 82, "fine": [84, 86, 87], "tune": [84, 86, 87], "custom": 84, "templat": 84, "chat": 84, "fulli": 84, "end": 85, "workflow": 85, "download": [85, 86], "7b": 85, "finetun": [85, 88, 89], "evalu": [85, 87], "eleutherai": [85, 87], "s": [85, 87], "eval": [85, 87], "har": [85, 87], "speed": 85, "up": 85, "quantiz": [85, 87], "librari": 85, "upload": 85, "hug": 85, "face": 85, "hub": 85, "first": 86, "llm": 86, "select": 86, "modifi": 86, "train": 86, "next": 86, "step": 86, "8b": 87, "access": 87, "text": 87, "our": 87, "faster": 87, "how": 88, "doe": 88, "work": 88, "appli": 88, "trade": 88, "off": 88, "qlora": 89, "save": 89, "deep": 89, "dive": 89, "from": 89}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})