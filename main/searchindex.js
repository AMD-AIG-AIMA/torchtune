Search.setIndex({"docnames": ["api_ref_config", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "examples/checkpointer", "examples/configs", "examples/finetune_llm", "examples/first_finetune_tutorial", "examples/lora_finetune", "examples/recipe_deepdive", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.Tokenizer", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.argparse.TuneRecipeArgumentParser", "generated/torchtune.utils.collate.padded_collate", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.logging.get_logger", "generated/torchtune.utils.memory.set_activation_checkpointing", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.precision.get_autocast", "generated/torchtune.utils.precision.get_dtype", "generated/torchtune.utils.precision.get_gradient_scaler", "generated/torchtune.utils.precision.list_dtypes", "generated/torchtune.utils.seed.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times"], "filenames": ["api_ref_config.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "examples/checkpointer.rst", "examples/configs.rst", "examples/finetune_llm.rst", "examples/first_finetune_tutorial.rst", "examples/lora_finetune.rst", "examples/recipe_deepdive.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.Tokenizer.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.argparse.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.collate.padded_collate.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.logging.get_logger.rst", "generated/torchtune.utils.memory.set_activation_checkpointing.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.precision.get_autocast.rst", "generated/torchtune.utils.precision.get_dtype.rst", "generated/torchtune.utils.precision.get_gradient_scaler.rst", "generated/torchtune.utils.precision.list_dtypes.rst", "generated/torchtune.utils.seed.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst"], "titles": ["torchtune.config", "torchtune.datasets", "torchtune.models.llama2", "torchtune.modules", "torchtune.utils", "Checkpointing in TorchTune", "Configs Deep-Dive", "LLM Full Finetuning Recipe", "Finetune your First LLM", "Finetuning Llama2 with LoRA", "Training Recipe Deep-Dive", "instantiate", "parse", "alpaca_cleaned_dataset", "alpaca_dataset", "grammar_dataset", "samsum_dataset", "slimorca_dataset", "llama2_7b", "lora_llama2", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "Tokenizer", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "padded_collate", "get_device", "get_world_size_and_rank", "init_distributed", "get_logger", "set_activation_checkpointing", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "get_autocast", "get_dtype", "get_gradient_scaler", "list_dtypes", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the TorchTune Documentation", "Install Instructions", "TorchTune Overview", "Computation times"], "terms": {"These": [3, 5, 6, 8, 9, 10, 11, 36], "ar": [3, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 19, 26, 31, 34, 35, 48, 55, 56], "common": [3, 6, 9], "can": [3, 5, 6, 7, 8, 9, 10, 11, 13, 14, 23, 24, 25, 34, 36, 45, 46, 54, 55, 56], "us": [3, 5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 34, 35, 36, 38, 43, 44, 45, 46, 47, 48, 49, 51, 54, 56], "all": [3, 6, 7, 8, 9, 10, 20, 21, 26, 28, 34, 36, 52, 54, 56, 57], "offer": 4, "allow": [4, 45], "seamless": 4, "transit": 4, "between": [4, 5, 9, 34], "format": [4, 8, 13, 14, 15, 16, 17, 34, 35], "train": [4, 5, 9, 13, 14, 15, 16, 17, 20, 29, 34, 35, 47, 48, 49, 54, 56], "interoper": [4, 5, 10, 56], "rest": 4, "ecosystem": [4, 5, 8, 10, 56], "For": [4, 5, 6, 7, 8, 9, 10, 13, 14, 19, 20, 26, 36, 46, 51], "comprehens": 4, "overview": [4, 6, 8, 9], "pleas": 4, "see": [4, 5, 7, 8, 9, 13, 22, 30, 36, 41, 46, 51, 55, 56], "tutori": [4, 5, 6, 7, 8, 10, 56], "enabl": [4, 6, 7, 8, 10, 31, 51], "work": [4, 5, 10, 36, 56], "set": [4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 24, 26, 33, 38, 42, 51, 56], "consumpt": 4, "dure": [4, 5, 7, 9, 13, 14, 15, 16, 20, 22, 24, 26, 27], "variou": 4, "dataset": [4, 6, 8, 9, 13, 14, 15, 16, 17, 56], "walk": [5, 7, 8, 10, 45, 56], "you": [5, 6, 7, 8, 9, 10, 11, 13, 14, 36, 45, 46, 54, 55, 56], "through": [5, 6, 7, 8, 10, 21, 56], "design": [5, 10], "behavior": 5, "associ": [5, 6, 9, 10], "util": [5, 6, 7, 8, 10, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 56], "what": [5, 6, 8, 54], "cover": 5, "deep": [5, 7, 8, 9, 54, 56], "dive": [5, 7, 8, 9, 54, 56], "how": [5, 6, 7, 8, 10, 54], "we": [5, 6, 7, 9, 10, 13, 14, 20, 22, 24, 25, 26, 31, 34, 35, 48, 56], "them": [5, 6, 7, 9, 21, 25, 28], "scenario": 5, "full": [5, 6, 8, 9, 10, 25, 34, 35, 54, 56], "finetun": [5, 6, 10, 13, 14, 50, 54, 56], "compos": 5, "compon": [5, 8, 9, 10, 56], "which": [5, 9, 10, 13, 14, 15, 16, 19, 20, 24, 25, 26, 27, 29, 34, 35, 43, 48, 49, 55, 56], "plug": 5, "ani": [5, 6, 7, 9, 10, 11, 12, 25, 28, 32, 33, 34, 35, 51], "recip": [5, 6, 11, 12, 15, 16, 21, 34, 35, 54, 55, 56], "evalu": [5, 8, 9, 10, 56], "gener": [5, 9, 10, 17, 25, 51, 52], "each": [5, 8, 9, 10, 19, 20, 24, 25, 26, 51, 56], "support": [5, 7, 8, 10, 11, 13, 14, 15, 16, 19, 20, 31, 35, 47, 48, 50, 56], "model": [5, 6, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 42, 54, 56], "make": [5, 6, 8, 9, 10, 20, 27, 56], "easi": [5, 8, 9, 10, 56], "understand": [5, 6, 8, 9, 10, 54, 56], "debug": [5, 6, 10], "extend": [5, 10, 56], "befor": [5, 10, 26, 27, 31, 34], "let": [5, 6, 8, 9], "s": [5, 6, 7, 8, 9, 10, 12, 19, 20, 24, 26, 27, 28, 30, 32, 34, 35, 38, 45, 54, 56], "defin": [5, 6, 9, 10, 21, 30, 31, 32], "some": [5, 6, 8, 9, 19, 32, 33, 54, 56], "concept": 5, "In": [5, 6, 7, 9, 10, 24, 31, 45, 46], "ll": [5, 6, 8, 10, 56], "talk": 5, "about": [5, 9, 10, 34, 46, 56], "take": [5, 6, 8, 9, 10, 11, 21, 22, 28, 34, 36, 38], "close": [5, 9, 10, 43, 44, 45, 46], "look": [5, 6, 7, 8, 9, 10, 45], "veri": [5, 26], "simpli": [5, 6], "dictat": 5, "state_dict": [5, 9, 28, 34, 35], "store": [5, 9, 43], "file": [5, 6, 8, 9, 10, 11, 12, 13, 14, 25, 34, 35, 36, 43, 53, 56, 57], "disk": [5, 43], "weight": [5, 8, 9, 10, 19, 20, 28, 30, 31, 34, 35, 46], "string": [5, 25, 30, 38, 48], "kei": [5, 6, 9, 19, 20, 22, 26, 33, 34], "identifi": 5, "state": [5, 9, 10, 28, 32, 33, 34, 35], "dict": [5, 6, 10, 11, 28, 32, 33, 34, 35, 40], "If": [5, 6, 8, 9, 10, 13, 14, 15, 16, 17, 19, 20, 28, 31, 34, 35, 38, 40, 45, 46, 48, 51], "identif": 5, "don": [5, 6, 7, 51], "t": [5, 6, 7, 17, 48, 51], "match": [5, 9], "up": [5, 8, 9, 10, 13, 14], "exactli": 5, "those": [5, 9], "definit": [5, 9], "either": [5, 9, 34], "run": [5, 6, 7, 8, 9, 12, 19, 21, 22, 26, 28, 34, 35, 45, 46, 55, 56], "explicit": 5, "error": [5, 6, 13, 34, 51, 55], "load": [5, 7, 9, 10, 34, 35, 36, 45], "rais": [5, 11, 17, 20, 26, 34, 35, 40, 46, 48, 51], "an": [5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20, 26, 30, 32, 33, 34, 35, 56], "except": 5, "wors": 5, "silent": [5, 21], "succe": 5, "infer": [5, 20, 22, 24, 26, 27], "expect": [5, 6, 9, 11, 24, 46], "addit": [5, 6, 9, 10, 11, 34, 35, 40, 42, 43, 45, 46, 48, 56], "line": [5, 8, 10, 36], "also": [5, 6, 8, 9, 10, 11, 19, 20, 26, 31, 38], "need": [5, 6, 8, 9, 10, 17, 20, 21, 26, 45, 46], "shape": [5, 20, 22, 24, 26, 27, 31], "valu": [5, 6, 7, 9, 17, 18, 19, 20, 22, 23, 26, 29, 34, 36, 43, 44, 45, 46, 51], "two": [5, 6, 8, 9, 56], "popular": [5, 8, 56], "llama2": [5, 6, 7, 8, 10, 11, 13, 14, 17, 18, 19, 21, 25, 26, 27, 54, 56], "meta": [5, 8, 15, 16, 34, 35], "offici": [5, 8], "implement": [5, 7, 9, 10, 13, 14, 15, 16, 17, 21, 23, 24, 29, 30, 31, 34, 45, 56], "when": [5, 6, 9, 10, 12, 26, 28, 29, 45], "download": [5, 9, 52, 55], "7b": [5, 7, 8, 9, 13, 14, 18, 34, 35], "from": [5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 25, 26, 27, 29, 30, 32, 34, 35, 36, 45, 46, 53, 57], "llama": [5, 7, 8, 15, 16, 23, 24, 34, 35], "websit": 5, "get": [5, 6, 8, 9, 10, 25, 39, 41, 48, 56], "access": [5, 6, 8, 34], "singl": [5, 6, 9, 11, 20, 34, 35], "pth": [5, 7, 8], "inspect": [5, 9], "content": [5, 25], "easili": [5, 6, 9, 56], "torch": [5, 7, 8, 9, 10, 22, 26, 28, 29, 38, 40, 42, 47, 48, 51], "import": [5, 6, 8, 9, 11, 45, 46], "consolid": [5, 7, 8], "00": [5, 7, 8, 53, 57], "mmap": 5, "true": [5, 6, 7, 8, 9, 13, 14, 15, 16, 25, 28, 34, 35, 40, 45], "weights_onli": 5, "map_loc": 5, "cpu": [5, 28, 48], "tensor": [5, 9, 20, 21, 22, 23, 24, 26, 27, 28, 31, 34, 37, 43, 44, 45, 46], "item": 5, "print": [5, 9, 13, 14, 15, 16, 17, 25], "f": [5, 9, 13, 14, 15, 16], "tok_embed": [5, 26], "size": [5, 7, 10, 11, 13, 14, 15, 16, 18, 20, 22, 23, 24, 25, 26, 27, 39, 56], "32000": [5, 11], "4096": [5, 9, 11, 13, 14, 20, 24], "len": [5, 13, 14, 15, 16, 26], "292": 5, "The": [5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 23, 24, 25, 28, 29, 34, 36, 38, 41, 48, 51, 56], "contain": [5, 9, 20, 22, 24, 25, 26, 27, 30, 32, 33, 34, 35, 36, 37, 45], "includ": [5, 6, 8, 9, 10, 31, 34, 35, 36, 56], "input": [5, 7, 9, 13, 14, 15, 16, 17, 20, 21, 23, 24, 25, 26, 27, 31, 34, 37, 51], "embed": [5, 19, 20, 22, 23, 24, 26], "tabl": [5, 9], "call": [5, 8, 9, 11, 21, 28, 36, 43, 44, 45, 46], "layer": [5, 9, 19, 20, 26, 27, 31, 56], "token": [5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 19, 20, 24, 26, 27], "have": [5, 6, 8, 9, 11, 20, 22, 30, 36, 45], "dim": [5, 20, 21, 23, 24, 26, 27], "hf": [5, 8, 34], "most": [5, 6, 8, 9], "within": [5, 6, 11, 17, 19, 21, 45, 51], "hug": [5, 8, 13, 14, 15, 16, 17, 29, 56], "face": [5, 8, 13, 14, 15, 16, 17, 29, 56], "hub": [5, 8], "default": [5, 6, 7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 29, 31, 34, 35, 36, 37, 43, 48, 51], "everi": [5, 10, 21, 45], "config": [5, 7, 9, 11, 12, 20, 34, 36, 56], "2": [5, 7, 8, 9, 17, 20, 25, 34, 35, 37, 51], "repo": [5, 34, 35], "first": [5, 6, 9, 11, 26, 34, 36, 54, 56], "big": 5, "split": 5, "across": [5, 10, 34, 45, 51], "bin": 5, "To": [5, 6, 7, 8, 9, 10, 34, 55, 56], "correctli": [5, 8, 10, 34, 55], "piec": 5, "one": [5, 9, 10, 21, 25, 55], "pytorch_model": 5, "00001": 5, "00002": 5, "embed_token": 5, "241": 5, "Not": 5, "onli": [5, 7, 9, 10, 19, 20, 24, 25, 26, 27, 31, 32, 35, 36, 48, 55], "doe": [5, 30, 34, 36], "fewer": [5, 20], "sinc": [5, 6, 7, 11, 21, 34], "instead": [5, 7, 21, 22, 31], "mismatch": 5, "name": [5, 6, 30, 33, 34, 35, 36, 38, 43, 44, 45, 46], "caus": [5, 25], "try": [5, 6, 9], "same": [5, 6, 9, 19, 20, 22, 25, 27, 36], "As": [5, 6, 9, 10, 31, 56], "re": [5, 6, 8, 9, 10, 56], "care": [5, 9, 21, 34], "like": [5, 6, 7, 8, 9, 10], "end": [5, 8, 10, 25, 56], "number": [5, 9, 10, 13, 14, 17, 19, 20, 22, 26, 29, 34, 35, 39, 51], "just": [5, 8, 9, 56], "save": [5, 9, 10, 34, 35], "less": [5, 7, 8, 17], "prone": 5, "manag": [5, 47], "invari": 5, "accept": [5, 6, 8, 17, 25], "multipl": [5, 6, 10, 31, 43, 44, 45, 46], "sourc": [5, 6, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52], "worri": 5, "explicitli": [5, 9, 30, 56], "convert": [5, 8, 34, 37], "time": [5, 25, 43, 45], "produc": 5, "back": [5, 9, 34], "origin": [5, 9, 13, 14, 28, 31], "form": [5, 6, 10, 13], "One": 5, "advantag": [5, 9], "being": [5, 34, 35, 38, 49], "should": [5, 6, 8, 9, 10, 19, 20, 21, 30, 36, 43, 44, 45, 46, 55, 56], "abl": [5, 8, 10], "fine": [5, 7, 8, 9, 10, 13, 14, 54, 56], "tune": [5, 6, 7, 8, 9, 10, 12, 13, 14, 54, 55, 56], "post": [5, 10], "tool": [5, 8], "quantiz": [5, 10, 19, 31], "eval": [5, 56], "without": [5, 6, 7, 9, 56], "code": [5, 26, 52, 56], "chang": [5, 6, 7, 8], "OR": 5, "convers": [5, 9, 34, 56], "script": [5, 8], "wai": [5, 6, 8, 55], "surround": [5, 10, 56], "load_checkpoint": [5, 10, 34, 35], "save_checkpoint": [5, 10, 34, 35], "method": [5, 6, 9, 10, 12, 13, 14, 15, 16, 17, 28, 30, 32, 36, 56], "convertor": 5, "avail": [5, 8, 9, 36, 38, 56], "here": [5, 6, 8, 9, 23, 24], "three": [5, 8, 10], "hfcheckpoint": 5, "read": [5, 34, 35, 56], "write": [5, 8, 10, 34, 35, 43], "compat": [5, 8, 34], "transform": [5, 9, 10, 19, 26, 27, 29], "framework": [5, 10, 56], "mention": 5, "abov": [5, 9, 28], "assum": [5, 9, 29, 32, 48], "checkpoint_dir": [5, 6, 7, 8, 34, 35], "necessari": [5, 9, 17, 43, 44, 45, 46], "json": [5, 34], "easiest": [5, 8], "sure": [5, 6, 8, 9], "everyth": [5, 8, 10, 36, 56], "follow": [5, 7, 8, 9, 10, 20, 29, 54, 55], "flow": 5, "By": [5, 9], "ignor": [5, 20, 21], "safetensor": 5, "output": [5, 8, 9, 13, 14, 15, 17, 19, 20, 21, 23, 24, 26, 27, 31, 33, 44, 55], "dir": [5, 8], "output_dir": [5, 6, 7, 8, 9, 34, 35], "specifi": [5, 6, 8, 10, 11, 19, 20], "argument": [5, 6, 7, 8, 9, 11, 17, 20, 36, 40, 42, 43, 45, 46, 55], "snippet": 5, "explain": 5, "setup": [5, 6, 9, 10, 26, 42], "_component_": [5, 6, 7, 8, 9, 11], "fullmodelhfcheckpoint": 5, "directori": [5, 6, 8, 34, 35, 43, 45], "sort": [5, 34], "id": [5, 13, 14, 17, 25, 34, 37], "so": [5, 6, 8, 9, 34, 36, 56], "order": [5, 8, 10, 34, 45, 46], "matter": [5, 9, 34], "checkpoint_fil": [5, 6, 7, 8, 9, 34, 35], "restart": [5, 7], "previou": [5, 34, 35], "more": [5, 6, 7, 8, 9, 10, 13, 22, 24, 36, 46, 51, 56], "next": 5, "section": [5, 10, 54], "recipe_checkpoint": [5, 7, 8, 34, 35], "null": [5, 6, 7, 8, 47], "usual": [5, 7, 9, 24, 34], "model_typ": [5, 7, 8, 34, 35], "resume_from_checkpoint": [5, 7, 8, 34, 35], "fals": [5, 6, 7, 8, 9, 13, 14, 15, 16, 17, 19, 20, 25, 31, 34, 35, 49], "requir": [5, 6, 17, 34, 45, 46, 51, 55], "param": [5, 9, 10, 31, 32, 33, 34], "directli": [5, 6, 8, 9, 11, 34], "help": [5, 8, 26, 34, 36, 54, 56], "ensur": [5, 6, 17, 19, 20, 34, 48, 56], "out": [5, 6, 7, 9, 13, 14, 15, 16, 34, 35, 54, 56], "case": [5, 9, 10, 19, 20, 34, 43, 48, 49, 56], "discrep": [5, 34], "along": 5, "detail": [5, 8, 9, 13, 22, 51], "found": [5, 6, 9, 23, 24], "metacheckpoint": 5, "github": [5, 13, 14, 15, 16, 20, 23, 24, 29, 55], "repositori": [5, 8], "fullmodelmetacheckpoint": [5, 7, 8], "torchtunecheckpoint": 5, "perform": [5, 9, 21, 56], "current": [5, 8, 19, 20, 24, 26, 27, 35, 39, 43, 45, 51, 55], "test": [5, 6, 10, 56], "complet": [5, 8, 10], "written": [5, 6, 10, 34, 35, 43, 44, 45, 46, 56], "begin": [5, 7, 25], "partit": 5, "ha": [5, 9, 25, 30, 32], "standard": [5, 44, 56], "key_1": 5, "weight_1": 5, "key_2": 5, "weight_2": 5, "mid": 5, "chekpoint": 5, "middl": 5, "inform": [5, 7, 8, 46, 56], "subsequ": [5, 10], "recipe_st": [5, 34, 35], "pt": [5, 34, 35], "epoch": [5, 7, 8, 9, 10, 29, 34, 35], "optim": [5, 6, 7, 8, 9, 10, 29], "etc": [5, 10, 34], "prevent": 5, "flood": 5, "overwritten": 5, "note": [5, 6, 9, 25, 26, 30, 34, 36, 48, 51], "updat": [5, 6, 7, 8, 9, 10], "hf_model_0001_0": 5, "hf_model_0002_0": 5, "both": [5, 9], "adapt": [5, 9, 30, 31, 32, 33, 34, 35], "merg": [5, 11, 34], "would": [5, 6, 9, 26], "our": [5, 9, 10, 56], "primari": [5, 6, 8, 10], "want": [5, 6, 7, 9, 11], "resum": [5, 10, 29, 34, 35], "initi": [5, 8, 9, 10, 12, 18, 25, 40], "frozen": [5, 9], "base": [5, 9, 17, 19, 24, 29, 31, 33, 34, 36, 43, 47], "well": [5, 6, 10, 56], "learnt": 5, "someth": [5, 7, 10], "NOT": 5, "refer": [5, 6, 7, 9, 10, 23, 24, 47, 56], "adapter_checkpoint": [5, 34, 35], "adapter_0": 5, "now": [5, 8, 9, 25], "knowledg": 5, "creat": [5, 6, 11, 13, 14, 15, 16, 18, 22, 29, 34, 35, 43, 45], "simpl": [5, 8, 54], "forward": [5, 9, 10, 20, 21, 23, 24, 26, 27, 31], "13b": 5, "modeltyp": [5, 34, 35], "llama2_13b": 5, "right": [5, 8, 9, 34], "pytorch_fil": 5, "00003": 5, "torchtune_sd": 5, "load_state_dict": [5, 9], "successfulli": 5, "vocab": [5, 11, 26], "70": 5, "x": [5, 9, 20, 21, 23, 24, 26, 27, 31], "randint": 5, "0": [5, 8, 9, 10, 19, 20, 25, 26, 29, 31, 37, 45, 46, 51, 53, 57], "1": [5, 7, 8, 9, 10, 17, 20, 25, 26, 29, 35, 37, 45, 46, 51], "no_grad": 5, "6": [5, 23, 37], "3989": 5, "9": 5, "0531": 5, "3": [5, 7, 36, 37, 41], "2375": 5, "5": [5, 7, 8, 29, 37], "2822": 5, "4": [5, 6, 7, 17, 20, 37, 56], "4872": 5, "7469": 5, "8": [5, 9, 13, 14, 15, 16], "6737": 5, "11": 5, "0023": 5, "8235": 5, "6819": 5, "2424": 5, "0109": 5, "6915": 5, "7": [5, 37], "3618": 5, "1628": 5, "8594": 5, "5857": 5, "1151": 5, "7808": 5, "2322": 5, "8850": 5, "9604": 5, "7624": 5, "6040": 5, "3159": 5, "5849": 5, "8039": 5, "9322": 5, "2010": 5, "6824": 5, "8929": 5, "8465": 5, "3794": 5, "3500": 5, "6145": 5, "5931": 5, "do": [5, 8, 9, 10, 46], "find": [5, 8, 10], "list": [5, 6, 8, 13, 14, 17, 19, 25, 30, 31, 34, 35, 36, 37, 41, 50], "builder": [5, 18], "hope": 5, "provid": [5, 6, 8, 10, 11, 17, 26, 36, 56], "deeper": 5, "insight": 5, "happi": 5, "thi": [6, 7, 8, 9, 10, 11, 13, 14, 17, 19, 20, 21, 24, 25, 26, 27, 28, 29, 30, 34, 35, 36, 38, 43, 45, 46, 51, 54, 56], "guid": [6, 7, 8, 9], "learn": [6, 7, 8, 9, 10, 29, 56], "yaml": [6, 8, 9, 10, 11, 12, 36, 56], "pars": [6, 8, 11, 36], "effect": 6, "cli": [6, 8, 12], "prerequisit": [6, 8, 9], "Be": [6, 8, 9], "familiar": [6, 8, 9], "torchtun": [6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 55], "instal": [6, 8, 9, 45, 46, 54], "fundament": 6, "There": [6, 9, 55], "entri": [6, 8, 10], "point": [6, 7, 8, 9, 10], "locat": [6, 9], "thei": [6, 9, 26, 36], "truth": 6, "reproduc": 6, "overridden": [6, 21, 36], "quick": 6, "experiment": 6, "modifi": [6, 9, 10, 28, 56], "serv": [6, 9], "particular": [6, 17], "seed": [6, 8, 10, 51], "shuffl": [6, 7, 8], "devic": [6, 7, 8, 10, 38, 47, 48], "cuda": [6, 7, 8, 38, 48], "dtype": [6, 7, 8, 10, 22, 28, 47, 48, 50], "fp32": 6, "enable_fsdp": 6, "mani": 6, "object": [6, 11, 20, 47, 49], "keyword": [6, 11, 17, 28], "loss": [6, 7, 8, 9, 10, 13, 14, 15, 16], "function": [6, 11, 12, 20, 21, 28, 38, 39, 51, 56], "exampl": [6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 25, 30, 34, 35, 37, 45, 46, 52, 53, 57], "subfield": 6, "dotpath": 6, "wish": 6, "exact": [6, 11], "path": [6, 7, 8, 9, 10, 11, 25, 34, 35, 36], "normal": [6, 9, 23, 25, 26, 27], "python": [6, 36, 41, 46, 51, 52], "alpaca_dataset": [6, 7, 8, 13], "custom": [6, 8, 9, 10, 56], "train_on_input": [6, 7, 13, 14, 15, 16, 17], "onc": [6, 8, 9], "ve": [6, 9, 22], "instanc": [6, 9, 11, 13, 14, 19, 21, 25, 28, 32, 33], "cfg": [6, 10, 12], "automat": [6, 11], "under": [6, 10], "preced": [6, 9, 11], "actual": 6, "throw": 6, "notic": [6, 9], "miss": [6, 9], "posit": [6, 11, 20, 24, 26, 27], "anoth": 6, "handl": [6, 9, 12, 25], "def": [6, 9, 10, 12], "dictconfig": [6, 10, 11, 12], "arg": [6, 10, 11, 26, 28, 30, 36, 44], "tupl": [6, 11, 17, 25, 28, 36, 37, 39], "kwarg": [6, 11, 28, 30, 36, 40, 42, 43, 44, 45, 46], "str": [6, 11, 25, 28, 30, 31, 32, 33, 34, 35, 36, 38, 41, 43, 44, 45, 46, 48, 50, 51], "mean": [6, 8, 9, 23], "pass": [6, 9, 11, 18, 19, 20, 21, 28, 40, 42, 45, 46, 48], "add": [6, 9, 36], "d": [6, 9, 20, 26, 27], "llama2_token": [6, 7, 8], "tmp": [6, 7, 8], "option": [6, 8, 10, 18, 19, 20, 24, 25, 26, 27, 28, 34, 35, 38, 41, 42, 43, 46, 48, 51, 55, 56], "bool": [6, 13, 14, 15, 16, 17, 19, 25, 28, 31, 34, 35, 40, 45, 49], "max_seq_len": [6, 7, 11, 13, 14, 17, 19, 20, 22, 24, 25, 26], "int": [6, 9, 13, 14, 17, 18, 19, 20, 22, 23, 24, 25, 26, 29, 31, 34, 35, 37, 39, 43, 44, 45, 46, 51], "512": [6, 7, 13, 14], "instructdataset": [6, 13, 14, 15, 16], "alreadi": [6, 8, 9, 40], "overwrit": 6, "duplic": [6, 56], "sometim": 6, "than": [6, 8, 9, 17, 20], "resolv": 6, "alpaca": [6, 7, 8, 9, 13, 14], "metric_logg": [6, 10], "metric_log": [6, 43, 44, 45, 46], "disklogg": 6, "log_dir": [6, 43, 45], "conveni": [6, 10], "quickli": 6, "verifi": [6, 8, 9, 38, 48], "properli": 6, "experi": [6, 9, 54, 56], "wa": [6, 9], "7b_full": [6, 8], "batch_siz": [6, 7, 8, 13, 14, 15, 16, 20, 27], "discuss": [6, 9], "guidelin": 6, "while": [6, 8, 10, 21, 56], "mai": [6, 8, 9], "tempt": 6, "put": [6, 8, 9, 10], "much": [6, 9], "give": [6, 9], "maximum": [6, 7, 13, 14, 17, 18, 19, 20, 22, 24, 26], "flexibl": 6, "switch": 6, "encourag": 6, "clariti": 6, "significantli": 6, "easier": [6, 8], "dont": 6, "slimorca_dataset": 6, "privat": 6, "typic": 6, "expos": [6, 8, 10], "parent": 6, "modul": [6, 9, 11, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 42, 51], "__init__": [6, 9, 10], "py": [6, 12, 13, 14, 15, 16, 20, 22, 23, 24, 29], "guarante": 6, "stabil": [6, 56], "underscor": 6, "_alpaca": 6, "collect": [6, 8], "differ": [6, 7, 9, 25, 56], "itself": 6, "via": [6, 9, 31], "pair": [6, 7, 37], "k1": [6, 10], "v1": [6, 10], "k2": [6, 10], "v2": [6, 10], "full_finetun": 6, "gpu": [6, 7, 8, 9], "full_finetune_distribut": [6, 7, 8], "checkpoint": [6, 7, 8, 9, 10, 34, 35, 42, 54, 56], "home": 6, "my_model_checkpoint": 6, "file_1": 6, "file_2": 6, "class": [6, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 30, 31, 32, 33, 34, 35, 36, 43, 44, 45, 46], "assign": 6, "nest": 6, "dot": 6, "notat": [6, 20, 24, 26, 27], "my_config": 6, "paramet": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 56], "supervis": 7, "given": [7, 9, 10, 11, 31, 38, 48, 56], "compris": 7, "label": [7, 10, 13, 14, 17, 37], "cross": 7, "entropi": 7, "lot": 7, "expens": 7, "effici": [7, 9, 24, 54, 56], "techniqu": [7, 9, 56], "lora": [7, 13, 14, 19, 31, 54, 56], "result": [7, 8, 10, 25], "higher": [7, 28], "qualiti": [7, 10], "mix": [7, 10, 47, 49, 56], "precis": [7, 10, 28, 47, 48, 49, 50, 56], "distribut": [7, 8, 38, 40, 42, 51, 56], "fsdp": [7, 8, 10, 49, 56], "activ": [7, 8, 10, 21, 42, 56], "aspect": [7, 56], "llama2_7b": [7, 8, 9], "sgd": [7, 8], "lr": [7, 8, 29], "2e": 7, "nn": [7, 8, 9, 11, 20, 21, 22, 26, 27, 28, 30, 32, 33, 42], "crossentropyloss": [7, 8], "bf16": [7, 8, 48], "enable_activation_checkpoint": [7, 8], "launch": [7, 8, 10], "tunecli": [7, 10], "nnode": [7, 8, 9], "nproc_per_nod": [7, 8, 9], "stanford": [7, 13, 14], "relat": [7, 9], "data": [7, 13, 14, 15, 16, 17, 43, 44, 45, 46], "mask": [7, 13, 14, 15, 16, 20, 25, 27], "prompt": [7, 13, 14, 15, 16, 17, 25, 26], "truncat": [7, 17, 25], "after": [7, 10, 22, 23, 43, 44, 45, 46], "sequenc": [7, 13, 14, 17, 19, 20, 22, 24, 25, 26, 27, 37], "length": [7, 13, 14, 17, 19, 20, 22, 24, 25, 26, 27, 35, 37], "limit": 7, "memori": [7, 9, 10, 13, 14, 42], "usag": [7, 55], "i": [7, 10, 28, 33], "e": [7, 20, 28, 30, 33, 55], "go": [7, 8, 25, 56], "down": [7, 8, 9], "slower": 7, "tokenizer_checkpoint": [7, 9], "path_to_model_token": 7, "batch": [7, 10, 13, 14, 15, 16, 18, 20, 22, 24, 25, 26, 27, 37, 56], "local": [7, 8, 51, 55], "global": [7, 51], "comput": [7, 19, 20, 21, 24, 26, 51], "num_gpu": 7, "gradient_accumulation_step": 7, "correspond": [7, 9, 30, 32, 48], "accumul": [7, 10, 56], "control": [7, 10, 13, 14, 15, 16, 51], "previous": 7, "incomplet": 7, "adam": 7, "known": [7, 25], "better": [7, 8, 56], "And": [7, 55], "process": [8, 10, 28, 51], "job": [8, 51], "integr": [8, 56], "latest": 8, "greatest": 8, "gate": 8, "grant": 8, "instruct": [8, 9, 13, 14, 54], "page": [8, 56], "host": 8, "minut": 8, "agreement": 8, "signup": 8, "author": [8, 56], "authent": 8, "Then": 8, "command": [8, 9, 10, 36, 55], "other": [8, 9, 10, 11, 13, 36], "respons": [8, 25], "user": [8, 10, 19, 20, 25], "thought": [8, 10, 56], "pipelin": [8, 10, 56], "consist": [8, 10], "configur": [8, 9, 10, 13, 14, 15, 16, 17, 27, 56], "overrid": [8, 10, 12], "dataclass": [8, 10], "core": [8, 10, 56], "logic": [8, 9, 10, 34, 56], "api": [8, 10], "togeth": [8, 9, 10], "valid": [8, 10], "environ": [8, 10], "basic": 8, "hold": 8, "hyperparamet": [8, 9, 56], "metric": [8, 10], "logger": [8, 10, 41, 43, 44, 45, 46], "wandb": [8, 10, 46], "new": [8, 9, 10, 43, 45], "exist": [8, 10], "copi": 8, "Or": 8, "visit": 8, "specif": [8, 10, 11], "past": [8, 22], "It": 8, "alpaca_llama_full_finetun": 8, "seem": 8, "good": [8, 9], "place": 8, "start": [8, 56], "cp": 8, "custom_config": 8, "random": [8, 51], "replic": 8, "lower": [8, 9], "sooner": 8, "rate": [8, 29, 56], "42": 8, "1e": [8, 19, 23], "proper": 8, "suit": [8, 10], "pytorch": [8, 9, 10, 17, 26, 28, 45, 47, 51, 54, 55, 56], "torchrun": [8, 10], "therefor": 8, "immedi": 8, "indic": 8, "succesfulli": 8, "log": [8, 10, 41, 43, 44, 45, 46], "log_1707246452": 8, "txt": [8, 43], "manual": [8, 9], "rank": [8, 9, 19, 31, 39, 51], "sampler": 8, "7553404569625854": 8, "13000": 8, "03": 8, "closer": [8, 9, 10], "teach": 9, "show": 9, "know": 9, "straight": 9, "your": [9, 11, 45, 46, 54, 56], "own": [9, 51], "jump": 9, "trainabl": [9, 31, 33], "low": [9, 19, 31], "decomposit": [9, 31], "matric": [9, 31], "neural": 9, "network": [9, 21], "freez": 9, "remain": [9, 29], "commonli": [9, 51], "linear": [9, 19, 26, 30, 31], "project": [9, 19, 20, 21, 46, 54], "self": [9, 10, 19, 20, 26, 27, 30], "attent": [9, 19, 20, 22, 24, 26, 27], "unfamiliar": 9, "check": [9, 26, 48, 54], "approxim": [9, 19, 31], "oppos": 9, "due": [9, 25], "substanti": 9, "reduct": 9, "gradient": [9, 10, 49, 56], "momentum": 9, "adamw": 9, "further": 9, "come": [9, 30], "primarili": [9, 10], "peak": 9, "its": [9, 15, 16, 19, 51], "reduc": [9, 26], "replac": [9, 13, 14, 15, 16, 28], "arbitrari": 9, "in_dim": [9, 30, 31], "out_dim": [9, 30, 31], "could": 9, "high": [9, 56], "min": 9, "paper": 9, "aghajanyan": 9, "et": 9, "al": 9, "hypothes": 9, "intrins": 9, "dimens": [9, 19, 20, 22, 24, 26, 31], "llm": [9, 10, 54, 56], "fact": 9, "properti": [9, 36], "A": [9, 10, 25, 28, 31, 34, 37, 53, 54, 57], "b": [9, 10, 20, 24, 26, 27, 31], "smaller": 9, "often": 9, "four": 9, "eight": 9, "practic": 9, "imag": 9, "below": [9, 24], "simplifi": 9, "represent": [9, 17], "step": [9, 10, 26, 29, 43, 44, 45, 46, 54], "left": 9, "compar": [9, 45], "blue": 9, "although": [9, 21], "introduc": [9, 20, 23, 31], "few": [9, 34], "extra": 9, "r": [9, 31], "rememb": 9, "q": [9, 20], "k": [9, 20], "v": [9, 20, 26], "approx": 9, "15m": 9, "8192": 9, "65k": 9, "over": [9, 10, 29, 36, 56], "99": 9, "minim": 9, "nativ": [9, 10, 54, 56], "loralinear": [9, 30], "alpha": [9, 31], "float": [9, 19, 20, 23, 29, 31, 43, 44, 45, 46], "dropout": [9, 19, 20, 31], "pretrain": 9, "bia": [9, 30, 31], "lora_a": [9, 31], "lora_b": [9, 31], "p": 9, "requires_grad": 9, "frozen_out": 9, "lora_out": 9, "final": [9, 19, 21, 26], "scale": [9, 19, 31], "return": [9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 47, 48, 49, 50, 51], "around": [9, 10, 25], "omit": 9, "favorit": 9, "With": [9, 12], "varieti": [9, 56], "construct": 9, "lora_llama2_7b": 9, "build": [9, 10, 56], "base_model": 9, "choos": 9, "q_proj": [9, 19, 20], "k_proj": [9, 19, 20], "v_proj": [9, 19, 20], "output_proj": [9, 19, 20], "lora_model": 9, "lora_attn_modul": [9, 19], "lora_llama_2_7b": 9, "alon": 9, "bit": 9, "attn": [9, 27], "causalselfattent": [9, 27], "in_featur": 9, "out_featur": 9, "pos_embed": [9, 20], "rotarypositionalembed": [9, 20], "inplac": 9, "addition": [9, 51], "type": [9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 31, 32, 34, 35, 39, 40, 41, 47, 48, 49], "transformerdecod": [9, 18, 19], "feel": 9, "free": 9, "yourself": [9, 10], "why": 9, "wrapper": [9, 10, 25], "strict": 9, "whenev": 9, "peft": [9, 30, 31, 32, 33], "validate_state_dict_for_lora": 9, "peft_util": 9, "get_adapter_param": [9, 33], "set_trainable_param": 9, "fetch": 9, "lora_param": 9, "total": [9, 29, 39, 53, 57], "total_param": 9, "sum": 9, "numel": 9, "trainable_param": 9, "100": [9, 10, 13, 14, 15, 16, 17, 37], "2f": 9, "6742609920": 9, "4194304": 9, "06": [9, 23], "relev": [9, 10], "taken": 9, "vram": 9, "least": [9, 17], "23gb": 9, "lora_finetune_distribut": 9, "done": [9, 48], "ad": [9, 10, 25], "my_model_checkpoint_path": 9, "my_tokenizer_checkpoint_path": 9, "7b_lora": 9, "clone": [9, 55], "depend": [9, 10], "constraint": 9, "hardwar": [9, 56], "coupl": 9, "factori": 9, "lora_rank": [9, 19], "lora_alpha": [9, 19], "16": 9, "benefici": 9, "increas": [9, 29], "32": [9, 11], "max": [9, 17, 25, 26, 29], "long": 9, "keep": 9, "embed_dim": [9, 11, 19, 20, 24, 27], "impact": 9, "rel": 9, "minor": 9, "64": 9, "lora_experiment_1": 9, "comparison": 9, "smooth": 9, "curv": 9, "baselin": 9, "500": 9, "seen": 9, "figur": 9, "w": [9, 18, 45, 46], "wandblogg": 9, "similar": 9, "account": [9, 46], "separ": [9, 25, 34], "exercis": 9, "task": 9, "longer": 9, "structur": 10, "target": [10, 56], "eg": [10, 26, 34, 56], "meaning": [10, 56], "featur": [10, 56], "appli": [10, 19, 20, 23, 24, 26, 27, 56], "famili": [10, 56], "complex": 10, "becom": 10, "harder": 10, "anticip": 10, "architectur": [10, 26], "methodolog": 10, "reason": 10, "possibl": 10, "trade": 10, "off": [10, 25], "vs": 10, "believ": 10, "best": 10, "fit": [10, 13, 14], "solut": 10, "meant": [10, 28], "level": [10, 41, 56], "expertis": 10, "routin": 10, "ones": 10, "modular": [10, 56], "block": [10, 19, 56], "wrap": [10, 42], "monolith": [10, 56], "trainer": [10, 39], "flag": [10, 13, 14, 15, 16], "extern": 10, "fulli": 10, "eleutherai": [10, 56], "har": [10, 56], "oper": [10, 51], "export": 10, "multi": [10, 20], "stage": 10, "distil": 10, "extract": 10, "turn": 10, "dataload": [10, 13, 14, 15, 16], "applic": [10, 20, 34, 35, 46, 47], "clean": [10, 13], "hood": 10, "parser": 10, "tunerecipeargumentpars": 10, "_": 10, "parse_known_arg": [10, 36], "var": 10, "recipe_param": 10, "fullfinetuneparam": 10, "env": 10, "variabl": 10, "group": [10, 20, 43, 44, 45, 46], "init_process_group": [10, 40], "backend": 10, "nccl": 10, "fullfinetunerecip": 10, "cleanup": 10, "stuff": 10, "carri": 10, "interfac": [10, 30], "_devic": 10, "get_devic": 10, "_dtype": 10, "get_dtyp": 10, "ckpt_dict": 10, "ckpt_path": 10, "model_checkpoint": 10, "_resume_from_checkpoint": 10, "_update_recipe_st": 10, "_model": 10, "_setup_model": 10, "_token": 10, "_setup_token": 10, "_optim": 10, "_setup_optim": 10, "_loss_fn": 10, "_setup_loss": 10, "_sampler": 10, "_dataload": 10, "_setup_data": 10, "backward": 10, "zero_grad": 10, "curr_epoch": 10, "rang": [10, 51], "epochs_run": 10, "total_epoch": 10, "idx": 10, "enumer": 10, "_autocast": 10, "logit": 10, "total_training_step": 10, "_log_every_n_step": 10, "_metric_logg": 10, "log_dict": [10, 43, 44, 45, 46], "decor": [10, 12], "recipe_main": [10, 12], "none": [10, 19, 20, 24, 25, 26, 27, 33, 34, 35, 38, 41, 42, 43, 44, 45, 46, 48, 51], "direct": 10, "field": [11, 13, 14, 15, 16], "num_lay": [11, 19, 26], "num_head": [11, 19, 20, 22, 24, 26], "num_kv_head": [11, 19, 20, 22], "vocab_s": [11, 19, 25], "must": [11, 13, 14, 15, 16, 17, 30, 36], "parsed_yaml": 11, "omegaconf": 11, "valueerror": [11, 17, 20, 26, 34, 35, 48, 51], "callabl": [12, 26], "main": [12, 13, 14, 15, 16, 20, 23, 24], "my_recip": 12, "foo": 12, "bar": [12, 56], "http": [13, 14, 15, 16, 17, 18, 20, 23, 24, 29, 34, 35, 36, 41, 45, 46, 47, 51, 55], "huggingfac": [13, 14, 15, 16, 17, 29, 34, 35], "co": [13, 14, 15, 16, 17, 34, 35], "yahma": 13, "tatsu": [13, 14], "lab": [13, 14], "templat": [13, 14, 15, 16, 17], "codebas": [13, 14, 15, 16], "com": [13, 14, 15, 16, 20, 23, 24, 29, 55], "stanford_alpaca": [13, 14], "blob": [13, 14, 15, 16, 20, 23, 24, 29], "761dc5bfbdeeffa89b8bff5d038781a4055f796a": [13, 14], "l31": [13, 14], "where": [13, 14, 15, 16, 20, 25, 26, 31], "ref": [13, 14, 46], "tloen": [13, 14], "l49": [13, 14], "contribut": [13, 14, 15, 16], "version": [13, 19, 20], "remov": 13, "hallucin": 13, "poorli": 13, "wrong": 13, "answer": 13, "card": 13, "encod": [13, 14, 15, 16, 17, 25], "decod": [13, 14, 15, 16, 17, 19, 25, 26], "whether": [13, 14, 15, 16, 17, 19, 25, 28, 31, 48, 49], "tab": [13, 14], "readm": [13, 14], "ov": [13, 14], "recommend": [13, 14, 45], "highest": [13, 14], "alpaca_d": [13, 14], "grammar": 15, "variant": [15, 16], "liweili": 15, "c4_200m": 15, "descript": 15, "llama_recip": [15, 16], "src": [15, 16, 29], "l50": 15, "grammar_d": 15, "summar": 16, "samsum": 16, "l13": 16, "dialogu": 16, "summari": 16, "samsum_d": 16, "1024": 17, "chatdataset": 17, "slimorca": 17, "open": 17, "orca": 17, "dedup": 17, "adher": 17, "chat": 17, "doesn": 17, "prescrib": 17, "though": 17, "ds": 17, "10": [17, 37], "sampl": 17, "351": 17, "82": 17, "391": 17, "221": 17, "220": 17, "193": 17, "12": 17, "471": 17, "arxiv": [18, 20, 23, 24], "org": [18, 20, 23, 24, 36, 41, 45, 47, 51], "ab": [18, 24], "2307": 18, "09288": 18, "max_batch_s": [18, 22], "kvcach": [18, 19, 20, 26], "instanti": [18, 19], "liter": 19, "apply_lora_to_mlp": 19, "apply_lora_to_output": 19, "intermediate_dim": 19, "attn_dropout": [19, 20, 26], "norm_ep": 19, "05": 19, "lora_dropout": 19, "quantize_bas": [19, 31], "mlp": [19, 26, 27], "vocabulari": [19, 25], "queri": [19, 20, 22, 26], "head": [19, 20, 22, 24, 26], "mha": [19, 20, 26], "onto": [19, 20], "scaled_dot_product_attent": [19, 20], "intermedi": 19, "scale_hidden_dim_for_mlp": 19, "epsilon": 19, "rm": 19, "norm": [19, 26, 27], "factor": [19, 31], "probabl": [19, 31], "subset": [19, 32], "head_dim": [20, 22, 24, 26], "kv_cach": 20, "gqa": 20, "pdf": [20, 23], "2305": 20, "13245v1": 20, "multihead": 20, "n": [20, 25, 53, 57], "extrem": 20, "share": 20, "mqa": 20, "credit": 20, "document": 20, "lightn": 20, "ai": [20, 46], "lit": 20, "gpt": 20, "lit_gpt": 20, "n_kv_head": 20, "calcul": 20, "g": [20, 30], "cach": [20, 22, 24], "rope": [20, 24], "input_po": [20, 24, 26, 27], "seq_length": [20, 27], "seq_len": [20, 24], "bigger": 20, "n_h": [20, 24], "num": [20, 24], "n_kv": 20, "kv": [20, 22, 26], "emb": [20, 26, 27], "h_d": [20, 24], "gate_proj": 21, "down_proj": 21, "up_proj": 21, "silu": 21, "feed": [21, 27], "deriv": [21, 26, 27], "hidden": 21, "fed": 21, "multipli": 21, "subclass": [21, 36], "afterward": 21, "former": 21, "regist": [21, 28], "hook": [21, 28], "latter": 21, "standalon": 22, "becaus": [22, 26], "expand": 22, "per": [22, 28], "dpython": [22, 28, 47], "ep": 23, "root": [23, 45], "squar": 23, "1910": 23, "07467": 23, "correct": [23, 24, 26, 38, 56], "verfic": [23, 24], "facebookresearch": [23, 24], "small": 23, "avoid": [23, 51], "divis": 23, "zero": 23, "10000": 24, "rotari": 24, "propos": 24, "2104": 24, "09864": 24, "l450": 24, "upto": 24, "init": [24, 46], "exceed": 24, "freq": 24, "recomput": 24, "geometr": 24, "progress": 24, "rotat": 24, "angl": 24, "bsz": 24, "todo": 24, "made": 24, "spm_model": 25, "sentencepieceprocessor": 25, "bos_id": 25, "eos_id": 25, "pad_id": 25, "sentencepiec": 25, "sentenc": 25, "pad": [25, 37], "non": 25, "from_fil": 25, "tokenized_text": 25, "hello": 25, "world": [25, 39], "add_bo": 25, "add_eo": 25, "31587": 25, "29644": 25, "102": 25, "text": 25, "trim_leading_whitespac": 25, "prefix": 25, "unbatch": 25, "prepend": 25, "bo": 25, "append": 25, "eo": 25, "trim": 25, "lead": 25, "whitespac": 25, "underli": 25, "s1": 25, "s2": 25, "classmethod": 25, "tokenize_messag": 25, "messag": 25, "concaten": 25, "problem": 25, "slice": 25, "tokenizer_path": 25, "role": 25, "system": 25, "assist": 25, "concat": 25, "1788": 25, "2643": 25, "13": 25, "1792": 25, "9508": 25, "465": 25, "22137": 25, "2933": 25, "join": 25, "attribut": 25, "transformerdecoderlay": 26, "move": 26, "space": 26, "belong": 26, "statement": 26, "improv": 26, "readabl": 26, "At": 26, "arang": 26, "prompt_length": 26, "causal_mask": 26, "m_": 26, "seq": 26, "sa_norm": 27, "mlp_norm": 27, "ff": 27, "common_util": 28, "bfloat16": 28, "offload_to_cpu": 28, "nf4": 28, "restor": 28, "offload": 28, "_register_state_dict_hook": 28, "m": 28, "mymodul": 28, "_after_": 28, "nf4tensor": 28, "unquant": 28, "unus": 28, "num_warmup_step": 29, "num_training_step": 29, "num_cycl": 29, "last_epoch": 29, "lambdalr": 29, "schedul": 29, "linearli": 29, "decreas": 29, "cosin": 29, "v4": 29, "23": 29, "l104": 29, "warmup": 29, "phase": 29, "wave": 29, "half": [29, 47], "index": [29, 37], "last": 29, "lr_schedul": 29, "appropri": 29, "protocol": 30, "adapter_param": [30, 31, 32, 33], "proj": 30, "use_bia": 31, "larg": 31, "languag": 31, "perturb": 31, "mapsto": 31, "w_0x": 31, "bax": 31, "map": [33, 34, 43, 44, 45, 46], "respect": 33, "0001_of_0003": 34, "0002_of_0003": 34, "preserv": 34, "weight_map": 34, "intermediate_checkpoint": [34, 35], "_output_dir": [34, 35], "parit": 34, "_weight_map": 34, "shard": [35, 49], "wip": 35, "argpars": 36, "tunerecipeargpars": 36, "argumentpars": 36, "builtin": [36, 47], "noth": 36, "treat": 36, "still": 36, "els": [36, 56], "consult": 36, "doc": [36, 41, 45, 46, 47, 51], "info": 36, "librari": [36, 41, 51, 54, 56], "html": [36, 41, 45, 47, 51], "namespac": 36, "act": 36, "alwai": 36, "precid": 36, "parse_arg": 36, "intern": 36, "inherit": [36, 56], "too": 36, "collat": 37, "padding_idx": 37, "ignore_idx": 37, "longest": 37, "integ": [37, 51], "tokenpair": 37, "token_pair": 37, "availab": 38, "machin": 38, "aka": 39, "runtimeerror": 40, "stream": 41, "handler": 41, "auto_wrap_polici": 42, "polici": 42, "filenam": 43, "log_": 43, "unixtimestamp": 43, "thread": 43, "safe": 43, "resourc": [43, 44, 45, 46], "flush": [43, 44, 45, 46], "union": [43, 44, 45, 46, 49, 51], "ndarrai": [43, 44, 45, 46], "scalar": [43, 44, 45, 46], "tag": [43, 44, 45, 46], "record": [43, 44, 45, 46], "payload": [43, 44, 45, 46], "dictionari": [43, 44, 45, 46], "organize_log": 45, "tensorboard": 45, "stabl": [45, 47, 51], "subdirectori": 45, "sub": 45, "logdir": 45, "startup": 45, "recurs": 45, "tree": 45, "tfevent": 45, "encount": 45, "frontend": 45, "organ": 45, "accordingli": 45, "my_log_dir": 45, "view": 45, "my_metr": [45, 46], "packag": [45, 46, 55], "pip": [45, 46, 55], "termin": [45, 46], "entiti": 46, "bias": 46, "my_project": 46, "my_ent": 46, "my_group": 46, "importerror": 46, "login": 46, "contextmanag": 47, "intellig": 47, "determin": 47, "autocast": 47, "amp": 47, "otherwis": 47, "context": 47, "request": 48, "inde": 48, "kernel": 48, "float32": 48, "isn": 48, "gradscal": 49, "shardedgradscal": 49, "scaler": 49, "awar": 49, "debug_mod": 51, "pseudo": 51, "numpi": 51, "determinist": 51, "warn": 51, "nondeterminist": 51, "cudnn": 51, "benchmark": [51, 56], "disabl": 51, "set_deterministic_debug_mod": 51, "algorithm": 51, "outsid": 51, "generated_examples_python": 52, "zip": 52, "galleri": [52, 57], "sphinx": 52, "000": [53, 57], "execut": [53, 57], "generated_exampl": 53, "mem": [53, 57], "mb": [53, 57], "topic": 54, "gentl": 54, "introduct": 54, "readi": 54, "interact": 54, "git": 55, "cd": 55, "confirm": 55, "recipe_arg": 55, "On": 56, "pointer": 56, "emphas": 56, "simplic": 56, "extens": 56, "component": 56, "reus": 56, "abstract": 56, "prove": 56, "democrat": 56, "box": 56, "zoo": 56, "excit": 56, "checkout": 56, "chekckpoint": 56, "embodi": 56, "philosophi": 56, "especi": 56, "usabl": 56, "eluetherai": 56, "composit": 56, "hard": 56, "No": 56, "outlin": 56, "prefer": 56, "unecessari": 56, "never": 56, "thoroughli": 56, "unit": 56, "numer": 56, "pariti": 56}, "objects": {"torchtune.config": [[11, 0, 1, "", "instantiate"], [12, 0, 1, "", "parse"]], "torchtune.datasets": [[13, 0, 1, "", "alpaca_cleaned_dataset"], [14, 0, 1, "", "alpaca_dataset"], [15, 0, 1, "", "grammar_dataset"], [16, 0, 1, "", "samsum_dataset"], [17, 0, 1, "", "slimorca_dataset"]], "torchtune.models.llama2": [[18, 0, 1, "", "llama2_7b"], [19, 0, 1, "", "lora_llama2"]], "torchtune.modules": [[20, 1, 1, "", "CausalSelfAttention"], [21, 1, 1, "", "FeedForward"], [22, 1, 1, "", "KVCache"], [23, 1, 1, "", "RMSNorm"], [24, 1, 1, "", "RotaryPositionalEmbeddings"], [25, 1, 1, "", "Tokenizer"], [26, 1, 1, "", "TransformerDecoder"], [27, 1, 1, "", "TransformerDecoderLayer"], [29, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[20, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[21, 2, 1, "", "forward"]], "torchtune.modules.RMSNorm": [[23, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[24, 2, 1, "", "forward"]], "torchtune.modules.Tokenizer": [[25, 2, 1, "", "decode"], [25, 2, 1, "", "encode"], [25, 2, 1, "", "from_file"], [25, 2, 1, "", "tokenize_messages"]], "torchtune.modules.TransformerDecoder": [[26, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoderLayer": [[27, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[28, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[30, 1, 1, "", "AdapterModule"], [31, 1, 1, "", "LoRALinear"], [32, 0, 1, "", "get_adapter_params"], [33, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[30, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[31, 2, 1, "", "adapter_params"], [31, 2, 1, "", "forward"]], "torchtune.utils": [[34, 1, 1, "", "FullModelHFCheckpointer"], [35, 1, 1, "", "FullModelMetaCheckpointer"], [38, 0, 1, "", "get_device"], [39, 0, 1, "", "get_world_size_and_rank"], [40, 0, 1, "", "init_distributed"]], "torchtune.utils.FullModelHFCheckpointer": [[34, 2, 1, "", "load_checkpoint"], [34, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[35, 2, 1, "", "load_checkpoint"], [35, 2, 1, "", "save_checkpoint"]], "torchtune.utils.argparse": [[36, 1, 1, "", "TuneRecipeArgumentParser"]], "torchtune.utils.argparse.TuneRecipeArgumentParser": [[36, 2, 1, "", "parse_known_args"]], "torchtune.utils.collate": [[37, 0, 1, "", "padded_collate"]], "torchtune.utils.logging": [[41, 0, 1, "", "get_logger"]], "torchtune.utils.memory": [[42, 0, 1, "", "set_activation_checkpointing"]], "torchtune.utils.metric_logging": [[43, 1, 1, "", "DiskLogger"], [44, 1, 1, "", "StdoutLogger"], [45, 1, 1, "", "TensorBoardLogger"], [46, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[43, 2, 1, "", "close"], [43, 2, 1, "", "log"], [43, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[44, 2, 1, "", "close"], [44, 2, 1, "", "log"], [44, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[45, 2, 1, "", "close"], [45, 2, 1, "", "log"], [45, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[46, 2, 1, "", "close"], [46, 2, 1, "", "log"], [46, 2, 1, "", "log_dict"]], "torchtune.utils.precision": [[47, 0, 1, "", "get_autocast"], [48, 0, 1, "", "get_dtype"], [49, 0, 1, "", "get_gradient_scaler"], [50, 0, 1, "", "list_dtypes"]], "torchtune.utils.seed": [[51, 0, 1, "", "set_seed"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 9, 54, 56], "config": [0, 6, 8, 10], "dataset": [1, 7], "model": [2, 3, 7, 8, 9], "llama2": [2, 9], "modul": 3, "compon": [3, 6], "build": 3, "block": 3, "peft": 3, "util": [3, 4], "checkpoint": [4, 5], "distribut": 4, "reduc": 4, "precis": 4, "memori": 4, "manag": 4, "metric": 4, "log": 4, "data": 4, "miscellan": 4, "overview": [5, 56], "format": 5, "handl": 5, "differ": 5, "intermedi": 5, "vs": 5, "final": 5, "lora": [5, 9], "put": 5, "thi": 5, "all": 5, "togeth": 5, "deep": [6, 10], "dive": [6, 10], "where": 6, "do": 6, "paramet": 6, "live": 6, "write": 6, "configur": 6, "us": [6, 10], "instanti": [6, 11], "referenc": 6, "other": 6, "field": 6, "interpol": 6, "valid": 6, "your": [6, 8, 10], "best": 6, "practic": 6, "airtight": 6, "public": 6, "api": 6, "onli": 6, "command": 6, "line": 6, "overrid": 6, "llm": [7, 8], "full": 7, "finetun": [7, 8, 9], "recip": [7, 8, 9, 10], "train": [7, 8, 10], "first": 8, "download": 8, "select": 8, "modifi": 8, "next": 8, "step": 8, "what": [9, 10, 56], "how": 9, "doe": 9, "work": 9, "appli": 9, "ar": 10, "script": 10, "class": 10, "run": 10, "cli": 10, "pars": [10, 12], "alpaca_cleaned_dataset": 13, "alpaca_dataset": 14, "grammar_dataset": 15, "samsum_dataset": 16, "slimorca_dataset": 17, "llama2_7b": 18, "lora_llama2": 19, "causalselfattent": 20, "todo": [20, 27], "feedforward": 21, "kvcach": 22, "rmsnorm": 23, "rotarypositionalembed": 24, "token": 25, "transformerdecod": 26, "transformerdecoderlay": 27, "reparametrize_as_dtype_state_dict_post_hook": 28, "get_cosine_schedule_with_warmup": 29, "adaptermodul": 30, "loralinear": 31, "get_adapter_param": 32, "set_trainable_param": 33, "fullmodelhfcheckpoint": 34, "fullmodelmetacheckpoint": 35, "tunerecipeargumentpars": 36, "padded_col": 37, "get_devic": 38, "get_world_size_and_rank": 39, "init_distribut": 40, "get_logg": 41, "set_activation_checkpoint": 42, "disklogg": 43, "stdoutlogg": 44, "tensorboardlogg": 45, "wandblogg": 46, "get_autocast": 47, "get_dtyp": 48, "get_gradient_scal": 49, "list_dtyp": 50, "set_se": 51, "comput": [53, 57], "time": [53, 57], "welcom": 54, "document": 54, "get": 54, "start": 54, "tutori": 54, "instal": 55, "instruct": 55, "kei": 56, "concept": 56, "design": 56, "principl": 56}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})