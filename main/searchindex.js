Search.setIndex({"docnames": ["api_ref_config", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "deep_dives/checkpointer", "deep_dives/configs", "deep_dives/recipe_deepdive", "deep_dives/wandb_logging", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.Tokenizer", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.argparse.TuneRecipeArgumentParser", "generated/torchtune.utils.collate.padded_collate", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.logging.get_logger", "generated/torchtune.utils.memory.set_activation_checkpointing", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.precision.get_autocast", "generated/torchtune.utils.precision.get_dtype", "generated/torchtune.utils.precision.get_gradient_scaler", "generated/torchtune.utils.precision.list_dtypes", "generated/torchtune.utils.profiler", "generated/torchtune.utils.seed.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times", "tutorials/e2e_flow", "tutorials/first_finetune_tutorial", "tutorials/lora_finetune", "tutorials/qlora_finetune"], "filenames": ["api_ref_config.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "deep_dives/checkpointer.rst", "deep_dives/configs.rst", "deep_dives/recipe_deepdive.rst", "deep_dives/wandb_logging.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.Tokenizer.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.argparse.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.collate.padded_collate.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.logging.get_logger.rst", "generated/torchtune.utils.memory.set_activation_checkpointing.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.precision.get_autocast.rst", "generated/torchtune.utils.precision.get_dtype.rst", "generated/torchtune.utils.precision.get_gradient_scaler.rst", "generated/torchtune.utils.precision.list_dtypes.rst", "generated/torchtune.utils.profiler.rst", "generated/torchtune.utils.seed.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst", "tutorials/e2e_flow.rst", "tutorials/first_finetune_tutorial.rst", "tutorials/lora_finetune.rst", "tutorials/qlora_finetune.rst"], "titles": ["torchtune.config", "torchtune.datasets", "torchtune.models.llama2", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "All about configs", "What are recipes?", "Logging to Weights &amp; Biases", "instantiate", "parse", "alpaca_cleaned_dataset", "alpaca_dataset", "grammar_dataset", "samsum_dataset", "slimorca_dataset", "llama2_7b", "lora_llama2", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "Tokenizer", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "padded_collate", "get_device", "get_world_size_and_rank", "init_distributed", "get_logger", "set_activation_checkpointing", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "get_autocast", "get_dtype", "get_gradient_scaler", "list_dtypes", "profiler", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times", "End-to-End Workflow with torchtune", "Finetune your First LLM", "Finetuning Llama2 with LoRA", "Finetuning Llama2 with QLoRA"], "terms": {"These": [3, 5, 6, 7, 9, 34, 57, 58, 59, 60], "ar": [3, 5, 6, 8, 9, 11, 12, 13, 14, 17, 24, 29, 32, 33, 46, 55, 57, 58, 59, 60], "common": [3, 6, 59], "can": [3, 5, 6, 7, 8, 9, 11, 12, 21, 22, 23, 32, 34, 43, 44, 53, 54, 55, 57, 58, 59, 60], "us": [3, 5, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 32, 33, 34, 36, 41, 42, 43, 44, 45, 46, 47, 50, 53, 54, 55, 58, 59], "all": [3, 7, 18, 19, 24, 26, 32, 34, 51, 53, 55, 56, 57, 58, 59], "offer": 4, "allow": [4, 43, 60], "seamless": 4, "transit": 4, "between": [4, 5, 32, 57, 59, 60], "format": [4, 11, 12, 13, 14, 15, 32, 33, 57, 58, 59], "train": [4, 5, 7, 8, 11, 12, 13, 14, 15, 18, 27, 32, 33, 45, 46, 47, 49, 53, 55, 57, 59, 60], "interoper": [4, 5, 7, 55, 57, 60], "rest": [4, 60], "ecosystem": [4, 5, 7, 55, 57, 58, 60], "For": [4, 5, 6, 7, 11, 12, 17, 18, 24, 34, 44, 50, 57, 58, 59, 60], "comprehens": 4, "overview": [4, 6, 8, 58, 59, 60], "pleas": [4, 54, 60], "see": [4, 5, 8, 11, 20, 28, 34, 39, 44, 49, 50, 54, 55, 57, 58, 59, 60], "deep": [4, 5, 6, 7, 8, 55], "dive": [4, 5, 6, 7, 8, 55], "enabl": [4, 6, 7, 8, 29, 49, 50, 58, 59, 60], "work": [4, 5, 7, 34, 55, 57, 60], "set": [4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 22, 24, 31, 36, 40, 50, 55, 57, 58, 59], "consumpt": 4, "dure": [4, 5, 11, 12, 13, 14, 18, 20, 22, 24, 25, 57, 59, 60], "provid": [4, 5, 6, 7, 9, 15, 24, 34, 55, 57, 58], "debug": [4, 5, 6, 7], "your": [4, 8, 9, 43, 44, 53, 54, 55, 57, 59, 60], "finetun": [4, 5, 6, 7, 11, 12, 48, 53, 55], "job": [4, 50, 58], "variou": 4, "dataset": [4, 6, 11, 12, 13, 14, 15, 55, 57, 58, 59, 60], "walk": [5, 7, 43, 55, 57, 58, 60], "you": [5, 6, 7, 8, 9, 11, 12, 34, 43, 44, 53, 54, 55, 57, 58, 59, 60], "through": [5, 6, 7, 8, 19, 55, 57, 58, 60], "design": [5, 7], "behavior": 5, "associ": [5, 6, 7, 57, 59], "util": [5, 6, 7, 8, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 55, 57, 58, 60], "what": [5, 6, 8, 53, 57, 58], "cover": [5, 6, 7, 8, 57, 60], "how": [5, 6, 7, 8, 53, 57, 58, 60], "we": [5, 6, 7, 8, 11, 12, 18, 20, 22, 23, 24, 29, 32, 33, 46, 55, 57, 58, 59, 60], "them": [5, 6, 19, 23, 26, 57, 59, 60], "scenario": 5, "full": [5, 6, 7, 23, 32, 33, 55, 59], "compos": 5, "compon": [5, 7, 49, 55, 58, 59, 60], "which": [5, 7, 11, 12, 13, 14, 17, 18, 22, 23, 24, 25, 27, 32, 33, 41, 46, 47, 55, 57, 59, 60], "plug": 5, "ani": [5, 6, 7, 9, 10, 23, 26, 30, 31, 32, 33, 50, 57, 59], "recip": [5, 6, 8, 9, 10, 13, 14, 19, 32, 33, 55, 57, 60], "evalu": [5, 7, 53, 55, 58, 59, 60], "gener": [5, 7, 15, 23, 50, 51, 53, 59, 60], "each": [5, 7, 17, 18, 22, 23, 24, 50, 55, 57, 58, 59], "support": [5, 7, 8, 9, 11, 12, 13, 14, 17, 18, 29, 33, 45, 46, 48, 55, 57, 58, 59, 60], "model": [5, 6, 7, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 40, 49, 53, 55, 60], "make": [5, 6, 7, 8, 18, 25, 55, 57, 58, 59, 60], "easi": [5, 7, 55, 58, 59], "understand": [5, 6, 7, 53, 55, 59, 60], "extend": [5, 7, 55], "befor": [5, 24, 25, 29, 32, 57], "let": [5, 6, 8, 57, 58, 59, 60], "s": [5, 6, 7, 8, 10, 17, 18, 22, 24, 25, 26, 28, 30, 32, 33, 36, 43, 49, 55, 58, 59, 60], "defin": [5, 6, 7, 19, 28, 29, 30, 59], "some": [5, 6, 17, 30, 31, 53, 55, 57, 58, 59, 60], "concept": [5, 57], "In": [5, 6, 7, 22, 29, 43, 44, 57, 59, 60], "ll": [5, 6, 7, 55, 57, 60], "talk": 5, "about": [5, 7, 32, 44, 55, 57, 59, 60], "take": [5, 6, 7, 9, 19, 20, 26, 32, 34, 36, 57, 58, 59, 60], "close": [5, 7, 41, 42, 43, 44, 59], "look": [5, 6, 7, 43, 57, 58, 59], "veri": [5, 24, 57], "simpli": [5, 6, 60], "dictat": 5, "state_dict": [5, 26, 32, 33, 59, 60], "store": [5, 41, 44, 59, 60], "file": [5, 6, 7, 8, 9, 10, 11, 12, 23, 32, 33, 34, 41, 44, 49, 52, 55, 56, 57, 58, 59, 60], "disk": [5, 41], "weight": [5, 7, 17, 18, 26, 28, 29, 32, 33, 44, 53, 57, 58, 59, 60], "string": [5, 23, 28, 36, 46], "kei": [5, 6, 8, 17, 18, 20, 24, 31, 32, 57, 59, 60], "identifi": 5, "state": [5, 7, 26, 30, 31, 32, 33, 57, 59, 60], "dict": [5, 6, 7, 8, 9, 26, 30, 31, 32, 33, 38], "If": [5, 6, 11, 12, 13, 14, 15, 17, 18, 26, 29, 32, 33, 36, 38, 43, 44, 46, 50, 54, 58, 59], "identif": 5, "don": [5, 6, 7, 50, 57, 60], "t": [5, 6, 7, 15, 46, 50, 57, 60], "match": [5, 57, 59], "up": [5, 7, 8, 11, 12, 58, 59, 60], "exactli": 5, "those": [5, 59], "definit": [5, 59], "either": [5, 32, 59, 60], "run": [5, 6, 8, 10, 17, 19, 20, 24, 26, 32, 33, 43, 44, 54, 55, 58, 59, 60], "explicit": 5, "error": [5, 6, 11, 32, 50], "load": [5, 7, 32, 33, 34, 43, 57, 59], "rais": [5, 9, 15, 18, 24, 32, 33, 38, 44, 46, 50], "an": [5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 24, 28, 30, 31, 32, 33, 44, 55, 57, 58, 59, 60], "except": 5, "wors": 5, "silent": [5, 19], "succe": 5, "infer": [5, 18, 20, 22, 24, 25, 53, 57, 60], "expect": [5, 6, 9, 22, 44, 59], "addit": [5, 6, 7, 9, 32, 33, 38, 40, 41, 43, 44, 46, 55, 59], "line": [5, 7, 34, 58], "also": [5, 6, 7, 8, 9, 17, 18, 24, 29, 36, 44, 54, 57, 58, 59, 60], "need": [5, 6, 7, 8, 15, 18, 19, 24, 43, 44, 57, 58, 59, 60], "shape": [5, 18, 20, 22, 24, 25, 29], "valu": [5, 6, 15, 16, 17, 18, 20, 21, 24, 27, 32, 34, 41, 42, 43, 44, 50, 59], "two": [5, 6, 55, 57, 58, 59, 60], "popular": [5, 55, 57, 58], "llama2": [5, 6, 7, 9, 11, 12, 15, 16, 17, 19, 23, 24, 25, 53, 55, 58], "meta": [5, 13, 14, 32, 33, 57, 58], "offici": [5, 58], "implement": [5, 7, 11, 12, 13, 14, 15, 19, 21, 22, 27, 28, 29, 32, 43, 55, 59, 60], "when": [5, 6, 7, 10, 24, 26, 27, 43, 57, 59, 60], "download": [5, 51, 54, 59, 60], "7b": [5, 11, 12, 16, 32, 33, 58, 59, 60], "from": [5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 19, 23, 24, 25, 27, 28, 30, 32, 33, 34, 43, 44, 52, 54, 56, 57, 58, 59], "llama": [5, 13, 14, 21, 22, 32, 33, 57, 58, 59], "websit": 5, "get": [5, 6, 7, 8, 23, 37, 39, 46, 55, 57, 58, 59], "access": [5, 6, 7, 32, 57, 58], "singl": [5, 6, 9, 18, 32, 33, 57, 59, 60], "pth": [5, 57, 58], "inspect": [5, 57, 59, 60], "content": [5, 23], "easili": [5, 6, 55, 59, 60], "torch": [5, 20, 24, 26, 27, 36, 38, 40, 45, 46, 49, 50, 57, 58, 59, 60], "import": [5, 6, 9, 43, 44, 57, 58, 59, 60], "consolid": [5, 58], "00": [5, 52, 56, 58], "mmap": [5, 57], "true": [5, 6, 11, 12, 13, 14, 23, 26, 32, 33, 38, 43, 57, 58, 59, 60], "weights_onli": 5, "map_loc": [5, 57], "cpu": [5, 7, 26, 46, 57, 60], "tensor": [5, 18, 19, 20, 21, 22, 24, 25, 26, 29, 32, 35, 41, 42, 43, 44, 59, 60], "item": 5, "print": [5, 11, 12, 13, 14, 15, 23, 59, 60], "f": [5, 8, 11, 12, 13, 14, 57, 59, 60], "tok_embed": [5, 24], "size": [5, 7, 9, 11, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 37, 55, 57, 59], "32000": [5, 9, 59], "4096": [5, 9, 11, 12, 18, 22, 59], "len": [5, 11, 12, 13, 14, 24], "292": 5, "The": [5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 21, 22, 23, 26, 27, 32, 34, 36, 39, 44, 46, 49, 50, 54, 55, 57, 58, 59, 60], "contain": [5, 18, 20, 22, 23, 24, 25, 28, 30, 31, 32, 33, 34, 35, 43, 57, 59], "includ": [5, 6, 7, 29, 32, 33, 34, 55, 57, 58, 59, 60], "input": [5, 11, 12, 13, 14, 15, 18, 19, 21, 22, 23, 24, 25, 29, 32, 35, 50, 59, 60], "embed": [5, 17, 18, 20, 21, 22, 24], "tabl": [5, 59, 60], "call": [5, 9, 19, 26, 34, 41, 42, 43, 44, 58, 59, 60], "layer": [5, 7, 17, 18, 24, 25, 29, 55, 59, 60], "token": [5, 6, 7, 11, 12, 13, 14, 15, 17, 18, 22, 24, 25, 57, 58, 59, 60], "have": [5, 6, 9, 18, 20, 28, 34, 43, 49, 57, 58, 59, 60], "dim": [5, 18, 19, 21, 22, 24, 25], "hf": [5, 32, 57, 58], "most": [5, 6, 58, 59, 60], "within": [5, 6, 9, 15, 17, 19, 43, 50, 57, 59, 60], "hug": [5, 11, 12, 13, 14, 15, 27, 55, 57, 58], "face": [5, 11, 12, 13, 14, 15, 27, 55, 57, 58], "hub": [5, 57, 58], "default": [5, 6, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 32, 33, 34, 35, 41, 46, 49, 50, 57, 59, 60], "everi": [5, 7, 19, 43, 60], "config": [5, 8, 9, 10, 18, 32, 34, 44, 55, 57, 59, 60], "2": [5, 15, 18, 23, 32, 33, 35, 50, 57, 58, 59], "repo": [5, 32, 33, 57], "first": [5, 6, 9, 24, 32, 34, 53, 55, 57, 59, 60], "big": [5, 57], "split": [5, 57], "across": [5, 7, 32, 43, 50, 57], "bin": [5, 57], "To": [5, 6, 7, 32, 54, 55, 57, 58, 59, 60], "correctli": [5, 7, 32, 54, 58, 60], "piec": 5, "one": [5, 7, 19, 23, 57, 60], "pytorch_model": [5, 57], "00001": 5, "00002": 5, "embed_token": 5, "241": 5, "Not": 5, "onli": [5, 8, 17, 18, 22, 23, 24, 25, 29, 30, 33, 34, 46, 57, 59, 60], "doe": [5, 28, 32, 34, 57], "fewer": [5, 18], "sinc": [5, 6, 9, 19, 32, 57], "instead": [5, 7, 19, 20, 29, 57, 59], "mismatch": 5, "name": [5, 6, 8, 28, 31, 32, 33, 34, 36, 41, 42, 43, 44, 57], "caus": [5, 23], "try": [5, 6, 57, 60], "same": [5, 6, 17, 18, 20, 23, 25, 34, 44, 57, 59, 60], "As": [5, 6, 7, 29, 55, 57, 60], "re": [5, 6, 55, 57, 58, 59], "care": [5, 19, 32, 57, 59], "like": [5, 6, 7, 8, 57, 58, 59], "end": [5, 7, 23, 53, 55, 58, 59], "number": [5, 7, 11, 12, 15, 17, 18, 20, 24, 27, 32, 33, 37, 50, 59], "just": [5, 55, 58, 59], "save": [5, 7, 8, 32, 33, 44, 53, 57, 59], "less": [5, 15, 57, 58, 60], "prone": 5, "manag": [5, 45, 49], "invari": 5, "accept": [5, 6, 15, 23, 58, 60], "multipl": [5, 6, 7, 29, 41, 42, 43, 44], "sourc": [5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 57], "worri": 5, "explicitli": [5, 28, 55, 59], "convert": [5, 32, 35, 57, 58, 60], "time": [5, 23, 41, 43, 57, 60], "produc": [5, 60], "back": [5, 32, 59, 60], "origin": [5, 11, 12, 26, 29, 57, 59, 60], "form": [5, 6, 7, 11], "One": [5, 57], "advantag": [5, 59], "being": [5, 32, 33, 36, 47, 60], "should": [5, 6, 7, 17, 18, 19, 28, 34, 41, 42, 43, 44, 54, 55, 57, 58, 59, 60], "abl": [5, 7, 57, 58], "fine": [5, 7, 8, 11, 12, 53, 55, 57, 58, 59], "tune": [5, 6, 7, 8, 10, 11, 12, 53, 54, 55, 57, 58, 59, 60], "post": [5, 60], "tool": [5, 57, 58], "quantiz": [5, 17, 29, 53, 60], "eval": [5, 53, 55], "without": [5, 6, 55, 57, 59], "code": [5, 7, 24, 51, 55], "chang": [5, 6, 8, 57, 58, 59, 60], "OR": 5, "convers": [5, 32, 55, 57, 59, 60], "script": [5, 8, 57, 58], "wai": [5, 6, 58], "surround": [5, 7, 55], "load_checkpoint": [5, 7, 32, 33], "save_checkpoint": [5, 7, 8, 32, 33], "method": [5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 26, 28, 30, 34, 55, 57, 59, 60], "convertor": 5, "avail": [5, 7, 34, 36, 55, 57, 59], "here": [5, 6, 8, 21, 22, 57, 58, 59, 60], "three": [5, 7, 58], "hfcheckpoint": 5, "read": [5, 32, 33, 55], "write": [5, 7, 32, 33, 41, 58], "compat": [5, 32, 58], "transform": [5, 7, 17, 24, 25, 27, 59], "framework": [5, 7, 55], "mention": [5, 57, 60], "abov": [5, 26, 57, 59, 60], "assum": [5, 27, 30, 46, 57, 59], "checkpoint_dir": [5, 6, 32, 33, 57, 58], "necessari": [5, 15, 41, 42, 43, 44, 59], "json": [5, 32, 49, 57], "easiest": [5, 58], "sure": [5, 6, 57, 58, 59, 60], "everyth": [5, 7, 34, 55, 58], "follow": [5, 7, 18, 27, 44, 53, 54, 57, 58, 59, 60], "flow": [5, 60], "By": [5, 59, 60], "ignor": [5, 18, 19], "safetensor": 5, "output": [5, 11, 12, 13, 15, 17, 18, 19, 21, 22, 24, 25, 29, 31, 42, 49, 54, 57, 58, 59, 60], "dir": [5, 57, 58], "output_dir": [5, 6, 32, 33, 49, 57, 58, 59, 60], "specifi": [5, 6, 7, 9, 17, 18, 57, 58, 60], "argument": [5, 6, 9, 15, 18, 34, 38, 40, 41, 43, 44, 58, 59], "snippet": 5, "explain": 5, "setup": [5, 6, 7, 24, 40, 57, 59, 60], "_component_": [5, 6, 8, 9, 57, 58, 59], "fullmodelhfcheckpoint": [5, 57], "directori": [5, 6, 32, 33, 41, 43, 44, 57, 58], "sort": [5, 32], "id": [5, 11, 12, 15, 23, 32, 35, 57], "so": [5, 6, 32, 34, 54, 55, 57, 58, 59, 60], "order": [5, 7, 32, 43, 44, 58], "matter": [5, 32, 59], "checkpoint_fil": [5, 6, 8, 32, 33, 57, 58, 59, 60], "restart": 5, "previou": [5, 32, 33], "more": [5, 6, 7, 11, 20, 22, 34, 44, 49, 50, 55, 57, 58, 59, 60], "next": [5, 60], "section": [5, 7, 53, 57, 60], "recipe_checkpoint": [5, 32, 33, 58], "null": [5, 6, 45, 58], "usual": [5, 22, 32, 57, 59], "model_typ": [5, 32, 33, 57, 58], "resume_from_checkpoint": [5, 32, 33, 58], "fals": [5, 6, 11, 12, 13, 14, 15, 17, 18, 23, 29, 32, 33, 47, 49, 57, 58, 59, 60], "requir": [5, 6, 15, 32, 43, 44, 50, 54, 60], "param": [5, 7, 29, 30, 31, 32, 59, 60], "directli": [5, 6, 7, 9, 32, 57, 58, 59, 60], "help": [5, 24, 32, 34, 53, 54, 55, 57, 58, 60], "ensur": [5, 6, 15, 17, 18, 32, 46, 55], "out": [5, 6, 7, 11, 12, 13, 14, 32, 33, 53, 55, 57, 58, 59, 60], "case": [5, 7, 8, 17, 18, 32, 41, 46, 47, 55, 57, 59, 60], "discrep": [5, 32], "along": [5, 59], "detail": [5, 11, 20, 49, 50, 57, 58, 59, 60], "found": [5, 6, 8, 21, 22, 59, 60], "metacheckpoint": 5, "github": [5, 11, 12, 13, 14, 18, 21, 22, 27, 54], "repositori": [5, 57, 58], "fullmodelmetacheckpoint": [5, 58], "torchtunecheckpoint": 5, "perform": [5, 19, 55, 57, 60], "current": [5, 17, 18, 22, 24, 25, 33, 37, 41, 43, 50, 57, 58], "test": [5, 6, 7, 55], "complet": [5, 7, 57, 58], "written": [5, 6, 7, 32, 33, 41, 42, 43, 44, 55], "begin": [5, 23, 60], "partit": [5, 60], "ha": [5, 23, 28, 30, 57, 59, 60], "standard": [5, 42, 55, 57], "key_1": 5, "weight_1": 5, "key_2": 5, "weight_2": 5, "mid": 5, "chekpoint": 5, "middl": [5, 57], "inform": [5, 44, 55, 57, 58], "subsequ": [5, 7], "recipe_st": [5, 32, 33], "pt": [5, 8, 32, 33, 57], "epoch": [5, 7, 8, 27, 32, 33, 57, 58], "optim": [5, 6, 7, 27, 57, 58, 59, 60], "etc": [5, 7, 32], "prevent": 5, "flood": 5, "overwritten": 5, "note": [5, 6, 23, 24, 28, 32, 34, 46, 49, 50, 57, 59, 60], "updat": [5, 6, 7, 57, 58, 59, 60], "hf_model_0001_0": [5, 57], "hf_model_0002_0": [5, 57], "both": [5, 57, 59, 60], "adapt": [5, 28, 29, 30, 31, 32, 33, 57, 59, 60], "merg": [5, 9, 32, 57, 60], "would": [5, 6, 8, 24, 57, 59, 60], "our": [5, 7, 55, 57, 58, 59, 60], "tutori": [5, 55, 57, 58, 59, 60], "primari": [5, 6, 7, 58], "want": [5, 6, 7, 8, 9, 54, 59], "resum": [5, 7, 27, 32, 33, 60], "initi": [5, 7, 10, 16, 23, 38, 58, 59, 60], "frozen": [5, 59, 60], "base": [5, 15, 17, 22, 27, 29, 31, 32, 34, 41, 45, 53, 57, 59, 60], "well": [5, 6, 7, 55, 57, 60], "learnt": [5, 57], "someth": [5, 7, 8, 57], "NOT": 5, "refer": [5, 6, 7, 21, 22, 45, 55, 59], "adapter_checkpoint": [5, 32, 33], "adapter_0": [5, 57], "now": [5, 23, 57, 58, 59, 60], "knowledg": 5, "creat": [5, 6, 9, 11, 12, 13, 14, 16, 20, 27, 32, 33, 41, 43, 57, 60], "simpl": [5, 7, 53, 58, 59, 60], "forward": [5, 7, 18, 19, 21, 22, 24, 25, 29, 59, 60], "13b": 5, "modeltyp": [5, 32, 33], "llama2_13b": 5, "right": [5, 32, 57, 58, 59], "pytorch_fil": 5, "00003": 5, "torchtune_sd": 5, "load_state_dict": [5, 59], "successfulli": 5, "vocab": [5, 9, 24], "70": 5, "x": [5, 18, 19, 21, 22, 24, 25, 29, 59, 60], "randint": 5, "0": [5, 7, 17, 18, 23, 24, 27, 29, 35, 43, 44, 50, 52, 56, 57, 58, 59, 60], "1": [5, 7, 15, 18, 23, 24, 27, 33, 35, 43, 44, 50, 57, 58, 59, 60], "no_grad": 5, "6": [5, 21, 35, 57, 60], "3989": 5, "9": [5, 57, 60], "0531": 5, "3": [5, 34, 35, 39, 57, 60], "2375": 5, "5": [5, 27, 35, 49, 57, 58], "2822": 5, "4": [5, 6, 15, 18, 35, 55, 57, 59, 60], "4872": 5, "7469": 5, "8": [5, 11, 12, 13, 14, 57, 59, 60], "6737": 5, "11": [5, 57, 60], "0023": 5, "8235": 5, "6819": 5, "2424": 5, "0109": 5, "6915": 5, "7": [5, 35], "3618": 5, "1628": 5, "8594": 5, "5857": 5, "1151": 5, "7808": 5, "2322": 5, "8850": 5, "9604": 5, "7624": 5, "6040": 5, "3159": 5, "5849": 5, "8039": 5, "9322": 5, "2010": 5, "6824": 5, "8929": 5, "8465": 5, "3794": 5, "3500": 5, "6145": 5, "5931": 5, "do": [5, 7, 44, 57, 58, 59], "find": [5, 7, 8, 57, 58, 59], "list": [5, 6, 11, 12, 15, 17, 23, 28, 29, 32, 33, 34, 35, 39, 48, 58], "builder": [5, 16, 60], "hope": 5, "deeper": 5, "insight": [5, 57], "happi": [5, 57], "thi": [6, 7, 8, 9, 11, 12, 15, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 36, 41, 43, 44, 49, 50, 53, 54, 55, 57, 58, 59, 60], "guid": [6, 8, 58, 59], "yaml": [6, 7, 9, 10, 34, 44, 55, 57, 58, 59, 60], "pars": [6, 9, 34, 58], "effect": 6, "cli": [6, 8, 10, 54, 57, 58], "prerequisit": [6, 57, 58, 59, 60], "Be": [6, 57, 58, 59, 60], "familiar": [6, 57, 58, 59, 60], "torchtun": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54, 58], "instal": [6, 8, 43, 44, 53, 57, 58, 59, 60], "fundament": 6, "There": [6, 57, 59], "entri": [6, 7, 58], "point": [6, 7, 57, 58, 59, 60], "locat": [6, 59, 60], "thei": [6, 7, 24, 34, 59], "truth": [6, 57], "reproduc": 6, "overridden": [6, 19, 34], "quick": 6, "experiment": 6, "modifi": [6, 7, 8, 26, 55, 57, 59, 60], "serv": [6, 59], "particular": [6, 15, 59, 60], "seed": [6, 7, 8, 50, 58], "shuffl": [6, 58], "devic": [6, 7, 36, 45, 46, 57, 58, 59], "cuda": [6, 36, 46, 57, 58, 60], "dtype": [6, 7, 20, 26, 45, 46, 48, 57, 58, 60], "fp32": [6, 60], "enable_fsdp": 6, "mani": [6, 57], "object": [6, 9, 18, 45, 47], "keyword": [6, 9, 15, 26], "loss": [6, 7, 11, 12, 13, 14, 58, 59, 60], "function": [6, 7, 9, 10, 18, 19, 26, 36, 37, 50, 55, 60], "exampl": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 23, 28, 32, 33, 35, 43, 44, 51, 52, 56, 57, 59, 60], "subfield": 6, "dotpath": 6, "wish": 6, "exact": [6, 9, 57], "path": [6, 7, 8, 9, 23, 32, 33, 34, 49, 57, 58, 59], "normal": [6, 21, 23, 24, 25, 59, 60], "python": [6, 34, 39, 44, 50, 51, 57], "alpaca_dataset": [6, 11, 58], "custom": [6, 7, 55, 57, 58, 59], "train_on_input": [6, 11, 12, 13, 14, 15], "onc": [6, 57, 58, 59, 60], "ve": [6, 20, 57, 59], "instanc": [6, 9, 11, 12, 17, 19, 23, 26, 30, 31, 59], "cfg": [6, 7, 10], "automat": [6, 8, 9, 60], "under": [6, 57, 60], "preced": [6, 9, 59], "actual": [6, 8], "throw": 6, "notic": [6, 59], "miss": [6, 59], "posit": [6, 9, 18, 22, 24, 25], "anoth": [6, 57], "handl": [6, 10, 23, 57, 59, 60], "def": [6, 7, 8, 10, 59, 60], "dictconfig": [6, 7, 9, 10, 44], "arg": [6, 9, 24, 26, 28, 34, 42], "tupl": [6, 9, 15, 23, 26, 34, 35, 37], "kwarg": [6, 9, 26, 28, 34, 38, 40, 41, 42, 43, 44], "str": [6, 9, 23, 26, 28, 29, 30, 31, 32, 33, 34, 36, 39, 41, 42, 43, 44, 46, 48, 49, 50], "mean": [6, 21, 58, 59], "pass": [6, 9, 16, 17, 18, 19, 26, 38, 40, 43, 44, 46, 59, 60], "add": [6, 8, 34, 57, 59, 60], "d": [6, 18, 24, 25, 59], "llama2_token": [6, 57, 58], "tmp": [6, 57, 58], "option": [6, 7, 16, 17, 18, 22, 23, 24, 25, 26, 32, 33, 36, 39, 40, 41, 44, 46, 49, 50, 54, 55, 57, 58], "bool": [6, 11, 12, 13, 14, 15, 17, 23, 26, 29, 32, 33, 38, 43, 47, 49, 60], "max_seq_len": [6, 9, 11, 12, 15, 17, 18, 20, 22, 23, 24], "int": [6, 8, 11, 12, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 29, 32, 33, 35, 37, 41, 42, 43, 44, 50, 59, 60], "512": [6, 11, 12, 60], "instructdataset": [6, 11, 12, 13, 14], "alreadi": [6, 38, 57, 58, 59], "overwrit": 6, "duplic": [6, 7, 55], "sometim": 6, "than": [6, 15, 18, 57, 58, 59, 60], "resolv": 6, "alpaca": [6, 11, 12, 57, 58, 59, 60], "metric_logg": [6, 7, 8], "metric_log": [6, 8, 41, 42, 43, 44], "disklogg": 6, "log_dir": [6, 41, 43], "conveni": [6, 7], "quickli": 6, "verifi": [6, 36, 46, 58, 59], "properli": 6, "experi": [6, 53, 55, 59], "wa": [6, 57, 59, 60], "7b_full": [6, 57, 58], "batch_siz": [6, 11, 12, 13, 14, 18, 25, 57, 58], "discuss": [6, 59], "guidelin": 6, "while": [6, 7, 19, 55, 57, 58, 60], "mai": [6, 49, 58, 59], "tempt": 6, "put": [6, 7, 58, 59], "much": [6, 57, 59, 60], "give": [6, 59], "maximum": [6, 11, 12, 15, 16, 17, 18, 20, 22, 24], "flexibl": 6, "switch": 6, "encourag": [6, 59], "clariti": 6, "significantli": 6, "easier": [6, 57, 58], "dont": 6, "slimorca_dataset": 6, "privat": 6, "typic": [6, 60], "expos": [6, 7, 58], "parent": 6, "modul": [6, 9, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 40, 50, 59, 60], "__init__": [6, 7, 59, 60], "py": [6, 10, 11, 12, 13, 14, 18, 20, 21, 22, 27, 57], "guarante": 6, "stabil": [6, 55, 60], "underscor": 6, "_alpaca": 6, "collect": [6, 58], "differ": [6, 8, 23, 55, 57, 59, 60], "itself": 6, "via": [6, 8, 29, 59, 60], "pair": [6, 35], "k1": [6, 7], "v1": [6, 7], "k2": [6, 7], "v2": [6, 7], "full_finetun": [6, 8], "gpu": [6, 57, 58, 59, 60], "full_finetune_distribut": [6, 57, 58], "checkpoint": [6, 7, 32, 33, 40, 44, 55, 58, 59, 60], "home": 6, "my_model_checkpoint": 6, "file_1": 6, "file_2": 6, "class": [6, 8, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 41, 42, 43, 44, 58, 59, 60], "assign": 6, "nest": 6, "dot": 6, "notat": [6, 18, 22, 24, 25], "my_config": 6, "core": [7, 55, 58, 60], "i": [7, 26, 31, 57, 60], "structur": [7, 57], "new": [7, 41, 43, 58, 59, 60], "user": [7, 17, 18, 23, 58], "thought": [7, 55, 58, 60], "target": [7, 55], "pipelin": [7, 55, 58], "llm": [7, 53, 55, 57, 59], "eg": [7, 24, 32, 55], "meaning": [7, 55, 57], "featur": [7, 8, 54, 55], "fsdp": [7, 47, 55, 58], "activ": [7, 19, 40, 55, 58, 60], "gradient": [7, 47, 55, 57, 59, 60], "accumul": [7, 55], "mix": [7, 45, 47, 55, 57], "precis": [7, 26, 45, 46, 47, 48, 55, 60], "appli": [7, 17, 18, 21, 22, 24, 25, 55, 60], "given": [7, 9, 29, 36, 46, 55, 59], "famili": [7, 55], "complex": 7, "becom": [7, 54], "harder": 7, "anticip": 7, "architectur": [7, 24], "methodolog": 7, "reason": [7, 57], "possibl": 7, "trade": 7, "off": [7, 23, 57], "memori": [7, 11, 12, 40, 53, 55, 57], "vs": 7, "qualiti": [7, 57, 59], "believ": 7, "best": 7, "suit": [7, 58], "specif": [7, 9, 57, 60], "b": [7, 18, 22, 24, 25, 29, 44, 59, 60], "fit": [7, 11, 12], "solut": 7, "result": [7, 23, 57, 58, 59, 60], "meant": [7, 26], "depend": [7, 8, 57, 59, 60], "level": [7, 39, 55, 60], "expertis": 7, "routin": 7, "yourself": [7, 59], "exist": [7, 58, 60], "ad": [7, 23, 59, 60], "ones": 7, "modular": [7, 55], "build": [7, 55, 59], "block": [7, 17, 55], "wandb": [7, 8, 44, 58], "log": [7, 39, 41, 42, 43, 44, 57, 58, 60], "fulli": 7, "nativ": [7, 53, 55, 59, 60], "pytorch": [7, 15, 24, 26, 43, 45, 49, 50, 53, 54, 55, 58, 59, 60], "correct": [7, 21, 22, 24, 36, 55], "numer": [7, 55], "pariti": [7, 55], "verif": 7, "extens": [7, 55], "comparison": [7, 59, 60], "benchmark": [7, 50, 55, 57, 59], "limit": 7, "hidden": [7, 19], "behind": 7, "100": [7, 11, 12, 13, 14, 15, 35, 49, 59, 60], "flag": [7, 11, 12, 13, 14, 60], "prefer": [7, 55], "over": [7, 27, 34, 55, 57, 59, 60], "unnecessari": 7, "abstract": [7, 55, 60], "No": [7, 55], "inherit": [7, 34, 55], "go": [7, 23, 55, 57, 58, 60], "upon": 7, "figur": [7, 59, 60], "spectrum": 7, "decid": 7, "interact": [7, 53], "start": [7, 8, 54, 55, 57, 58], "paradigm": 7, "consist": [7, 58], "configur": [7, 11, 12, 13, 14, 15, 25, 55, 58, 59, 60], "paramet": [7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 49, 50, 53, 55, 57, 58, 59, 60], "command": [7, 34, 54, 58, 59, 60], "overrid": [7, 10, 57, 58, 60], "togeth": [7, 58, 59], "valid": [7, 54, 57, 58], "environ": [7, 54, 57, 58], "logic": [7, 32, 55, 58, 59], "api": [7, 8, 57, 58, 60], "closer": [7, 59], "monolith": [7, 55], "trainer": [7, 37], "A": [7, 8, 23, 26, 29, 32, 35, 52, 53, 56, 57, 59, 60], "wrapper": [7, 23, 59], "around": [7, 23, 49, 57, 59, 60], "extern": 7, "primarili": [7, 59], "eleutherai": [7, 55, 59], "har": [7, 55, 59], "control": [7, 11, 12, 13, 14, 50, 57], "multi": [7, 18], "stage": 7, "distil": 7, "oper": [7, 49, 50], "turn": 7, "dataload": [7, 11, 12, 13, 14], "applic": [7, 18, 32, 33, 44, 45], "clean": [7, 11], "after": [7, 20, 21, 41, 42, 43, 44, 60], "process": [7, 26, 50, 58, 60], "group": [7, 18, 41, 42, 43, 44], "init_process_group": [7, 38], "backend": 7, "gloo": 7, "els": [7, 34, 55, 60], "nccl": 7, "fullfinetunerecipedistribut": 7, "cleanup": 7, "other": [7, 9, 11, 34, 58, 59], "stuff": 7, "carri": 7, "relev": [7, 57, 59], "interfac": [7, 28], "metric": [7, 58], "logger": [7, 39, 41, 42, 43, 44, 58], "self": [7, 8, 17, 18, 24, 25, 28, 59, 60], "_devic": 7, "get_devic": 7, "_dtype": 7, "get_dtyp": 7, "ckpt_dict": 7, "wrap": [7, 40, 49], "_model": 7, "_setup_model": 7, "_token": 7, "_setup_token": 7, "_optim": 7, "_setup_optim": 7, "_loss_fn": 7, "_setup_loss": 7, "_sampler": 7, "_dataload": 7, "_setup_data": 7, "backward": [7, 60], "zero_grad": 7, "curr_epoch": 7, "rang": [7, 50], "epochs_run": [7, 8], "total_epoch": [7, 8], "idx": 7, "batch": [7, 11, 12, 13, 14, 16, 18, 20, 22, 23, 24, 25, 35, 55, 59], "enumer": 7, "_autocast": 7, "logit": 7, "label": [7, 11, 12, 15, 35], "total_training_step": 7, "_log_every_n_step": 7, "_metric_logg": 7, "log_dict": [7, 41, 42, 43, 44], "step": [7, 24, 27, 41, 42, 43, 44, 49, 53, 57, 59, 60], "learn": [7, 27, 55, 58, 59, 60], "decor": [7, 10], "recipe_main": [7, 10], "none": [7, 8, 17, 18, 22, 23, 24, 25, 31, 32, 33, 36, 39, 40, 41, 42, 43, 44, 46, 50, 57], "fullfinetunerecip": 7, "direct": 7, "wandblogg": [8, 59, 60], "workspac": 8, "seen": [8, 59, 60], "screenshot": 8, "below": [8, 22, 59, 60], "packag": [8, 43, 44, 54], "pip": [8, 43, 44, 54], "Then": [8, 58], "login": [8, 44], "built": [8, 60], "project": [8, 17, 18, 19, 44, 53, 59, 60], "grab": 8, "tab": [8, 11, 12], "click": 8, "sampl": [8, 15, 57], "desir": 8, "suggest": 8, "approach": 8, "joinpath": 8, "_checkpoint": [8, 57], "_output_dir": [8, 32, 33], "torchtune_model_": 8, "with_suffix": 8, "wandb_at": 8, "artifact": 8, "type": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 33, 37, 38, 39, 45, 46, 47, 49, 57, 59, 60], "descript": [8, 13], "whatev": 8, "metadata": 8, "seed_kei": 8, "epochs_kei": 8, "total_epochs_kei": 8, "max_steps_kei": 8, "max_steps_per_epoch": 8, "add_fil": 8, "log_artifact": 8, "field": [9, 11, 12, 13, 14], "num_lay": [9, 17, 24], "32": [9, 59, 60], "num_head": [9, 17, 18, 20, 22, 24], "num_kv_head": [9, 17, 18, 20], "vocab_s": [9, 17, 23], "must": [9, 11, 12, 13, 14, 15, 28, 34, 60], "return": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 45, 46, 47, 48, 49, 50, 59, 60], "nn": [9, 18, 19, 20, 24, 25, 26, 28, 30, 31, 40, 58, 59, 60], "parsed_yaml": 9, "embed_dim": [9, 17, 18, 22, 25, 59], "omegaconf": 9, "valueerror": [9, 15, 18, 24, 32, 33, 46, 50], "callabl": [10, 24], "main": [10, 11, 12, 13, 14, 18, 21, 22], "my_recip": 10, "With": [10, 57, 59, 60], "foo": 10, "bar": [10, 55], "http": [11, 12, 13, 14, 15, 16, 18, 21, 22, 27, 32, 33, 34, 39, 43, 44, 45, 49, 50, 54], "huggingfac": [11, 12, 13, 14, 15, 27, 32, 33], "co": [11, 12, 13, 14, 15, 32, 33], "yahma": 11, "data": [11, 12, 13, 14, 15, 41, 42, 43, 44, 57, 60], "tatsu": [11, 12], "lab": [11, 12], "prompt": [11, 12, 13, 14, 15, 23, 24, 57], "templat": [11, 12, 13, 14, 15], "codebas": [11, 12, 13, 14, 57], "com": [11, 12, 13, 14, 18, 21, 22, 27, 54], "stanford_alpaca": [11, 12], "blob": [11, 12, 13, 14, 18, 21, 22, 27], "761dc5bfbdeeffa89b8bff5d038781a4055f796a": [11, 12], "l31": [11, 12], "where": [11, 12, 13, 14, 18, 23, 24, 29], "instruct": [11, 12, 53, 58, 59, 60], "mask": [11, 12, 13, 14, 18, 23, 25], "ref": [11, 12, 44], "tloen": [11, 12], "lora": [11, 12, 17, 29, 53, 55], "l49": [11, 12], "contribut": [11, 12, 13, 14], "replac": [11, 12, 13, 14, 26, 59], "version": [11, 17, 18, 54, 60], "remov": 11, "hallucin": 11, "poorli": 11, "wrong": 11, "answer": [11, 57], "card": 11, "encod": [11, 12, 13, 14, 15, 23], "decod": [11, 12, 13, 14, 15, 17, 23, 24], "whether": [11, 12, 13, 14, 15, 17, 23, 26, 29, 46, 47], "stanford": [11, 12], "readm": [11, 12], "ov": [11, 12], "recommend": [11, 12, 43, 57, 60], "highest": [11, 12], "sequenc": [11, 12, 15, 17, 18, 20, 22, 23, 24, 25, 35], "length": [11, 12, 15, 17, 18, 20, 22, 23, 24, 25, 33, 35], "alpaca_d": [11, 12], "grammar": 13, "its": [13, 14, 17, 50, 57, 59], "variant": [13, 14], "liweili": 13, "c4_200m": 13, "llama_recip": [13, 14], "src": [13, 14, 27], "l50": 13, "grammar_d": 13, "summar": 14, "samsum": 14, "l13": 14, "dialogu": 14, "summari": 14, "samsum_d": 14, "1024": 15, "chatdataset": 15, "represent": [15, 59, 60], "slimorca": 15, "open": [15, 57], "orca": 15, "dedup": 15, "adher": 15, "chat": 15, "doesn": [15, 57], "prescrib": 15, "truncat": [15, 23], "least": [15, 59], "though": 15, "max": [15, 23, 24, 27, 59], "ds": 15, "10": [15, 35, 57, 60], "351": 15, "82": [15, 57], "391": 15, "221": 15, "220": 15, "193": 15, "12": 15, "471": 15, "transformerdecod": [16, 17, 59], "w": [16, 43, 44, 57, 59, 60], "arxiv": [16, 18, 21, 22], "org": [16, 18, 21, 22, 34, 39, 43, 45, 49, 50], "ab": [16, 22], "2307": 16, "09288": 16, "max_batch_s": [16, 20], "kvcach": [16, 17, 18, 24], "instanti": [16, 17], "lora_attn_modul": [17, 59, 60], "liter": 17, "q_proj": [17, 18, 59, 60], "k_proj": [17, 18, 59, 60], "v_proj": [17, 18, 59, 60], "output_proj": [17, 18, 59, 60], "apply_lora_to_mlp": [17, 59], "apply_lora_to_output": [17, 59], "intermediate_dim": 17, "attn_dropout": [17, 18, 24], "float": [17, 18, 21, 27, 29, 41, 42, 43, 44, 59, 60], "norm_ep": 17, "1e": [17, 21, 58], "05": 17, "lora_rank": [17, 59], "lora_alpha": [17, 59], "lora_dropout": 17, "quantize_bas": [17, 29, 60], "linear": [17, 24, 28, 29, 59, 60], "attent": [17, 18, 20, 22, 24, 25, 59, 60], "mlp": [17, 24, 25, 59], "final": [17, 19, 24, 57, 59, 60], "vocabulari": [17, 23], "queri": [17, 18, 20, 24], "head": [17, 18, 20, 22, 24], "mha": [17, 18, 24], "dimens": [17, 18, 20, 22, 24, 29, 59, 60], "dropout": [17, 18, 29, 59, 60], "onto": [17, 18], "scaled_dot_product_attent": [17, 18], "intermedi": [17, 60], "comput": [17, 18, 19, 22, 24, 50, 57, 60], "scale_hidden_dim_for_mlp": 17, "epsilon": 17, "rm": 17, "norm": [17, 24, 25], "rank": [17, 29, 37, 50, 58, 59, 60], "low": [17, 29, 57, 59, 60], "approxim": [17, 29, 59], "scale": [17, 29, 59, 60], "factor": [17, 29, 57], "probabl": [17, 29, 57], "subset": [17, 30], "head_dim": [18, 20, 22, 24], "pos_embed": [18, 59], "kv_cach": 18, "gqa": 18, "introduc": [18, 21, 29, 59, 60], "pdf": [18, 21], "2305": 18, "13245v1": 18, "multihead": 18, "n": [18, 23, 52, 56], "extrem": 18, "share": 18, "mqa": 18, "credit": 18, "document": 18, "lightn": 18, "ai": [18, 44], "lit": 18, "gpt": [18, 57], "lit_gpt": 18, "v": [18, 24, 59], "k": [18, 59], "q": [18, 59], "n_kv_head": 18, "calcul": 18, "e": [18, 26, 28, 31, 54, 57, 59, 60], "g": [18, 28, 59, 60], "rotarypositionalembed": [18, 59], "cach": [18, 20, 22], "rope": [18, 22], "input_po": [18, 22, 24, 25], "seq_length": [18, 25], "seq_len": [18, 22], "bigger": 18, "n_h": [18, 22], "num": [18, 22], "n_kv": 18, "kv": [18, 20, 24], "emb": [18, 24, 25], "h_d": [18, 22], "gate_proj": 19, "down_proj": 19, "up_proj": 19, "silu": 19, "feed": [19, 25], "network": [19, 59, 60], "deriv": [19, 24, 25], "fed": 19, "multipli": 19, "subclass": [19, 34], "although": [19, 59], "afterward": 19, "former": 19, "regist": [19, 26, 60], "hook": [19, 26, 60], "latter": 19, "standalon": 20, "past": 20, "becaus": [20, 24, 57], "expand": 20, "per": [20, 26, 60], "dpython": [20, 26, 45], "ep": 21, "06": [21, 59], "root": [21, 43], "squar": 21, "1910": 21, "07467": 21, "verfic": [21, 22], "facebookresearch": [21, 22], "small": [21, 57], "avoid": [21, 50, 60], "divis": 21, "zero": [21, 57], "10000": 22, "rotari": 22, "propos": 22, "2104": 22, "09864": 22, "l450": 22, "upto": 22, "init": [22, 44, 60], "exceed": 22, "freq": 22, "recomput": 22, "geometr": 22, "progress": 22, "rotat": 22, "angl": 22, "bsz": 22, "todo": 22, "made": [22, 57], "effici": [22, 53, 55, 57, 59], "spm_model": 23, "sentencepieceprocessor": 23, "bos_id": 23, "eos_id": 23, "pad_id": 23, "sentencepiec": 23, "sentenc": 23, "pad": [23, 35], "non": 23, "from_fil": 23, "tokenized_text": 23, "hello": [23, 57], "world": [23, 37], "add_bo": 23, "add_eo": 23, "31587": 23, "29644": 23, "102": 23, "text": [23, 57], "trim_leading_whitespac": 23, "prefix": 23, "unbatch": 23, "prepend": 23, "bo": 23, "append": 23, "eo": 23, "trim": 23, "lead": 23, "whitespac": 23, "underli": [23, 60], "s1": 23, "s2": 23, "due": [23, 59, 60], "classmethod": 23, "tokenize_messag": 23, "messag": [23, 54], "concaten": 23, "problem": 23, "known": 23, "slice": 23, "tokenizer_path": 23, "role": 23, "system": 23, "assist": 23, "respons": [23, 57, 58], "separ": [23, 32, 59, 60], "concat": 23, "1788": 23, "2643": 23, "13": [23, 57, 60], "1792": 23, "9508": 23, "465": 23, "22137": 23, "2933": 23, "join": 23, "attribut": 23, "transformerdecoderlay": 24, "move": 24, "space": 24, "check": [24, 46, 53, 58, 59], "belong": 24, "reduc": [24, 59, 60], "statement": 24, "improv": [24, 57, 59], "readabl": [24, 57], "At": 24, "arang": 24, "prompt_length": 24, "causal_mask": 24, "m_": 24, "seq": 24, "attn": [25, 59, 60], "causalselfattent": [25, 59], "sa_norm": 25, "mlp_norm": 25, "ff": 25, "common_util": 26, "bfloat16": [26, 57, 59], "offload_to_cpu": 26, "nf4": [26, 60], "restor": 26, "higher": [26, 60], "offload": [26, 60], "_register_state_dict_hook": 26, "m": 26, "mymodul": 26, "_after_": 26, "nf4tensor": [26, 60], "unquant": [26, 57, 60], "unus": 26, "num_warmup_step": 27, "num_training_step": 27, "num_cycl": 27, "last_epoch": 27, "lambdalr": 27, "rate": [27, 55, 58], "schedul": [27, 49], "linearli": 27, "increas": [27, 59], "lr": [27, 58], "decreas": [27, 59, 60], "cosin": 27, "remain": [27, 59], "v4": 27, "23": 27, "l104": 27, "warmup": [27, 49], "phase": 27, "total": [27, 37, 52, 56, 57, 59], "wave": 27, "half": [27, 45], "index": [27, 35, 57], "last": 27, "lr_schedul": 27, "appropri": [27, 60], "peft": [28, 29, 30, 31, 59, 60], "protocol": 28, "adapter_param": [28, 29, 30, 31], "correspond": [28, 30, 46], "come": [28, 59], "proj": 28, "in_dim": [28, 29, 59, 60], "out_dim": [28, 29, 59, 60], "bia": [28, 29, 59, 60], "loralinear": [28, 59, 60], "alpha": [29, 59, 60], "use_bia": 29, "larg": [29, 60], "languag": [29, 59], "perturb": 29, "decomposit": [29, 59], "matric": [29, 59, 60], "trainabl": [29, 31, 59, 60], "mapsto": 29, "w_0x": 29, "r": [29, 59], "bax": 29, "lora_a": [29, 59, 60], "lora_b": [29, 59, 60], "map": [31, 32, 41, 42, 43, 44, 57, 59], "respect": 31, "get_adapter_param": [31, 59], "few": [32, 59, 60], "0001_of_0003": 32, "0002_of_0003": 32, "preserv": [32, 60], "weight_map": [32, 57], "intermediate_checkpoint": [32, 33], "parit": 32, "_weight_map": 32, "shard": [33, 47], "wip": 33, "argpars": 34, "tunerecipeargpars": 34, "argumentpars": 34, "builtin": [34, 45], "noth": 34, "treat": 34, "still": [34, 59, 60], "consult": 34, "doc": [34, 39, 43, 44, 45, 49, 50], "info": 34, "librari": [34, 39, 50, 53, 55, 60], "html": [34, 39, 43, 45, 49, 50], "parse_known_arg": 34, "namespac": 34, "act": 34, "alwai": 34, "precid": 34, "parse_arg": 34, "intern": 34, "properti": [34, 59], "too": 34, "collat": 35, "padding_idx": 35, "ignore_idx": 35, "longest": 35, "integ": [35, 50], "tokenpair": 35, "token_pair": 35, "availab": 36, "machin": [36, 57], "distribut": [36, 38, 40, 50, 55, 58], "aka": 37, "runtimeerror": 38, "stream": 39, "handler": 39, "auto_wrap_polici": 40, "polici": 40, "filenam": 41, "log_": 41, "unixtimestamp": 41, "txt": [41, 58], "thread": 41, "safe": 41, "resourc": [41, 42, 43, 44], "flush": [41, 42, 43, 44], "union": [41, 42, 43, 44, 47, 50], "ndarrai": [41, 42, 43, 44], "scalar": [41, 42, 43, 44], "tag": [41, 42, 43, 44], "record": [41, 42, 43, 44], "payload": [41, 42, 43, 44], "dictionari": [41, 42, 43, 44, 57], "organize_log": 43, "tensorboard": 43, "stabl": [43, 45, 49, 50, 54], "subdirectori": 43, "sub": 43, "compar": [43, 57, 59, 60], "logdir": 43, "startup": 43, "recurs": 43, "tree": [43, 57], "tfevent": 43, "encount": 43, "frontend": 43, "organ": 43, "accordingli": 43, "my_log_dir": 43, "view": [43, 57], "my_metr": [43, 44], "termin": [43, 44], "entiti": 44, "bias": 44, "my_project": 44, "my_ent": 44, "my_group": 44, "importerror": 44, "account": [44, 59, 60], "log_config": 44, "local": [44, 50, 54, 57, 58], "link": 44, "capecap": 44, "6053ofw0": 44, "torchtune_config_j67sb73v": 44, "contextmanag": [45, 49], "intellig": 45, "determin": 45, "autocast": 45, "amp": 45, "otherwis": 45, "context": [45, 49], "bf16": [46, 58, 60], "request": [46, 57], "inde": [46, 57], "kernel": 46, "float32": 46, "done": [46, 59, 60], "isn": 46, "gradscal": 47, "shardedgradscal": 47, "scaler": 47, "awar": 47, "torchtune_perf_trac": 49, "wait": 49, "trace": 49, "speed": [49, 60], "reduct": [49, 59], "debug_mod": 50, "pseudo": 50, "random": [50, 58], "commonli": [50, 57, 59, 60], "numpi": 50, "own": [50, 57, 59], "determinist": 50, "global": 50, "warn": 50, "nondeterminist": 50, "addition": [50, 59], "cudnn": 50, "disabl": 50, "set_deterministic_debug_mod": 50, "algorithm": 50, "outsid": [50, 57, 59], "generated_examples_python": 51, "zip": 51, "galleri": [51, 56], "sphinx": 51, "000": [52, 56], "execut": [52, 56], "generated_exampl": 52, "mem": [52, 56], "mb": [52, 56], "topic": 53, "gentl": 53, "introduct": 53, "workflow": [53, 58, 59], "readi": 53, "qlora": [53, 55, 59], "maxim": [53, 55], "pre": 54, "requisit": 54, "proper": [54, 58], "host": [54, 58], "page": [54, 55, 58], "latest": [54, 58, 60], "confirm": 54, "And": [54, 57], "usag": [54, 57, 60], "h": 54, "ls": [54, 57], "cp": [54, 57, 58], "welcom": 54, "show": [54, 59], "exit": 54, "greatest": [54, 58], "contributor": 54, "cd": [54, 57], "On": [55, 59], "pointer": 55, "author": [55, 58], "emphas": 55, "aspect": 55, "simplic": 55, "component": 55, "reus": 55, "high": [55, 59], "prove": 55, "democrat": 55, "box": [55, 60], "hardwar": [55, 57, 59], "zoo": 55, "varieti": [55, 59], "techniqu": [55, 57, 59], "integr": [55, 57, 58, 59, 60], "excit": 55, "checkout": 55, "attain": 55, "better": [55, 57], "chekckpoint": 55, "hyperparamet": [55, 58, 59, 60], "embodi": 55, "philosophi": 55, "especi": [55, 57], "usabl": 55, "eluetherai": 55, "composit": 55, "hard": 55, "outlin": 55, "unecessari": 55, "never": 55, "thoroughli": 55, "unit": 55, "favorit": [57, 59], "commun": 57, "seemlessli": 57, "beyond": [57, 60], "connect": 57, "larger": 57, "might": 57, "amount": 57, "natur": 57, "task": [57, 59, 60], "export": 57, "mobil": 57, "phone": 57, "leverag": [57, 60], "mode": 57, "lot": 57, "plai": 57, "freez": [57, 59], "percentag": 57, "learnabl": 57, "keep": [57, 59], "16gb": [57, 59], "rtx": 57, "3090": 57, "4090": 57, "peak": [57, 59, 60], "hour": 57, "full_finetune_single_devic": 57, "7b_full_single_devic": 57, "7b_full_single_device_low_memori": 57, "mistral": 57, "13b_full": 57, "lora_finetune_single_devic": [57, 59, 60], "7b_lora_single_devic": [57, 59, 60], "7b_qlora_single_devic": [57, 60], "7b_lora": [57, 59], "473": 57, "98": [57, 60], "gb": [57, 59, 60], "50": 57, "484": 57, "01": 57, "similar": [57, 59, 60], "fact": [57, 59], "ident": 57, "third": 57, "smaller": [57, 59, 60], "But": [57, 59], "realli": 57, "eleuther_ev": 57, "eleuther_evalu": 57, "plan": 57, "copi": [57, 58, 60], "element": 57, "custom_eval_config": 57, "truthfulqa_mc2": [57, 59], "qa": 57, "measur": 57, "propens": 57, "question": 57, "shot": 57, "accuraci": [57, 59, 60], "baselin": [57, 59], "324": 57, "loglikelihood": 57, "195": 57, "121": 57, "27": 57, "second": [57, 59, 60], "197": 57, "acc": 57, "388": 57, "38": 57, "shown": 57, "489": 57, "48": [57, 60], "great": 57, "seem": [57, 58], "custom_generation_config": 57, "kick": 57, "top_k": 57, "300": 57, "temperatur": 57, "interest": 57, "site": 57, "visit": 57, "bai": 57, "area": 57, "92": 57, "exploratorium": 57, "san": 57, "francisco": 57, "magazin": 57, "awesom": 57, "bridg": 57, "pretti": 57, "cool": 57, "96": [57, 60], "61": 57, "sec": 57, "25": 57, "83": 57, "99": [57, 59], "15": [57, 59, 60], "72": 57, "know": [57, 59], "littl": 57, "saw": 57, "took": 57, "torchao": [57, 60], "bit": [57, 59, 60], "custom_quantization_config": 57, "68": 57, "19": [57, 60], "76": 57, "69": 57, "95": 57, "67": 57, "4w": 57, "unlik": 57, "won": 57, "engin": 57, "fullmodeltorchtunecheckpoint": 57, "int4weightonlyquant": 57, "groupsiz": 57, "256": 57, "did": [57, 60], "park": 57, "sit": 57, "top": [57, 60], "hill": 57, "beauti": 57, "62": 57, "17": [57, 59], "85": 57, "compil": [57, 60], "hood": [57, 60], "sped": 57, "almost": [57, 59], "3x": 57, "benefit": 57, "yet": 57, "fast": 57, "clone": [57, 59, 60], "assumpt": 57, "satisfi": 57, "new_dir": 57, "output_dict": 57, "sd_1": 57, "sd_2": 57, "dump": 57, "convert_hf_checkpoint": 57, "checkpoint_path": 57, "my": 57, "justin": 57, "am": 57, "school": 57, "math": 57, "teacher": 57, "ws": 57, "94": 57, "103": 57, "28": 57, "bandwidth": 57, "achiev": [57, 59, 60], "1391": 57, "84": 57, "thats": 57, "hopefulli": 57, "gave": 57, "launch": 58, "gate": 58, "grant": 58, "minut": 58, "agreement": 58, "signup": 58, "authent": 58, "dataclass": 58, "hold": 58, "It": [58, 60], "alpaca_llama_full_finetun": 58, "good": [58, 59], "place": 58, "custom_config": 58, "replic": 58, "lower": [58, 59], "sooner": 58, "42": 58, "llama2_7b": [58, 59], "sgd": 58, "crossentropyloss": 58, "enable_activation_checkpoint": 58, "torchrun": 58, "therefor": [58, 60], "nnode": [58, 59], "nproc_per_nod": [58, 59], "immedi": 58, "down": [58, 59, 60], "indic": 58, "succesfulli": 58, "log_1707246452": 58, "manual": [58, 60], "sampler": 58, "7553404569625854": 58, "13000": 58, "03": 58, "e2": 58, "teach": 59, "straight": 59, "jump": 59, "neural": [59, 60], "unfamiliar": 59, "oppos": [59, 60], "substanti": 59, "momentum": 59, "adamw": 59, "further": [59, 60], "arbitrari": 59, "could": 59, "min": 59, "relat": 59, "paper": [59, 60], "aghajanyan": 59, "et": 59, "al": 59, "hypothes": 59, "intrins": 59, "often": 59, "four": 59, "eight": 59, "practic": 59, "imag": 59, "simplifi": 59, "left": 59, "blue": 59, "extra": [59, 60], "rememb": 59, "approx": 59, "15m": 59, "8192": 59, "65k": 59, "minim": [59, 60], "pretrain": [59, 60], "p": [59, 60], "requires_grad": [59, 60], "frozen_out": [59, 60], "lora_out": [59, 60], "omit": 59, "construct": 59, "lora_llama2_7b": 59, "base_model": 59, "choos": 59, "lora_model": 59, "lora_llama_2_7b": [59, 60], "alon": 59, "in_featur": 59, "out_featur": 59, "inplac": 59, "feel": 59, "free": 59, "why": 59, "strict": 59, "whenev": 59, "validate_state_dict_for_lora": 59, "peft_util": 59, "set_trainable_param": 59, "fetch": 59, "lora_param": 59, "total_param": 59, "sum": 59, "numel": 59, "trainable_param": 59, "2f": 59, "6742609920": 59, "4194304": 59, "taken": [59, 60], "vram": 59, "lora_finetune_distribut": 59, "my_model_checkpoint_path": [59, 60], "tokenizer_checkpoint": [59, 60], "my_tokenizer_checkpoint_path": [59, 60], "constraint": 59, "coupl": [59, 60], "factori": 59, "16": [59, 60], "benefici": 59, "long": 59, "impact": 59, "rel": 59, "minor": 59, "64": 59, "lora_experiment_1": 59, "smooth": [59, 60], "curv": [59, 60], "500": 59, "ran": 59, "footprint": 59, "commod": 59, "cogniz": 59, "ax": 59, "parallel": 59, "truthfulqa": 59, "previous": 59, "57": [59, 60], "475": 59, "87": 59, "508": 59, "128": 59, "86": 59, "504": 59, "04": 59, "514": 59, "lowest": 59, "absolut": 59, "4gb": 59, "tradeoff": 59, "even": [59, 60], "potenti": 59, "enhanc": 60, "maintain": 60, "therebi": 60, "highli": 60, "develop": 60, "part": 60, "vanilla": 60, "style": 60, "held": 60, "bespok": 60, "normalfloat": 60, "8x": 60, "retain": 60, "vast": 60, "major": 60, "highlight": 60, "degrad": 60, "normatfloat": 60, "doubl": 60, "themselv": 60, "prune": 60, "deepdiv": 60, "idea": 60, "distinct": 60, "storag": 60, "datatyp": 60, "de": 60, "incur": 60, "consum": 60, "counterpart": 60, "set_default_devic": 60, "qlora_linear": 60, "memory_alloc": 60, "177": 60, "152": 60, "byte": 60, "del": 60, "empty_cach": 60, "lora_linear": 60, "081": 60, "344": 60, "qlora_llama2_7b": 60, "qlora_model": 60, "essenti": 60, "reparametrize_as_dtype_state_dict_post_hook": 60, "entir": 60, "stat": 60, "iter": 60, "alloc": 60, "reserv": 60, "against": 60, "35": 60, "40": 60, "29": 60, "quit": 60, "slow": 60, "slower": 60, "149": 60, "9157477021217346": 60, "25880": 60, "02": 60, "08": 60, "14": 60, "15it": 60, "thing": 60, "nightli": 60, "200": 60, "hundr": 60, "228": 60, "8158286809921265": 60, "59": 60, "95it": 60, "exercis": 60, "portion": 60, "augment": 60, "linear_nf4": 60, "to_nf4": 60, "linear_weight": 60, "autograd": 60, "regular": 60, "incom": 60, "variabl": 60}, "objects": {"torchtune.config": [[9, 0, 1, "", "instantiate"], [10, 0, 1, "", "parse"]], "torchtune.datasets": [[11, 0, 1, "", "alpaca_cleaned_dataset"], [12, 0, 1, "", "alpaca_dataset"], [13, 0, 1, "", "grammar_dataset"], [14, 0, 1, "", "samsum_dataset"], [15, 0, 1, "", "slimorca_dataset"]], "torchtune.models.llama2": [[16, 0, 1, "", "llama2_7b"], [17, 0, 1, "", "lora_llama2"]], "torchtune.modules": [[18, 1, 1, "", "CausalSelfAttention"], [19, 1, 1, "", "FeedForward"], [20, 1, 1, "", "KVCache"], [21, 1, 1, "", "RMSNorm"], [22, 1, 1, "", "RotaryPositionalEmbeddings"], [23, 1, 1, "", "Tokenizer"], [24, 1, 1, "", "TransformerDecoder"], [25, 1, 1, "", "TransformerDecoderLayer"], [27, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[18, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[19, 2, 1, "", "forward"]], "torchtune.modules.RMSNorm": [[21, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[22, 2, 1, "", "forward"]], "torchtune.modules.Tokenizer": [[23, 2, 1, "", "decode"], [23, 2, 1, "", "encode"], [23, 2, 1, "", "from_file"], [23, 2, 1, "", "tokenize_messages"]], "torchtune.modules.TransformerDecoder": [[24, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoderLayer": [[25, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[26, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[28, 1, 1, "", "AdapterModule"], [29, 1, 1, "", "LoRALinear"], [30, 0, 1, "", "get_adapter_params"], [31, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[28, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[29, 2, 1, "", "adapter_params"], [29, 2, 1, "", "forward"]], "torchtune.utils": [[32, 1, 1, "", "FullModelHFCheckpointer"], [33, 1, 1, "", "FullModelMetaCheckpointer"], [36, 0, 1, "", "get_device"], [37, 0, 1, "", "get_world_size_and_rank"], [38, 0, 1, "", "init_distributed"], [49, 0, 1, "", "profiler"]], "torchtune.utils.FullModelHFCheckpointer": [[32, 2, 1, "", "load_checkpoint"], [32, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[33, 2, 1, "", "load_checkpoint"], [33, 2, 1, "", "save_checkpoint"]], "torchtune.utils.argparse": [[34, 1, 1, "", "TuneRecipeArgumentParser"]], "torchtune.utils.argparse.TuneRecipeArgumentParser": [[34, 2, 1, "", "parse_known_args"]], "torchtune.utils.collate": [[35, 0, 1, "", "padded_collate"]], "torchtune.utils.logging": [[39, 0, 1, "", "get_logger"]], "torchtune.utils.memory": [[40, 0, 1, "", "set_activation_checkpointing"]], "torchtune.utils.metric_logging": [[41, 1, 1, "", "DiskLogger"], [42, 1, 1, "", "StdoutLogger"], [43, 1, 1, "", "TensorBoardLogger"], [44, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[41, 2, 1, "", "close"], [41, 2, 1, "", "log"], [41, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[42, 2, 1, "", "close"], [42, 2, 1, "", "log"], [42, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[43, 2, 1, "", "close"], [43, 2, 1, "", "log"], [43, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[44, 2, 1, "", "close"], [44, 2, 1, "", "log"], [44, 2, 1, "", "log_config"], [44, 2, 1, "", "log_dict"]], "torchtune.utils.precision": [[45, 0, 1, "", "get_autocast"], [46, 0, 1, "", "get_dtype"], [47, 0, 1, "", "get_gradient_scaler"], [48, 0, 1, "", "list_dtypes"]], "torchtune.utils.seed": [[50, 0, 1, "", "set_seed"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 53, 55, 57, 59, 60], "config": [0, 6, 7, 58], "dataset": 1, "model": [2, 3, 8, 57, 58, 59], "llama2": [2, 57, 59, 60], "modul": 3, "compon": [3, 6], "build": [3, 60], "block": 3, "peft": 3, "util": [3, 4], "checkpoint": [4, 5, 8, 57], "distribut": 4, "reduc": 4, "precis": 4, "memori": [4, 59, 60], "manag": 4, "perform": [4, 59], "profil": [4, 49], "metric": [4, 8], "log": [4, 8], "data": 4, "miscellan": 4, "overview": [5, 55, 57], "format": 5, "handl": 5, "differ": 5, "intermedi": 5, "vs": 5, "final": 5, "lora": [5, 57, 59, 60], "put": [5, 60], "thi": 5, "all": [5, 6, 60], "togeth": [5, 60], "about": 6, "where": 6, "do": 6, "paramet": 6, "live": 6, "write": 6, "configur": 6, "us": [6, 7, 57, 60], "instanti": [6, 9], "referenc": 6, "other": [6, 57], "field": 6, "interpol": 6, "valid": 6, "your": [6, 7, 58], "best": 6, "practic": 6, "airtight": 6, "public": 6, "api": 6, "onli": 6, "command": 6, "line": 6, "overrid": 6, "what": [7, 55, 59, 60], "ar": 7, "recip": [7, 58, 59], "script": 7, "class": 7, "run": [7, 57], "cli": 7, "pars": [7, 10], "weight": 8, "bias": 8, "logger": 8, "w": 8, "b": 8, "alpaca_cleaned_dataset": 11, "alpaca_dataset": 12, "grammar_dataset": 13, "samsum_dataset": 14, "slimorca_dataset": 15, "llama2_7b": 16, "lora_llama2": 17, "causalselfattent": 18, "todo": [18, 25], "feedforward": 19, "kvcach": 20, "rmsnorm": 21, "rotarypositionalembed": 22, "token": 23, "transformerdecod": 24, "transformerdecoderlay": 25, "reparametrize_as_dtype_state_dict_post_hook": 26, "get_cosine_schedule_with_warmup": 27, "adaptermodul": 28, "loralinear": 29, "get_adapter_param": 30, "set_trainable_param": 31, "fullmodelhfcheckpoint": 32, "fullmodelmetacheckpoint": 33, "tunerecipeargumentpars": 34, "padded_col": 35, "get_devic": 36, "get_world_size_and_rank": 37, "init_distribut": 38, "get_logg": 39, "set_activation_checkpoint": 40, "disklogg": 41, "stdoutlogg": 42, "tensorboardlogg": 43, "wandblogg": 44, "get_autocast": 45, "get_dtyp": 46, "get_gradient_scal": 47, "list_dtyp": 48, "set_se": 50, "comput": [52, 56], "time": [52, 56], "welcom": 53, "document": 53, "get": 53, "start": 53, "tutori": 53, "instal": 54, "instruct": 54, "via": 54, "pypi": 54, "git": 54, "clone": 54, "kei": 55, "concept": 55, "design": 55, "principl": 55, "end": 57, "workflow": 57, "download": [57, 58], "7b": 57, "finetun": [57, 58, 59, 60], "evalu": 57, "eleutherai": 57, "s": 57, "eval": 57, "har": 57, "gener": 57, "speed": 57, "up": 57, "quantiz": 57, "librari": 57, "first": 58, "llm": 58, "select": 58, "modifi": 58, "train": 58, "next": 58, "step": 58, "how": 59, "doe": 59, "work": 59, "appli": 59, "trade": 59, "off": 59, "qlora": 60, "save": 60, "deep": 60, "dive": 60, "from": 60}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})