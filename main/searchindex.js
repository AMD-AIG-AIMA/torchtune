Search.setIndex({"docnames": ["api_ref_config", "api_ref_data", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "deep_dives/checkpointer", "deep_dives/configs", "deep_dives/recipe_deepdive", "deep_dives/wandb_logging", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.config.validate", "generated/torchtune.data.AlpacaInstructTemplate", "generated/torchtune.data.ChatFormat", "generated/torchtune.data.ChatMLFormat", "generated/torchtune.data.GrammarErrorCorrectionTemplate", "generated/torchtune.data.InstructTemplate", "generated/torchtune.data.Llama2ChatFormat", "generated/torchtune.data.Message", "generated/torchtune.data.MistralChatFormat", "generated/torchtune.data.SummarizeTemplate", "generated/torchtune.data.sharegpt_to_llama2_messages", "generated/torchtune.data.truncate", "generated/torchtune.data.validate_messages", "generated/torchtune.datasets.ChatDataset", "generated/torchtune.datasets.ConcatDataset", "generated/torchtune.datasets.InstructDataset", "generated/torchtune.datasets.PackedDataset", "generated/torchtune.datasets.PreferenceDataset", "generated/torchtune.datasets.TextCompletionDataset", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.chat_dataset", "generated/torchtune.datasets.cnn_dailymail_articles_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.instruct_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.datasets.stack_exchanged_paired_dataset", "generated/torchtune.datasets.text_completion_dataset", "generated/torchtune.datasets.wikitext_dataset", "generated/torchtune.models.gemma.gemma_2b", "generated/torchtune.models.llama2.llama2_13b", "generated/torchtune.models.llama2.llama2_70b", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2_13b", "generated/torchtune.models.llama2.lora_llama2_70b", "generated/torchtune.models.llama2.lora_llama2_7b", "generated/torchtune.models.llama2.qlora_llama2_13b", "generated/torchtune.models.llama2.qlora_llama2_7b", "generated/torchtune.models.llama3.llama3_70b", "generated/torchtune.models.llama3.llama3_8b", "generated/torchtune.models.llama3.lora_llama3_70b", "generated/torchtune.models.llama3.lora_llama3_8b", "generated/torchtune.models.llama3.qlora_llama3_8b", "generated/torchtune.models.mistral.lora_mistral_7b", "generated/torchtune.models.mistral.mistral_7b", "generated/torchtune.models.mistral.qlora_mistral_7b", "generated/torchtune.models.phi3.lora_phi3_mini", "generated/torchtune.models.phi3.phi3_mini", "generated/torchtune.models.phi3.qlora_phi3_mini", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.modules.tokenizers.SentencePieceTokenizer", "generated/torchtune.modules.tokenizers.TikTokenTokenizer", "generated/torchtune.utils.FSDPPolicyType", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.TuneRecipeArgumentParser", "generated/torchtune.utils.generate", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_dtype", "generated/torchtune.utils.get_full_finetune_fsdp_wrap_policy", "generated/torchtune.utils.get_logger", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.list_dtypes", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.padded_collate", "generated/torchtune.utils.profiler", "generated/torchtune.utils.set_activation_checkpointing", "generated/torchtune.utils.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times", "tutorials/chat", "tutorials/datasets", "tutorials/e2e_flow", "tutorials/first_finetune_tutorial", "tutorials/llama3", "tutorials/lora_finetune", "tutorials/qlora_finetune"], "filenames": ["api_ref_config.rst", "api_ref_data.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "deep_dives/checkpointer.rst", "deep_dives/configs.rst", "deep_dives/recipe_deepdive.rst", "deep_dives/wandb_logging.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.config.validate.rst", "generated/torchtune.data.AlpacaInstructTemplate.rst", "generated/torchtune.data.ChatFormat.rst", "generated/torchtune.data.ChatMLFormat.rst", "generated/torchtune.data.GrammarErrorCorrectionTemplate.rst", "generated/torchtune.data.InstructTemplate.rst", "generated/torchtune.data.Llama2ChatFormat.rst", "generated/torchtune.data.Message.rst", "generated/torchtune.data.MistralChatFormat.rst", "generated/torchtune.data.SummarizeTemplate.rst", "generated/torchtune.data.sharegpt_to_llama2_messages.rst", "generated/torchtune.data.truncate.rst", "generated/torchtune.data.validate_messages.rst", "generated/torchtune.datasets.ChatDataset.rst", "generated/torchtune.datasets.ConcatDataset.rst", "generated/torchtune.datasets.InstructDataset.rst", "generated/torchtune.datasets.PackedDataset.rst", "generated/torchtune.datasets.PreferenceDataset.rst", "generated/torchtune.datasets.TextCompletionDataset.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.chat_dataset.rst", "generated/torchtune.datasets.cnn_dailymail_articles_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.instruct_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.datasets.stack_exchanged_paired_dataset.rst", "generated/torchtune.datasets.text_completion_dataset.rst", "generated/torchtune.datasets.wikitext_dataset.rst", "generated/torchtune.models.gemma.gemma_2b.rst", "generated/torchtune.models.llama2.llama2_13b.rst", "generated/torchtune.models.llama2.llama2_70b.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2_13b.rst", "generated/torchtune.models.llama2.lora_llama2_70b.rst", "generated/torchtune.models.llama2.lora_llama2_7b.rst", "generated/torchtune.models.llama2.qlora_llama2_13b.rst", "generated/torchtune.models.llama2.qlora_llama2_7b.rst", "generated/torchtune.models.llama3.llama3_70b.rst", "generated/torchtune.models.llama3.llama3_8b.rst", "generated/torchtune.models.llama3.lora_llama3_70b.rst", "generated/torchtune.models.llama3.lora_llama3_8b.rst", "generated/torchtune.models.llama3.qlora_llama3_8b.rst", "generated/torchtune.models.mistral.lora_mistral_7b.rst", "generated/torchtune.models.mistral.mistral_7b.rst", "generated/torchtune.models.mistral.qlora_mistral_7b.rst", "generated/torchtune.models.phi3.lora_phi3_mini.rst", "generated/torchtune.models.phi3.phi3_mini.rst", "generated/torchtune.models.phi3.qlora_phi3_mini.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.modules.tokenizers.SentencePieceTokenizer.rst", "generated/torchtune.modules.tokenizers.TikTokenTokenizer.rst", "generated/torchtune.utils.FSDPPolicyType.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.generate.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_dtype.rst", "generated/torchtune.utils.get_full_finetune_fsdp_wrap_policy.rst", "generated/torchtune.utils.get_logger.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.list_dtypes.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.padded_collate.rst", "generated/torchtune.utils.profiler.rst", "generated/torchtune.utils.set_activation_checkpointing.rst", "generated/torchtune.utils.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst", "tutorials/chat.rst", "tutorials/datasets.rst", "tutorials/e2e_flow.rst", "tutorials/first_finetune_tutorial.rst", "tutorials/llama3.rst", "tutorials/lora_finetune.rst", "tutorials/qlora_finetune.rst"], "titles": ["torchtune.config", "torchtune.data", "torchtune.datasets", "torchtune.models", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "All About Configs", "What Are Recipes?", "Logging to Weights &amp; Biases", "instantiate", "parse", "validate", "AlpacaInstructTemplate", "ChatFormat", "ChatMLFormat", "GrammarErrorCorrectionTemplate", "InstructTemplate", "Llama2ChatFormat", "Message", "MistralChatFormat", "SummarizeTemplate", "sharegpt_to_llama2_messages", "truncate", "validate_messages", "ChatDataset", "ConcatDataset", "InstructDataset", "PackedDataset", "PreferenceDataset", "TextCompletionDataset", "alpaca_cleaned_dataset", "alpaca_dataset", "chat_dataset", "cnn_dailymail_articles_dataset", "grammar_dataset", "instruct_dataset", "samsum_dataset", "slimorca_dataset", "stack_exchanged_paired_dataset", "text_completion_dataset", "wikitext_dataset", "gemma_2b", "llama2_13b", "llama2_70b", "llama2_7b", "lora_llama2_13b", "lora_llama2_70b", "lora_llama2_7b", "qlora_llama2_13b", "qlora_llama2_7b", "llama3_70b", "llama3_8b", "lora_llama3_70b", "lora_llama3_8b", "qlora_llama3_8b", "lora_mistral_7b", "mistral_7b", "qlora_mistral_7b", "lora_phi3_mini", "phi3_mini", "qlora_phi3_mini", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "SentencePieceTokenizer", "TikTokenTokenizer", "torchtune.utils.FSDPPolicyType", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "generate", "get_device", "get_dtype", "get_full_finetune_fsdp_wrap_policy", "get_logger", "get_world_size_and_rank", "init_distributed", "list_dtypes", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "padded_collate", "profiler", "set_activation_checkpointing", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times", "Fine-tuning Llama3 with Chat Data", "Configuring Datasets for Fine-Tuning", "End-to-End Workflow with torchtune", "Fine-Tune Your First LLM", "Meta Llama3 in torchtune", "Finetuning Llama2 with LoRA", "Finetuning Llama2 with QLoRA"], "terms": {"For": [2, 5, 6, 7, 8, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 40, 41, 62, 67, 78, 80, 92, 95, 96, 100, 103, 104, 105, 106, 107, 108, 109], "detail": [2, 6, 33, 38, 64, 77, 84, 94, 96, 105, 106, 107, 108, 109], "usag": [2, 69, 100, 104, 105, 106, 107, 109], "guid": [2, 7, 9, 101, 103, 104, 106, 108], "pleas": [2, 5, 49, 50, 55, 58, 61, 77, 84, 95, 100, 109], "see": [2, 5, 6, 9, 18, 20, 33, 38, 41, 49, 50, 55, 58, 61, 64, 71, 77, 80, 84, 85, 92, 94, 95, 96, 100, 101, 103, 104, 105, 106, 107, 108, 109], "our": [2, 6, 8, 101, 103, 104, 105, 106, 108, 109], "tutori": [2, 6, 95, 101, 103, 104, 105, 106, 107, 108, 109], "support": [2, 6, 8, 9, 10, 20, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 60, 62, 72, 79, 83, 88, 101, 103, 104, 105, 106, 107, 108, 109], "sever": 2, "wide": 2, "us": [2, 4, 6, 9, 10, 11, 15, 18, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 62, 63, 65, 66, 67, 68, 69, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 89, 90, 91, 92, 96, 99, 100, 101, 104, 106, 107, 108], "help": [2, 6, 18, 67, 78, 80, 99, 100, 101, 103, 104, 105, 106, 107, 109], "quickli": [2, 7, 30, 103, 104], "bootstrap": 2, "your": [2, 5, 9, 10, 25, 30, 91, 92, 99, 100, 101, 103, 104, 107, 108, 109], "fine": [2, 6, 8, 9, 28, 99, 101, 105, 108], "tune": [2, 3, 6, 7, 8, 9, 11, 28, 99, 100, 101, 105, 108, 109], "also": [2, 6, 7, 8, 9, 10, 33, 36, 40, 62, 67, 72, 82, 84, 92, 100, 103, 104, 105, 106, 107, 108, 109], "common": [2, 4, 7, 103, 104, 107, 108], "format": [2, 5, 13, 14, 15, 16, 17, 18, 20, 21, 22, 25, 27, 29, 31, 32, 33, 36, 38, 78, 79, 103, 105, 106, 107, 108], "like": [2, 6, 7, 8, 9, 25, 100, 103, 104, 105, 106, 108], "chat": [2, 14, 15, 18, 19, 22, 25, 33, 38], "model": [2, 6, 7, 8, 10, 15, 20, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 78, 79, 81, 84, 94, 95, 99, 101, 103, 104, 109], "instruct": [2, 3, 13, 15, 17, 19, 20, 27, 28, 29, 31, 32, 36, 40, 60, 99, 103, 106, 108, 109], "These": [2, 4, 6, 7, 8, 10, 28, 80, 103, 104, 105, 106, 107, 108, 109], "ar": [2, 4, 6, 7, 9, 10, 13, 16, 17, 18, 19, 20, 21, 24, 27, 28, 29, 31, 32, 33, 35, 36, 37, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 67, 72, 77, 78, 79, 81, 83, 100, 101, 103, 104, 105, 106, 107, 108, 109], "especi": [2, 101, 105], "specifi": [2, 6, 7, 8, 10, 33, 62, 67, 68, 77, 81, 84, 92, 95, 103, 104, 105, 106, 107, 109], "from": [2, 3, 6, 7, 8, 9, 10, 13, 16, 17, 18, 19, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 40, 41, 42, 43, 44, 45, 57, 63, 67, 68, 70, 71, 73, 75, 78, 79, 80, 81, 91, 92, 98, 100, 102, 104, 105, 106, 107, 108], "yaml": [2, 7, 8, 10, 11, 33, 36, 40, 80, 92, 101, 103, 104, 105, 106, 107, 108, 109], "config": [2, 6, 9, 10, 11, 12, 33, 36, 40, 62, 78, 80, 92, 101, 103, 104, 105, 107, 108, 109], "represent": [2, 108, 109], "abov": [2, 6, 69, 100, 105, 107, 108, 109], "all": [3, 4, 8, 12, 25, 26, 28, 33, 62, 63, 67, 69, 76, 78, 80, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108], "famili": [3, 8, 31, 32, 34, 38, 39, 41, 101, 107], "download": [3, 6, 97, 100, 103, 104, 107, 108, 109], "meta": [3, 6, 18, 78, 79, 103, 105, 106], "llama": [3, 6, 18, 25, 33, 65, 66, 78, 79, 103, 105, 106, 107, 108], "8b": [3, 52, 53, 54, 59, 103], "hf": [3, 6, 78, 103, 105, 106, 107], "token": [3, 6, 7, 8, 19, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 62, 66, 67, 68, 75, 76, 81, 84, 93, 104, 105, 106, 107, 108, 109], "access_token": 3, "pre": [3, 18, 28, 100, 103, 104], "train": [3, 5, 6, 8, 9, 18, 25, 26, 27, 28, 31, 32, 33, 35, 36, 37, 38, 62, 66, 67, 68, 69, 70, 78, 79, 83, 94, 99, 101, 103, 104, 105, 107, 108, 109], "can": [3, 4, 6, 7, 8, 9, 10, 12, 19, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 40, 41, 65, 66, 75, 77, 78, 80, 84, 91, 92, 95, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109], "hug": [3, 6, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 70, 101, 106, 107], "face": [3, 6, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 70, 101, 106, 107], "hub": [3, 6, 104, 106], "follow": [3, 6, 8, 22, 25, 28, 62, 70, 92, 99, 100, 104, 105, 106, 107, 108, 109], "command": [3, 8, 9, 80, 100, 103, 104, 105, 106, 107, 108, 109], "2": [3, 6, 9, 24, 28, 38, 62, 75, 78, 79, 93, 96, 103, 105, 106, 107, 108], "7b": [3, 6, 27, 29, 30, 31, 32, 34, 36, 40, 41, 45, 48, 50, 56, 57, 78, 79, 103, 106, 107, 108, 109], "mini": [3, 59, 60, 61], "microsoft": [3, 60], "4k": [3, 60], "hf_token": 3, "ignor": [3, 6, 62, 63], "pattern": [3, 76], "ai": [3, 57, 62, 92, 103, 107], "mistralai": 3, "v0": 3, "1": [3, 6, 8, 28, 38, 62, 67, 70, 75, 76, 79, 81, 91, 92, 93, 96, 103, 105, 106, 107, 108, 109], "googl": [3, 42], "2b": [3, 42], "offer": 5, "allow": [5, 26, 91, 109], "seamless": 5, "transit": 5, "between": [5, 6, 78, 104, 105, 107, 108, 109], "interoper": [5, 6, 8, 101, 105, 109], "rest": [5, 103, 109], "ecosystem": [5, 6, 8, 101, 105, 107, 109], "comprehens": 5, "overview": [5, 7, 9, 99, 106, 108, 109], "deep": [5, 6, 7, 8, 9, 101, 106, 107], "dive": [5, 6, 7, 8, 9, 101, 106, 107], "enabl": [5, 7, 8, 9, 26, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 72, 94, 96, 107, 108, 109], "work": [5, 6, 8, 80, 101, 105, 107, 109], "set": [5, 6, 7, 8, 9, 27, 28, 29, 30, 31, 32, 34, 35, 36, 37, 38, 40, 41, 66, 67, 74, 77, 82, 84, 95, 96, 101, 103, 105, 106, 107, 108], "consumpt": [5, 26], "dure": [5, 6, 26, 27, 28, 31, 32, 35, 37, 62, 64, 66, 67, 68, 69, 103, 105, 107, 108, 109], "provid": [5, 6, 7, 8, 10, 15, 20, 23, 25, 26, 27, 28, 29, 38, 67, 80, 84, 92, 101, 103, 104, 105, 106, 107], "debug": [5, 6, 7, 8], "finetun": [5, 6, 7, 8, 46, 47, 48, 53, 54, 59, 88, 99, 101, 106, 107], "job": [5, 9, 96, 106], "variou": [5, 17], "dataset": [5, 7, 13, 16, 17, 19, 21, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 101, 106, 107], "walk": [6, 8, 91, 101, 103, 104, 105, 106, 109], "you": [6, 7, 8, 9, 10, 17, 18, 25, 27, 29, 30, 31, 32, 34, 36, 40, 41, 80, 81, 91, 92, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109], "through": [6, 7, 8, 9, 63, 101, 103, 104, 105, 106, 109], "design": [6, 8], "behavior": [6, 103, 104], "associ": [6, 7, 8, 81, 105, 108], "util": [6, 7, 8, 9, 10, 26, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 101, 105, 106, 107, 109], "what": [6, 7, 9, 18, 20, 35, 37, 99, 103, 104, 105, 106, 107], "cover": [6, 7, 8, 9, 103, 105, 109], "how": [6, 7, 8, 9, 77, 95, 99, 103, 104, 105, 106, 107, 109], "we": [6, 7, 8, 9, 27, 28, 29, 30, 31, 32, 34, 36, 40, 41, 62, 64, 66, 67, 72, 75, 78, 79, 81, 83, 101, 103, 104, 105, 106, 107, 108, 109], "them": [6, 7, 25, 26, 27, 29, 36, 63, 69, 75, 103, 104, 105, 108, 109], "scenario": [6, 26], "full": [6, 7, 8, 33, 36, 49, 50, 55, 58, 61, 75, 101, 104, 107, 108], "compos": 6, "compon": [6, 8, 12, 94, 101, 104, 106, 108, 109], "which": [6, 8, 26, 27, 28, 31, 32, 35, 37, 46, 47, 48, 53, 54, 56, 59, 62, 66, 67, 68, 70, 75, 78, 79, 83, 89, 92, 95, 101, 103, 104, 105, 106, 107, 108, 109], "plug": 6, "ani": [6, 7, 8, 10, 11, 12, 13, 16, 17, 21, 22, 23, 25, 27, 29, 30, 33, 34, 36, 40, 41, 69, 73, 74, 75, 78, 79, 81, 96, 103, 104, 105, 106, 107, 108], "recip": [6, 7, 9, 10, 11, 63, 78, 79, 101, 103, 104, 105, 107, 109], "evalu": [6, 8, 99, 101, 106, 108, 109], "gener": [6, 8, 13, 16, 21, 25, 27, 28, 29, 34, 38, 75, 96, 97, 99, 103, 104, 108, 109], "each": [6, 8, 14, 17, 26, 28, 46, 47, 48, 53, 54, 56, 59, 62, 66, 67, 68, 75, 76, 96, 101, 104, 105, 106, 107, 108], "make": [6, 7, 8, 9, 62, 68, 101, 105, 106, 107, 108, 109], "easi": [6, 8, 101, 104, 108], "understand": [6, 7, 8, 99, 101, 103, 104, 108, 109], "extend": [6, 8, 101], "befor": [6, 24, 27, 28, 29, 62, 67, 68, 72, 78, 105], "let": [6, 7, 9, 103, 104, 105, 106, 107, 108, 109], "s": [6, 7, 8, 9, 10, 11, 13, 14, 15, 18, 20, 24, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 46, 47, 48, 53, 54, 56, 59, 62, 64, 66, 67, 68, 69, 71, 73, 76, 77, 78, 79, 82, 84, 91, 94, 95, 101, 103, 104, 106, 108, 109], "defin": [6, 7, 8, 63, 71, 72, 73, 104, 106, 108], "some": [6, 7, 15, 73, 74, 99, 101, 103, 104, 105, 106, 108, 109], "concept": [6, 105, 106], "In": [6, 7, 8, 25, 66, 72, 77, 91, 92, 103, 105, 107, 108, 109], "ll": [6, 7, 8, 76, 81, 101, 103, 104, 105, 106, 107, 109], "talk": 6, "about": [6, 8, 78, 92, 101, 103, 105, 106, 107, 108, 109], "take": [6, 7, 8, 10, 63, 64, 69, 78, 80, 82, 103, 104, 105, 106, 107, 108, 109], "close": [6, 8, 89, 90, 91, 92, 108], "look": [6, 7, 8, 91, 100, 103, 104, 105, 106, 107, 108], "veri": [6, 26, 67, 105], "simpli": [6, 7, 28, 103, 104, 105, 107, 109], "dictat": 6, "state_dict": [6, 69, 78, 79, 108, 109], "store": [6, 26, 89, 92, 108, 109], "file": [6, 7, 8, 9, 10, 11, 75, 76, 78, 79, 80, 89, 92, 94, 98, 101, 102, 103, 104, 105, 106, 107, 108, 109], "disk": [6, 30, 89], "weight": [6, 8, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 62, 69, 71, 72, 78, 79, 92, 99, 103, 105, 106, 107, 108, 109], "string": [6, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 71, 75, 76, 82, 83, 104], "kei": [6, 7, 9, 25, 27, 29, 36, 62, 64, 67, 68, 74, 78, 105, 106, 108, 109], "identifi": 6, "state": [6, 8, 69, 73, 74, 78, 79, 105, 107, 108, 109], "dict": [6, 7, 8, 9, 10, 13, 16, 17, 19, 21, 22, 25, 27, 29, 30, 33, 34, 36, 40, 41, 69, 73, 74, 78, 79, 87, 93, 104], "If": [6, 7, 12, 13, 16, 17, 20, 21, 23, 24, 25, 27, 29, 31, 32, 35, 36, 37, 38, 62, 66, 67, 68, 69, 72, 78, 79, 81, 82, 83, 84, 87, 91, 92, 96, 100, 103, 104, 105, 106, 107, 108], "don": [6, 7, 8, 92, 96, 103, 104, 105, 106, 107, 109], "t": [6, 7, 8, 76, 83, 92, 96, 103, 104, 105, 106, 107, 109], "match": [6, 25, 27, 29, 36, 100, 104, 105, 107, 108], "up": [6, 8, 9, 27, 28, 29, 30, 31, 32, 34, 36, 40, 41, 103, 104, 106, 107, 108, 109], "exactli": 6, "those": [6, 108], "definit": [6, 108], "either": [6, 78, 81, 95, 108, 109], "run": [6, 7, 9, 11, 63, 64, 67, 69, 78, 79, 91, 92, 100, 101, 103, 104, 106, 107, 108, 109], "explicit": 6, "error": [6, 7, 24, 78, 96], "load": [6, 8, 25, 26, 27, 28, 29, 30, 78, 79, 80, 91, 103, 104, 105, 107, 108], "rais": [6, 10, 12, 20, 24, 33, 38, 62, 64, 67, 78, 79, 83, 87, 92, 96], "an": [6, 7, 8, 9, 10, 13, 19, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 62, 67, 71, 73, 74, 77, 78, 79, 84, 92, 101, 103, 104, 105, 106, 107, 108, 109], "except": [6, 19, 20, 104], "wors": 6, "silent": [6, 63], "succe": 6, "infer": [6, 18, 25, 62, 64, 66, 67, 68, 99, 103, 105, 106, 107, 109], "expect": [6, 7, 10, 13, 16, 17, 21, 25, 27, 29, 33, 36, 66, 92, 103, 104, 108], "addit": [6, 7, 8, 10, 25, 27, 29, 30, 33, 34, 36, 40, 41, 77, 78, 79, 83, 84, 87, 89, 91, 92, 95, 101, 103, 106, 108], "line": [6, 8, 80, 104, 106, 107], "need": [6, 7, 8, 9, 17, 25, 28, 38, 62, 63, 67, 91, 92, 100, 103, 104, 105, 106, 107, 108, 109], "shape": [6, 62, 64, 66, 67, 68, 72, 81], "valu": [6, 7, 22, 38, 42, 43, 44, 45, 51, 52, 57, 62, 64, 65, 67, 68, 70, 78, 80, 81, 89, 90, 91, 92, 96, 104, 106, 107, 108], "two": [6, 7, 24, 101, 105, 106, 107, 108, 109], "popular": [6, 101, 104, 105], "llama2": [6, 7, 8, 10, 18, 22, 25, 27, 29, 30, 31, 32, 34, 36, 38, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 63, 67, 68, 75, 99, 101, 106, 107], "offici": [6, 18, 103, 106, 107], "implement": [6, 8, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 63, 65, 66, 70, 71, 72, 78, 91, 101, 104, 108, 109], "when": [6, 7, 8, 11, 19, 26, 28, 62, 66, 67, 68, 69, 70, 81, 84, 91, 105, 107, 108, 109], "websit": 6, "get": [6, 7, 8, 9, 25, 75, 83, 85, 86, 100, 101, 103, 104, 105, 106, 108], "access": [6, 7, 8, 26, 78, 105, 106], "singl": [6, 7, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 26, 28, 62, 78, 79, 103, 104, 105, 106, 107, 108, 109], "pth": [6, 105, 107], "inspect": [6, 105, 108, 109], "content": [6, 19, 22, 25, 75, 103, 104], "easili": [6, 7, 101, 104, 108, 109], "torch": [6, 26, 64, 67, 69, 70, 81, 82, 83, 87, 94, 95, 96, 105, 106, 107, 108, 109], "import": [6, 7, 10, 33, 36, 40, 91, 92, 103, 104, 105, 106, 108, 109], "consolid": [6, 107], "00": [6, 98, 102, 106, 107], "mmap": [6, 105], "true": [6, 7, 19, 27, 28, 31, 32, 33, 35, 36, 37, 49, 50, 55, 58, 61, 62, 67, 68, 69, 75, 76, 77, 78, 79, 84, 87, 91, 103, 104, 105, 107, 108, 109], "weights_onli": 6, "map_loc": [6, 105], "cpu": [6, 8, 69, 83, 100, 105, 109], "tensor": [6, 62, 63, 64, 65, 66, 67, 68, 69, 72, 78, 81, 89, 90, 91, 92, 93, 108, 109], "item": 6, "print": [6, 9, 26, 31, 32, 35, 37, 38, 75, 81, 103, 104, 106, 108, 109], "f": [6, 9, 31, 32, 35, 37, 103, 105, 108, 109], "tok_embed": [6, 67], "size": [6, 8, 10, 31, 32, 35, 37, 62, 64, 65, 66, 67, 68, 86, 101, 104, 105, 106, 107, 108], "32000": [6, 10, 108], "4096": [6, 10, 27, 29, 30, 31, 32, 34, 36, 40, 41, 62, 66, 104, 108], "len": [6, 26, 31, 32, 35, 37, 67], "292": 6, "The": [6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 35, 37, 38, 39, 46, 47, 48, 53, 54, 59, 65, 66, 69, 70, 75, 76, 77, 78, 80, 82, 83, 85, 92, 94, 96, 100, 101, 103, 104, 105, 106, 107, 108, 109], "contain": [6, 19, 26, 28, 30, 40, 62, 64, 66, 67, 68, 71, 73, 74, 75, 76, 78, 79, 80, 91, 93, 103, 105, 107, 108], "includ": [6, 7, 8, 14, 17, 72, 78, 79, 80, 101, 103, 104, 105, 106, 107, 108, 109], "input": [6, 13, 14, 17, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 62, 63, 65, 66, 67, 68, 72, 75, 78, 93, 96, 103, 104, 108, 109], "embed": [6, 62, 64, 65, 66, 67, 84, 103, 107], "tabl": [6, 103, 109], "call": [6, 10, 19, 63, 69, 80, 89, 90, 91, 92, 103, 104, 108, 109], "layer": [6, 8, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 62, 67, 68, 72, 77, 84, 101, 107, 108, 109], "have": [6, 7, 10, 62, 64, 71, 80, 84, 91, 94, 100, 103, 104, 105, 106, 107, 108, 109], "dim": [6, 62, 63, 65, 66, 67, 68], "most": [6, 7, 76, 103, 106, 108, 109], "within": [6, 7, 10, 25, 28, 38, 63, 81, 91, 96, 104, 105, 107, 108, 109], "default": [6, 7, 15, 19, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 75, 76, 78, 79, 80, 81, 83, 89, 92, 93, 94, 96, 100, 104, 105, 107, 108, 109], "everi": [6, 8, 63, 91, 100, 109], "repo": [6, 78, 79, 105], "first": [6, 7, 10, 24, 28, 64, 67, 76, 78, 80, 99, 101, 103, 104, 105, 107, 108, 109], "big": [6, 105], "split": [6, 28, 103, 104, 105], "across": [6, 8, 26, 78, 91, 96, 105, 107], "bin": [6, 105], "To": [6, 7, 8, 9, 28, 78, 100, 101, 103, 104, 105, 106, 107, 108, 109], "correctli": [6, 8, 12, 78, 100, 103, 106, 109], "piec": 6, "one": [6, 8, 24, 63, 75, 103, 104, 105, 106, 107, 109], "pytorch_model": [6, 105], "00001": 6, "00002": 6, "embed_token": 6, "241": 6, "Not": 6, "onli": [6, 9, 19, 28, 34, 72, 73, 75, 79, 80, 81, 83, 84, 104, 105, 106, 107, 108, 109], "doe": [6, 20, 25, 28, 60, 62, 67, 68, 71, 78, 80, 103, 105], "fewer": [6, 62], "sinc": [6, 7, 10, 63, 78, 103, 105, 107], "instead": [6, 8, 28, 33, 36, 40, 63, 64, 72, 105, 107, 108], "mismatch": 6, "name": [6, 7, 9, 13, 16, 17, 21, 25, 27, 29, 30, 36, 38, 40, 41, 71, 74, 76, 78, 79, 80, 81, 82, 89, 90, 91, 92, 103, 105, 107], "caus": [6, 75], "try": [6, 7, 103, 105, 106, 107, 109], "same": [6, 7, 46, 47, 48, 53, 54, 59, 62, 64, 68, 75, 80, 84, 92, 103, 105, 107, 108, 109], "As": [6, 7, 8, 9, 72, 101, 105, 107, 109], "re": [6, 7, 76, 101, 103, 105, 106, 107, 108], "care": [6, 63, 78, 105, 107, 108], "end": [6, 8, 19, 26, 76, 99, 101, 103, 107, 108], "number": [6, 8, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 62, 64, 67, 70, 78, 79, 81, 86, 96, 106, 108], "just": [6, 13, 101, 103, 104, 106, 107, 108], "save": [6, 8, 9, 69, 78, 79, 84, 92, 99, 103, 104, 105, 107, 108], "less": [6, 38, 105, 106, 107, 109], "prone": 6, "manag": [6, 26, 94, 103], "invari": 6, "accept": [6, 7, 38, 75, 77, 104, 106, 109], "multipl": [6, 7, 8, 19, 25, 26, 62, 67, 68, 72, 89, 90, 91, 92, 106, 107], "sourc": [6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 103, 104, 105], "worri": [6, 103, 106], "explicitli": [6, 71, 101, 108], "convert": [6, 22, 25, 78, 93, 103, 105, 109], "time": [6, 75, 89, 91, 103, 104, 105, 107, 109], "produc": [6, 109], "back": [6, 24, 78, 104, 108, 109], "origin": [6, 31, 32, 69, 72, 103, 105, 107, 108, 109], "form": [6, 7, 8, 24], "One": [6, 105], "advantag": [6, 108], "being": [6, 78, 79, 82, 109], "should": [6, 7, 8, 14, 17, 18, 19, 20, 22, 28, 33, 36, 40, 46, 47, 48, 53, 54, 56, 59, 62, 63, 71, 77, 80, 89, 90, 91, 92, 100, 101, 104, 105, 106, 107, 108, 109], "abl": [6, 8, 105, 106, 107], "post": [6, 109], "tool": [6, 104, 105, 106], "quantiz": [6, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 72, 99, 106, 109], "eval": [6, 99, 101], "without": [6, 7, 9, 100, 101, 103, 105, 108], "code": [6, 8, 67, 97, 101, 104, 106], "chang": [6, 7, 9, 13, 100, 105, 106, 107, 108, 109], "OR": 6, "convers": [6, 14, 15, 18, 20, 22, 24, 25, 33, 38, 78, 101, 103, 104, 105, 107, 108, 109], "script": [6, 9, 105, 106, 107], "wai": [6, 7, 25, 103, 104, 105, 106, 107], "surround": [6, 8, 101], "load_checkpoint": [6, 8, 78, 79], "save_checkpoint": [6, 8, 9, 78, 79], "method": [6, 7, 8, 9, 11, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 69, 71, 73, 80, 100, 101, 104, 105, 107, 108, 109], "convertor": 6, "avail": [6, 8, 41, 80, 82, 83, 101, 105, 107, 108], "here": [6, 7, 9, 15, 35, 65, 66, 103, 104, 105, 106, 107, 108, 109], "three": [6, 8, 106], "hfcheckpoint": 6, "read": [6, 78, 79, 101], "write": [6, 8, 78, 79, 89, 103, 104, 106], "compat": [6, 78], "transform": [6, 8, 25, 27, 29, 46, 47, 48, 53, 54, 56, 59, 67, 68, 70, 95, 108], "framework": [6, 8, 101], "mention": [6, 105, 109], "assum": [6, 13, 16, 17, 21, 27, 29, 36, 62, 66, 67, 68, 70, 73, 76, 83, 105, 108], "checkpoint_dir": [6, 7, 78, 79, 105, 107], "necessari": [6, 38, 89, 90, 91, 92, 103, 108], "json": [6, 78, 94, 104, 105], "easiest": [6, 105, 106], "sure": [6, 7, 105, 106, 107, 108, 109], "everyth": [6, 8, 80, 101, 106], "flow": [6, 25, 27, 28, 29, 109], "By": [6, 107, 108, 109], "safetensor": 6, "output": [6, 17, 31, 32, 35, 38, 46, 47, 48, 53, 54, 56, 59, 62, 63, 65, 66, 67, 68, 72, 74, 81, 84, 90, 94, 100, 103, 104, 105, 106, 107, 108, 109], "dir": [6, 92, 100, 105, 106, 107], "output_dir": [6, 7, 78, 79, 94, 105, 107, 108, 109], "argument": [6, 7, 10, 17, 25, 27, 29, 30, 33, 34, 36, 38, 40, 41, 49, 50, 55, 58, 61, 62, 77, 80, 84, 87, 89, 91, 92, 95, 103, 104, 107, 108], "snippet": 6, "explain": 6, "setup": [6, 7, 8, 67, 95, 104, 105, 108, 109], "_component_": [6, 7, 9, 10, 33, 36, 40, 103, 104, 105, 107, 108], "fullmodelhfcheckpoint": [6, 105], "directori": [6, 7, 78, 79, 89, 91, 92, 105, 106, 107], "sort": [6, 78], "id": [6, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 62, 66, 67, 68, 75, 76, 78, 81, 93, 103, 104, 105], "so": [6, 7, 28, 78, 80, 100, 101, 103, 105, 106, 107, 108, 109], "order": [6, 8, 78, 91, 92, 106], "matter": [6, 78, 108], "checkpoint_fil": [6, 7, 9, 78, 79, 105, 107, 108, 109], "restart": 6, "previou": [6, 28, 78, 79], "more": [6, 7, 8, 33, 38, 64, 66, 77, 80, 92, 94, 95, 96, 101, 104, 105, 106, 107, 108, 109], "next": [6, 28, 81, 107, 109], "section": [6, 8, 99, 105, 107, 109], "recipe_checkpoint": [6, 78, 79], "null": [6, 7], "usual": [6, 66, 78, 92, 105, 108], "model_typ": [6, 78, 79, 105, 107], "resume_from_checkpoint": [6, 78, 79], "fals": [6, 7, 19, 22, 25, 27, 28, 31, 32, 33, 35, 36, 37, 38, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 62, 67, 68, 72, 75, 76, 78, 79, 94, 103, 104, 105, 107, 108, 109], "requir": [6, 7, 26, 30, 38, 40, 78, 91, 92, 96, 100, 103, 104, 106, 109], "param": [6, 8, 46, 47, 48, 53, 54, 59, 72, 73, 74, 78, 108, 109], "directli": [6, 7, 8, 10, 33, 36, 40, 77, 78, 105, 106, 107, 108, 109], "ensur": [6, 7, 12, 24, 38, 62, 78, 83, 101, 104, 106], "out": [6, 7, 8, 25, 27, 31, 32, 33, 35, 37, 78, 79, 99, 101, 103, 105, 106, 107, 108, 109], "case": [6, 8, 9, 19, 62, 78, 83, 89, 95, 101, 103, 104, 105, 107, 108, 109], "discrep": [6, 78], "along": [6, 107, 108], "found": [6, 7, 9, 65, 66, 108, 109], "metacheckpoint": 6, "github": [6, 10, 46, 47, 48, 53, 54, 59, 62, 65, 66, 70, 100, 104, 106], "repositori": [6, 18, 105, 106], "fullmodelmetacheckpoint": [6, 107], "torchtunecheckpoint": 6, "perform": [6, 28, 63, 81, 101, 103, 105, 107, 109], "current": [6, 28, 60, 62, 64, 66, 67, 68, 79, 84, 86, 89, 91, 96, 105, 106, 107], "test": [6, 7, 8, 101, 103], "complet": [6, 8, 28, 34, 103, 104, 105, 106, 107], "written": [6, 7, 8, 78, 79, 89, 90, 91, 92, 101], "begin": [6, 28, 75, 76, 103, 107, 109], "partit": [6, 109], "ha": [6, 71, 73, 75, 104, 105, 106, 107, 108, 109], "standard": [6, 90, 101, 103, 105, 107], "key_1": 6, "weight_1": 6, "key_2": 6, "weight_2": 6, "mid": 6, "chekpoint": 6, "middl": [6, 105], "inform": [6, 19, 92, 95, 101, 105, 106, 107], "subsequ": [6, 8], "recipe_st": [6, 78, 79], "pt": [6, 9, 78, 79, 105, 107], "epoch": [6, 8, 9, 70, 78, 79, 103, 105, 106, 107], "optim": [6, 7, 8, 26, 60, 70, 103, 105, 106, 107, 108, 109], "etc": [6, 8, 78, 106], "prevent": [6, 28], "flood": 6, "overwritten": 6, "note": [6, 7, 17, 19, 67, 71, 75, 78, 94, 96, 103, 104, 105, 108, 109], "updat": [6, 7, 8, 64, 100, 103, 105, 106, 107, 108, 109], "hf_model_0001_0": [6, 105], "hf_model_0002_0": [6, 105], "both": [6, 26, 105, 108, 109], "adapt": [6, 71, 72, 73, 74, 78, 79, 103, 105, 108, 109], "merg": [6, 10, 78, 105, 107, 109], "would": [6, 7, 9, 28, 67, 100, 103, 104, 105, 108, 109], "primari": [6, 7, 8, 106], "want": [6, 7, 8, 9, 10, 25, 81, 100, 103, 104, 105, 106, 107, 108], "resum": [6, 8, 70, 78, 79, 109], "initi": [6, 8, 11, 26, 28, 42, 43, 44, 45, 51, 52, 57, 87, 106, 108, 109], "frozen": [6, 108, 109], "base": [6, 10, 27, 29, 38, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 66, 70, 72, 74, 78, 80, 84, 89, 99, 103, 105, 106, 107, 108, 109], "well": [6, 7, 8, 101, 104, 105, 107, 109], "learnt": [6, 103, 105], "someth": [6, 8, 9, 103, 105], "NOT": 6, "refer": [6, 7, 8, 65, 66, 101, 108], "adapter_checkpoint": [6, 78, 79], "adapter_0": [6, 105], "now": [6, 75, 103, 104, 105, 106, 107, 108, 109], "knowledg": 6, "creat": [6, 7, 10, 28, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 64, 70, 77, 78, 79, 89, 91, 103, 104, 105, 107, 109], "simpl": [6, 8, 99, 104, 106, 108, 109], "forward": [6, 8, 62, 63, 65, 66, 67, 68, 72, 107, 108, 109], "13b": [6, 43, 46, 49], "modeltyp": [6, 78, 79], "llama2_13b": [6, 46], "right": [6, 78, 105, 107, 108], "pytorch_fil": 6, "00003": 6, "torchtune_sd": 6, "load_state_dict": [6, 108], "successfulli": [6, 106], "vocab": [6, 10, 67, 107], "70": [6, 51], "x": [6, 62, 63, 65, 66, 67, 68, 72, 81, 108, 109], "randint": 6, "0": [6, 8, 28, 46, 47, 48, 49, 50, 62, 67, 70, 72, 75, 81, 91, 92, 93, 96, 98, 102, 103, 104, 105, 106, 107, 108, 109], "no_grad": 6, "6": [6, 28, 65, 93, 105, 109], "3989": 6, "9": [6, 105, 109], "0531": 6, "3": [6, 28, 59, 60, 76, 80, 85, 93, 103, 105, 106, 107, 109], "2375": 6, "5": [6, 70, 93, 94, 105, 106, 107], "2822": 6, "4": [6, 38, 62, 93, 101, 105, 107, 108, 109], "4872": 6, "7469": 6, "8": [6, 31, 32, 35, 37, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 105, 108, 109], "6737": 6, "11": [6, 105, 107, 109], "0023": 6, "8235": 6, "6819": 6, "2424": 6, "0109": 6, "6915": 6, "7": [6, 93], "3618": 6, "1628": 6, "8594": 6, "5857": 6, "1151": 6, "7808": 6, "2322": 6, "8850": 6, "9604": 6, "7624": 6, "6040": 6, "3159": 6, "5849": 6, "8039": 6, "9322": 6, "2010": 6, "6824": 6, "8929": 6, "8465": 6, "3794": 6, "3500": 6, "6145": 6, "5931": 6, "do": [6, 8, 25, 27, 29, 36, 38, 92, 103, 104, 105, 106, 107, 108], "find": [6, 8, 9, 105, 106, 108], "list": [6, 7, 14, 15, 18, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 71, 72, 75, 76, 78, 79, 80, 81, 85, 88, 93, 103, 104, 106, 107], "builder": [6, 34, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 103, 104, 109], "hope": 6, "deeper": [6, 106], "insight": [6, 105], "happi": [6, 105], "thi": [7, 8, 9, 10, 19, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 40, 41, 60, 62, 63, 66, 67, 68, 69, 70, 71, 75, 77, 78, 79, 80, 81, 82, 83, 89, 91, 92, 94, 95, 96, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109], "pars": [7, 10, 76, 80, 103, 106], "effect": 7, "cli": [7, 9, 11, 100, 105, 106], "prerequisit": [7, 103, 104, 105, 106, 107, 108, 109], "Be": [7, 103, 105, 106, 107, 108, 109], "familiar": [7, 103, 105, 106, 107, 108, 109], "torchtun": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 100, 103, 104, 106], "instal": [7, 9, 91, 92, 99, 105, 106, 107, 108, 109], "fundament": 7, "There": [7, 14, 24, 103, 105, 106, 107, 108], "entri": [7, 8, 106], "point": [7, 8, 22, 104, 105, 106, 107, 108, 109], "locat": [7, 107, 108, 109], "thei": [7, 8, 19, 26, 67, 80, 103, 104, 108], "truth": [7, 105, 107], "reproduc": 7, "overridden": [7, 63, 80], "quick": [7, 26], "experiment": 7, "modifi": [7, 8, 9, 69, 101, 105, 107, 108, 109], "serv": [7, 77, 104, 108], "particular": [7, 25, 26, 38, 77, 104, 108, 109], "seed": [7, 8, 9, 96, 106], "shuffl": [7, 28], "devic": [7, 8, 82, 83, 103, 105, 106, 107, 108], "cuda": [7, 82, 83, 100, 105, 109], "dtype": [7, 8, 64, 67, 69, 83, 88, 105, 109], "fp32": [7, 109], "enable_fsdp": 7, "mani": [7, 28, 104, 105], "object": [7, 10, 14, 15, 18, 20, 62, 77, 103], "keyword": [7, 10, 25, 27, 29, 30, 33, 34, 36, 38, 40, 41, 69, 103, 104], "loss": [7, 8, 27, 31, 32, 35, 37, 106, 108, 109], "function": [7, 8, 10, 11, 25, 62, 63, 69, 77, 81, 82, 86, 96, 101, 103, 104, 109], "exampl": [7, 8, 9, 10, 11, 15, 18, 20, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 62, 71, 75, 77, 78, 79, 81, 91, 92, 93, 97, 98, 100, 102, 103, 104, 105, 107, 108, 109], "subfield": 7, "dotpath": 7, "wish": [7, 104], "exact": [7, 10, 105], "path": [7, 8, 9, 10, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 75, 76, 78, 79, 80, 94, 103, 104, 105, 107, 108], "normal": [7, 25, 28, 65, 67, 68, 75, 103, 104, 108, 109], "python": [7, 76, 80, 85, 92, 96, 97, 105], "alpaca_dataset": [7, 31, 104], "custom": [7, 8, 25, 27, 29, 33, 36, 40, 95, 101, 105, 106, 107, 108], "train_on_input": [7, 22, 25, 27, 31, 32, 33, 35, 36, 37, 38, 104], "onc": [7, 105, 106, 107, 108, 109], "ve": [7, 64, 76, 103, 104, 105, 107, 108], "instanc": [7, 10, 26, 63, 69, 73, 74, 108], "cfg": [7, 8, 11, 12], "automat": [7, 9, 10, 33, 105, 109], "under": [7, 104, 105, 107, 109], "preced": [7, 10, 107, 108], "actual": [7, 9, 25, 103], "throw": 7, "notic": [7, 103, 104, 108], "miss": [7, 108], "posit": [7, 10, 28, 62, 64, 66, 67, 68, 107], "anoth": [7, 105], "handl": [7, 11, 19, 26, 75, 103, 105, 108, 109], "def": [7, 8, 9, 11, 77, 103, 104, 108, 109], "dictconfig": [7, 8, 10, 11, 12, 92], "arg": [7, 10, 67, 69, 71, 80, 90], "tupl": [7, 10, 26, 38, 64, 69, 75, 76, 77, 80, 86, 93], "kwarg": [7, 10, 69, 71, 80, 87, 89, 90, 91, 92, 95, 104], "str": [7, 10, 13, 16, 17, 19, 21, 22, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 69, 71, 72, 73, 74, 75, 76, 78, 79, 80, 82, 83, 85, 88, 89, 90, 91, 92, 93, 94, 96, 103, 104], "mean": [7, 62, 65, 67, 68, 103, 104, 106, 108], "pass": [7, 10, 25, 26, 27, 29, 30, 33, 34, 36, 40, 41, 62, 63, 69, 77, 83, 84, 87, 91, 92, 95, 103, 104, 108, 109], "add": [7, 9, 25, 28, 76, 80, 104, 105, 107, 108, 109], "d": [7, 19, 62, 64, 67, 68, 76, 103, 108], "llama2_token": [7, 105], "tmp": [7, 103, 106, 107], "option": [7, 8, 13, 16, 17, 21, 23, 25, 27, 28, 29, 30, 33, 34, 36, 38, 40, 41, 46, 47, 48, 53, 54, 56, 59, 62, 66, 67, 68, 69, 75, 76, 78, 79, 81, 82, 83, 85, 89, 92, 94, 96, 100, 101, 104, 105], "bool": [7, 19, 22, 25, 27, 28, 31, 32, 33, 35, 36, 37, 38, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 69, 72, 75, 76, 77, 78, 79, 84, 87, 91, 94, 95, 109], "max_seq_len": [7, 10, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 62, 64, 66, 67, 75, 76, 103, 104], "int": [7, 9, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 62, 64, 65, 66, 67, 70, 72, 75, 76, 77, 78, 79, 81, 84, 86, 89, 90, 91, 92, 93, 95, 96, 103, 104, 108, 109], "512": [7, 31, 32, 104, 109], "instructdataset": [7, 31, 32, 35, 36, 37, 104], "alreadi": [7, 87, 100, 104, 105, 108], "overwrit": [7, 100], "duplic": [7, 8, 101], "sometim": 7, "than": [7, 24, 38, 62, 64, 77, 103, 104, 105, 106, 107, 108, 109], "resolv": [7, 106], "alpaca": [7, 13, 31, 32, 46, 47, 48, 53, 54, 59, 104], "metric_logg": [7, 8, 9], "metric_log": [7, 9, 89, 90, 91, 92], "disklogg": 7, "log_dir": [7, 89, 91, 92], "conveni": [7, 8], "verifi": [7, 82, 83, 84, 103, 106, 108], "properli": 7, "experi": [7, 92, 99, 101, 103, 107, 108], "wa": [7, 103, 105, 107, 108, 109], "cp": [7, 100, 103, 105, 106, 107], "7b_lora_single_devic": [7, 105, 106, 108, 109], "my_config": 7, "discuss": [7, 106, 108], "guidelin": 7, "while": [7, 8, 46, 47, 48, 53, 54, 59, 63, 101, 105, 109], "mai": [7, 9, 84, 94, 103, 104, 106, 108], "tempt": 7, "put": [7, 8, 106, 108], "much": [7, 105, 107, 108, 109], "give": [7, 104, 108], "maximum": [7, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 62, 64, 66, 67, 76], "flexibl": [7, 26, 104], "switch": 7, "encourag": [7, 108], "clariti": 7, "significantli": 7, "easier": [7, 105, 106], "dont": 7, "slimorca_dataset": 7, "privat": 7, "typic": [7, 28, 30, 40, 104, 109], "expos": [7, 8, 103, 106], "parent": 7, "modul": [7, 10, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 84, 95, 96, 103, 106, 108, 109], "__init__": [7, 8, 108, 109], "py": [7, 10, 46, 47, 48, 53, 54, 59, 62, 64, 65, 66, 70, 105, 107], "guarante": 7, "stabil": [7, 101, 109], "underscor": 7, "_alpaca": 7, "collect": [7, 81, 106], "differ": [7, 9, 25, 26, 27, 29, 75, 101, 103, 105, 107, 108, 109], "itself": 7, "via": [7, 9, 33, 36, 40, 72, 78, 108, 109], "pair": [7, 39, 93, 104], "k1": [7, 8], "v1": [7, 8, 41], "k2": [7, 8], "v2": [7, 8, 104], "lora_finetune_single_devic": [7, 103, 105, 106, 107, 108, 109], "checkpoint": [7, 8, 69, 76, 78, 79, 92, 95, 101, 107, 108, 109], "home": 7, "my_model_checkpoint": 7, "file_1": 7, "file_2": 7, "my_tokenizer_path": 7, "class": [7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 26, 27, 28, 29, 30, 33, 36, 62, 63, 64, 65, 66, 67, 68, 71, 72, 73, 74, 75, 76, 78, 79, 80, 89, 90, 91, 92, 103, 104, 106, 108, 109], "assign": 7, "nest": 7, "dot": 7, "notat": [7, 62, 66, 67, 68], "core": [8, 101, 104, 106, 109], "i": [8, 18, 20, 62, 67, 68, 69, 74, 76, 81, 104, 105, 107, 109], "structur": [8, 14, 15, 18, 20, 25, 103, 104, 105], "new": [8, 34, 57, 89, 91, 103, 105, 106, 107, 108, 109], "user": [8, 14, 15, 18, 19, 20, 22, 24, 25, 62, 75, 103, 104, 106], "thought": [8, 101, 106, 109], "target": [8, 101], "pipelin": [8, 101], "llm": [8, 99, 101, 104, 105, 108], "eg": [8, 67, 78, 101], "meaning": [8, 101, 105], "featur": [8, 9, 100, 101, 105, 106], "fsdp": [8, 77, 84, 101, 106, 107], "activ": [8, 63, 95, 101, 109], "gradient": [8, 101, 105, 107, 108, 109], "accumul": [8, 101], "mix": [8, 104, 105], "precis": [8, 69, 83, 101, 106, 109], "appli": [8, 25, 27, 29, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 62, 65, 66, 67, 68, 95, 101, 109], "given": [8, 10, 17, 24, 72, 81, 82, 83, 101, 108], "complex": 8, "becom": [8, 100, 104], "harder": 8, "anticip": 8, "architectur": [8, 18, 20, 67, 104], "methodolog": 8, "reason": [8, 81, 105], "possibl": [8, 25, 28, 33, 104], "trade": 8, "off": [8, 75, 105], "memori": [8, 26, 27, 28, 29, 30, 31, 32, 34, 36, 40, 41, 69, 84, 99, 101, 105, 106, 107], "vs": [8, 106], "qualiti": [8, 105, 108], "believ": 8, "best": [8, 103], "suit": [8, 106], "specif": [8, 10, 84, 103, 104, 105, 109], "b": [8, 62, 64, 66, 67, 68, 72, 92, 108, 109], "fit": [8, 25, 27, 28, 29, 30, 31, 32, 34, 36, 40, 41, 104], "solut": 8, "result": [8, 75, 105, 107, 108, 109], "meant": [8, 69], "depend": [8, 9, 13, 104, 105, 108, 109], "level": [8, 85, 101, 109], "expertis": 8, "routin": 8, "yourself": [8, 107, 108], "exist": [8, 100, 105, 106, 107, 109], "ad": [8, 75, 103, 108, 109], "ones": 8, "modular": [8, 101], "build": [8, 33, 36, 40, 101, 107, 108], "block": [8, 28, 46, 47, 48, 53, 54, 56, 59, 101], "wandb": [8, 9, 92, 106], "log": [8, 85, 89, 90, 91, 92, 105, 106, 107, 109], "fulli": [8, 26], "nativ": [8, 99, 101, 108, 109], "pytorch": [8, 67, 69, 77, 91, 94, 95, 96, 99, 100, 101, 107, 108, 109], "correct": [8, 16, 35, 65, 66, 67, 82, 101, 103, 104], "numer": [8, 101], "pariti": [8, 101], "verif": 8, "extens": [8, 101], "comparison": [8, 108, 109], "benchmark": [8, 96, 101, 105, 107, 108], "limit": [8, 104], "hidden": [8, 63], "behind": 8, "100": [8, 27, 31, 32, 35, 37, 38, 81, 93, 94, 108, 109], "flag": [8, 27, 31, 32, 35, 37, 77, 84, 109], "prefer": [8, 39, 101, 104], "over": [8, 70, 80, 101, 105, 107, 108, 109], "unnecessari": 8, "abstract": [8, 14, 17, 101, 106, 109], "No": [8, 101], "inherit": [8, 80, 101, 104], "go": [8, 18, 20, 75, 101, 104, 105, 106, 109], "upon": [8, 26, 107], "figur": [8, 108, 109], "spectrum": 8, "decid": 8, "interact": [8, 99, 106], "start": [8, 9, 26, 76, 100, 101, 103, 104, 105, 106], "paradigm": 8, "consist": [8, 41, 106], "configur": [8, 27, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 68, 101, 103, 106, 107, 108, 109], "paramet": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 87, 89, 90, 91, 92, 93, 94, 95, 96, 99, 101, 103, 104, 105, 106, 107, 108, 109], "overrid": [8, 11, 105, 106, 107, 109], "togeth": [8, 28, 92, 106, 108], "valid": [8, 24, 100, 105, 106], "environ": [8, 100, 105, 106], "logic": [8, 78, 101, 106, 108], "api": [8, 9, 49, 50, 55, 58, 61, 103, 105, 106, 107, 109], "closer": [8, 108], "monolith": [8, 101], "trainer": [8, 86], "A": [8, 9, 22, 26, 28, 62, 67, 68, 69, 72, 75, 76, 77, 78, 80, 93, 98, 99, 102, 103, 105, 108, 109], "wrapper": [8, 75, 76, 108], "around": [8, 25, 75, 76, 94, 103, 105, 108, 109], "extern": [8, 104], "primarili": [8, 26, 108], "eleutherai": [8, 101, 108], "har": [8, 101, 108], "control": [8, 27, 31, 32, 35, 37, 96, 105], "multi": [8, 25, 62, 107], "stage": 8, "distil": 8, "oper": [8, 26, 94, 96], "turn": [8, 19, 24, 25, 76, 103], "dataload": [8, 28, 31, 32, 35, 37], "applic": [8, 62, 78, 79, 92], "clean": [8, 9, 31], "after": [8, 62, 64, 65, 67, 68, 89, 90, 91, 92, 103, 109], "process": [8, 9, 69, 96, 104, 106, 109], "group": [8, 62, 89, 90, 91, 92, 107], "init_process_group": [8, 87], "backend": 8, "gloo": 8, "els": [8, 80, 92, 101, 109], "nccl": 8, "fullfinetunerecipedistribut": 8, "cleanup": 8, "other": [8, 10, 26, 80, 84, 104, 106, 107, 108], "stuff": 8, "carri": 8, "relev": [8, 19, 105, 108], "interfac": [8, 14, 17, 26, 71], "metric": [8, 106], "logger": [8, 85, 89, 90, 91, 92, 106], "self": [8, 9, 28, 46, 47, 48, 53, 54, 56, 59, 62, 67, 68, 71, 104, 108, 109], "_devic": 8, "get_devic": 8, "_dtype": 8, "get_dtyp": 8, "ckpt_dict": 8, "wrap": [8, 77, 84, 94, 95, 103], "_model": 8, "_setup_model": 8, "_token": [8, 104], "_setup_token": 8, "_optim": 8, "_setup_optim": 8, "_loss_fn": 8, "_setup_loss": 8, "_sampler": 8, "_dataload": 8, "_setup_data": 8, "backward": [8, 109], "zero_grad": 8, "curr_epoch": 8, "rang": [8, 96, 107], "epochs_run": [8, 9], "total_epoch": [8, 9], "idx": [8, 28], "batch": [8, 28, 31, 32, 35, 37, 62, 64, 66, 67, 68, 75, 93, 101, 104, 106, 107, 108], "enumer": 8, "_autocast": 8, "logit": [8, 81], "label": [8, 25, 27, 28, 29, 30, 31, 32, 33, 34, 36, 38, 39, 40, 41, 93], "global_step": 8, "_log_every_n_step": 8, "_metric_logg": 8, "log_dict": [8, 89, 90, 91, 92], "step": [8, 28, 67, 70, 76, 89, 90, 91, 92, 94, 99, 105, 108, 109], "learn": [8, 26, 70, 101, 103, 104, 106, 107, 108, 109], "decor": [8, 11], "recipe_main": [8, 11], "none": [8, 9, 12, 13, 16, 17, 20, 21, 23, 24, 25, 27, 28, 29, 30, 33, 34, 36, 38, 40, 41, 62, 64, 66, 67, 68, 74, 75, 76, 78, 79, 81, 82, 83, 85, 89, 90, 91, 92, 95, 96, 103, 104, 105], "fullfinetunerecip": 8, "direct": [8, 100], "wandblogg": [9, 108, 109], "workspac": 9, "seen": [9, 108, 109], "screenshot": 9, "below": [9, 66, 77, 104, 107, 108, 109], "packag": [9, 91, 92, 100], "pip": [9, 91, 92, 100, 105, 107], "Then": [9, 106], "login": [9, 92, 105], "built": [9, 39, 100, 103, 106, 109], "project": [9, 46, 47, 48, 53, 54, 56, 59, 62, 63, 84, 92, 99, 108, 109], "grab": [9, 107], "tab": 9, "tip": 9, "straggler": 9, "background": 9, "crash": 9, "otherwis": [9, 103], "exit": [9, 100], "resourc": [9, 89, 90, 91, 92], "kill": 9, "ps": 9, "aux": 9, "grep": 9, "awk": 9, "xarg": 9, "click": 9, "sampl": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 27, 28, 29, 30, 36, 38, 40, 62, 66, 67, 68, 81, 103, 105], "desir": [9, 25, 103], "suggest": 9, "approach": [9, 26, 104], "full_finetun": 9, "joinpath": 9, "_checkpoint": [9, 105], "_output_dir": [9, 78, 79], "torchtune_model_": 9, "with_suffix": 9, "wandb_at": 9, "artifact": 9, "type": [9, 10, 11, 19, 22, 23, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 59, 60, 62, 64, 65, 66, 67, 68, 69, 72, 73, 75, 76, 77, 78, 79, 81, 83, 84, 85, 86, 87, 94, 95, 104, 105, 108, 109], "descript": [9, 33, 38], "whatev": 9, "metadata": 9, "seed_kei": 9, "epochs_kei": 9, "total_epochs_kei": 9, "max_steps_kei": 9, "max_steps_per_epoch": 9, "add_fil": 9, "log_artifact": 9, "field": [10, 17, 19, 22, 25, 28, 31, 32, 35, 37, 104], "hydra": 10, "facebook": 10, "research": 10, "http": [10, 25, 27, 29, 30, 33, 34, 36, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 53, 54, 55, 57, 58, 59, 60, 61, 62, 65, 66, 70, 77, 78, 79, 80, 85, 91, 92, 94, 95, 96, 100, 104, 105], "com": [10, 46, 47, 48, 53, 54, 59, 62, 65, 66, 70, 100], "facebookresearch": [10, 65, 66], "blob": [10, 46, 47, 48, 53, 54, 59, 62, 65, 66, 70], "main": [10, 11, 62, 65, 66, 100, 105, 107], "_intern": 10, "_instantiate2": 10, "l148": 10, "omegaconf": 10, "num_lay": [10, 67], "32": [10, 107, 108, 109], "num_head": [10, 62, 64, 66, 67], "num_kv_head": [10, 62, 64], "vocab_s": 10, "must": [10, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 71, 76, 80, 109], "return": [10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 59, 60, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 74, 75, 76, 77, 78, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 96, 103, 104, 108, 109], "nn": [10, 62, 63, 64, 67, 68, 69, 71, 73, 74, 77, 95, 108, 109], "parsed_yaml": 10, "embed_dim": [10, 62, 66, 68, 108], "valueerror": [10, 20, 24, 33, 38, 62, 64, 67, 78, 79, 83, 96], "callabl": [11, 25, 27, 29, 67, 77, 81, 84, 95], "With": [11, 105, 108, 109], "my_recip": 11, "foo": 11, "bar": [11, 101, 106], "instanti": [12, 42, 43, 44, 45, 46, 47, 48, 51, 52, 53, 54, 56, 57, 59, 60], "configerror": 12, "cannot": [12, 107], "data": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 89, 90, 91, 92, 104, 105, 109], "prompt": [13, 14, 16, 17, 18, 20, 21, 22, 25, 27, 29, 31, 32, 33, 35, 36, 37, 38, 40, 67, 75, 81, 104, 105, 107], "templat": [13, 14, 16, 17, 21, 25, 27, 29, 31, 32, 35, 36, 37, 38], "style": [13, 28, 31, 32, 33, 38, 109], "slightli": 13, "classmethod": [13, 14, 15, 16, 17, 18, 19, 20, 21, 104], "map": [13, 16, 17, 21, 22, 25, 26, 27, 28, 29, 36, 74, 78, 89, 90, 91, 92, 103, 104, 105, 108], "column_map": [13, 16, 17, 21, 25, 27, 29, 36, 104], "placehold": [13, 14, 16, 17, 21, 25, 27, 29, 36, 104], "column": [13, 16, 17, 21, 25, 27, 29, 30, 36, 40, 62, 67, 68, 103, 104], "ident": [13, 16, 17, 20, 21, 27, 28, 29, 36, 105], "role": [14, 19, 22, 25, 75, 103, 104], "system": [14, 15, 18, 19, 20, 22, 24, 25, 75, 103, 104], "assist": [14, 15, 18, 19, 22, 24, 25, 75, 81, 103, 104], "messag": [14, 15, 18, 20, 22, 24, 25, 33, 75, 76, 100, 103, 104], "accord": [14, 20, 103], "openai": [15, 33, 104], "markup": 15, "languag": [15, 72, 81, 108], "It": [15, 20, 103, 104, 109], "huggingfac": [15, 25, 27, 29, 30, 33, 34, 36, 40, 41, 60, 70, 78, 79, 105], "im_start": 15, "context": [15, 60, 94, 104], "im_end": 15, "goe": 15, "respons": [15, 75, 104, 105, 106, 107], "appropri": [15, 18, 20, 26, 70, 104, 109], "tag": [15, 18, 20, 25, 76, 89, 90, 91, 92, 103], "grammar": [16, 35, 104], "sentenc": [16, 28], "alwai": [17, 80], "human": [18, 22, 103], "taken": [18, 108, 109], "inst": [18, 20, 25, 103, 104], "sy": [18, 103, 104], "respect": [18, 26, 74, 103, 104], "honest": [18, 103, 104], "am": [18, 20, 103, 104, 105, 107], "pari": [18, 20, 104], "capit": [18, 20, 104], "franc": [18, 20, 104], "known": [18, 20, 75, 104], "its": [18, 20, 28, 62, 66, 67, 68, 96, 104, 105, 107, 108], "stun": [18, 20, 104], "liter": [19, 46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61], "mask": [19, 27, 28, 31, 32, 35, 37, 62, 67, 68, 75, 76, 103, 104], "ipython": 19, "eot": 19, "dataclass": [19, 103], "repres": [19, 103], "individu": [19, 28, 92, 95, 103, 104], "tiktoken": [19, 76, 107], "special": [19, 25, 76, 104], "variabl": [19, 25, 26, 27, 29, 36, 109], "writer": 19, "whether": [19, 22, 25, 27, 31, 32, 33, 35, 36, 37, 38, 46, 47, 48, 53, 54, 56, 59, 69, 72, 75, 76, 77, 83, 103, 104], "correspond": [19, 71, 73, 83, 106, 107], "consecut": [19, 24], "from_dict": [19, 103], "construct": [19, 108], "dictionari": [19, 28, 89, 90, 91, 92, 105], "mistral": [20, 25, 38, 56, 57, 58, 103, 105, 106], "llama2chatformat": [20, 103, 104], "summar": [21, 37, 103, 104], "task": [21, 26, 34, 103, 104, 105, 107, 108, 109], "dialogu": [21, 37, 103], "dialog": 21, "adher": 22, "sharegpt": [22, 33], "gpt": [22, 62, 105], "remain": [22, 70, 108], "unmask": 22, "eos_id": 23, "length": [23, 24, 26, 27, 28, 29, 30, 31, 32, 34, 36, 38, 40, 41, 60, 62, 64, 66, 67, 68, 75, 76, 79, 93], "last": [23, 28, 70, 104], "replac": [23, 27, 31, 32, 35, 37, 69, 108], "forth": [24, 104], "come": [24, 71, 108], "empti": 24, "shorter": 24, "min": [24, 108], "invalid": 24, "convert_to_messag": [25, 103], "chat_format": [25, 33, 38, 103, 104], "chatformat": [25, 33, 104], "load_dataset_kwarg": [25, 27, 29, 30, 33, 34, 36, 40, 41], "multiturn": [25, 103], "foreach": 25, "prepar": [25, 103], "truncat": [25, 27, 28, 29, 30, 34, 36, 38, 40, 41, 75, 76, 104], "encod": [25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 75, 76, 103], "decod": [25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 67, 75, 76, 81, 103], "anyth": [25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41], "load_dataset": [25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 103, 104], "co": [25, 27, 29, 30, 33, 34, 36, 40, 41, 60, 78, 79, 105], "doc": [25, 27, 29, 30, 33, 34, 36, 40, 41, 77, 80, 85, 91, 92, 94, 96, 105], "en": [25, 27, 29, 30, 33, 34, 36, 40, 41], "package_refer": [25, 27, 29, 30, 33, 34, 36, 40, 41], "loading_method": [25, 27, 29, 30, 33, 34, 36, 40, 41], "text": [25, 28, 30, 34, 40, 41, 75, 76, 103, 105], "extra": [25, 100, 108, 109], "still": [25, 80, 108, 109], "llama3": [25, 38, 51, 52, 53, 54, 55, 81, 84, 99, 104], "where": [25, 26, 31, 32, 35, 37, 62, 67, 72, 75, 104], "unless": 25, "check": [25, 33, 67, 83, 99, 103, 105, 106, 108], "concaten": [26, 75], "sub": [26, 91], "unifi": 26, "were": [26, 103, 106], "simplifi": [26, 108], "simultan": 26, "intern": [26, 80], "aggreg": 26, "transpar": 26, "index": [26, 62, 66, 67, 68, 70, 93, 100, 103, 105], "howev": [26, 100], "constitu": 26, "might": [26, 105], "larg": [26, 72, 109], "comput": [26, 62, 63, 66, 67, 96, 105, 109], "cumul": 26, "maintain": [26, 109], "indic": [26, 28, 62, 66, 67, 68, 77, 103], "deleg": 26, "retriev": [26, 84], "lead": [26, 75], "high": [26, 101, 108], "scale": [26, 46, 47, 48, 53, 54, 56, 59, 72, 81, 108, 109], "consid": 26, "strategi": 26, "stream": [26, 85], "demand": 26, "deriv": [26, 63, 67, 68], "_dataset": 26, "_len": 26, "total": [26, 70, 86, 98, 102, 105, 107, 108], "combin": 26, "_index": 26, "lookup": 26, "dataset1": 26, "mycustomdataset": 26, "params1": 26, "dataset2": 26, "params2": 26, "concat_dataset": 26, "data_point": 26, "1500": 26, "element": [26, 76, 105], "focus": [26, 106], "enhanc": [26, 109], "divers": 26, "machin": [26, 82, 105], "instructtempl": [27, 29, 104], "contribut": [27, 31, 32, 35, 37], "disabl": [27, 29, 30, 34, 36, 40, 41, 96], "recommend": [27, 29, 30, 31, 32, 34, 36, 40, 41, 91, 103, 105, 109], "highest": [27, 29, 30, 31, 32, 34, 36, 40, 41], "sequenc": [27, 28, 29, 30, 31, 32, 34, 36, 38, 40, 41, 62, 64, 66, 67, 68, 75, 76, 93, 103], "ds": [28, 38], "max_pack": 28, "split_across_pack": 28, "greedi": 28, "pack": [28, 31, 32, 33, 35, 36, 37, 38, 62, 66, 67, 68], "done": [28, 83, 108, 109], "preprocess": 28, "outsid": [28, 96, 105, 107, 108], "sampler": [28, 106], "part": [28, 103, 109], "buffer": 28, "long": [28, 103, 108], "enough": [28, 103], "attent": [28, 46, 47, 48, 53, 54, 56, 59, 60, 62, 64, 66, 67, 68, 107, 108, 109], "lower": [28, 108], "triangular": 28, "cross": 28, "attend": [28, 62, 67, 68], "rel": [28, 62, 66, 67, 68, 108], "pad": [28, 81, 93, 104], "max": [28, 38, 67, 70, 75, 108], "wise": 28, "collat": [28, 93, 104], "made": [28, 33, 36, 40, 66, 105], "smaller": [28, 105, 107, 108, 109], "jam": 28, "vari": 28, "s1": [28, 75], "s2": [28, 75], "s3": 28, "s4": 28, "contamin": 28, "input_po": [28, 62, 64, 66, 67, 68], "matrix": 28, "causal": [28, 62, 67, 68], "continu": [28, 104], "increment": 28, "move": [28, 67], "entir": [28, 103, 109], "avoid": [28, 65, 69, 96, 109], "freeform": [30, 40], "unstructur": [30, 41], "corpu": [30, 34, 41], "local": [30, 40, 92, 96, 100, 103, 105, 106], "tabular": [30, 40], "omit": [30, 40, 108], "yahma": [31, 36], "codebas": [31, 32, 35, 37, 105], "prior": [31, 32, 33, 35, 36, 37, 38], "alpaca_d": [31, 32], "batch_siz": [31, 32, 35, 37, 62, 64, 67, 68, 105], "tatsu": 32, "lab": 32, "conversation_styl": [33, 104], "chatdataset": [33, 38, 103, 104], "friendli": [33, 36, 40, 81, 103], "huggingfaceh4": 33, "no_robot": 33, "chatmlformat": 33, "2096": [33, 36, 40], "accomplish": [33, 36, 40], "packeddataset": [33, 36, 104], "ccdv": 34, "cnn_dailymail": 34, "textcompletiondataset": [34, 40, 41, 104], "similar": [34, 39, 41, 104, 105, 107, 108, 109], "cnn": 34, "dailymail": 34, "articl": [34, 41], "extract": 34, "highlight": [34, 109], "liweili": 35, "c4_200m": 35, "variant": [35, 37], "mirror": [35, 37], "llama_recip": [35, 37], "grammar_d": 35, "alpaca_clean": 36, "alpacainstructtempl": [36, 104], "samsum": [37, 104], "summari": [37, 104], "samsum_d": 37, "open": [38, 42, 104, 105], "orca": 38, "slimorca": 38, "dedup": 38, "1024": [38, 39, 104], "prescrib": 38, "least": [38, 107, 108], "though": [38, 103], "10": [38, 93, 105, 107, 109], "351": 38, "82": [38, 105], "391": 38, "221": 38, "220": 38, "193": 38, "12": [38, 100], "471": 38, "lvwerra": [39, 104], "stack": [39, 104], "exchang": [39, 104], "preferencedataset": [39, 104], "stackexchangepair": 39, "textdataset": 40, "allenai": [40, 104], "c4": [40, 104], "data_dir": [40, 104], "realnewslik": [40, 104], "wikitext": 41, "subset": [41, 73], "103": [41, 105], "raw": 41, "wikipedia": 41, "page": [41, 100, 101, 106, 107], "gemma": 42, "gemmatransformerdecod": 42, "w": [42, 43, 44, 45, 51, 52, 57, 91, 92, 103, 105, 108, 109], "blog": 42, "technolog": 42, "develop": [42, 109], "transformerdecod": [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 81, 108], "arxiv": [43, 44, 45, 49, 50, 55, 58, 61, 62, 65, 66], "org": [43, 44, 45, 49, 50, 55, 58, 61, 62, 65, 66, 77, 80, 85, 91, 94, 95, 96, 100], "ab": [43, 44, 45, 49, 50, 55, 58, 61, 66], "2307": [43, 44, 45], "09288": [43, 44, 45], "70b": [44, 47, 51, 53, 107], "lora_attn_modul": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 108, 109], "q_proj": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 62, 108, 109], "k_proj": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 62, 108, 109], "v_proj": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 62, 108, 109], "output_proj": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 62, 108, 109], "apply_lora_to_mlp": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 108], "apply_lora_to_output": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 108], "lora_rank": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 108], "lora_alpha": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 108], "float": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 62, 65, 70, 72, 81, 89, 90, 91, 92, 108, 109], "16": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 108, 109], "lora_dropout": [46, 47, 48, 49, 50], "05": [46, 47, 48, 49, 50], "quantize_bas": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 72, 109], "lora": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 72, 78, 99, 101, 103, 106, 107], "tloen": [46, 47, 48, 53, 54, 59], "8bb8579e403dc78e37fe81ffbb253c413007323f": [46, 47, 48, 53, 54, 59], "l41": [46, 47, 48, 53, 54, 59], "l43": [46, 47, 48, 53, 54, 59], "linear": [46, 47, 48, 49, 50, 53, 54, 55, 56, 58, 59, 61, 67, 71, 72, 108, 109], "mlp": [46, 47, 48, 53, 54, 56, 59, 67, 68, 107, 108], "final": [46, 47, 48, 53, 54, 56, 59, 63, 67, 76, 105, 107, 108, 109], "rank": [46, 47, 48, 53, 54, 56, 59, 72, 86, 96, 106, 108, 109], "low": [46, 47, 48, 53, 54, 56, 59, 72, 105, 108, 109], "approxim": [46, 47, 48, 53, 54, 56, 59, 72, 108], "factor": [46, 47, 48, 53, 54, 56, 59, 72, 105], "llama2_70b": 47, "llama2_7b": [48, 108], "qlora": [49, 50, 55, 58, 61, 69, 99, 101, 107, 108], "per": [49, 50, 55, 58, 61, 64, 69, 107, 109], "paper": [49, 50, 55, 58, 61, 108, 109], "2305": [49, 50, 55, 58, 61, 62], "14314": [49, 50, 55, 58, 61], "lora_llama2_13b": 49, "lora_llama2_7b": [50, 108], "llama3_70b": 53, "llama3_8b": [54, 81, 107], "lora_llama3_8b": 55, "announc": 57, "lora_mistral_7b": 58, "phi3": [59, 60, 61], "phi3_mini": 59, "ref": [60, 92], "phi": 60, "128k": 60, "nor": 60, "slide": 60, "window": [60, 104], "lora_phi3_mini": 61, "head_dim": [62, 64, 67], "pos_embed": [62, 108], "kv_cach": 62, "kvcach": [62, 67], "attn_dropout": [62, 67], "head": [62, 64, 66, 67, 107], "queri": [62, 64, 67, 68, 107], "gqa": 62, "introduc": [62, 65, 72, 103, 104, 108, 109], "pdf": [62, 65], "13245v1": 62, "version": [62, 81, 100, 107, 109], "multihead": 62, "mha": [62, 67], "n": [62, 75, 76, 98, 102, 103, 104], "extrem": 62, "share": [62, 104, 105], "mqa": 62, "credit": 62, "document": [62, 77, 84, 104], "lightn": 62, "lit": 62, "lit_gpt": 62, "v": [62, 67, 108], "k": [62, 108], "q": [62, 108], "n_kv_head": 62, "dimens": [62, 64, 66, 67, 72, 107, 108, 109], "calcul": [62, 67, 107], "e": [62, 69, 71, 74, 78, 100, 105, 107, 108, 109], "g": [62, 71, 78, 107, 108, 109], "rotarypositionalembed": [62, 108], "cach": [62, 64, 66, 67, 100], "rope": [62, 66], "dropout": [62, 72, 108, 109], "onto": 62, "scaled_dot_product_attent": 62, "seq_length": [62, 68, 81], "boolean": [62, 67, 68, 77], "softmax": [62, 67, 68], "row": [62, 67, 68, 103], "j": [62, 67, 68], "seq_len": 62, "bigger": 62, "n_h": [62, 66], "num": [62, 66], "n_kv": 62, "kv": [62, 64, 67], "emb": [62, 67, 68], "h_d": [62, 66], "gate_proj": 63, "down_proj": 63, "up_proj": 63, "silu": 63, "feed": [63, 68], "network": [63, 108, 109], "fed": [63, 103], "multipli": 63, "subclass": [63, 80], "although": [63, 108], "afterward": 63, "former": 63, "regist": [63, 69, 109], "hook": [63, 69, 109], "latter": 63, "standalon": 64, "past": 64, "becaus": [64, 67, 103, 105, 107], "expand": 64, "dpython": [64, 67, 69], "reset": [64, 67], "zero": [64, 65, 105, 107], "k_val": 64, "v_val": 64, "h": [64, 100], "longer": [64, 104], "ep": 65, "1e": 65, "06": [65, 108], "root": [65, 91, 92], "squar": 65, "1910": 65, "07467": 65, "verfic": [65, 66], "small": [65, 105], "divis": 65, "10000": 66, "rotari": [66, 107], "propos": 66, "2104": 66, "09864": 66, "l450": 66, "upto": 66, "init": [66, 92, 109], "exceed": 66, "freq": 66, "recomput": 66, "geometr": 66, "progress": [66, 106], "rotat": 66, "angl": 66, "todo": 66, "effici": [66, 84, 99, 101, 105, 106, 108], "transformerdecoderlay": 67, "norm": [67, 68], "space": 67, "belong": 67, "reduc": [67, 101, 104, 108, 109], "statement": 67, "improv": [67, 84, 105, 107, 108], "readabl": [67, 105], "At": 67, "arang": 67, "prompt_length": 67, "causal_mask": 67, "m_": 67, "seq": 67, "reset_cach": 67, "setup_cach": 67, "attn": [68, 108, 109], "causalselfattent": [68, 108], "sa_norm": 68, "mlp_norm": 68, "ff": 68, "common_util": 69, "bfloat16": [69, 105, 106, 107, 108], "offload_to_cpu": 69, "nf4": [69, 109], "restor": 69, "higher": [69, 107, 109], "offload": [69, 109], "increas": [69, 70, 107, 108], "peak": [69, 105, 107, 108, 109], "gpu": [69, 105, 106, 107, 108, 109], "_register_state_dict_hook": 69, "m": [69, 76, 81, 103], "mymodul": 69, "_after_": 69, "nf4tensor": [69, 109], "unquant": [69, 105, 109], "unus": 69, "num_warmup_step": 70, "num_training_step": 70, "num_cycl": 70, "last_epoch": 70, "lambdalr": 70, "rate": [70, 101, 106], "schedul": [70, 94, 106], "linearli": 70, "lr": 70, "decreas": [70, 104, 108, 109], "cosin": 70, "v4": 70, "23": [70, 107], "src": 70, "l104": 70, "warmup": [70, 94], "phase": 70, "wave": 70, "half": 70, "lr_schedul": 70, "peft": [71, 72, 73, 74, 78, 108, 109], "protocol": 71, "adapter_param": [71, 72, 73, 74], "proj": 71, "in_dim": [71, 72, 108, 109], "out_dim": [71, 72, 108, 109], "bia": [71, 72, 108, 109], "loralinear": [71, 108, 109], "alpha": [72, 108, 109], "use_bia": 72, "perturb": 72, "decomposit": [72, 108], "matric": [72, 108, 109], "trainabl": [72, 74, 108, 109], "mapsto": 72, "w_0x": 72, "r": [72, 76, 108], "bax": 72, "probabl": [72, 81, 105], "lora_a": [72, 108, 109], "lora_b": [72, 108, 109], "get_adapter_param": [74, 108], "sentencepieceprocessor": 75, "pretrain": [75, 76, 103, 106, 108, 109], "non": 75, "spm_model": [75, 103], "tokenized_text": 75, "hello": [75, 103, 105, 107], "world": [75, 86, 105], "add_bo": [75, 76, 103], "add_eo": [75, 76, 103], "31587": 75, "29644": 75, "102": 75, "trim_leading_whitespac": 75, "prefix": 75, "unbatch": 75, "prepend": [75, 76], "bo": [75, 76, 103, 104], "append": [75, 100], "eo": [75, 76, 103, 104], "trim": 75, "whitespac": 75, "underli": [75, 109], "sentencepiec": [75, 107], "due": [75, 108, 109], "tokenize_messag": [75, 76, 103, 104], "problem": 75, "slice": 75, "tokenizer_path": 75, "separ": [75, 78, 103, 106, 107, 108, 109], "concat": 75, "1788": 75, "2643": 75, "13": [75, 105, 107, 109], "1792": 75, "9508": 75, "465": 75, "22137": 75, "2933": 75, "join": 75, "attribut": 75, "llama3_tiktoken": 76, "p": [76, 77, 108, 109], "l": 76, "all_special_token": 76, "bos_token": 76, "begin_of_text": [76, 103], "eos_token": 76, "end_of_text": 76, "start_header_id": [76, 103], "end_header_id": [76, 103], "step_id": 76, "eom_id": 76, "eot_id": [76, 103], "python_tag": 76, "identif": 76, "regex": 76, "second": [76, 105, 107, 108, 109], "uniqu": 76, "256": [76, 105, 107], "header": [76, 103], "token_id": 76, "truncate_at_eo": 76, "tokenize_head": 76, "datatyp": [77, 109], "polici": [77, 84, 95], "denot": 77, "integ": [77, 93, 96], "auto_wrap_polici": [77, 84, 95], "submodul": 77, "obei": 77, "contract": 77, "get_fsdp_polici": 77, "modules_to_wrap": [77, 84], "min_num_param": 77, "my_fsdp_polici": 77, "recurs": [77, 91], "isinst": [77, 104], "sum": [77, 108], "numel": [77, 108], "1000": 77, "functool": 77, "partial": 77, "stabl": [77, 91, 94, 96, 100], "html": [77, 80, 85, 91, 94, 95, 96, 99], "alia": 77, "from_pretrain": 78, "few": [78, 104, 107, 108, 109], "0001_of_0003": 78, "0002_of_0003": 78, "preserv": [78, 109], "weight_map": [78, 105], "intermediate_checkpoint": [78, 79], "parit": 78, "_weight_map": 78, "shard": [79, 107], "wip": 79, "argpars": 80, "argumentpars": 80, "builtin": 80, "said": 80, "noth": 80, "treat": [80, 103], "consult": 80, "info": [80, 106], "librari": [80, 85, 96, 99, 101, 104, 109], "parse_known_arg": 80, "namespac": 80, "act": 80, "precid": 80, "parse_arg": 80, "properti": [80, 108], "too": [80, 107], "max_generated_token": 81, "pad_id": 81, "temperatur": [81, 105], "top_k": [81, 105], "stop_token": 81, "custom_generate_next_token": 81, "condit": [81, 104], "bsz": 81, "predict": 81, "prune": [81, 109], "stop": 81, "compil": [81, 105, 107, 109], "generate_next_token": 81, "llama3_token": [81, 107], "hi": [81, 103], "my": [81, 103, 104, 105, 107], "jeremi": 81, "availab": 82, "distribut": [82, 87, 95, 96, 101, 106, 107], "bf16": [83, 109], "request": [83, 104, 105], "inde": [83, 105], "kernel": 83, "runtimeerror": [83, 87], "float32": 83, "isn": 83, "hardwar": [83, 101, 104, 105, 108], "memory_efficient_fsdp_wrap": 84, "maxim": [84, 99, 101], "been": [84, 107], "workload": 84, "15": [84, 103, 105, 108, 109], "alongsid": 84, "ac": 84, "fullyshardeddataparallel": 84, "const": 84, "fsdppolicytyp": 84, "handler": 85, "aka": 86, "filenam": 89, "log_": 89, "unixtimestamp": 89, "txt": [89, 104, 106], "thread": 89, "safe": 89, "flush": [89, 90, 91, 92], "union": [89, 90, 91, 92, 95, 96], "ndarrai": [89, 90, 91, 92], "scalar": [89, 90, 91, 92], "record": [89, 90, 91, 92], "payload": [89, 90, 91, 92], "organize_log": 91, "tensorboard": 91, "subdirectori": 91, "compar": [91, 105, 108, 109], "logdir": 91, "startup": 91, "tree": [91, 104, 105], "tfevent": 91, "encount": 91, "frontend": 91, "organ": 91, "accordingli": 91, "my_log_dir": 91, "view": [91, 105, 106], "my_metr": [91, 92], "termin": [91, 92], "entiti": 92, "bias": 92, "sent": 92, "usernam": 92, "my_project": 92, "my_ent": 92, "my_group": 92, "importerror": 92, "account": [92, 108, 109], "log_config": 92, "link": [92, 105], "capecap": 92, "6053ofw0": 92, "torchtune_config_j67sb73v": 92, "padding_idx": 93, "ignore_idx": 93, "longest": 93, "token_pair": 93, "torchtune_perf_trac": 94, "contextmanag": 94, "wait": 94, "trace": 94, "speed": [94, 107, 109], "reduct": [94, 108], "acwrappolicytyp": 95, "describ": [95, 104], "author": [95, 101, 106, 109], "intermedi": [95, 107, 109], "fsdp_adavnced_tutori": 95, "debug_mod": 96, "pseudo": 96, "random": [96, 106], "commonli": [96, 105, 108, 109], "numpi": 96, "own": [96, 103, 104, 105, 108], "determinist": 96, "global": [96, 104], "warn": 96, "nondeterminist": 96, "addition": [96, 104, 108], "cudnn": 96, "set_deterministic_debug_mod": 96, "algorithm": 96, "generated_examples_python": 97, "zip": 97, "galleri": [97, 102], "sphinx": 97, "000": [98, 102, 107], "execut": [98, 102], "generated_exampl": 98, "mem": [98, 102], "mb": [98, 102], "topic": 99, "gentl": 99, "introduct": 99, "first_finetune_tutori": 99, "readi": [99, 103], "workflow": [99, 104, 106, 108], "requisit": 100, "proper": [100, 106], "host": [100, 106], "latest": [100, 106, 109], "confirm": 100, "And": [100, 105, 107], "ls": [100, 105, 106, 107], "welcom": 100, "show": [100, 103, 108], "greatest": [100, 106], "contributor": 100, "cd": [100, 105], "even": [100, 103, 104, 107, 108, 109], "commit": 100, "branch": 100, "url": 100, "whl": 100, "therebi": [100, 109], "forc": 100, "reinstal": 100, "opt": [100, 106], "suffix": 100, "cu121": 100, "On": [101, 108], "pointer": 101, "emphas": 101, "aspect": 101, "simplic": 101, "component": 101, "reus": 101, "prove": 101, "democrat": 101, "box": [101, 109], "zoo": 101, "varieti": [101, 108], "techniqu": [101, 105, 106, 108], "integr": [101, 105, 106, 107, 108, 109], "excit": 101, "checkout": 101, "quickstart": 101, "attain": 101, "better": [101, 103, 104, 105], "chekckpoint": 101, "hyperparamet": [101, 106, 108, 109], "embodi": 101, "philosophi": 101, "usabl": 101, "composit": 101, "hard": [101, 104], "outlin": 101, "unecessari": 101, "never": 101, "thoroughli": 101, "unit": 101, "know": [103, 104, 105, 107, 108], "align": 103, "intend": 103, "nice": 103, "meet": 103, "overhaul": 103, "sai": [103, 106], "accompani": 103, "who": 103, "influenti": 103, "hip": 103, "hop": 103, "artist": [103, 107], "2pac": 103, "rakim": 103, "c": 103, "na": 103, "flavor": [103, 104], "certain": 103, "msg": 103, "formatted_messag": [103, 104], "nyou": [103, 104], "nwho": 103, "sentencepiecetoken": 103, "why": [103, 106, 108], "user_messag": 103, "518": 103, "25580": 103, "29962": 103, "3532": 103, "14816": 103, "29903": 103, "6778": 103, "piece_to_id": 103, "reserv": [103, 109], "vector": 103, "place": 103, "manual": [103, 109], "529": 103, "29879": 103, "29958": 103, "tiktokentoken": 103, "nhere": 103, "_encode_special_token": 103, "128000": 103, "128009": 103, "pure": 103, "That": 103, "won": [103, 105, 107], "mess": 103, "govern": 103, "prime": 103, "strictli": 103, "summarizetempl": [103, 104], "lightweight": 103, "ask": 103, "untouch": 103, "nsummari": 103, "robust": 103, "csv": [103, 104], "question": [103, 104, 105, 107], "answer": [103, 105, 107], "onlin": 103, "forum": 103, "panda": 103, "pd": 103, "df": 103, "read_csv": 103, "your_fil": 103, "nrow": 103, "tolist": 103, "iloc": 103, "gp": 103, "receiv": 103, "commun": [103, 104, 105], "satellit": 103, "thing": [103, 109], "message_convert": 103, "input_msg": 103, "output_msg": 103, "assistant_messag": 103, "But": [103, 105, 107, 108], "mistralchatformat": 103, "custom_dataset": 103, "2048": 103, "data_fil": [103, 104], "honor": 103, "copi": [103, 105, 106, 107, 109], "8b_lora_single_devic": [103, 107], "launch": [103, 106], "custom_8b_lora_single_devic": 103, "steer": 104, "wheel": 104, "publicli": 104, "great": [104, 105], "full_finetune_single_devic": [104, 105, 106], "8b_full_single_devic": 104, "hood": [104, 105, 109], "text_completion_dataset": 104, "padded_col": 104, "upper": 104, "constraint": [104, 108], "slow": [104, 109], "down": [104, 108, 109], "signific": 104, "speedup": [104, 107], "minim": [104, 106, 108, 109], "my_data": 104, "instruct_dataset": 104, "fix": 104, "goal": 104, "agnost": 104, "respond": 104, "further": [104, 108, 109], "classifi": 104, "anim": 104, "plant": 104, "miner": 104, "oak": 104, "copper": 104, "ore": 104, "eleph": 104, "customtempl": 104, "cl": 104, "chat_dataset": 104, "quit": [104, 109], "similarli": 104, "incorpor": 104, "advanc": 104, "customchatformat": 104, "vicgal": 104, "gpt4": 104, "drive": 104, "rajpurkar": 104, "io": 104, "squad": 104, "explor": 104, "rlhf": 104, "adjust": 104, "chosen": 104, "reject": 104, "chosen_messag": 104, "transformed_sampl": 104, "key_chosen": 104, "rejected_messag": 104, "key_reject": 104, "chosen_input_id": 104, "c_mask": 104, "chosen_label": 104, "np": 104, "cross_entropy_ignore_idx": 104, "rejected_input_id": 104, "r_mask": 104, "rejected_label": 104, "stack_exchanged_paired_dataset": 104, "had": 104, "stackexchangedpairedtempl": 104, "response_j": 104, "response_k": 104, "rl": 104, "favorit": [105, 107, 108], "seemlessli": 105, "beyond": [105, 109], "connect": 105, "larger": [105, 107], "amount": 105, "natur": 105, "export": 105, "mobil": 105, "phone": 105, "leverag": [105, 107, 109], "mode": 105, "lot": 105, "plai": 105, "freez": [105, 108], "percentag": 105, "learnabl": 105, "keep": [105, 108], "16gb": [105, 108], "rtx": 105, "3090": 105, "4090": 105, "hour": 105, "7b_full_low_memori": [105, 106], "full_finetune_distribut": [105, 106], "7b_full": [105, 106], "13b_full": [105, 106], "7b_qlora_single_devic": [105, 106, 109], "473": 105, "98": [105, 109], "gb": [105, 107, 108, 109], "50": 105, "484": 105, "01": [105, 106], "fact": [105, 107, 108], "third": 105, "realli": 105, "eleuther_ev": [105, 107], "eleuther_evalu": [105, 107], "lm_eval": [105, 107], "plan": 105, "custom_eval_config": [105, 107], "truthfulqa_mc2": [105, 107, 108], "measur": [105, 107], "propens": [105, 107], "shot": [105, 107], "accuraci": [105, 107, 108, 109], "baselin": [105, 108], "324": 105, "loglikelihood": 105, "195": 105, "121": 105, "27": 105, "197": 105, "acc": 105, "388": 105, "38": 105, "shown": 105, "489": 105, "48": [105, 109], "seem": 105, "custom_generation_config": [105, 107], "kick": 105, "300": 105, "interest": 105, "site": 105, "visit": 105, "bai": 105, "area": 105, "92": [105, 107], "exploratorium": 105, "san": 105, "francisco": 105, "magazin": 105, "awesom": 105, "bridg": 105, "pretti": 105, "cool": 105, "96": [105, 109], "61": 105, "sec": [105, 107], "25": 105, "83": 105, "99": [105, 108], "72": 105, "littl": 105, "saw": 105, "took": [105, 107], "torchao": [105, 107, 109], "bit": [105, 107, 108, 109], "custom_quantization_config": [105, 107], "68": 105, "19": [105, 107, 109], "76": 105, "69": 105, "95": [105, 107], "67": 105, "4w": [105, 107], "unlik": [105, 107], "engin": [105, 107], "fullmodeltorchtunecheckpoint": [105, 107], "int4weightonlyquant": [105, 107], "groupsiz": [105, 107], "did": [105, 107, 109], "park": 105, "sit": 105, "top": [105, 109], "hill": 105, "beauti": 105, "62": [105, 107], "17": [105, 108], "85": 105, "sped": 105, "almost": [105, 107, 108], "3x": [105, 107], "benefit": 105, "doesn": 105, "yet": 105, "fast": 105, "clone": [105, 108, 109], "assumpt": 105, "satisfi": 105, "new_dir": 105, "output_dict": 105, "sd_1": 105, "sd_2": 105, "dump": 105, "convert_hf_checkpoint": 105, "checkpoint_path": 105, "justin": 105, "school": 105, "math": 105, "teacher": 105, "ws": 105, "94": [105, 107], "28": 105, "bandwidth": [105, 107], "achiev": [105, 107, 108, 109], "1391": 105, "84": 105, "thats": 105, "seamlessli": 105, "authent": [105, 106], "hopefulli": 105, "gave": 105, "gate": 106, "grant": 106, "minut": 106, "agreement": 106, "altern": 106, "hackabl": 106, "singularli": 106, "technic": 106, "purpos": [106, 107], "depth": 106, "principl": 106, "boilerpl": 106, "hold": 106, "substanti": [106, 108], "custom_config": 106, "replic": 106, "lorafinetunerecipesingledevic": 106, "lora_finetune_output": 106, "log_1713194212": 106, "52": 106, "3697006702423096": 106, "25880": [106, 109], "24": [106, 107], "55": 106, "83it": 106, "monitor": 106, "tqdm": 106, "interv": 106, "e2": 106, "releas": 107, "focu": 107, "128": [107, 108], "theta": 107, "gain": 107, "illustr": 107, "basic": 107, "observ": 107, "18": 107, "consum": [107, 109], "vram": [107, 108], "overal": 107, "nproc_per_nod": [107, 108], "lora_finetune_distribut": [107, 108], "8b_lora": 107, "8b_qlora_single_devic": 107, "alloc": [107, 109], "coupl": [107, 108, 109], "122": 107, "sarah": 107, "busi": 107, "mum": 107, "young": 107, "children": 107, "live": 107, "north": 107, "east": 107, "england": 107, "135": 107, "88": 107, "138": 107, "346": 107, "09": 107, "139": 107, "31": 107, "far": 107, "drill": 107, "90": 107, "93": 107, "91": 107, "104": 107, "four": [107, 108], "again": 107, "jake": 107, "disciplin": 107, "passion": 107, "draw": 107, "paint": 107, "57": [107, 108, 109], "broader": 107, "teach": 108, "straight": 108, "jump": 108, "neural": [108, 109], "unfamiliar": 108, "oppos": [108, 109], "momentum": 108, "adamw": 108, "arbitrari": 108, "could": 108, "relat": 108, "aghajanyan": 108, "et": 108, "al": 108, "hypothes": 108, "intrins": 108, "often": 108, "eight": 108, "practic": 108, "imag": 108, "left": 108, "blue": 108, "rememb": 108, "approx": 108, "15m": 108, "8192": 108, "65k": 108, "requires_grad": [108, 109], "frozen_out": [108, 109], "lora_out": [108, 109], "base_model": 108, "choos": 108, "lora_model": 108, "lora_llama_2_7b": [108, 109], "alon": 108, "in_featur": 108, "out_featur": 108, "inplac": 108, "feel": 108, "free": 108, "strict": 108, "whenev": 108, "validate_state_dict_for_lora": 108, "peft_util": 108, "set_trainable_param": 108, "fetch": 108, "lora_param": 108, "total_param": 108, "trainable_param": 108, "2f": 108, "6742609920": 108, "4194304": 108, "nnode": 108, "7b_lora": 108, "my_model_checkpoint_path": [108, 109], "tokenizer_checkpoint": [108, 109], "my_tokenizer_checkpoint_path": [108, 109], "factori": 108, "benefici": 108, "impact": 108, "minor": 108, "good": 108, "64": 108, "lora_experiment_1": 108, "smooth": [108, 109], "curv": [108, 109], "500": 108, "ran": 108, "footprint": 108, "commod": 108, "cogniz": 108, "ax": 108, "parallel": 108, "truthfulqa": 108, "previous": 108, "475": 108, "87": 108, "508": 108, "86": 108, "504": 108, "04": 108, "514": 108, "lowest": 108, "absolut": 108, "4gb": 108, "tradeoff": 108, "potenti": 108, "highli": 109, "vanilla": 109, "held": 109, "therefor": 109, "bespok": 109, "normalfloat": 109, "8x": 109, "retain": 109, "vast": 109, "major": 109, "degrad": 109, "normatfloat": 109, "doubl": 109, "themselv": 109, "deepdiv": 109, "idea": 109, "distinct": 109, "storag": 109, "de": 109, "incur": 109, "counterpart": 109, "set_default_devic": 109, "qlora_linear": 109, "memory_alloc": 109, "177": 109, "152": 109, "byte": 109, "del": 109, "empty_cach": 109, "lora_linear": 109, "081": 109, "344": 109, "qlora_llama2_7b": 109, "qlora_model": 109, "essenti": 109, "reparametrize_as_dtype_state_dict_post_hook": 109, "stat": 109, "iter": 109, "against": 109, "35": 109, "40": 109, "29": 109, "slower": 109, "149": 109, "9157477021217346": 109, "02": 109, "08": 109, "14": 109, "15it": 109, "nightli": 109, "200": 109, "hundr": 109, "228": 109, "8158286809921265": 109, "59": 109, "95it": 109, "exercis": 109, "portion": 109, "augment": 109, "linear_nf4": 109, "to_nf4": 109, "linear_weight": 109, "autograd": 109, "regular": 109, "incom": 109}, "objects": {"torchtune.config": [[10, 0, 1, "", "instantiate"], [11, 0, 1, "", "parse"], [12, 0, 1, "", "validate"]], "torchtune.data": [[13, 1, 1, "", "AlpacaInstructTemplate"], [14, 1, 1, "", "ChatFormat"], [15, 1, 1, "", "ChatMLFormat"], [16, 1, 1, "", "GrammarErrorCorrectionTemplate"], [17, 1, 1, "", "InstructTemplate"], [18, 1, 1, "", "Llama2ChatFormat"], [19, 1, 1, "", "Message"], [20, 1, 1, "", "MistralChatFormat"], [21, 1, 1, "", "SummarizeTemplate"], [22, 0, 1, "", "sharegpt_to_llama2_messages"], [23, 0, 1, "", "truncate"], [24, 0, 1, "", "validate_messages"]], "torchtune.data.AlpacaInstructTemplate": [[13, 2, 1, "", "format"]], "torchtune.data.ChatFormat": [[14, 2, 1, "", "format"]], "torchtune.data.ChatMLFormat": [[15, 2, 1, "", "format"]], "torchtune.data.GrammarErrorCorrectionTemplate": [[16, 2, 1, "", "format"]], "torchtune.data.InstructTemplate": [[17, 2, 1, "", "format"]], "torchtune.data.Llama2ChatFormat": [[18, 2, 1, "", "format"]], "torchtune.data.Message": [[19, 2, 1, "", "from_dict"]], "torchtune.data.MistralChatFormat": [[20, 2, 1, "", "format"], [20, 3, 1, "", "system"]], "torchtune.data.SummarizeTemplate": [[21, 2, 1, "", "format"]], "torchtune.datasets": [[25, 1, 1, "", "ChatDataset"], [26, 1, 1, "", "ConcatDataset"], [27, 1, 1, "", "InstructDataset"], [28, 1, 1, "", "PackedDataset"], [29, 1, 1, "", "PreferenceDataset"], [30, 1, 1, "", "TextCompletionDataset"], [31, 0, 1, "", "alpaca_cleaned_dataset"], [32, 0, 1, "", "alpaca_dataset"], [33, 0, 1, "", "chat_dataset"], [34, 0, 1, "", "cnn_dailymail_articles_dataset"], [35, 0, 1, "", "grammar_dataset"], [36, 0, 1, "", "instruct_dataset"], [37, 0, 1, "", "samsum_dataset"], [38, 0, 1, "", "slimorca_dataset"], [39, 0, 1, "", "stack_exchanged_paired_dataset"], [40, 0, 1, "", "text_completion_dataset"], [41, 0, 1, "", "wikitext_dataset"]], "torchtune.models.gemma": [[42, 0, 1, "", "gemma_2b"]], "torchtune.models.llama2": [[43, 0, 1, "", "llama2_13b"], [44, 0, 1, "", "llama2_70b"], [45, 0, 1, "", "llama2_7b"], [46, 0, 1, "", "lora_llama2_13b"], [47, 0, 1, "", "lora_llama2_70b"], [48, 0, 1, "", "lora_llama2_7b"], [49, 0, 1, "", "qlora_llama2_13b"], [50, 0, 1, "", "qlora_llama2_7b"]], "torchtune.models.llama3": [[51, 0, 1, "", "llama3_70b"], [52, 0, 1, "", "llama3_8b"], [53, 0, 1, "", "lora_llama3_70b"], [54, 0, 1, "", "lora_llama3_8b"], [55, 0, 1, "", "qlora_llama3_8b"]], "torchtune.models.mistral": [[56, 0, 1, "", "lora_mistral_7b"], [57, 0, 1, "", "mistral_7b"], [58, 0, 1, "", "qlora_mistral_7b"]], "torchtune.models.phi3": [[59, 0, 1, "", "lora_phi3_mini"], [60, 0, 1, "", "phi3_mini"], [61, 0, 1, "", "qlora_phi3_mini"]], "torchtune.modules": [[62, 1, 1, "", "CausalSelfAttention"], [63, 1, 1, "", "FeedForward"], [64, 1, 1, "", "KVCache"], [65, 1, 1, "", "RMSNorm"], [66, 1, 1, "", "RotaryPositionalEmbeddings"], [67, 1, 1, "", "TransformerDecoder"], [68, 1, 1, "", "TransformerDecoderLayer"], [70, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[62, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[63, 2, 1, "", "forward"]], "torchtune.modules.KVCache": [[64, 2, 1, "", "reset"], [64, 2, 1, "", "update"]], "torchtune.modules.RMSNorm": [[65, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[66, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoder": [[67, 2, 1, "", "forward"], [67, 2, 1, "", "reset_caches"], [67, 2, 1, "", "setup_caches"]], "torchtune.modules.TransformerDecoderLayer": [[68, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[69, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[71, 1, 1, "", "AdapterModule"], [72, 1, 1, "", "LoRALinear"], [73, 0, 1, "", "get_adapter_params"], [74, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[71, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[72, 2, 1, "", "adapter_params"], [72, 2, 1, "", "forward"]], "torchtune.modules.tokenizers": [[75, 1, 1, "", "SentencePieceTokenizer"], [76, 1, 1, "", "TikTokenTokenizer"]], "torchtune.modules.tokenizers.SentencePieceTokenizer": [[75, 2, 1, "", "decode"], [75, 2, 1, "", "encode"], [75, 2, 1, "", "tokenize_messages"]], "torchtune.modules.tokenizers.TikTokenTokenizer": [[76, 2, 1, "", "decode"], [76, 2, 1, "", "encode"], [76, 2, 1, "", "tokenize_message"], [76, 2, 1, "", "tokenize_messages"]], "torchtune.utils": [[77, 4, 1, "", "FSDPPolicyType"], [78, 1, 1, "", "FullModelHFCheckpointer"], [79, 1, 1, "", "FullModelMetaCheckpointer"], [80, 1, 1, "", "TuneRecipeArgumentParser"], [81, 0, 1, "", "generate"], [82, 0, 1, "", "get_device"], [83, 0, 1, "", "get_dtype"], [84, 0, 1, "", "get_full_finetune_fsdp_wrap_policy"], [85, 0, 1, "", "get_logger"], [86, 0, 1, "", "get_world_size_and_rank"], [87, 0, 1, "", "init_distributed"], [88, 0, 1, "", "list_dtypes"], [93, 0, 1, "", "padded_collate"], [94, 0, 1, "", "profiler"], [95, 0, 1, "", "set_activation_checkpointing"], [96, 0, 1, "", "set_seed"]], "torchtune.utils.FullModelHFCheckpointer": [[78, 2, 1, "", "load_checkpoint"], [78, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[79, 2, 1, "", "load_checkpoint"], [79, 2, 1, "", "save_checkpoint"]], "torchtune.utils.TuneRecipeArgumentParser": [[80, 2, 1, "", "parse_known_args"]], "torchtune.utils.metric_logging": [[89, 1, 1, "", "DiskLogger"], [90, 1, 1, "", "StdoutLogger"], [91, 1, 1, "", "TensorBoardLogger"], [92, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[89, 2, 1, "", "close"], [89, 2, 1, "", "log"], [89, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[90, 2, 1, "", "close"], [90, 2, 1, "", "log"], [90, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[91, 2, 1, "", "close"], [91, 2, 1, "", "log"], [91, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[92, 2, 1, "", "close"], [92, 2, 1, "", "log"], [92, 2, 1, "", "log_config"], [92, 2, 1, "", "log_dict"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:data"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "data", "Python data"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 6, 77, 99, 101, 105, 107, 108, 109], "config": [0, 7, 8, 106], "data": [1, 5, 103], "instruct": [1, 100, 104, 107], "templat": [1, 103, 104], "chat": [1, 103, 104], "format": [1, 6, 104], "type": 1, "convert": 1, "helper": 1, "func": 1, "dataset": [2, 103, 104], "exampl": 2, "gener": [2, 81, 105, 107], "builder": 2, "class": [2, 8], "model": [3, 4, 9, 105, 106, 107, 108], "llama3": [3, 103, 107], "llama2": [3, 103, 105, 108, 109], "phi": 3, "3": 3, "mistral": 3, "gemma": 3, "modul": 4, "compon": [4, 7], "build": [4, 100, 109], "block": 4, "token": [4, 103], "peft": 4, "util": [4, 5, 77], "checkpoint": [5, 6, 9, 105], "distribut": 5, "reduc": 5, "precis": 5, "memori": [5, 104, 108, 109], "manag": 5, "perform": [5, 108], "profil": [5, 94], "metric": [5, 9], "log": [5, 9], "miscellan": 5, "overview": [6, 101, 105], "handl": 6, "differ": 6, "intermedi": 6, "vs": 6, "final": 6, "lora": [6, 105, 108, 109], "put": [6, 109], "thi": 6, "all": [6, 7, 109], "togeth": [6, 109], "about": 7, "where": 7, "do": 7, "paramet": 7, "live": 7, "write": 7, "configur": [7, 104], "us": [7, 8, 103, 105, 109], "instanti": [7, 10], "referenc": 7, "other": [7, 105], "field": 7, "interpol": 7, "valid": [7, 12], "your": [7, 8, 105, 106], "best": 7, "practic": 7, "airtight": 7, "public": 7, "api": 7, "onli": 7, "command": 7, "line": 7, "overrid": 7, "what": [8, 101, 108, 109], "ar": 8, "recip": [8, 106, 108], "script": 8, "run": [8, 105], "cli": 8, "pars": [8, 11], "weight": 9, "bias": 9, "logger": 9, "w": 9, "b": 9, "alpacainstructtempl": 13, "chatformat": 14, "chatmlformat": 15, "grammarerrorcorrectiontempl": 16, "instructtempl": 17, "llama2chatformat": 18, "messag": 19, "mistralchatformat": 20, "summarizetempl": 21, "sharegpt_to_llama2_messag": 22, "truncat": 23, "validate_messag": 24, "chatdataset": 25, "concatdataset": 26, "instructdataset": 27, "packeddataset": 28, "preferencedataset": 29, "textcompletiondataset": 30, "alpaca_cleaned_dataset": 31, "alpaca_dataset": 32, "chat_dataset": 33, "cnn_dailymail_articles_dataset": 34, "grammar_dataset": 35, "instruct_dataset": 36, "samsum_dataset": 37, "slimorca_dataset": 38, "stack_exchanged_paired_dataset": 39, "text_completion_dataset": 40, "wikitext_dataset": 41, "gemma_2b": 42, "llama2_13b": 43, "llama2_70b": 44, "llama2_7b": 45, "lora_llama2_13b": 46, "lora_llama2_70b": 47, "lora_llama2_7b": 48, "qlora_llama2_13b": 49, "qlora_llama2_7b": 50, "llama3_70b": 51, "llama3_8b": 52, "lora_llama3_70b": 53, "lora_llama3_8b": 54, "qlora_llama3_8b": 55, "lora_mistral_7b": 56, "mistral_7b": 57, "qlora_mistral_7b": 58, "lora_phi3_mini": 59, "phi3_mini": 60, "qlora_phi3_mini": 61, "causalselfattent": 62, "todo": [62, 68], "feedforward": 63, "kvcach": 64, "rmsnorm": 65, "rotarypositionalembed": 66, "transformerdecod": 67, "transformerdecoderlay": 68, "reparametrize_as_dtype_state_dict_post_hook": 69, "get_cosine_schedule_with_warmup": 70, "adaptermodul": 71, "loralinear": 72, "get_adapter_param": 73, "set_trainable_param": 74, "sentencepiecetoken": 75, "tiktokentoken": 76, "fsdppolicytyp": 77, "fullmodelhfcheckpoint": 78, "fullmodelmetacheckpoint": 79, "tunerecipeargumentpars": 80, "get_devic": 82, "get_dtyp": 83, "get_full_finetune_fsdp_wrap_polici": 84, "get_logg": 85, "get_world_size_and_rank": 86, "init_distribut": 87, "list_dtyp": 88, "disklogg": 89, "stdoutlogg": 90, "tensorboardlogg": 91, "wandblogg": 92, "padded_col": 93, "set_activation_checkpoint": 95, "set_se": 96, "comput": [98, 102], "time": [98, 102], "welcom": 99, "document": 99, "get": [99, 107], "start": 99, "tutori": 99, "instal": 100, "via": [100, 107], "pypi": 100, "git": 100, "clone": 100, "nightli": 100, "kei": 101, "concept": 101, "design": 101, "principl": 101, "fine": [103, 104, 106, 107], "tune": [103, 104, 106, 107], "chang": 103, "from": [103, 109], "prompt": 103, "special": 103, "when": 103, "should": 103, "i": 103, "custom": [103, 104], "built": 104, "hug": [104, 105], "face": [104, 105], "set": 104, "max": 104, "sequenc": 104, "length": 104, "sampl": 104, "pack": 104, "unstructur": 104, "text": [104, 107], "corpu": 104, "multipl": 104, "local": 104, "remot": 104, "fulli": 104, "end": 105, "workflow": 105, "download": [105, 106], "7b": 105, "finetun": [105, 108, 109], "evalu": [105, 107], "eleutherai": [105, 107], "s": [105, 107], "eval": [105, 107], "har": [105, 107], "speed": 105, "up": 105, "quantiz": [105, 107], "librari": 105, "upload": 105, "hub": 105, "first": 106, "llm": 106, "select": 106, "modifi": 106, "train": 106, "next": 106, "step": 106, "meta": 107, "8b": 107, "access": 107, "our": 107, "faster": 107, "how": 108, "doe": 108, "work": 108, "appli": 108, "trade": 108, "off": 108, "qlora": 109, "save": 109, "deep": 109, "dive": 109}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})