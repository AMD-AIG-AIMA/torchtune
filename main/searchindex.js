Search.setIndex({"docnames": ["api_ref_config", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "examples/checkpointer", "examples/configs", "examples/finetune_llm", "examples/first_finetune_tutorial", "examples/lora_finetune", "examples/recipe_deepdive", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.Tokenizer", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.argparse.TuneRecipeArgumentParser", "generated/torchtune.utils.collate.padded_collate", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.logging.get_logger", "generated/torchtune.utils.memory.set_activation_checkpointing", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.precision.get_autocast", "generated/torchtune.utils.precision.get_dtype", "generated/torchtune.utils.precision.get_gradient_scaler", "generated/torchtune.utils.precision.list_dtypes", "generated/torchtune.utils.seed.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times"], "filenames": ["api_ref_config.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "examples/checkpointer.rst", "examples/configs.rst", "examples/finetune_llm.rst", "examples/first_finetune_tutorial.rst", "examples/lora_finetune.rst", "examples/recipe_deepdive.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.Tokenizer.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.argparse.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.collate.padded_collate.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.logging.get_logger.rst", "generated/torchtune.utils.memory.set_activation_checkpointing.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.precision.get_autocast.rst", "generated/torchtune.utils.precision.get_dtype.rst", "generated/torchtune.utils.precision.get_gradient_scaler.rst", "generated/torchtune.utils.precision.list_dtypes.rst", "generated/torchtune.utils.seed.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst"], "titles": ["torchtune.config", "torchtune.datasets", "torchtune.models.llama2", "torchtune.modules", "torchtune.utils", "Checkpointing in TorchTune", "Configs Deep-Dive", "LLM Full Finetuning Recipe", "Finetune your First LLM", "Finetuning Llama2 with LoRA", "Training Recipe Deep-Dive", "instantiate", "parse", "alpaca_cleaned_dataset", "alpaca_dataset", "grammar_dataset", "samsum_dataset", "slimorca_dataset", "llama2_7b", "lora_llama2", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "Tokenizer", "TransformerDecoder", "TransformerDecoderLayer", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "padded_collate", "get_device", "get_world_size_and_rank", "init_distributed", "get_logger", "set_activation_checkpointing", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "get_autocast", "get_dtype", "get_gradient_scaler", "list_dtypes", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the TorchTune Documentation", "Install Instructions", "TorchTune Overview", "Computation times"], "terms": {"offer": 4, "allow": [4, 44], "seamless": 4, "transit": 4, "between": [4, 5, 9, 33], "format": [4, 8, 13, 14, 15, 16, 17, 33, 34], "train": [4, 5, 9, 13, 14, 15, 16, 17, 20, 28, 33, 34, 46, 47, 48, 53, 55], "interoper": [4, 5, 10, 55], "rest": 4, "ecosystem": [4, 5, 8, 10, 55], "For": [4, 5, 6, 7, 8, 9, 10, 13, 14, 19, 20, 26, 35, 45, 50], "comprehens": 4, "overview": [4, 6, 8, 9], "pleas": 4, "see": [4, 5, 7, 8, 9, 13, 22, 29, 35, 40, 45, 50, 54, 55], "tutori": [4, 5, 6, 7, 8, 10, 55], "enabl": [4, 6, 7, 8, 10, 30, 50], "work": [4, 5, 10, 35, 55], "set": [4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 24, 26, 32, 37, 41, 50, 55], "consumpt": 4, "dure": [4, 5, 7, 9, 13, 14, 15, 16, 20, 22, 24, 26, 27], "variou": 4, "dataset": [4, 6, 8, 9, 13, 14, 15, 16, 17, 55], "walk": [5, 7, 8, 10, 44, 55], "you": [5, 6, 7, 8, 9, 10, 11, 13, 14, 35, 44, 45, 53, 54, 55], "through": [5, 6, 7, 8, 10, 21, 55], "design": [5, 10], "behavior": 5, "associ": [5, 6, 9, 10], "util": [5, 6, 7, 8, 10, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 55], "what": [5, 6, 8, 53], "cover": 5, "deep": [5, 7, 8, 9, 53, 55], "dive": [5, 7, 8, 9, 53, 55], "how": [5, 6, 7, 8, 10, 53], "we": [5, 6, 7, 9, 10, 13, 14, 20, 22, 24, 25, 26, 30, 33, 34, 47, 55], "them": [5, 6, 7, 9, 21, 25], "scenario": 5, "full": [5, 6, 8, 9, 10, 25, 33, 34, 53, 55], "finetun": [5, 6, 10, 13, 14, 49, 53, 55], "ar": [5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 19, 26, 30, 33, 34, 47, 54, 55], "compos": 5, "compon": [5, 8, 9, 10, 55], "which": [5, 9, 10, 13, 14, 15, 16, 19, 20, 24, 25, 26, 27, 28, 33, 34, 42, 47, 48, 54, 55], "can": [5, 6, 7, 8, 9, 10, 11, 13, 14, 23, 24, 25, 33, 35, 44, 45, 53, 54, 55], "plug": 5, "ani": [5, 6, 7, 9, 10, 11, 12, 25, 31, 32, 33, 34, 50], "recip": [5, 6, 11, 12, 15, 16, 21, 33, 34, 53, 54, 55], "evalu": [5, 8, 9, 10, 55], "gener": [5, 9, 10, 17, 25, 50, 51], "each": [5, 8, 9, 10, 19, 20, 24, 25, 26, 50, 55], "support": [5, 7, 8, 10, 11, 13, 14, 15, 16, 19, 20, 30, 34, 46, 47, 49, 55], "model": [5, 6, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 41, 53, 55], "make": [5, 6, 8, 9, 10, 20, 27, 55], "easi": [5, 8, 9, 10, 55], "understand": [5, 6, 8, 9, 10, 53, 55], "debug": [5, 6, 10], "extend": [5, 10, 55], "befor": [5, 10, 26, 27, 30, 33], "let": [5, 6, 8, 9], "s": [5, 6, 7, 8, 9, 10, 12, 19, 20, 24, 26, 27, 29, 31, 33, 34, 37, 44, 53, 55], "defin": [5, 6, 9, 10, 21, 29, 30, 31], "some": [5, 6, 8, 9, 19, 31, 32, 53, 55], "concept": 5, "In": [5, 6, 7, 9, 10, 24, 30, 44, 45], "ll": [5, 6, 8, 10, 55], "talk": 5, "about": [5, 9, 10, 33, 45, 55], "take": [5, 6, 8, 9, 10, 11, 21, 22, 33, 35, 37], "close": [5, 9, 10, 42, 43, 44, 45], "look": [5, 6, 7, 8, 9, 10, 44], "veri": [5, 26], "simpli": [5, 6], "dictat": 5, "state_dict": [5, 9, 33, 34], "store": [5, 9, 42], "file": [5, 6, 8, 9, 10, 11, 12, 13, 14, 25, 33, 34, 35, 42, 52, 55, 56], "disk": [5, 42], "weight": [5, 8, 9, 10, 19, 20, 29, 30, 33, 34, 45], "string": [5, 25, 29, 37, 47], "kei": [5, 6, 9, 19, 20, 22, 26, 32, 33], "identifi": 5, "state": [5, 9, 10, 31, 32, 33, 34], "dict": [5, 6, 10, 11, 31, 32, 33, 34, 39], "If": [5, 6, 8, 9, 10, 13, 14, 15, 16, 17, 19, 20, 30, 33, 34, 37, 39, 44, 45, 47, 50], "identif": 5, "don": [5, 6, 7, 50], "t": [5, 6, 7, 17, 47, 50], "match": [5, 9], "up": [5, 8, 9, 10, 13, 14], "exactli": 5, "those": [5, 9], "definit": [5, 9], "either": [5, 9, 33], "run": [5, 6, 7, 8, 9, 12, 19, 21, 22, 26, 33, 34, 44, 45, 54, 55], "explicit": 5, "error": [5, 6, 13, 33, 50, 54], "load": [5, 7, 9, 10, 33, 34, 35, 44], "rais": [5, 11, 17, 20, 26, 33, 34, 39, 45, 47, 50], "an": [5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20, 26, 29, 31, 32, 33, 34, 55], "except": 5, "wors": 5, "silent": [5, 21], "succe": 5, "infer": [5, 20, 22, 24, 26, 27], "expect": [5, 6, 9, 11, 24, 45], "addit": [5, 6, 9, 10, 11, 33, 34, 39, 41, 42, 44, 45, 47, 55], "line": [5, 8, 10, 35], "also": [5, 6, 8, 9, 10, 11, 19, 20, 26, 30, 37], "need": [5, 6, 8, 9, 10, 17, 20, 21, 26, 44, 45], "shape": [5, 20, 22, 24, 26, 27, 30], "valu": [5, 6, 7, 9, 17, 18, 19, 20, 22, 23, 26, 28, 33, 35, 42, 43, 44, 45, 50], "two": [5, 6, 8, 9, 55], "popular": [5, 8, 55], "llama2": [5, 6, 7, 8, 10, 11, 13, 14, 17, 18, 19, 21, 25, 26, 27, 53, 55], "meta": [5, 8, 15, 16, 33, 34], "offici": [5, 8], "implement": [5, 7, 9, 10, 13, 14, 15, 16, 17, 21, 23, 24, 28, 29, 30, 33, 44, 55], "when": [5, 6, 9, 10, 12, 26, 28, 44], "download": [5, 9, 51, 54], "7b": [5, 7, 8, 9, 13, 14, 18, 33, 34], "from": [5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 21, 25, 26, 27, 28, 29, 31, 33, 34, 35, 44, 45, 52, 56], "llama": [5, 7, 8, 15, 16, 23, 24, 33, 34], "websit": 5, "get": [5, 6, 8, 9, 10, 25, 38, 40, 47, 55], "access": [5, 6, 8, 33], "singl": [5, 6, 9, 11, 20, 33, 34], "pth": [5, 7, 8], "inspect": [5, 9], "content": [5, 25], "easili": [5, 6, 9, 55], "torch": [5, 7, 8, 9, 10, 22, 26, 28, 37, 39, 41, 46, 47, 50], "import": [5, 6, 8, 9, 11, 44, 45], "consolid": [5, 7, 8], "00": [5, 7, 8, 52, 56], "mmap": 5, "true": [5, 6, 7, 8, 9, 13, 14, 15, 16, 25, 33, 34, 39, 44], "weights_onli": 5, "map_loc": 5, "cpu": [5, 47], "tensor": [5, 9, 20, 21, 22, 23, 24, 26, 27, 30, 33, 36, 42, 43, 44, 45], "item": 5, "print": [5, 9, 13, 14, 15, 16, 17, 25], "f": [5, 9, 13, 14, 15, 16], "tok_embed": [5, 26], "size": [5, 7, 10, 11, 13, 14, 15, 16, 18, 20, 22, 23, 24, 25, 26, 27, 38, 55], "32000": [5, 11], "4096": [5, 9, 11, 13, 14, 20, 24], "len": [5, 13, 14, 15, 16, 26], "292": 5, "The": [5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 23, 24, 25, 28, 33, 35, 37, 40, 47, 50, 55], "contain": [5, 9, 20, 22, 24, 25, 26, 27, 29, 31, 32, 33, 34, 35, 36, 44], "includ": [5, 6, 8, 9, 10, 30, 33, 34, 35, 55], "input": [5, 7, 9, 13, 14, 15, 16, 17, 20, 21, 23, 24, 25, 26, 27, 30, 33, 36, 50], "embed": [5, 19, 20, 22, 23, 24, 26], "tabl": [5, 9], "call": [5, 8, 9, 11, 21, 35, 42, 43, 44, 45], "layer": [5, 9, 19, 20, 26, 27, 30, 55], "token": [5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 17, 19, 20, 24, 26, 27], "have": [5, 6, 8, 9, 11, 20, 22, 29, 35, 44], "dim": [5, 20, 21, 23, 24, 26, 27], "hf": [5, 8, 33], "most": [5, 6, 8, 9], "within": [5, 6, 11, 17, 19, 21, 44, 50], "hug": [5, 8, 13, 14, 15, 16, 17, 28, 55], "face": [5, 8, 13, 14, 15, 16, 17, 28, 55], "hub": [5, 8], "default": [5, 6, 7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 33, 34, 35, 36, 42, 47, 50], "everi": [5, 10, 21, 44], "config": [5, 7, 9, 11, 12, 20, 33, 35, 55], "2": [5, 7, 8, 9, 17, 20, 25, 33, 34, 36, 50], "repo": [5, 33, 34], "first": [5, 6, 9, 11, 26, 33, 35, 53, 55], "big": 5, "split": 5, "across": [5, 10, 33, 44, 50], "bin": 5, "To": [5, 6, 7, 8, 9, 10, 33, 54, 55], "correctli": [5, 8, 10, 33, 54], "piec": 5, "one": [5, 9, 10, 21, 25, 54], "pytorch_model": 5, "00001": 5, "00002": 5, "embed_token": 5, "241": 5, "Not": 5, "onli": [5, 7, 9, 10, 19, 20, 24, 25, 26, 27, 30, 31, 34, 35, 47, 54], "doe": [5, 29, 33, 35], "fewer": [5, 20], "sinc": [5, 6, 7, 11, 21, 33], "instead": [5, 7, 21, 22, 30], "mismatch": 5, "name": [5, 6, 29, 32, 33, 34, 35, 37, 42, 43, 44, 45], "caus": [5, 25], "try": [5, 6, 9], "same": [5, 6, 9, 19, 20, 22, 25, 27, 35], "As": [5, 6, 9, 10, 30, 55], "re": [5, 6, 8, 9, 10, 55], "care": [5, 9, 21, 33], "like": [5, 6, 7, 8, 9, 10], "end": [5, 8, 10, 25, 55], "number": [5, 9, 10, 13, 14, 17, 19, 20, 22, 26, 28, 33, 34, 38, 50], "just": [5, 8, 9, 55], "save": [5, 9, 10, 33, 34], "less": [5, 7, 8, 17], "prone": 5, "manag": [5, 46], "invari": 5, "accept": [5, 6, 8, 17, 25], "multipl": [5, 6, 10, 30, 42, 43, 44, 45], "sourc": [5, 6, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51], "worri": 5, "explicitli": [5, 9, 29, 55], "convert": [5, 8, 33, 36], "time": [5, 25, 42, 44], "produc": 5, "back": [5, 9, 33], "origin": [5, 9, 13, 14, 30], "form": [5, 6, 10, 13], "One": 5, "advantag": [5, 9], "being": [5, 33, 34, 37, 48], "should": [5, 6, 8, 9, 10, 19, 20, 21, 29, 35, 42, 43, 44, 45, 54, 55], "abl": [5, 8, 10], "us": [5, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 33, 34, 35, 37, 42, 43, 44, 45, 46, 47, 48, 50, 53, 55], "fine": [5, 7, 8, 9, 10, 13, 14, 53, 55], "tune": [5, 6, 7, 8, 9, 10, 12, 13, 14, 53, 54, 55], "post": [5, 10], "tool": [5, 8], "quantiz": [5, 10, 19, 30], "eval": [5, 55], "without": [5, 6, 7, 9, 55], "code": [5, 26, 51, 55], "chang": [5, 6, 7, 8], "OR": 5, "convers": [5, 9, 33, 55], "script": [5, 8], "wai": [5, 6, 8, 54], "surround": [5, 10, 55], "load_checkpoint": [5, 10, 33, 34], "save_checkpoint": [5, 10, 33, 34], "method": [5, 6, 9, 10, 12, 13, 14, 15, 16, 17, 29, 31, 35, 55], "convertor": 5, "avail": [5, 8, 9, 35, 37, 55], "here": [5, 6, 8, 9, 23, 24], "three": [5, 8, 10], "hfcheckpoint": 5, "read": [5, 33, 34, 55], "write": [5, 8, 10, 33, 34, 42], "compat": [5, 8, 33], "transform": [5, 9, 10, 19, 26, 27, 28], "framework": [5, 10, 55], "mention": 5, "abov": [5, 9], "assum": [5, 9, 28, 31, 47], "checkpoint_dir": [5, 6, 7, 8, 33, 34], "necessari": [5, 9, 17, 42, 43, 44, 45], "json": [5, 33], "easiest": [5, 8], "sure": [5, 6, 8, 9], "everyth": [5, 8, 10, 35, 55], "follow": [5, 7, 8, 9, 10, 20, 28, 53, 54], "flow": 5, "By": [5, 9], "ignor": [5, 20, 21], "safetensor": 5, "output": [5, 8, 9, 13, 14, 15, 17, 19, 20, 21, 23, 24, 26, 27, 30, 32, 43, 54], "dir": [5, 8], "output_dir": [5, 6, 7, 8, 9, 33, 34], "specifi": [5, 6, 8, 10, 11, 19, 20], "argument": [5, 6, 7, 8, 9, 11, 17, 20, 35, 39, 41, 42, 44, 45, 54], "snippet": 5, "explain": 5, "setup": [5, 6, 9, 10, 26, 41], "_component_": [5, 6, 7, 8, 9, 11], "fullmodelhfcheckpoint": 5, "directori": [5, 6, 8, 33, 34, 42, 44], "sort": [5, 33], "id": [5, 13, 14, 17, 25, 33, 36], "so": [5, 6, 8, 9, 33, 35, 55], "order": [5, 8, 10, 33, 44, 45], "matter": [5, 9, 33], "checkpoint_fil": [5, 6, 7, 8, 9, 33, 34], "restart": [5, 7], "previou": [5, 33, 34], "more": [5, 6, 7, 8, 9, 10, 13, 22, 24, 35, 45, 50, 55], "next": 5, "section": [5, 10, 53], "recipe_checkpoint": [5, 7, 8, 33, 34], "null": [5, 6, 7, 8, 46], "usual": [5, 7, 9, 24, 33], "model_typ": [5, 7, 8, 33, 34], "resume_from_checkpoint": [5, 7, 8, 33, 34], "fals": [5, 6, 7, 8, 9, 13, 14, 15, 16, 17, 19, 20, 25, 30, 33, 34, 48], "requir": [5, 6, 17, 33, 44, 45, 50, 54], "param": [5, 9, 10, 30, 31, 32, 33], "directli": [5, 6, 8, 9, 11, 33], "help": [5, 8, 26, 33, 35, 53, 55], "ensur": [5, 6, 17, 19, 20, 33, 47, 55], "out": [5, 6, 7, 9, 13, 14, 15, 16, 33, 34, 53, 55], "case": [5, 9, 10, 19, 20, 33, 42, 47, 48, 55], "discrep": [5, 33], "along": 5, "detail": [5, 8, 9, 13, 22, 50], "found": [5, 6, 9, 23, 24], "metacheckpoint": 5, "github": [5, 13, 14, 15, 16, 20, 23, 24, 28, 54], "repositori": [5, 8], "fullmodelmetacheckpoint": [5, 7, 8], "torchtunecheckpoint": 5, "perform": [5, 9, 21, 55], "current": [5, 8, 19, 20, 24, 26, 27, 34, 38, 42, 44, 50, 54], "test": [5, 6, 10, 55], "complet": [5, 8, 10], "written": [5, 6, 10, 33, 34, 42, 43, 44, 45, 55], "begin": [5, 7, 25], "partit": 5, "ha": [5, 9, 25, 29, 31], "standard": [5, 43, 55], "key_1": 5, "weight_1": 5, "key_2": 5, "weight_2": 5, "mid": 5, "chekpoint": 5, "middl": 5, "inform": [5, 7, 8, 45, 55], "subsequ": [5, 10], "recipe_st": [5, 33, 34], "pt": [5, 33, 34], "These": [5, 6, 8, 9, 10, 11, 35], "epoch": [5, 7, 8, 9, 10, 28, 33, 34], "optim": [5, 6, 7, 8, 9, 10, 28], "etc": [5, 10, 33], "prevent": 5, "flood": 5, "overwritten": 5, "note": [5, 6, 9, 25, 26, 29, 33, 35, 47, 50], "updat": [5, 6, 7, 8, 9, 10], "hf_model_0001_0": 5, "hf_model_0002_0": 5, "both": [5, 9], "adapt": [5, 9, 29, 30, 31, 32, 33, 34], "merg": [5, 11, 33], "would": [5, 6, 9, 26], "our": [5, 9, 10, 55], "primari": [5, 6, 8, 10], "want": [5, 6, 7, 9, 11], "resum": [5, 10, 28, 33, 34], "initi": [5, 8, 9, 10, 12, 18, 25, 39], "frozen": [5, 9], "base": [5, 9, 17, 19, 24, 28, 30, 32, 33, 35, 42, 46], "well": [5, 6, 10, 55], "learnt": 5, "someth": [5, 7, 10], "NOT": 5, "refer": [5, 6, 7, 9, 10, 23, 24, 46, 55], "adapter_checkpoint": [5, 33, 34], "adapter_0": 5, "now": [5, 8, 9, 25], "knowledg": 5, "creat": [5, 6, 11, 13, 14, 15, 16, 18, 22, 28, 33, 34, 42, 44], "simpl": [5, 8, 53], "forward": [5, 9, 10, 20, 21, 23, 24, 26, 27, 30], "13b": 5, "modeltyp": [5, 33, 34], "llama2_13b": 5, "right": [5, 8, 9, 33], "pytorch_fil": 5, "00003": 5, "torchtune_sd": 5, "load_state_dict": [5, 9], "successfulli": 5, "vocab": [5, 11, 26], "70": 5, "x": [5, 9, 20, 21, 23, 24, 26, 27, 30], "randint": 5, "0": [5, 8, 9, 10, 19, 20, 25, 26, 28, 30, 36, 44, 45, 50, 52, 56], "1": [5, 7, 8, 9, 10, 17, 20, 25, 26, 28, 34, 36, 44, 45, 50], "no_grad": 5, "6": [5, 23, 36], "3989": 5, "9": 5, "0531": 5, "3": [5, 7, 35, 36, 40], "2375": 5, "5": [5, 7, 8, 28, 36], "2822": 5, "4": [5, 6, 7, 17, 20, 36, 55], "4872": 5, "7469": 5, "8": [5, 9, 13, 14, 15, 16], "6737": 5, "11": 5, "0023": 5, "8235": 5, "6819": 5, "2424": 5, "0109": 5, "6915": 5, "7": [5, 36], "3618": 5, "1628": 5, "8594": 5, "5857": 5, "1151": 5, "7808": 5, "2322": 5, "8850": 5, "9604": 5, "7624": 5, "6040": 5, "3159": 5, "5849": 5, "8039": 5, "9322": 5, "2010": 5, "6824": 5, "8929": 5, "8465": 5, "3794": 5, "3500": 5, "6145": 5, "5931": 5, "do": [5, 8, 9, 10, 45], "find": [5, 8, 10], "list": [5, 6, 8, 13, 14, 17, 19, 25, 29, 30, 33, 34, 35, 36, 40, 49], "builder": [5, 18], "hope": 5, "provid": [5, 6, 8, 10, 11, 17, 26, 35, 55], "deeper": 5, "insight": 5, "happi": 5, "thi": [6, 7, 8, 9, 10, 11, 13, 14, 17, 19, 20, 21, 24, 25, 26, 27, 28, 29, 33, 34, 35, 37, 42, 44, 45, 50, 53, 55], "guid": [6, 7, 8, 9], "learn": [6, 7, 8, 9, 10, 28, 55], "yaml": [6, 8, 9, 10, 11, 12, 35, 55], "pars": [6, 8, 11, 35], "effect": 6, "cli": [6, 8, 12], "prerequisit": [6, 8, 9], "Be": [6, 8, 9], "familiar": [6, 8, 9], "torchtun": [6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 54], "instal": [6, 8, 9, 44, 45, 53], "fundament": 6, "There": [6, 9, 54], "entri": [6, 8, 10], "point": [6, 7, 8, 9, 10], "all": [6, 7, 8, 9, 10, 20, 21, 26, 33, 35, 51, 53, 55, 56], "locat": [6, 9], "thei": [6, 9, 26, 35], "truth": 6, "reproduc": 6, "overridden": [6, 21, 35], "quick": 6, "experiment": 6, "modifi": [6, 9, 10, 55], "serv": [6, 9], "particular": [6, 17], "seed": [6, 8, 10, 50], "shuffl": [6, 7, 8], "devic": [6, 7, 8, 10, 37, 46, 47], "cuda": [6, 7, 8, 37, 47], "dtype": [6, 7, 8, 10, 22, 46, 47, 49], "fp32": 6, "enable_fsdp": 6, "mani": 6, "object": [6, 11, 20, 46, 48], "keyword": [6, 11, 17], "loss": [6, 7, 8, 9, 10, 13, 14, 15, 16], "function": [6, 11, 12, 20, 21, 37, 38, 50, 55], "common": [6, 9], "exampl": [6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 25, 29, 33, 34, 36, 44, 45, 51, 52, 56], "subfield": 6, "dotpath": 6, "wish": 6, "exact": [6, 11], "path": [6, 7, 8, 9, 10, 11, 25, 33, 34, 35], "normal": [6, 9, 23, 25, 26, 27], "python": [6, 35, 40, 45, 50, 51], "alpaca_dataset": [6, 7, 8, 13], "custom": [6, 8, 9, 10, 55], "train_on_input": [6, 7, 13, 14, 15, 16, 17], "onc": [6, 8, 9], "ve": [6, 9, 22], "instanc": [6, 9, 11, 13, 14, 19, 21, 25, 31, 32], "cfg": [6, 10, 12], "automat": [6, 11], "under": [6, 10], "preced": [6, 9, 11], "actual": 6, "throw": 6, "notic": [6, 9], "miss": [6, 9], "posit": [6, 11, 20, 24, 26, 27], "anoth": 6, "handl": [6, 9, 12, 25], "def": [6, 9, 10, 12], "dictconfig": [6, 10, 11, 12], "arg": [6, 10, 11, 26, 29, 35, 43], "tupl": [6, 11, 17, 25, 35, 36, 38], "kwarg": [6, 11, 29, 35, 39, 41, 42, 43, 44, 45], "str": [6, 11, 25, 29, 30, 31, 32, 33, 34, 35, 37, 40, 42, 43, 44, 45, 47, 49, 50], "mean": [6, 8, 9, 23], "pass": [6, 9, 11, 18, 19, 20, 21, 39, 41, 44, 45, 47], "add": [6, 9, 35], "d": [6, 9, 20, 26, 27], "llama2_token": [6, 7, 8], "tmp": [6, 7, 8], "option": [6, 8, 10, 18, 19, 20, 24, 25, 26, 27, 33, 34, 37, 40, 41, 42, 45, 47, 50, 54, 55], "bool": [6, 13, 14, 15, 16, 17, 19, 25, 30, 33, 34, 39, 44, 48], "max_seq_len": [6, 7, 11, 13, 14, 17, 19, 20, 22, 24, 25, 26], "int": [6, 9, 13, 14, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 30, 33, 34, 36, 38, 42, 43, 44, 45, 50], "512": [6, 7, 13, 14], "instructdataset": [6, 13, 14, 15, 16], "alreadi": [6, 8, 9, 39], "overwrit": 6, "duplic": [6, 55], "sometim": 6, "than": [6, 8, 9, 17, 20], "resolv": 6, "alpaca": [6, 7, 8, 9, 13, 14], "metric_logg": [6, 10], "metric_log": [6, 42, 43, 44, 45], "disklogg": 6, "log_dir": [6, 42, 44], "conveni": [6, 10], "quickli": 6, "verifi": [6, 8, 9, 37, 47], "properli": 6, "experi": [6, 9, 53, 55], "wa": [6, 9], "7b_full": [6, 8], "batch_siz": [6, 7, 8, 13, 14, 15, 16, 20, 27], "discuss": [6, 9], "guidelin": 6, "while": [6, 8, 10, 21, 55], "mai": [6, 8, 9], "tempt": 6, "put": [6, 8, 9, 10], "much": [6, 9], "give": [6, 9], "maximum": [6, 7, 13, 14, 17, 18, 19, 20, 22, 24, 26], "flexibl": 6, "switch": 6, "encourag": 6, "clariti": 6, "significantli": 6, "easier": [6, 8], "dont": 6, "slimorca_dataset": 6, "privat": 6, "typic": 6, "expos": [6, 8, 10], "parent": 6, "modul": [6, 9, 11, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 41, 50], "__init__": [6, 9, 10], "py": [6, 12, 13, 14, 15, 16, 20, 22, 23, 24, 28], "guarante": 6, "stabil": [6, 55], "underscor": 6, "_alpaca": 6, "collect": [6, 8], "differ": [6, 7, 9, 25, 55], "itself": 6, "via": [6, 9, 30], "pair": [6, 7, 36], "k1": [6, 10], "v1": [6, 10], "k2": [6, 10], "v2": [6, 10], "full_finetun": 6, "gpu": [6, 7, 8, 9], "full_finetune_distribut": [6, 7, 8], "checkpoint": [6, 7, 8, 9, 10, 33, 34, 41, 53, 55], "home": 6, "my_model_checkpoint": 6, "file_1": 6, "file_2": 6, "class": [6, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 42, 43, 44, 45], "assign": 6, "nest": 6, "dot": 6, "notat": [6, 20, 24, 26, 27], "my_config": 6, "paramet": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 50, 53, 55], "supervis": 7, "given": [7, 9, 10, 11, 30, 37, 47, 55], "compris": 7, "label": [7, 10, 13, 14, 17, 36], "cross": 7, "entropi": 7, "lot": 7, "expens": 7, "effici": [7, 9, 24, 53, 55], "techniqu": [7, 9, 55], "lora": [7, 13, 14, 19, 30, 53, 55], "result": [7, 8, 10, 25], "higher": 7, "qualiti": [7, 10], "mix": [7, 10, 46, 48, 55], "precis": [7, 10, 46, 47, 48, 49, 55], "distribut": [7, 8, 37, 39, 41, 50, 55], "fsdp": [7, 8, 10, 48, 55], "activ": [7, 8, 10, 21, 41, 55], "aspect": [7, 55], "llama2_7b": [7, 8, 9], "sgd": [7, 8], "lr": [7, 8, 28], "2e": 7, "nn": [7, 8, 9, 11, 20, 21, 22, 26, 27, 29, 31, 32, 41], "crossentropyloss": [7, 8], "bf16": [7, 8, 47], "enable_activation_checkpoint": [7, 8], "launch": [7, 8, 10], "tunecli": [7, 10], "nnode": [7, 8, 9], "nproc_per_nod": [7, 8, 9], "stanford": [7, 13, 14], "relat": [7, 9], "data": [7, 13, 14, 15, 16, 17, 42, 43, 44, 45], "mask": [7, 13, 14, 15, 16, 20, 25, 27], "prompt": [7, 13, 14, 15, 16, 17, 25, 26], "truncat": [7, 17, 25], "after": [7, 10, 22, 23, 42, 43, 44, 45], "sequenc": [7, 13, 14, 17, 19, 20, 22, 24, 25, 26, 27, 36], "length": [7, 13, 14, 17, 19, 20, 22, 24, 25, 26, 27, 34, 36], "limit": 7, "memori": [7, 9, 10, 13, 14, 41], "usag": [7, 54], "i": [7, 10, 32], "e": [7, 20, 29, 32, 54], "go": [7, 8, 25, 55], "down": [7, 8, 9], "slower": 7, "tokenizer_checkpoint": [7, 9], "path_to_model_token": 7, "batch": [7, 10, 13, 14, 15, 16, 18, 20, 22, 24, 25, 26, 27, 36, 55], "local": [7, 8, 50, 54], "global": [7, 50], "comput": [7, 19, 20, 21, 24, 26, 50], "num_gpu": 7, "gradient_accumulation_step": 7, "correspond": [7, 9, 29, 31, 47], "accumul": [7, 10, 55], "control": [7, 10, 13, 14, 15, 16, 50], "previous": 7, "incomplet": 7, "adam": 7, "known": [7, 25], "better": [7, 8, 55], "And": [7, 54], "process": [8, 10, 50], "job": [8, 50], "integr": [8, 55], "latest": 8, "greatest": 8, "gate": 8, "grant": 8, "instruct": [8, 9, 13, 14, 53], "page": [8, 55], "host": 8, "minut": 8, "agreement": 8, "signup": 8, "author": [8, 55], "authent": 8, "Then": 8, "command": [8, 9, 10, 35, 54], "other": [8, 9, 10, 11, 13, 35], "respons": [8, 25], "user": [8, 10, 19, 20, 25], "thought": [8, 10, 55], "pipelin": [8, 10, 55], "consist": [8, 10], "configur": [8, 9, 10, 13, 14, 15, 16, 17, 27, 55], "overrid": [8, 10, 12], "dataclass": [8, 10], "core": [8, 10, 55], "logic": [8, 9, 10, 33, 55], "api": [8, 10], "togeth": [8, 9, 10], "valid": [8, 10], "environ": [8, 10], "basic": 8, "hold": 8, "hyperparamet": [8, 9, 55], "metric": [8, 10], "logger": [8, 10, 40, 42, 43, 44, 45], "wandb": [8, 10, 45], "new": [8, 9, 10, 42, 44], "exist": [8, 10], "copi": 8, "Or": 8, "visit": 8, "specif": [8, 10, 11], "past": [8, 22], "It": 8, "alpaca_llama_full_finetun": 8, "seem": 8, "good": [8, 9], "place": 8, "start": [8, 55], "cp": 8, "custom_config": 8, "random": [8, 50], "replic": 8, "lower": [8, 9], "sooner": 8, "rate": [8, 28, 55], "42": 8, "1e": [8, 19, 23], "proper": 8, "suit": [8, 10], "pytorch": [8, 9, 10, 17, 26, 44, 46, 50, 53, 54, 55], "torchrun": [8, 10], "therefor": 8, "immedi": 8, "indic": 8, "succesfulli": 8, "log": [8, 10, 40, 42, 43, 44, 45], "log_1707246452": 8, "txt": [8, 42], "manual": [8, 9], "rank": [8, 9, 19, 30, 38, 50], "sampler": 8, "7553404569625854": 8, "13000": 8, "03": 8, "closer": [8, 9, 10], "teach": 9, "show": 9, "know": 9, "straight": 9, "your": [9, 11, 44, 45, 53, 55], "own": [9, 50], "jump": 9, "trainabl": [9, 30, 32], "low": [9, 19, 30], "decomposit": [9, 30], "matric": [9, 30], "neural": 9, "network": [9, 21], "freez": 9, "remain": [9, 28], "commonli": [9, 50], "linear": [9, 19, 26, 29, 30], "project": [9, 19, 20, 21, 45, 53], "self": [9, 10, 19, 20, 26, 27, 29], "attent": [9, 19, 20, 22, 24, 26, 27], "unfamiliar": 9, "check": [9, 26, 47, 53], "approxim": [9, 19, 30], "oppos": 9, "due": [9, 25], "substanti": 9, "reduct": 9, "gradient": [9, 10, 48, 55], "momentum": 9, "adamw": 9, "further": 9, "come": [9, 29], "primarili": [9, 10], "peak": 9, "its": [9, 15, 16, 19, 50], "reduc": [9, 26], "replac": [9, 13, 14, 15, 16], "arbitrari": 9, "in_dim": [9, 29, 30], "out_dim": [9, 29, 30], "could": 9, "high": [9, 55], "min": 9, "paper": 9, "aghajanyan": 9, "et": 9, "al": 9, "hypothes": 9, "intrins": 9, "dimens": [9, 19, 20, 22, 24, 26, 30], "llm": [9, 10, 53, 55], "fact": 9, "properti": [9, 35], "A": [9, 10, 25, 30, 33, 36, 52, 53, 56], "b": [9, 10, 20, 24, 26, 27, 30], "smaller": 9, "often": 9, "four": 9, "eight": 9, "practic": 9, "imag": 9, "below": [9, 24], "simplifi": 9, "represent": [9, 17], "step": [9, 10, 26, 28, 42, 43, 44, 45, 53], "left": 9, "compar": [9, 44], "blue": 9, "although": [9, 21], "introduc": [9, 20, 23, 30], "few": [9, 33], "extra": 9, "r": [9, 30], "rememb": 9, "q": [9, 20], "k": [9, 20], "v": [9, 20, 26], "approx": 9, "15m": 9, "8192": 9, "65k": 9, "over": [9, 10, 28, 35, 55], "99": 9, "minim": 9, "nativ": [9, 10, 53, 55], "loralinear": [9, 29], "alpha": [9, 30], "float": [9, 19, 20, 23, 28, 30, 42, 43, 44, 45], "dropout": [9, 19, 20, 30], "pretrain": 9, "bia": [9, 29, 30], "lora_a": [9, 30], "lora_b": [9, 30], "p": 9, "requires_grad": 9, "frozen_out": 9, "lora_out": 9, "final": [9, 19, 21, 26], "scale": [9, 19, 30], "return": [9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 36, 37, 38, 39, 40, 46, 47, 48, 49, 50], "around": [9, 10, 25], "omit": 9, "favorit": 9, "With": [9, 12], "varieti": [9, 55], "construct": 9, "lora_llama2_7b": 9, "build": [9, 10, 55], "base_model": 9, "choos": 9, "q_proj": [9, 19, 20], "k_proj": [9, 19, 20], "v_proj": [9, 19, 20], "output_proj": [9, 19, 20], "lora_model": 9, "lora_attn_modul": [9, 19], "lora_llama_2_7b": 9, "alon": 9, "bit": 9, "attn": [9, 27], "causalselfattent": [9, 27], "in_featur": 9, "out_featur": 9, "pos_embed": [9, 20], "rotarypositionalembed": [9, 20], "inplac": 9, "addition": [9, 50], "type": [9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 30, 31, 33, 34, 38, 39, 40, 46, 47, 48], "transformerdecod": [9, 18, 19], "feel": 9, "free": 9, "yourself": [9, 10], "why": 9, "wrapper": [9, 10, 25], "strict": 9, "whenev": 9, "peft": [9, 29, 30, 31, 32], "validate_state_dict_for_lora": 9, "peft_util": 9, "get_adapter_param": [9, 32], "set_trainable_param": 9, "fetch": 9, "lora_param": 9, "total": [9, 28, 38, 52, 56], "total_param": 9, "sum": 9, "numel": 9, "trainable_param": 9, "100": [9, 10, 13, 14, 15, 16, 17, 36], "2f": 9, "6742609920": 9, "4194304": 9, "06": [9, 23], "relev": [9, 10], "taken": 9, "vram": 9, "least": [9, 17], "23gb": 9, "lora_finetune_distribut": 9, "done": [9, 47], "ad": [9, 10, 25], "my_model_checkpoint_path": 9, "my_tokenizer_checkpoint_path": 9, "7b_lora": 9, "clone": [9, 54], "depend": [9, 10], "constraint": 9, "hardwar": [9, 55], "coupl": 9, "factori": 9, "lora_rank": [9, 19], "lora_alpha": [9, 19], "16": 9, "benefici": 9, "increas": [9, 28], "32": [9, 11], "max": [9, 17, 25, 26, 28], "long": 9, "keep": 9, "embed_dim": [9, 11, 19, 20, 24, 27], "impact": 9, "rel": 9, "minor": 9, "64": 9, "lora_experiment_1": 9, "comparison": 9, "smooth": 9, "curv": 9, "baselin": 9, "500": 9, "seen": 9, "figur": 9, "w": [9, 18, 44, 45], "wandblogg": 9, "similar": 9, "account": [9, 45], "separ": [9, 25, 33], "exercis": 9, "task": 9, "longer": 9, "structur": 10, "target": [10, 55], "eg": [10, 26, 33, 55], "meaning": [10, 55], "featur": [10, 55], "appli": [10, 19, 20, 23, 24, 26, 27, 55], "famili": [10, 55], "complex": 10, "becom": 10, "harder": 10, "anticip": 10, "architectur": [10, 26], "methodolog": 10, "reason": 10, "possibl": 10, "trade": 10, "off": [10, 25], "vs": 10, "believ": 10, "best": 10, "fit": [10, 13, 14], "solut": 10, "meant": 10, "level": [10, 40, 55], "expertis": 10, "routin": 10, "ones": 10, "modular": [10, 55], "block": [10, 19, 55], "wrap": [10, 41], "monolith": [10, 55], "trainer": [10, 38], "flag": [10, 13, 14, 15, 16], "extern": 10, "fulli": 10, "eleutherai": [10, 55], "har": [10, 55], "oper": [10, 50], "export": 10, "multi": [10, 20], "stage": 10, "distil": 10, "extract": 10, "turn": 10, "dataload": [10, 13, 14, 15, 16], "applic": [10, 20, 33, 34, 45, 46], "clean": [10, 13], "hood": 10, "parser": 10, "tunerecipeargumentpars": 10, "_": 10, "parse_known_arg": [10, 35], "var": 10, "recipe_param": 10, "fullfinetuneparam": 10, "env": 10, "variabl": 10, "group": [10, 20, 42, 43, 44, 45], "init_process_group": [10, 39], "backend": 10, "nccl": 10, "fullfinetunerecip": 10, "cleanup": 10, "stuff": 10, "carri": 10, "interfac": [10, 29], "_devic": 10, "get_devic": 10, "_dtype": 10, "get_dtyp": 10, "ckpt_dict": 10, "ckpt_path": 10, "model_checkpoint": 10, "_resume_from_checkpoint": 10, "_update_recipe_st": 10, "_model": 10, "_setup_model": 10, "_token": 10, "_setup_token": 10, "_optim": 10, "_setup_optim": 10, "_loss_fn": 10, "_setup_loss": 10, "_sampler": 10, "_dataload": 10, "_setup_data": 10, "backward": 10, "zero_grad": 10, "curr_epoch": 10, "rang": [10, 50], "epochs_run": 10, "total_epoch": 10, "idx": 10, "enumer": 10, "_autocast": 10, "logit": 10, "total_training_step": 10, "_log_every_n_step": 10, "_metric_logg": 10, "log_dict": [10, 42, 43, 44, 45], "decor": [10, 12], "recipe_main": [10, 12], "none": [10, 19, 20, 24, 25, 26, 27, 32, 33, 34, 37, 40, 41, 42, 43, 44, 45, 47, 50], "direct": 10, "field": [11, 13, 14, 15, 16], "num_lay": [11, 19, 26], "num_head": [11, 19, 20, 22, 24, 26], "num_kv_head": [11, 19, 20, 22], "vocab_s": [11, 19, 25], "must": [11, 13, 14, 15, 16, 17, 29, 35], "parsed_yaml": 11, "omegaconf": 11, "valueerror": [11, 17, 20, 26, 33, 34, 47, 50], "callabl": [12, 26], "main": [12, 13, 14, 15, 16, 20, 23, 24], "my_recip": 12, "foo": 12, "bar": [12, 55], "http": [13, 14, 15, 16, 17, 18, 20, 23, 24, 28, 33, 34, 35, 40, 44, 45, 46, 50, 54], "huggingfac": [13, 14, 15, 16, 17, 28, 33, 34], "co": [13, 14, 15, 16, 17, 33, 34], "yahma": 13, "tatsu": [13, 14], "lab": [13, 14], "templat": [13, 14, 15, 16, 17], "codebas": [13, 14, 15, 16], "com": [13, 14, 15, 16, 20, 23, 24, 28, 54], "stanford_alpaca": [13, 14], "blob": [13, 14, 15, 16, 20, 23, 24, 28], "761dc5bfbdeeffa89b8bff5d038781a4055f796a": [13, 14], "l31": [13, 14], "where": [13, 14, 15, 16, 20, 25, 26, 30], "ref": [13, 14, 45], "tloen": [13, 14], "l49": [13, 14], "contribut": [13, 14, 15, 16], "version": [13, 19, 20], "remov": 13, "hallucin": 13, "poorli": 13, "wrong": 13, "answer": 13, "card": 13, "encod": [13, 14, 15, 16, 17, 25], "decod": [13, 14, 15, 16, 17, 19, 25, 26], "whether": [13, 14, 15, 16, 17, 19, 25, 30, 47, 48], "tab": [13, 14], "readm": [13, 14], "ov": [13, 14], "recommend": [13, 14, 44], "highest": [13, 14], "alpaca_d": [13, 14], "grammar": 15, "variant": [15, 16], "liweili": 15, "c4_200m": 15, "descript": 15, "llama_recip": [15, 16], "src": [15, 16, 28], "l50": 15, "grammar_d": 15, "summar": 16, "samsum": 16, "l13": 16, "dialogu": 16, "summari": 16, "samsum_d": 16, "1024": 17, "chatdataset": 17, "slimorca": 17, "open": 17, "orca": 17, "dedup": 17, "adher": 17, "chat": 17, "doesn": 17, "prescrib": 17, "though": 17, "ds": 17, "10": [17, 36], "sampl": 17, "351": 17, "82": 17, "391": 17, "221": 17, "220": 17, "193": 17, "12": 17, "471": 17, "arxiv": [18, 20, 23, 24], "org": [18, 20, 23, 24, 35, 40, 44, 46, 50], "ab": [18, 24], "2307": 18, "09288": 18, "max_batch_s": [18, 22], "kvcach": [18, 19, 20, 26], "instanti": [18, 19], "liter": 19, "apply_lora_to_mlp": 19, "apply_lora_to_output": 19, "intermediate_dim": 19, "attn_dropout": [19, 20, 26], "norm_ep": 19, "05": 19, "lora_dropout": 19, "quantize_bas": [19, 30], "mlp": [19, 26, 27], "vocabulari": [19, 25], "queri": [19, 20, 22, 26], "head": [19, 20, 22, 24, 26], "mha": [19, 20, 26], "onto": [19, 20], "scaled_dot_product_attent": [19, 20], "intermedi": 19, "scale_hidden_dim_for_mlp": 19, "epsilon": 19, "rm": 19, "norm": [19, 26, 27], "factor": [19, 30], "probabl": [19, 30], "subset": [19, 31], "head_dim": [20, 22, 24, 26], "kv_cach": 20, "gqa": 20, "pdf": [20, 23], "2305": 20, "13245v1": 20, "multihead": 20, "n": [20, 25, 52, 56], "extrem": 20, "share": 20, "mqa": 20, "credit": 20, "document": 20, "lightn": 20, "ai": [20, 45], "lit": 20, "gpt": 20, "lit_gpt": 20, "n_kv_head": 20, "calcul": 20, "g": [20, 29], "cach": [20, 22, 24], "rope": [20, 24], "input_po": [20, 24, 26, 27], "seq_length": [20, 27], "seq_len": [20, 24], "bigger": 20, "n_h": [20, 24], "num": [20, 24], "n_kv": 20, "kv": [20, 22, 26], "emb": [20, 26, 27], "h_d": [20, 24], "gate_proj": 21, "down_proj": 21, "up_proj": 21, "silu": 21, "feed": [21, 27], "deriv": [21, 26, 27], "hidden": 21, "fed": 21, "multipli": 21, "subclass": [21, 35], "afterward": 21, "former": 21, "regist": 21, "hook": 21, "latter": 21, "standalon": 22, "becaus": [22, 26], "expand": 22, "per": 22, "dpython": [22, 46], "ep": 23, "root": [23, 44], "squar": 23, "1910": 23, "07467": 23, "correct": [23, 24, 26, 37, 55], "verfic": [23, 24], "facebookresearch": [23, 24], "small": 23, "avoid": [23, 50], "divis": 23, "zero": 23, "10000": 24, "rotari": 24, "propos": 24, "2104": 24, "09864": 24, "l450": 24, "upto": 24, "init": [24, 45], "exceed": 24, "freq": 24, "recomput": 24, "geometr": 24, "progress": 24, "rotat": 24, "angl": 24, "bsz": 24, "todo": 24, "made": 24, "spm_model": 25, "sentencepieceprocessor": 25, "bos_id": 25, "eos_id": 25, "pad_id": 25, "sentencepiec": 25, "sentenc": 25, "pad": [25, 36], "non": 25, "from_fil": 25, "tokenized_text": 25, "hello": 25, "world": [25, 38], "add_bo": 25, "add_eo": 25, "31587": 25, "29644": 25, "102": 25, "text": 25, "trim_leading_whitespac": 25, "prefix": 25, "unbatch": 25, "prepend": 25, "bo": 25, "append": 25, "eo": 25, "trim": 25, "lead": 25, "whitespac": 25, "underli": 25, "s1": 25, "s2": 25, "classmethod": 25, "tokenize_messag": 25, "messag": 25, "concaten": 25, "problem": 25, "slice": 25, "tokenizer_path": 25, "role": 25, "system": 25, "assist": 25, "concat": 25, "1788": 25, "2643": 25, "13": 25, "1792": 25, "9508": 25, "465": 25, "22137": 25, "2933": 25, "join": 25, "attribut": 25, "transformerdecoderlay": 26, "move": 26, "space": 26, "belong": 26, "statement": 26, "improv": 26, "readabl": 26, "At": 26, "arang": 26, "prompt_length": 26, "causal_mask": 26, "m_": 26, "seq": 26, "sa_norm": 27, "mlp_norm": 27, "ff": 27, "num_warmup_step": 28, "num_training_step": 28, "num_cycl": 28, "last_epoch": 28, "lambdalr": 28, "schedul": 28, "linearli": 28, "decreas": 28, "cosin": 28, "v4": 28, "23": 28, "l104": 28, "warmup": 28, "phase": 28, "wave": 28, "half": [28, 46], "index": [28, 36], "last": 28, "lr_schedul": 28, "appropri": 28, "protocol": 29, "adapter_param": [29, 30, 31, 32], "proj": 29, "use_bia": 30, "larg": 30, "languag": 30, "perturb": 30, "mapsto": 30, "w_0x": 30, "bax": 30, "map": [32, 33, 42, 43, 44, 45], "respect": 32, "0001_of_0003": 33, "0002_of_0003": 33, "preserv": 33, "weight_map": 33, "intermediate_checkpoint": [33, 34], "_output_dir": [33, 34], "parit": 33, "_weight_map": 33, "shard": [34, 48], "wip": 34, "argpars": 35, "tunerecipeargpars": 35, "argumentpars": 35, "builtin": [35, 46], "noth": 35, "treat": 35, "still": 35, "els": [35, 55], "consult": 35, "doc": [35, 40, 44, 45, 46, 50], "info": 35, "librari": [35, 40, 50, 53, 55], "html": [35, 40, 44, 46, 50], "namespac": 35, "act": 35, "alwai": 35, "precid": 35, "parse_arg": 35, "intern": 35, "inherit": [35, 55], "too": 35, "collat": 36, "padding_idx": 36, "ignore_idx": 36, "longest": 36, "integ": [36, 50], "tokenpair": 36, "token_pair": 36, "availab": 37, "machin": 37, "aka": 38, "runtimeerror": 39, "stream": 40, "handler": 40, "auto_wrap_polici": 41, "polici": 41, "filenam": 42, "log_": 42, "unixtimestamp": 42, "thread": 42, "safe": 42, "resourc": [42, 43, 44, 45], "flush": [42, 43, 44, 45], "union": [42, 43, 44, 45, 48, 50], "ndarrai": [42, 43, 44, 45], "scalar": [42, 43, 44, 45], "tag": [42, 43, 44, 45], "record": [42, 43, 44, 45], "payload": [42, 43, 44, 45], "dictionari": [42, 43, 44, 45], "organize_log": 44, "tensorboard": 44, "stabl": [44, 46, 50], "subdirectori": 44, "sub": 44, "logdir": 44, "startup": 44, "recurs": 44, "tree": 44, "tfevent": 44, "encount": 44, "frontend": 44, "organ": 44, "accordingli": 44, "my_log_dir": 44, "view": 44, "my_metr": [44, 45], "packag": [44, 45, 54], "pip": [44, 45, 54], "termin": [44, 45], "entiti": 45, "bias": 45, "my_project": 45, "my_ent": 45, "my_group": 45, "importerror": 45, "login": 45, "contextmanag": 46, "intellig": 46, "determin": 46, "autocast": 46, "amp": 46, "otherwis": 46, "context": 46, "request": 47, "inde": 47, "kernel": 47, "float32": 47, "isn": 47, "gradscal": 48, "shardedgradscal": 48, "scaler": 48, "awar": 48, "debug_mod": 50, "pseudo": 50, "numpi": 50, "determinist": 50, "warn": 50, "nondeterminist": 50, "cudnn": 50, "benchmark": [50, 55], "disabl": 50, "set_deterministic_debug_mod": 50, "algorithm": 50, "outsid": 50, "generated_examples_python": 51, "zip": 51, "galleri": [51, 56], "sphinx": 51, "000": [52, 56], "execut": [52, 56], "generated_exampl": 52, "mem": [52, 56], "mb": [52, 56], "topic": 53, "gentl": 53, "introduct": 53, "readi": 53, "interact": 53, "git": 54, "cd": 54, "confirm": 54, "recipe_arg": 54, "On": 55, "pointer": 55, "emphas": 55, "simplic": 55, "extens": 55, "component": 55, "reus": 55, "abstract": 55, "prove": 55, "democrat": 55, "box": 55, "zoo": 55, "excit": 55, "checkout": 55, "chekckpoint": 55, "embodi": 55, "philosophi": 55, "especi": 55, "usabl": 55, "eluetherai": 55, "composit": 55, "hard": 55, "No": 55, "outlin": 55, "prefer": 55, "unecessari": 55, "never": 55, "thoroughli": 55, "unit": 55, "numer": 55, "pariti": 55}, "objects": {"torchtune.config": [[11, 0, 1, "", "instantiate"], [12, 0, 1, "", "parse"]], "torchtune.datasets": [[13, 0, 1, "", "alpaca_cleaned_dataset"], [14, 0, 1, "", "alpaca_dataset"], [15, 0, 1, "", "grammar_dataset"], [16, 0, 1, "", "samsum_dataset"], [17, 0, 1, "", "slimorca_dataset"]], "torchtune.models.llama2": [[18, 0, 1, "", "llama2_7b"], [19, 0, 1, "", "lora_llama2"]], "torchtune.modules": [[20, 1, 1, "", "CausalSelfAttention"], [21, 1, 1, "", "FeedForward"], [22, 1, 1, "", "KVCache"], [23, 1, 1, "", "RMSNorm"], [24, 1, 1, "", "RotaryPositionalEmbeddings"], [25, 1, 1, "", "Tokenizer"], [26, 1, 1, "", "TransformerDecoder"], [27, 1, 1, "", "TransformerDecoderLayer"], [28, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[20, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[21, 2, 1, "", "forward"]], "torchtune.modules.RMSNorm": [[23, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[24, 2, 1, "", "forward"]], "torchtune.modules.Tokenizer": [[25, 2, 1, "", "decode"], [25, 2, 1, "", "encode"], [25, 2, 1, "", "from_file"], [25, 2, 1, "", "tokenize_messages"]], "torchtune.modules.TransformerDecoder": [[26, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoderLayer": [[27, 2, 1, "", "forward"]], "torchtune.modules.peft": [[29, 1, 1, "", "AdapterModule"], [30, 1, 1, "", "LoRALinear"], [31, 0, 1, "", "get_adapter_params"], [32, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[29, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[30, 2, 1, "", "adapter_params"], [30, 2, 1, "", "forward"]], "torchtune.utils": [[33, 1, 1, "", "FullModelHFCheckpointer"], [34, 1, 1, "", "FullModelMetaCheckpointer"], [37, 0, 1, "", "get_device"], [38, 0, 1, "", "get_world_size_and_rank"], [39, 0, 1, "", "init_distributed"]], "torchtune.utils.FullModelHFCheckpointer": [[33, 2, 1, "", "load_checkpoint"], [33, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[34, 2, 1, "", "load_checkpoint"], [34, 2, 1, "", "save_checkpoint"]], "torchtune.utils.argparse": [[35, 1, 1, "", "TuneRecipeArgumentParser"]], "torchtune.utils.argparse.TuneRecipeArgumentParser": [[35, 2, 1, "", "parse_known_args"]], "torchtune.utils.collate": [[36, 0, 1, "", "padded_collate"]], "torchtune.utils.logging": [[40, 0, 1, "", "get_logger"]], "torchtune.utils.memory": [[41, 0, 1, "", "set_activation_checkpointing"]], "torchtune.utils.metric_logging": [[42, 1, 1, "", "DiskLogger"], [43, 1, 1, "", "StdoutLogger"], [44, 1, 1, "", "TensorBoardLogger"], [45, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[42, 2, 1, "", "close"], [42, 2, 1, "", "log"], [42, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[43, 2, 1, "", "close"], [43, 2, 1, "", "log"], [43, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[44, 2, 1, "", "close"], [44, 2, 1, "", "log"], [44, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[45, 2, 1, "", "close"], [45, 2, 1, "", "log"], [45, 2, 1, "", "log_dict"]], "torchtune.utils.precision": [[46, 0, 1, "", "get_autocast"], [47, 0, 1, "", "get_dtype"], [48, 0, 1, "", "get_gradient_scaler"], [49, 0, 1, "", "list_dtypes"]], "torchtune.utils.seed": [[50, 0, 1, "", "set_seed"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 9, 53, 55], "config": [0, 6, 8, 10], "dataset": [1, 7], "model": [2, 3, 7, 8, 9], "llama2": [2, 9], "modul": 3, "compon": [3, 6], "build": 3, "block": 3, "peft": 3, "util": 4, "checkpoint": [4, 5], "distribut": 4, "reduc": 4, "precis": 4, "memori": 4, "manag": 4, "metric": 4, "log": 4, "data": 4, "miscellan": 4, "overview": [5, 55], "format": 5, "handl": 5, "differ": 5, "intermedi": 5, "vs": 5, "final": 5, "lora": [5, 9], "put": 5, "thi": 5, "all": 5, "togeth": 5, "deep": [6, 10], "dive": [6, 10], "where": 6, "do": 6, "paramet": 6, "live": 6, "write": 6, "configur": 6, "us": [6, 10], "instanti": [6, 11], "referenc": 6, "other": 6, "field": 6, "interpol": 6, "valid": 6, "your": [6, 8, 10], "best": 6, "practic": 6, "airtight": 6, "public": 6, "api": 6, "onli": 6, "command": 6, "line": 6, "overrid": 6, "llm": [7, 8], "full": 7, "finetun": [7, 8, 9], "recip": [7, 8, 9, 10], "train": [7, 8, 10], "first": 8, "download": 8, "select": 8, "modifi": 8, "next": 8, "step": 8, "what": [9, 10, 55], "how": 9, "doe": 9, "work": 9, "appli": 9, "ar": 10, "script": 10, "class": 10, "run": 10, "cli": 10, "pars": [10, 12], "alpaca_cleaned_dataset": 13, "alpaca_dataset": 14, "grammar_dataset": 15, "samsum_dataset": 16, "slimorca_dataset": 17, "llama2_7b": 18, "lora_llama2": 19, "causalselfattent": 20, "todo": [20, 27], "feedforward": 21, "kvcach": 22, "rmsnorm": 23, "rotarypositionalembed": 24, "token": 25, "transformerdecod": 26, "transformerdecoderlay": 27, "get_cosine_schedule_with_warmup": 28, "adaptermodul": 29, "loralinear": 30, "get_adapter_param": 31, "set_trainable_param": 32, "fullmodelhfcheckpoint": 33, "fullmodelmetacheckpoint": 34, "tunerecipeargumentpars": 35, "padded_col": 36, "get_devic": 37, "get_world_size_and_rank": 38, "init_distribut": 39, "get_logg": 40, "set_activation_checkpoint": 41, "disklogg": 42, "stdoutlogg": 43, "tensorboardlogg": 44, "wandblogg": 45, "get_autocast": 46, "get_dtyp": 47, "get_gradient_scal": 48, "list_dtyp": 49, "set_se": 50, "comput": [52, 56], "time": [52, 56], "welcom": 53, "document": 53, "get": 53, "start": 53, "tutori": 53, "instal": 54, "instruct": 54, "kei": 55, "concept": 55, "design": 55, "principl": 55}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})