Search.setIndex({"docnames": ["api_ref_config", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "deep_dives/checkpointer", "deep_dives/configs", "deep_dives/recipe_deepdive", "deep_dives/wandb_logging", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.Tokenizer", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.TuneRecipeArgumentParser", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_dtype", "generated/torchtune.utils.get_logger", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.list_dtypes", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.padded_collate", "generated/torchtune.utils.profiler", "generated/torchtune.utils.set_activation_checkpointing", "generated/torchtune.utils.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times", "tutorials/e2e_flow", "tutorials/first_finetune_tutorial", "tutorials/lora_finetune", "tutorials/qlora_finetune"], "filenames": ["api_ref_config.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "deep_dives/checkpointer.rst", "deep_dives/configs.rst", "deep_dives/recipe_deepdive.rst", "deep_dives/wandb_logging.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.Tokenizer.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_dtype.rst", "generated/torchtune.utils.get_logger.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.list_dtypes.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.padded_collate.rst", "generated/torchtune.utils.profiler.rst", "generated/torchtune.utils.set_activation_checkpointing.rst", "generated/torchtune.utils.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst", "tutorials/e2e_flow.rst", "tutorials/first_finetune_tutorial.rst", "tutorials/lora_finetune.rst", "tutorials/qlora_finetune.rst"], "titles": ["torchtune.config", "torchtune.datasets", "torchtune.models.llama2", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "All about configs", "What are recipes?", "Logging to Weights &amp; Biases", "instantiate", "parse", "alpaca_cleaned_dataset", "alpaca_dataset", "grammar_dataset", "samsum_dataset", "slimorca_dataset", "llama2_7b", "lora_llama2", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "Tokenizer", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "get_device", "get_dtype", "get_logger", "get_world_size_and_rank", "init_distributed", "list_dtypes", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "padded_collate", "profiler", "set_activation_checkpointing", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times", "End-to-End Workflow with torchtune", "Finetune your First LLM", "Finetuning Llama2 with LoRA", "Finetuning Llama2 with QLoRA"], "terms": {"These": [3, 5, 6, 7, 9, 34, 55, 56, 57, 58], "ar": [3, 5, 6, 8, 9, 11, 12, 13, 14, 17, 24, 29, 32, 33, 36, 53, 55, 56, 57, 58], "common": [3, 6, 57], "can": [3, 5, 6, 7, 8, 9, 11, 12, 21, 22, 23, 32, 34, 43, 44, 51, 52, 53, 55, 56, 57, 58], "us": [3, 5, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 32, 33, 34, 35, 36, 41, 42, 43, 44, 48, 51, 52, 53, 56, 57], "all": [3, 7, 18, 19, 24, 26, 32, 34, 49, 51, 53, 54, 55, 56, 57], "offer": 4, "allow": [4, 43, 58], "seamless": 4, "transit": 4, "between": [4, 5, 32, 55, 57, 58], "format": [4, 11, 12, 13, 14, 15, 32, 33, 55, 56, 57], "train": [4, 5, 7, 8, 11, 12, 13, 14, 15, 18, 27, 32, 33, 36, 46, 51, 53, 55, 57, 58], "interoper": [4, 5, 7, 53, 55, 58], "rest": [4, 58], "ecosystem": [4, 5, 7, 53, 55, 56, 58], "For": [4, 5, 6, 7, 11, 12, 17, 18, 24, 34, 44, 48, 55, 56, 57, 58], "comprehens": 4, "overview": [4, 6, 8, 56, 57, 58], "pleas": [4, 52, 58], "see": [4, 5, 8, 11, 20, 28, 34, 37, 44, 46, 48, 52, 53, 55, 56, 57, 58], "deep": [4, 5, 6, 7, 8, 53], "dive": [4, 5, 6, 7, 8, 53], "enabl": [4, 6, 7, 8, 29, 46, 48, 56, 57, 58], "work": [4, 5, 7, 34, 53, 55, 58], "set": [4, 5, 6, 7, 8, 11, 12, 13, 14, 15, 22, 24, 31, 35, 47, 48, 53, 55, 56, 57], "consumpt": 4, "dure": [4, 5, 11, 12, 13, 14, 18, 20, 22, 24, 25, 55, 57, 58], "provid": [4, 5, 6, 7, 9, 15, 24, 34, 53, 55, 56], "debug": [4, 5, 6, 7], "your": [4, 8, 9, 43, 44, 51, 52, 53, 55, 57, 58], "finetun": [4, 5, 6, 7, 11, 12, 40, 51, 53], "job": [4, 48, 56], "variou": 4, "dataset": [4, 6, 11, 12, 13, 14, 15, 53, 55, 56, 57, 58], "walk": [5, 7, 43, 53, 55, 56, 58], "you": [5, 6, 7, 8, 9, 11, 12, 34, 43, 44, 51, 52, 53, 55, 56, 57, 58], "through": [5, 6, 7, 8, 19, 53, 55, 56, 58], "design": [5, 7], "behavior": 5, "associ": [5, 6, 7, 55, 57], "util": [5, 6, 7, 8, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 53, 55, 56, 58], "what": [5, 6, 8, 51, 55, 56], "cover": [5, 6, 7, 8, 55, 58], "how": [5, 6, 7, 8, 51, 55, 56, 58], "we": [5, 6, 7, 8, 11, 12, 18, 20, 22, 23, 24, 29, 32, 33, 36, 53, 55, 56, 57, 58], "them": [5, 6, 19, 23, 26, 55, 57, 58], "scenario": 5, "full": [5, 6, 7, 23, 32, 33, 53, 57], "compos": 5, "compon": [5, 7, 46, 53, 56, 57, 58], "which": [5, 7, 11, 12, 13, 14, 17, 18, 22, 23, 24, 25, 27, 32, 33, 36, 41, 53, 55, 57, 58], "plug": 5, "ani": [5, 6, 7, 9, 10, 23, 26, 30, 31, 32, 33, 48, 55, 57], "recip": [5, 6, 8, 9, 10, 13, 14, 19, 32, 33, 53, 55, 58], "evalu": [5, 7, 51, 53, 56, 57, 58], "gener": [5, 7, 15, 23, 48, 49, 51, 57, 58], "each": [5, 7, 17, 18, 22, 23, 24, 48, 53, 55, 56, 57], "support": [5, 7, 8, 9, 11, 12, 13, 14, 17, 18, 29, 33, 36, 40, 53, 55, 56, 57, 58], "model": [5, 6, 7, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 46, 47, 51, 53, 58], "make": [5, 6, 7, 8, 18, 25, 53, 55, 56, 57, 58], "easi": [5, 7, 53, 56, 57], "understand": [5, 6, 7, 51, 53, 57, 58], "extend": [5, 7, 53], "befor": [5, 24, 25, 29, 32, 55], "let": [5, 6, 8, 55, 56, 57, 58], "s": [5, 6, 7, 8, 10, 17, 18, 22, 24, 25, 26, 28, 30, 32, 33, 35, 43, 46, 53, 56, 57, 58], "defin": [5, 6, 7, 19, 28, 29, 30, 57], "some": [5, 6, 17, 30, 31, 51, 53, 55, 56, 57, 58], "concept": [5, 55], "In": [5, 6, 7, 22, 29, 43, 44, 55, 57, 58], "ll": [5, 6, 7, 53, 55, 58], "talk": 5, "about": [5, 7, 32, 44, 53, 55, 57, 58], "take": [5, 6, 7, 9, 19, 20, 26, 32, 34, 35, 55, 56, 57, 58], "close": [5, 7, 41, 42, 43, 44, 57], "look": [5, 6, 7, 43, 55, 56, 57], "veri": [5, 24, 55], "simpli": [5, 6, 58], "dictat": 5, "state_dict": [5, 26, 32, 33, 57, 58], "store": [5, 41, 44, 57, 58], "file": [5, 6, 7, 8, 9, 10, 11, 12, 23, 32, 33, 34, 41, 44, 46, 50, 53, 54, 55, 56, 57, 58], "disk": [5, 41], "weight": [5, 7, 17, 18, 26, 28, 29, 32, 33, 44, 51, 55, 56, 57, 58], "string": [5, 23, 28, 35, 36], "kei": [5, 6, 8, 17, 18, 20, 24, 31, 32, 55, 57, 58], "identifi": 5, "state": [5, 7, 26, 30, 31, 32, 33, 55, 57, 58], "dict": [5, 6, 7, 8, 9, 26, 30, 31, 32, 33, 39], "If": [5, 6, 11, 12, 13, 14, 15, 17, 18, 26, 29, 32, 33, 35, 36, 39, 43, 44, 48, 52, 56, 57], "identif": 5, "don": [5, 6, 7, 48, 55, 58], "t": [5, 6, 7, 15, 36, 48, 55, 58], "match": [5, 55, 57], "up": [5, 7, 8, 11, 12, 56, 57, 58], "exactli": 5, "those": [5, 57], "definit": [5, 57], "either": [5, 32, 57, 58], "run": [5, 6, 8, 10, 17, 19, 20, 24, 26, 32, 33, 43, 44, 52, 53, 56, 57, 58], "explicit": 5, "error": [5, 6, 11, 32, 48], "load": [5, 7, 32, 33, 34, 43, 55, 57], "rais": [5, 9, 15, 18, 24, 32, 33, 36, 39, 44, 48], "an": [5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 17, 18, 24, 28, 30, 31, 32, 33, 44, 53, 55, 56, 57, 58], "except": 5, "wors": 5, "silent": [5, 19], "succe": 5, "infer": [5, 18, 20, 22, 24, 25, 51, 55, 58], "expect": [5, 6, 9, 22, 44, 57], "addit": [5, 6, 7, 9, 32, 33, 36, 39, 41, 43, 44, 47, 53, 57], "line": [5, 7, 34, 56], "also": [5, 6, 7, 8, 9, 17, 18, 24, 29, 35, 44, 52, 55, 56, 57, 58], "need": [5, 6, 7, 8, 15, 18, 19, 24, 43, 44, 55, 56, 57, 58], "shape": [5, 18, 20, 22, 24, 25, 29], "valu": [5, 6, 15, 16, 17, 18, 20, 21, 24, 27, 32, 34, 41, 42, 43, 44, 48, 57], "two": [5, 6, 53, 55, 56, 57, 58], "popular": [5, 53, 55, 56], "llama2": [5, 6, 7, 9, 11, 12, 15, 16, 17, 19, 23, 24, 25, 51, 53, 56], "meta": [5, 13, 14, 32, 33, 55, 56], "offici": [5, 56], "implement": [5, 7, 11, 12, 13, 14, 15, 19, 21, 22, 27, 28, 29, 32, 43, 53, 57, 58], "when": [5, 6, 7, 10, 24, 26, 27, 43, 55, 57, 58], "download": [5, 49, 52, 57, 58], "7b": [5, 11, 12, 16, 32, 33, 56, 57, 58], "from": [5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 19, 23, 24, 25, 27, 28, 30, 32, 33, 34, 43, 44, 50, 52, 54, 55, 56, 57], "llama": [5, 13, 14, 21, 22, 32, 33, 55, 56, 57], "websit": 5, "get": [5, 6, 7, 8, 23, 36, 37, 38, 53, 55, 56, 57], "access": [5, 6, 7, 32, 55, 56], "singl": [5, 6, 9, 18, 32, 33, 55, 57, 58], "pth": [5, 55, 56], "inspect": [5, 55, 57, 58], "content": [5, 23], "easili": [5, 6, 53, 57, 58], "torch": [5, 20, 24, 26, 27, 35, 36, 39, 46, 47, 48, 55, 56, 57, 58], "import": [5, 6, 9, 43, 44, 55, 56, 57, 58], "consolid": [5, 56], "00": [5, 50, 54, 56], "mmap": [5, 55], "true": [5, 6, 11, 12, 13, 14, 23, 26, 32, 33, 39, 43, 55, 56, 57, 58], "weights_onli": 5, "map_loc": [5, 55], "cpu": [5, 7, 26, 36, 55, 58], "tensor": [5, 18, 19, 20, 21, 22, 24, 25, 26, 29, 32, 41, 42, 43, 44, 45, 57, 58], "item": 5, "print": [5, 11, 12, 13, 14, 15, 23, 57, 58], "f": [5, 8, 11, 12, 13, 14, 55, 57, 58], "tok_embed": [5, 24], "size": [5, 7, 9, 11, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 38, 53, 55, 57], "32000": [5, 9, 57], "4096": [5, 9, 11, 12, 18, 22, 57], "len": [5, 11, 12, 13, 14, 24], "292": 5, "The": [5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17, 21, 22, 23, 26, 27, 32, 34, 35, 36, 37, 44, 46, 48, 52, 53, 55, 56, 57, 58], "contain": [5, 18, 20, 22, 23, 24, 25, 28, 30, 31, 32, 33, 34, 43, 45, 55, 57], "includ": [5, 6, 7, 29, 32, 33, 34, 53, 55, 56, 57, 58], "input": [5, 11, 12, 13, 14, 15, 18, 19, 21, 22, 23, 24, 25, 29, 32, 45, 48, 57, 58], "embed": [5, 17, 18, 20, 21, 22, 24], "tabl": [5, 57, 58], "call": [5, 9, 19, 26, 34, 41, 42, 43, 44, 56, 57, 58], "layer": [5, 7, 17, 18, 24, 25, 29, 53, 57, 58], "token": [5, 6, 7, 11, 12, 13, 14, 15, 17, 18, 22, 24, 25, 55, 56, 57, 58], "have": [5, 6, 9, 18, 20, 28, 34, 43, 46, 55, 56, 57, 58], "dim": [5, 18, 19, 21, 22, 24, 25], "hf": [5, 32, 55, 56], "most": [5, 6, 56, 57, 58], "within": [5, 6, 9, 15, 17, 19, 43, 48, 55, 57, 58], "hug": [5, 11, 12, 13, 14, 15, 27, 53, 55, 56], "face": [5, 11, 12, 13, 14, 15, 27, 53, 55, 56], "hub": [5, 55, 56], "default": [5, 6, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 29, 32, 33, 34, 36, 41, 45, 46, 48, 55, 57, 58], "everi": [5, 7, 19, 43, 58], "config": [5, 8, 9, 10, 18, 32, 34, 44, 53, 55, 57, 58], "2": [5, 15, 18, 23, 32, 33, 45, 48, 55, 56, 57], "repo": [5, 32, 33, 55], "first": [5, 6, 9, 24, 32, 34, 51, 53, 55, 57, 58], "big": [5, 55], "split": [5, 55], "across": [5, 7, 32, 43, 48, 55], "bin": [5, 55], "To": [5, 6, 7, 32, 52, 53, 55, 56, 57, 58], "correctli": [5, 7, 32, 52, 56, 58], "piec": 5, "one": [5, 7, 19, 23, 55, 58], "pytorch_model": [5, 55], "00001": 5, "00002": 5, "embed_token": 5, "241": 5, "Not": 5, "onli": [5, 8, 17, 18, 22, 23, 24, 25, 29, 30, 33, 34, 36, 55, 57, 58], "doe": [5, 28, 32, 34, 55], "fewer": [5, 18], "sinc": [5, 6, 9, 19, 32, 55], "instead": [5, 7, 19, 20, 29, 55, 57], "mismatch": 5, "name": [5, 6, 8, 28, 31, 32, 33, 34, 35, 41, 42, 43, 44, 55], "caus": [5, 23], "try": [5, 6, 55, 58], "same": [5, 6, 17, 18, 20, 23, 25, 34, 44, 55, 57, 58], "As": [5, 6, 7, 29, 53, 55, 58], "re": [5, 6, 53, 55, 56, 57], "care": [5, 19, 32, 55, 57], "like": [5, 6, 7, 8, 55, 56, 57], "end": [5, 7, 23, 51, 53, 56, 57], "number": [5, 7, 11, 12, 15, 17, 18, 20, 24, 27, 32, 33, 38, 48, 57], "just": [5, 53, 56, 57], "save": [5, 7, 8, 32, 33, 44, 51, 55, 57], "less": [5, 15, 55, 56, 58], "prone": 5, "manag": [5, 46], "invari": 5, "accept": [5, 6, 15, 23, 56, 58], "multipl": [5, 6, 7, 29, 41, 42, 43, 44], "sourc": [5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 55], "worri": 5, "explicitli": [5, 28, 53, 57], "convert": [5, 32, 45, 55, 56, 58], "time": [5, 23, 41, 43, 55, 58], "produc": [5, 58], "back": [5, 32, 57, 58], "origin": [5, 11, 12, 26, 29, 55, 57, 58], "form": [5, 6, 7, 11], "One": [5, 55], "advantag": [5, 57], "being": [5, 32, 33, 35, 58], "should": [5, 6, 7, 17, 18, 19, 28, 34, 41, 42, 43, 44, 52, 53, 55, 56, 57, 58], "abl": [5, 7, 55, 56], "fine": [5, 7, 8, 11, 12, 51, 53, 55, 56, 57], "tune": [5, 6, 7, 8, 10, 11, 12, 51, 52, 53, 55, 56, 57, 58], "post": [5, 58], "tool": [5, 55, 56], "quantiz": [5, 17, 29, 51, 58], "eval": [5, 51, 53], "without": [5, 6, 53, 55, 57], "code": [5, 7, 24, 49, 53], "chang": [5, 6, 8, 55, 56, 57, 58], "OR": 5, "convers": [5, 32, 53, 55, 57, 58], "script": [5, 8, 55, 56], "wai": [5, 6, 56], "surround": [5, 7, 53], "load_checkpoint": [5, 7, 32, 33], "save_checkpoint": [5, 7, 8, 32, 33], "method": [5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 26, 28, 30, 34, 53, 55, 57, 58], "convertor": 5, "avail": [5, 7, 34, 35, 53, 55, 57], "here": [5, 6, 8, 21, 22, 55, 56, 57, 58], "three": [5, 7, 56], "hfcheckpoint": 5, "read": [5, 32, 33, 53], "write": [5, 7, 32, 33, 41, 56], "compat": [5, 32, 56], "transform": [5, 7, 17, 24, 25, 27, 57], "framework": [5, 7, 53], "mention": [5, 55, 58], "abov": [5, 26, 55, 57, 58], "assum": [5, 27, 30, 36, 55, 57], "checkpoint_dir": [5, 6, 32, 33, 55, 56], "necessari": [5, 15, 41, 42, 43, 44, 57], "json": [5, 32, 46, 55], "easiest": [5, 56], "sure": [5, 6, 55, 56, 57, 58], "everyth": [5, 7, 34, 53, 56], "follow": [5, 7, 18, 27, 44, 51, 52, 55, 56, 57, 58], "flow": [5, 58], "By": [5, 57, 58], "ignor": [5, 18, 19], "safetensor": 5, "output": [5, 11, 12, 13, 15, 17, 18, 19, 21, 22, 24, 25, 29, 31, 42, 46, 52, 55, 56, 57, 58], "dir": [5, 55, 56], "output_dir": [5, 6, 32, 33, 46, 55, 56, 57, 58], "specifi": [5, 6, 7, 9, 17, 18, 55, 56, 58], "argument": [5, 6, 9, 15, 18, 34, 39, 41, 43, 44, 47, 56, 57], "snippet": 5, "explain": 5, "setup": [5, 6, 7, 24, 47, 55, 57, 58], "_component_": [5, 6, 8, 9, 55, 56, 57], "fullmodelhfcheckpoint": [5, 55], "directori": [5, 6, 32, 33, 41, 43, 44, 55, 56], "sort": [5, 32], "id": [5, 11, 12, 15, 23, 32, 45, 55], "so": [5, 6, 32, 34, 52, 53, 55, 56, 57, 58], "order": [5, 7, 32, 43, 44, 56], "matter": [5, 32, 57], "checkpoint_fil": [5, 6, 8, 32, 33, 55, 56, 57, 58], "restart": 5, "previou": [5, 32, 33], "more": [5, 6, 7, 11, 20, 22, 34, 44, 46, 48, 53, 55, 56, 57, 58], "next": [5, 58], "section": [5, 7, 51, 55, 58], "recipe_checkpoint": [5, 32, 33, 56], "null": [5, 6, 56], "usual": [5, 22, 32, 55, 57], "model_typ": [5, 32, 33, 55, 56], "resume_from_checkpoint": [5, 32, 33, 56], "fals": [5, 6, 11, 12, 13, 14, 15, 17, 18, 23, 29, 32, 33, 46, 55, 56, 57, 58], "requir": [5, 6, 15, 32, 43, 44, 48, 52, 58], "param": [5, 7, 29, 30, 31, 32, 57, 58], "directli": [5, 6, 7, 9, 32, 55, 56, 57, 58], "help": [5, 24, 32, 34, 51, 52, 53, 55, 56, 58], "ensur": [5, 6, 15, 17, 18, 32, 36, 53], "out": [5, 6, 7, 11, 12, 13, 14, 32, 33, 51, 53, 55, 56, 57, 58], "case": [5, 7, 8, 17, 18, 32, 36, 41, 53, 55, 57, 58], "discrep": [5, 32], "along": [5, 57], "detail": [5, 11, 20, 46, 48, 55, 56, 57, 58], "found": [5, 6, 8, 21, 22, 57, 58], "metacheckpoint": 5, "github": [5, 11, 12, 13, 14, 18, 21, 22, 27, 52], "repositori": [5, 55, 56], "fullmodelmetacheckpoint": [5, 56], "torchtunecheckpoint": 5, "perform": [5, 19, 53, 55, 58], "current": [5, 17, 18, 22, 24, 25, 33, 38, 41, 43, 48, 55, 56], "test": [5, 6, 7, 53], "complet": [5, 7, 55, 56], "written": [5, 6, 7, 32, 33, 41, 42, 43, 44, 53], "begin": [5, 23, 58], "partit": [5, 58], "ha": [5, 23, 28, 30, 55, 57, 58], "standard": [5, 42, 53, 55], "key_1": 5, "weight_1": 5, "key_2": 5, "weight_2": 5, "mid": 5, "chekpoint": 5, "middl": [5, 55], "inform": [5, 44, 53, 55, 56], "subsequ": [5, 7], "recipe_st": [5, 32, 33], "pt": [5, 8, 32, 33, 55], "epoch": [5, 7, 8, 27, 32, 33, 55, 56], "optim": [5, 6, 7, 27, 55, 56, 57, 58], "etc": [5, 7, 32], "prevent": 5, "flood": 5, "overwritten": 5, "note": [5, 6, 23, 24, 28, 32, 34, 36, 46, 48, 55, 57, 58], "updat": [5, 6, 7, 55, 56, 57, 58], "hf_model_0001_0": [5, 55], "hf_model_0002_0": [5, 55], "both": [5, 55, 57, 58], "adapt": [5, 28, 29, 30, 31, 32, 33, 55, 57, 58], "merg": [5, 9, 32, 55, 58], "would": [5, 6, 8, 24, 55, 57, 58], "our": [5, 7, 53, 55, 56, 57, 58], "tutori": [5, 53, 55, 56, 57, 58], "primari": [5, 6, 7, 56], "want": [5, 6, 7, 8, 9, 52, 57], "resum": [5, 7, 27, 32, 33, 58], "initi": [5, 7, 10, 16, 23, 39, 56, 57, 58], "frozen": [5, 57, 58], "base": [5, 15, 17, 22, 27, 29, 31, 32, 34, 41, 51, 55, 57, 58], "well": [5, 6, 7, 53, 55, 58], "learnt": [5, 55], "someth": [5, 7, 8, 55], "NOT": 5, "refer": [5, 6, 7, 21, 22, 53, 57], "adapter_checkpoint": [5, 32, 33], "adapter_0": [5, 55], "now": [5, 23, 55, 56, 57, 58], "knowledg": 5, "creat": [5, 6, 9, 11, 12, 13, 14, 16, 20, 27, 32, 33, 41, 43, 55, 58], "simpl": [5, 7, 51, 56, 57, 58], "forward": [5, 7, 18, 19, 21, 22, 24, 25, 29, 57, 58], "13b": 5, "modeltyp": [5, 32, 33], "llama2_13b": 5, "right": [5, 32, 55, 56, 57], "pytorch_fil": 5, "00003": 5, "torchtune_sd": 5, "load_state_dict": [5, 57], "successfulli": 5, "vocab": [5, 9, 24], "70": 5, "x": [5, 18, 19, 21, 22, 24, 25, 29, 57, 58], "randint": 5, "0": [5, 7, 17, 18, 23, 24, 27, 29, 43, 44, 45, 48, 50, 54, 55, 56, 57, 58], "1": [5, 7, 15, 18, 23, 24, 27, 33, 43, 44, 45, 48, 55, 56, 57, 58], "no_grad": 5, "6": [5, 21, 45, 55, 58], "3989": 5, "9": [5, 55, 58], "0531": 5, "3": [5, 34, 37, 45, 55, 58], "2375": 5, "5": [5, 27, 45, 46, 55, 56], "2822": 5, "4": [5, 6, 15, 18, 45, 53, 55, 57, 58], "4872": 5, "7469": 5, "8": [5, 11, 12, 13, 14, 55, 57, 58], "6737": 5, "11": [5, 55, 58], "0023": 5, "8235": 5, "6819": 5, "2424": 5, "0109": 5, "6915": 5, "7": [5, 45], "3618": 5, "1628": 5, "8594": 5, "5857": 5, "1151": 5, "7808": 5, "2322": 5, "8850": 5, "9604": 5, "7624": 5, "6040": 5, "3159": 5, "5849": 5, "8039": 5, "9322": 5, "2010": 5, "6824": 5, "8929": 5, "8465": 5, "3794": 5, "3500": 5, "6145": 5, "5931": 5, "do": [5, 7, 44, 55, 56, 57], "find": [5, 7, 8, 55, 56, 57], "list": [5, 6, 11, 12, 15, 17, 23, 28, 29, 32, 33, 34, 37, 40, 45, 56], "builder": [5, 16, 58], "hope": 5, "deeper": 5, "insight": [5, 55], "happi": [5, 55], "thi": [6, 7, 8, 9, 11, 12, 15, 17, 18, 19, 22, 23, 24, 25, 26, 27, 28, 32, 33, 34, 35, 41, 43, 44, 46, 48, 51, 52, 53, 55, 56, 57, 58], "guid": [6, 8, 56, 57], "yaml": [6, 7, 9, 10, 34, 44, 53, 55, 56, 57, 58], "pars": [6, 9, 34, 56], "effect": 6, "cli": [6, 8, 10, 52, 55, 56], "prerequisit": [6, 55, 56, 57, 58], "Be": [6, 55, 56, 57, 58], "familiar": [6, 55, 56, 57, 58], "torchtun": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 52, 56], "instal": [6, 8, 43, 44, 51, 55, 56, 57, 58], "fundament": 6, "There": [6, 55, 57], "entri": [6, 7, 56], "point": [6, 7, 55, 56, 57, 58], "locat": [6, 57, 58], "thei": [6, 7, 24, 34, 57], "truth": [6, 55], "reproduc": 6, "overridden": [6, 19, 34], "quick": 6, "experiment": 6, "modifi": [6, 7, 8, 26, 53, 55, 57, 58], "serv": [6, 57], "particular": [6, 15, 57, 58], "seed": [6, 7, 8, 48, 56], "shuffl": [6, 56], "devic": [6, 7, 35, 36, 55, 56, 57], "cuda": [6, 35, 36, 55, 56, 58], "dtype": [6, 7, 20, 26, 36, 40, 55, 56, 58], "fp32": [6, 58], "enable_fsdp": 6, "mani": [6, 55], "object": [6, 9, 18], "keyword": [6, 9, 15, 26], "loss": [6, 7, 11, 12, 13, 14, 56, 57, 58], "function": [6, 7, 9, 10, 18, 19, 26, 35, 38, 48, 53, 58], "exampl": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 23, 28, 32, 33, 43, 44, 45, 49, 50, 54, 55, 57, 58], "subfield": 6, "dotpath": 6, "wish": 6, "exact": [6, 9, 55], "path": [6, 7, 8, 9, 23, 32, 33, 34, 46, 55, 56, 57], "normal": [6, 21, 23, 24, 25, 57, 58], "python": [6, 34, 37, 44, 48, 49, 55], "alpaca_dataset": [6, 11, 56], "custom": [6, 7, 53, 55, 56, 57], "train_on_input": [6, 11, 12, 13, 14, 15], "onc": [6, 55, 56, 57, 58], "ve": [6, 20, 55, 57], "instanc": [6, 9, 11, 12, 17, 19, 23, 26, 30, 31, 57], "cfg": [6, 7, 10], "automat": [6, 8, 9, 58], "under": [6, 55, 58], "preced": [6, 9, 57], "actual": [6, 8], "throw": 6, "notic": [6, 57], "miss": [6, 57], "posit": [6, 9, 18, 22, 24, 25], "anoth": [6, 55], "handl": [6, 10, 23, 55, 57, 58], "def": [6, 7, 8, 10, 57, 58], "dictconfig": [6, 7, 9, 10, 44], "arg": [6, 9, 24, 26, 28, 34, 42], "tupl": [6, 9, 15, 23, 26, 34, 38, 45], "kwarg": [6, 9, 26, 28, 34, 39, 41, 42, 43, 44, 47], "str": [6, 9, 23, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 40, 41, 42, 43, 44, 46, 48], "mean": [6, 21, 56, 57], "pass": [6, 9, 16, 17, 18, 19, 26, 36, 39, 43, 44, 47, 57, 58], "add": [6, 8, 34, 55, 57, 58], "d": [6, 18, 24, 25, 57], "llama2_token": [6, 55, 56], "tmp": [6, 55, 56], "option": [6, 7, 16, 17, 18, 22, 23, 24, 25, 26, 32, 33, 35, 36, 37, 41, 44, 46, 47, 48, 52, 53, 55, 56], "bool": [6, 11, 12, 13, 14, 15, 17, 23, 26, 29, 32, 33, 39, 43, 46, 58], "max_seq_len": [6, 9, 11, 12, 15, 17, 18, 20, 22, 23, 24], "int": [6, 8, 11, 12, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 29, 32, 33, 38, 41, 42, 43, 44, 45, 48, 57, 58], "512": [6, 11, 12, 58], "instructdataset": [6, 11, 12, 13, 14], "alreadi": [6, 39, 55, 56, 57], "overwrit": 6, "duplic": [6, 7, 53], "sometim": 6, "than": [6, 15, 18, 55, 56, 57, 58], "resolv": 6, "alpaca": [6, 11, 12, 55, 56, 57, 58], "metric_logg": [6, 7, 8], "metric_log": [6, 8, 41, 42, 43, 44], "disklogg": 6, "log_dir": [6, 41, 43], "conveni": [6, 7], "quickli": 6, "verifi": [6, 35, 36, 56, 57], "properli": 6, "experi": [6, 51, 53, 57], "wa": [6, 55, 57, 58], "7b_full": [6, 55, 56], "batch_siz": [6, 11, 12, 13, 14, 18, 25, 55, 56], "discuss": [6, 57], "guidelin": 6, "while": [6, 7, 19, 53, 55, 56, 58], "mai": [6, 46, 56, 57], "tempt": 6, "put": [6, 7, 56, 57], "much": [6, 55, 57, 58], "give": [6, 57], "maximum": [6, 11, 12, 15, 16, 17, 18, 20, 22, 24], "flexibl": 6, "switch": 6, "encourag": [6, 57], "clariti": 6, "significantli": 6, "easier": [6, 55, 56], "dont": 6, "slimorca_dataset": 6, "privat": 6, "typic": [6, 58], "expos": [6, 7, 56], "parent": 6, "modul": [6, 9, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 47, 48, 57, 58], "__init__": [6, 7, 57, 58], "py": [6, 10, 11, 12, 13, 14, 18, 20, 21, 22, 27, 55], "guarante": 6, "stabil": [6, 53, 58], "underscor": 6, "_alpaca": 6, "collect": [6, 56], "differ": [6, 8, 23, 53, 55, 57, 58], "itself": 6, "via": [6, 8, 29, 57, 58], "pair": [6, 45], "k1": [6, 7], "v1": [6, 7], "k2": [6, 7], "v2": [6, 7], "full_finetun": [6, 8], "gpu": [6, 55, 56, 57, 58], "full_finetune_distribut": [6, 55, 56], "checkpoint": [6, 7, 32, 33, 44, 47, 53, 56, 57, 58], "home": 6, "my_model_checkpoint": 6, "file_1": 6, "file_2": 6, "class": [6, 8, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 30, 31, 32, 33, 34, 41, 42, 43, 44, 56, 57, 58], "assign": 6, "nest": 6, "dot": 6, "notat": [6, 18, 22, 24, 25], "my_config": 6, "core": [7, 53, 56, 58], "i": [7, 26, 31, 55, 58], "structur": [7, 55], "new": [7, 41, 43, 56, 57, 58], "user": [7, 17, 18, 23, 56], "thought": [7, 53, 56, 58], "target": [7, 53], "pipelin": [7, 53, 56], "llm": [7, 51, 53, 55, 57], "eg": [7, 24, 32, 53], "meaning": [7, 53, 55], "featur": [7, 8, 52, 53], "fsdp": [7, 53, 56], "activ": [7, 19, 47, 53, 56, 58], "gradient": [7, 53, 55, 57, 58], "accumul": [7, 53], "mix": [7, 53, 55], "precis": [7, 26, 36, 53, 58], "appli": [7, 17, 18, 21, 22, 24, 25, 53, 58], "given": [7, 9, 29, 35, 36, 53, 57], "famili": [7, 53], "complex": 7, "becom": [7, 52], "harder": 7, "anticip": 7, "architectur": [7, 24], "methodolog": 7, "reason": [7, 55], "possibl": 7, "trade": 7, "off": [7, 23, 55], "memori": [7, 11, 12, 51, 53, 55], "vs": 7, "qualiti": [7, 55, 57], "believ": 7, "best": 7, "suit": [7, 56], "specif": [7, 9, 55, 58], "b": [7, 18, 22, 24, 25, 29, 44, 57, 58], "fit": [7, 11, 12], "solut": 7, "result": [7, 23, 55, 56, 57, 58], "meant": [7, 26], "depend": [7, 8, 55, 57, 58], "level": [7, 37, 53, 58], "expertis": 7, "routin": 7, "yourself": [7, 57], "exist": [7, 56, 58], "ad": [7, 23, 57, 58], "ones": 7, "modular": [7, 53], "build": [7, 53, 57], "block": [7, 17, 53], "wandb": [7, 8, 44, 56], "log": [7, 37, 41, 42, 43, 44, 55, 56, 58], "fulli": 7, "nativ": [7, 51, 53, 57, 58], "pytorch": [7, 15, 24, 26, 43, 46, 48, 51, 52, 53, 56, 57, 58], "correct": [7, 21, 22, 24, 35, 53], "numer": [7, 53], "pariti": [7, 53], "verif": 7, "extens": [7, 53], "comparison": [7, 57, 58], "benchmark": [7, 48, 53, 55, 57], "limit": 7, "hidden": [7, 19], "behind": 7, "100": [7, 11, 12, 13, 14, 15, 45, 46, 57, 58], "flag": [7, 11, 12, 13, 14, 58], "prefer": [7, 53], "over": [7, 27, 34, 53, 55, 57, 58], "unnecessari": 7, "abstract": [7, 53, 58], "No": [7, 53], "inherit": [7, 34, 53], "go": [7, 23, 53, 55, 56, 58], "upon": 7, "figur": [7, 57, 58], "spectrum": 7, "decid": 7, "interact": [7, 51], "start": [7, 8, 52, 53, 55, 56], "paradigm": 7, "consist": [7, 56], "configur": [7, 11, 12, 13, 14, 15, 25, 53, 56, 57, 58], "paramet": [7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 39, 41, 42, 43, 44, 45, 46, 47, 48, 51, 53, 55, 56, 57, 58], "command": [7, 34, 52, 56, 57, 58], "overrid": [7, 10, 55, 56, 58], "togeth": [7, 56, 57], "valid": [7, 52, 55, 56], "environ": [7, 52, 55, 56], "logic": [7, 32, 53, 56, 57], "api": [7, 8, 55, 56, 58], "closer": [7, 57], "monolith": [7, 53], "trainer": [7, 38], "A": [7, 8, 23, 26, 29, 32, 45, 50, 51, 54, 55, 57, 58], "wrapper": [7, 23, 57], "around": [7, 23, 46, 55, 57, 58], "extern": 7, "primarili": [7, 57], "eleutherai": [7, 53, 57], "har": [7, 53, 57], "control": [7, 11, 12, 13, 14, 48, 55], "multi": [7, 18], "stage": 7, "distil": 7, "oper": [7, 46, 48], "turn": 7, "dataload": [7, 11, 12, 13, 14], "applic": [7, 18, 32, 33, 44], "clean": [7, 11], "after": [7, 20, 21, 41, 42, 43, 44, 58], "process": [7, 26, 48, 56, 58], "group": [7, 18, 41, 42, 43, 44], "init_process_group": [7, 39], "backend": 7, "gloo": 7, "els": [7, 34, 53, 58], "nccl": 7, "fullfinetunerecipedistribut": 7, "cleanup": 7, "other": [7, 9, 11, 34, 56, 57], "stuff": 7, "carri": 7, "relev": [7, 55, 57], "interfac": [7, 28], "metric": [7, 56], "logger": [7, 37, 41, 42, 43, 44, 56], "self": [7, 8, 17, 18, 24, 25, 28, 57, 58], "_devic": 7, "get_devic": 7, "_dtype": 7, "get_dtyp": 7, "ckpt_dict": 7, "wrap": [7, 46, 47], "_model": 7, "_setup_model": 7, "_token": 7, "_setup_token": 7, "_optim": 7, "_setup_optim": 7, "_loss_fn": 7, "_setup_loss": 7, "_sampler": 7, "_dataload": 7, "_setup_data": 7, "backward": [7, 58], "zero_grad": 7, "curr_epoch": 7, "rang": [7, 48], "epochs_run": [7, 8], "total_epoch": [7, 8], "idx": 7, "batch": [7, 11, 12, 13, 14, 16, 18, 20, 22, 23, 24, 25, 45, 53, 57], "enumer": 7, "_autocast": 7, "logit": 7, "label": [7, 11, 12, 15, 45], "total_training_step": 7, "_log_every_n_step": 7, "_metric_logg": 7, "log_dict": [7, 41, 42, 43, 44], "step": [7, 24, 27, 41, 42, 43, 44, 46, 51, 55, 57, 58], "learn": [7, 27, 53, 56, 57, 58], "decor": [7, 10], "recipe_main": [7, 10], "none": [7, 8, 17, 18, 22, 23, 24, 25, 31, 32, 33, 35, 36, 37, 41, 42, 43, 44, 47, 48, 55], "fullfinetunerecip": 7, "direct": 7, "wandblogg": [8, 57, 58], "workspac": 8, "seen": [8, 57, 58], "screenshot": 8, "below": [8, 22, 57, 58], "packag": [8, 43, 44, 52], "pip": [8, 43, 44, 52], "Then": [8, 56], "login": [8, 44], "built": [8, 58], "project": [8, 17, 18, 19, 44, 51, 57, 58], "grab": 8, "tab": [8, 11, 12], "click": 8, "sampl": [8, 15, 55], "desir": 8, "suggest": 8, "approach": 8, "joinpath": 8, "_checkpoint": [8, 55], "_output_dir": [8, 32, 33], "torchtune_model_": 8, "with_suffix": 8, "wandb_at": 8, "artifact": 8, "type": [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 29, 30, 32, 33, 36, 37, 38, 39, 46, 55, 57, 58], "descript": [8, 13], "whatev": 8, "metadata": 8, "seed_kei": 8, "epochs_kei": 8, "total_epochs_kei": 8, "max_steps_kei": 8, "max_steps_per_epoch": 8, "add_fil": 8, "log_artifact": 8, "field": [9, 11, 12, 13, 14], "num_lay": [9, 17, 24], "32": [9, 57, 58], "num_head": [9, 17, 18, 20, 22, 24], "num_kv_head": [9, 17, 18, 20], "vocab_s": [9, 17, 23], "must": [9, 11, 12, 13, 14, 15, 28, 34, 58], "return": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 39, 40, 45, 46, 48, 57, 58], "nn": [9, 18, 19, 20, 24, 25, 26, 28, 30, 31, 47, 56, 57, 58], "parsed_yaml": 9, "embed_dim": [9, 17, 18, 22, 25, 57], "omegaconf": 9, "valueerror": [9, 15, 18, 24, 32, 33, 36, 48], "callabl": [10, 24], "main": [10, 11, 12, 13, 14, 18, 21, 22], "my_recip": 10, "With": [10, 55, 57, 58], "foo": 10, "bar": [10, 53], "http": [11, 12, 13, 14, 15, 16, 18, 21, 22, 27, 32, 33, 34, 37, 43, 44, 46, 48, 52], "huggingfac": [11, 12, 13, 14, 15, 27, 32, 33], "co": [11, 12, 13, 14, 15, 32, 33], "yahma": 11, "data": [11, 12, 13, 14, 15, 41, 42, 43, 44, 55, 58], "tatsu": [11, 12], "lab": [11, 12], "prompt": [11, 12, 13, 14, 15, 23, 24, 55], "templat": [11, 12, 13, 14, 15], "codebas": [11, 12, 13, 14, 55], "com": [11, 12, 13, 14, 18, 21, 22, 27, 52], "stanford_alpaca": [11, 12], "blob": [11, 12, 13, 14, 18, 21, 22, 27], "761dc5bfbdeeffa89b8bff5d038781a4055f796a": [11, 12], "l31": [11, 12], "where": [11, 12, 13, 14, 18, 23, 24, 29], "instruct": [11, 12, 51, 56, 57, 58], "mask": [11, 12, 13, 14, 18, 23, 25], "ref": [11, 12, 44], "tloen": [11, 12], "lora": [11, 12, 17, 29, 51, 53], "l49": [11, 12], "contribut": [11, 12, 13, 14], "replac": [11, 12, 13, 14, 26, 57], "version": [11, 17, 18, 52, 58], "remov": 11, "hallucin": 11, "poorli": 11, "wrong": 11, "answer": [11, 55], "card": 11, "encod": [11, 12, 13, 14, 15, 23], "decod": [11, 12, 13, 14, 15, 17, 23, 24], "whether": [11, 12, 13, 14, 15, 17, 23, 26, 29, 36], "stanford": [11, 12], "readm": [11, 12], "ov": [11, 12], "recommend": [11, 12, 43, 55, 58], "highest": [11, 12], "sequenc": [11, 12, 15, 17, 18, 20, 22, 23, 24, 25, 45], "length": [11, 12, 15, 17, 18, 20, 22, 23, 24, 25, 33, 45], "alpaca_d": [11, 12], "grammar": 13, "its": [13, 14, 17, 48, 55, 57], "variant": [13, 14], "liweili": 13, "c4_200m": 13, "llama_recip": [13, 14], "src": [13, 14, 27], "l50": 13, "grammar_d": 13, "summar": 14, "samsum": 14, "l13": 14, "dialogu": 14, "summari": 14, "samsum_d": 14, "1024": 15, "chatdataset": 15, "represent": [15, 57, 58], "slimorca": 15, "open": [15, 55], "orca": 15, "dedup": 15, "adher": 15, "chat": 15, "doesn": [15, 55], "prescrib": 15, "truncat": [15, 23], "least": [15, 57], "though": 15, "max": [15, 23, 24, 27, 57], "ds": 15, "10": [15, 45, 55, 58], "351": 15, "82": [15, 55], "391": 15, "221": 15, "220": 15, "193": 15, "12": 15, "471": 15, "transformerdecod": [16, 17, 57], "w": [16, 43, 44, 55, 57, 58], "arxiv": [16, 18, 21, 22], "org": [16, 18, 21, 22, 34, 37, 43, 46, 48], "ab": [16, 22], "2307": 16, "09288": 16, "max_batch_s": [16, 20], "kvcach": [16, 17, 18, 24], "instanti": [16, 17], "lora_attn_modul": [17, 57, 58], "liter": 17, "q_proj": [17, 18, 57, 58], "k_proj": [17, 18, 57, 58], "v_proj": [17, 18, 57, 58], "output_proj": [17, 18, 57, 58], "apply_lora_to_mlp": [17, 57], "apply_lora_to_output": [17, 57], "intermediate_dim": 17, "attn_dropout": [17, 18, 24], "float": [17, 18, 21, 27, 29, 41, 42, 43, 44, 57, 58], "norm_ep": 17, "1e": [17, 21, 56], "05": 17, "lora_rank": [17, 57], "lora_alpha": [17, 57], "lora_dropout": 17, "quantize_bas": [17, 29, 58], "linear": [17, 24, 28, 29, 57, 58], "attent": [17, 18, 20, 22, 24, 25, 57, 58], "mlp": [17, 24, 25, 57], "final": [17, 19, 24, 55, 57, 58], "vocabulari": [17, 23], "queri": [17, 18, 20, 24], "head": [17, 18, 20, 22, 24], "mha": [17, 18, 24], "dimens": [17, 18, 20, 22, 24, 29, 57, 58], "dropout": [17, 18, 29, 57, 58], "onto": [17, 18], "scaled_dot_product_attent": [17, 18], "intermedi": [17, 58], "comput": [17, 18, 19, 22, 24, 48, 55, 58], "scale_hidden_dim_for_mlp": 17, "epsilon": 17, "rm": 17, "norm": [17, 24, 25], "rank": [17, 29, 38, 48, 56, 57, 58], "low": [17, 29, 55, 57, 58], "approxim": [17, 29, 57], "scale": [17, 29, 57, 58], "factor": [17, 29, 55], "probabl": [17, 29, 55], "subset": [17, 30], "head_dim": [18, 20, 22, 24], "pos_embed": [18, 57], "kv_cach": 18, "gqa": 18, "introduc": [18, 21, 29, 57, 58], "pdf": [18, 21], "2305": 18, "13245v1": 18, "multihead": 18, "n": [18, 23, 50, 54], "extrem": 18, "share": 18, "mqa": 18, "credit": 18, "document": 18, "lightn": 18, "ai": [18, 44], "lit": 18, "gpt": [18, 55], "lit_gpt": 18, "v": [18, 24, 57], "k": [18, 57], "q": [18, 57], "n_kv_head": 18, "calcul": 18, "e": [18, 26, 28, 31, 52, 55, 57, 58], "g": [18, 28, 57, 58], "rotarypositionalembed": [18, 57], "cach": [18, 20, 22], "rope": [18, 22], "input_po": [18, 22, 24, 25], "seq_length": [18, 25], "seq_len": [18, 22], "bigger": 18, "n_h": [18, 22], "num": [18, 22], "n_kv": 18, "kv": [18, 20, 24], "emb": [18, 24, 25], "h_d": [18, 22], "gate_proj": 19, "down_proj": 19, "up_proj": 19, "silu": 19, "feed": [19, 25], "network": [19, 57, 58], "deriv": [19, 24, 25], "fed": 19, "multipli": 19, "subclass": [19, 34], "although": [19, 57], "afterward": 19, "former": 19, "regist": [19, 26, 58], "hook": [19, 26, 58], "latter": 19, "standalon": 20, "past": 20, "becaus": [20, 24, 55], "expand": 20, "per": [20, 26, 58], "dpython": [20, 26], "ep": 21, "06": [21, 57], "root": [21, 43], "squar": 21, "1910": 21, "07467": 21, "verfic": [21, 22], "facebookresearch": [21, 22], "small": [21, 55], "avoid": [21, 48, 58], "divis": 21, "zero": [21, 55], "10000": 22, "rotari": 22, "propos": 22, "2104": 22, "09864": 22, "l450": 22, "upto": 22, "init": [22, 44, 58], "exceed": 22, "freq": 22, "recomput": 22, "geometr": 22, "progress": 22, "rotat": 22, "angl": 22, "bsz": 22, "todo": 22, "made": [22, 55], "effici": [22, 51, 53, 55, 57], "spm_model": 23, "sentencepieceprocessor": 23, "bos_id": 23, "eos_id": 23, "pad_id": 23, "sentencepiec": 23, "sentenc": 23, "pad": [23, 45], "non": 23, "from_fil": 23, "tokenized_text": 23, "hello": [23, 55], "world": [23, 38], "add_bo": 23, "add_eo": 23, "31587": 23, "29644": 23, "102": 23, "text": [23, 55], "trim_leading_whitespac": 23, "prefix": 23, "unbatch": 23, "prepend": 23, "bo": 23, "append": 23, "eo": 23, "trim": 23, "lead": 23, "whitespac": 23, "underli": [23, 58], "s1": 23, "s2": 23, "due": [23, 57, 58], "classmethod": 23, "tokenize_messag": 23, "messag": [23, 52], "concaten": 23, "problem": 23, "known": 23, "slice": 23, "tokenizer_path": 23, "role": 23, "system": 23, "assist": 23, "respons": [23, 55, 56], "separ": [23, 32, 57, 58], "concat": 23, "1788": 23, "2643": 23, "13": [23, 55, 58], "1792": 23, "9508": 23, "465": 23, "22137": 23, "2933": 23, "join": 23, "attribut": 23, "transformerdecoderlay": 24, "move": 24, "space": 24, "check": [24, 36, 51, 56, 57], "belong": 24, "reduc": [24, 57, 58], "statement": 24, "improv": [24, 55, 57], "readabl": [24, 55], "At": 24, "arang": 24, "prompt_length": 24, "causal_mask": 24, "m_": 24, "seq": 24, "attn": [25, 57, 58], "causalselfattent": [25, 57], "sa_norm": 25, "mlp_norm": 25, "ff": 25, "common_util": 26, "bfloat16": [26, 55, 57], "offload_to_cpu": 26, "nf4": [26, 58], "restor": 26, "higher": [26, 58], "offload": [26, 58], "_register_state_dict_hook": 26, "m": 26, "mymodul": 26, "_after_": 26, "nf4tensor": [26, 58], "unquant": [26, 55, 58], "unus": 26, "num_warmup_step": 27, "num_training_step": 27, "num_cycl": 27, "last_epoch": 27, "lambdalr": 27, "rate": [27, 53, 56], "schedul": [27, 46], "linearli": 27, "increas": [27, 57], "lr": [27, 56], "decreas": [27, 57, 58], "cosin": 27, "remain": [27, 57], "v4": 27, "23": 27, "l104": 27, "warmup": [27, 46], "phase": 27, "total": [27, 38, 50, 54, 55, 57], "wave": 27, "half": 27, "index": [27, 45, 55], "last": 27, "lr_schedul": 27, "appropri": [27, 58], "peft": [28, 29, 30, 31, 57, 58], "protocol": 28, "adapter_param": [28, 29, 30, 31], "correspond": [28, 30, 36], "come": [28, 57], "proj": 28, "in_dim": [28, 29, 57, 58], "out_dim": [28, 29, 57, 58], "bia": [28, 29, 57, 58], "loralinear": [28, 57, 58], "alpha": [29, 57, 58], "use_bia": 29, "larg": [29, 58], "languag": [29, 57], "perturb": 29, "decomposit": [29, 57], "matric": [29, 57, 58], "trainabl": [29, 31, 57, 58], "mapsto": 29, "w_0x": 29, "r": [29, 57], "bax": 29, "lora_a": [29, 57, 58], "lora_b": [29, 57, 58], "map": [31, 32, 41, 42, 43, 44, 55, 57], "respect": 31, "get_adapter_param": [31, 57], "few": [32, 57, 58], "0001_of_0003": 32, "0002_of_0003": 32, "preserv": [32, 58], "weight_map": [32, 55], "intermediate_checkpoint": [32, 33], "parit": 32, "_weight_map": 32, "shard": 33, "wip": 33, "tunerecipeargpars": 34, "argpars": 34, "argumentpars": 34, "builtin": 34, "noth": 34, "treat": 34, "still": [34, 57, 58], "consult": 34, "doc": [34, 37, 43, 44, 46, 48], "info": 34, "librari": [34, 37, 48, 51, 53, 58], "html": [34, 37, 43, 46, 48], "parse_known_arg": 34, "namespac": 34, "act": 34, "alwai": 34, "precid": 34, "parse_arg": 34, "intern": 34, "properti": [34, 57], "too": 34, "availab": 35, "machin": [35, 55], "distribut": [35, 39, 47, 48, 53, 56], "bf16": [36, 56, 58], "request": [36, 55], "inde": [36, 55], "kernel": 36, "float32": 36, "done": [36, 57, 58], "isn": 36, "stream": 37, "handler": 37, "aka": 38, "runtimeerror": 39, "filenam": 41, "log_": 41, "unixtimestamp": 41, "txt": [41, 56], "thread": 41, "safe": 41, "resourc": [41, 42, 43, 44], "flush": [41, 42, 43, 44], "union": [41, 42, 43, 44, 48], "ndarrai": [41, 42, 43, 44], "scalar": [41, 42, 43, 44], "tag": [41, 42, 43, 44], "record": [41, 42, 43, 44], "payload": [41, 42, 43, 44], "dictionari": [41, 42, 43, 44, 55], "organize_log": 43, "tensorboard": 43, "stabl": [43, 46, 48, 52], "subdirectori": 43, "sub": 43, "compar": [43, 55, 57, 58], "logdir": 43, "startup": 43, "recurs": 43, "tree": [43, 55], "tfevent": 43, "encount": 43, "frontend": 43, "organ": 43, "accordingli": 43, "my_log_dir": 43, "view": [43, 55], "my_metr": [43, 44], "termin": [43, 44], "entiti": 44, "bias": 44, "my_project": 44, "my_ent": 44, "my_group": 44, "importerror": 44, "account": [44, 57, 58], "log_config": 44, "local": [44, 48, 52, 55, 56], "link": 44, "capecap": 44, "6053ofw0": 44, "torchtune_config_j67sb73v": 44, "padding_idx": 45, "ignore_idx": 45, "longest": 45, "integ": [45, 48], "tokenpair": 45, "collat": 45, "token_pair": 45, "torchtune_perf_trac": 46, "contextmanag": 46, "wait": 46, "trace": 46, "speed": [46, 58], "reduct": [46, 57], "context": 46, "auto_wrap_polici": 47, "polici": 47, "debug_mod": 48, "pseudo": 48, "random": [48, 56], "commonli": [48, 55, 57, 58], "numpi": 48, "own": [48, 55, 57], "determinist": 48, "global": 48, "warn": 48, "nondeterminist": 48, "addition": [48, 57], "cudnn": 48, "disabl": 48, "set_deterministic_debug_mod": 48, "algorithm": 48, "outsid": [48, 55, 57], "generated_examples_python": 49, "zip": 49, "galleri": [49, 54], "sphinx": 49, "000": [50, 54], "execut": [50, 54], "generated_exampl": 50, "mem": [50, 54], "mb": [50, 54], "topic": 51, "gentl": 51, "introduct": 51, "workflow": [51, 56, 57], "readi": 51, "qlora": [51, 53, 57], "maxim": [51, 53], "pre": 52, "requisit": 52, "proper": [52, 56], "host": [52, 56], "page": [52, 53, 56], "latest": [52, 56, 58], "confirm": 52, "And": [52, 55], "usag": [52, 55, 58], "h": 52, "ls": [52, 55], "cp": [52, 55, 56], "welcom": 52, "show": [52, 57], "exit": 52, "greatest": [52, 56], "contributor": 52, "cd": [52, 55], "On": [53, 57], "pointer": 53, "author": [53, 56], "emphas": 53, "aspect": 53, "simplic": 53, "component": 53, "reus": 53, "high": [53, 57], "prove": 53, "democrat": 53, "box": [53, 58], "hardwar": [53, 55, 57], "zoo": 53, "varieti": [53, 57], "techniqu": [53, 55, 57], "integr": [53, 55, 56, 57, 58], "excit": 53, "checkout": 53, "attain": 53, "better": [53, 55], "chekckpoint": 53, "hyperparamet": [53, 56, 57, 58], "embodi": 53, "philosophi": 53, "especi": [53, 55], "usabl": 53, "eluetherai": 53, "composit": 53, "hard": 53, "outlin": 53, "unecessari": 53, "never": 53, "thoroughli": 53, "unit": 53, "favorit": [55, 57], "commun": 55, "seemlessli": 55, "beyond": [55, 58], "connect": 55, "larger": 55, "might": 55, "amount": 55, "natur": 55, "task": [55, 57, 58], "export": 55, "mobil": 55, "phone": 55, "leverag": [55, 58], "mode": 55, "lot": 55, "plai": 55, "freez": [55, 57], "percentag": 55, "learnabl": 55, "keep": [55, 57], "16gb": [55, 57], "rtx": 55, "3090": 55, "4090": 55, "peak": [55, 57, 58], "hour": 55, "full_finetune_single_devic": 55, "7b_full_single_devic": 55, "7b_full_single_device_low_memori": 55, "mistral": 55, "13b_full": 55, "lora_finetune_single_devic": [55, 57, 58], "7b_lora_single_devic": [55, 57, 58], "7b_qlora_single_devic": [55, 58], "7b_lora": [55, 57], "473": 55, "98": [55, 58], "gb": [55, 57, 58], "50": 55, "484": 55, "01": 55, "similar": [55, 57, 58], "fact": [55, 57], "ident": 55, "third": 55, "smaller": [55, 57, 58], "But": [55, 57], "realli": 55, "eleuther_ev": 55, "eleuther_evalu": 55, "plan": 55, "copi": [55, 56, 58], "element": 55, "custom_eval_config": 55, "truthfulqa_mc2": [55, 57], "qa": 55, "measur": 55, "propens": 55, "question": 55, "shot": 55, "accuraci": [55, 57, 58], "baselin": [55, 57], "324": 55, "loglikelihood": 55, "195": 55, "121": 55, "27": 55, "second": [55, 57, 58], "197": 55, "acc": 55, "388": 55, "38": 55, "shown": 55, "489": 55, "48": [55, 58], "great": 55, "seem": [55, 56], "custom_generation_config": 55, "kick": 55, "top_k": 55, "300": 55, "temperatur": 55, "interest": 55, "site": 55, "visit": 55, "bai": 55, "area": 55, "92": 55, "exploratorium": 55, "san": 55, "francisco": 55, "magazin": 55, "awesom": 55, "bridg": 55, "pretti": 55, "cool": 55, "96": [55, 58], "61": 55, "sec": 55, "25": 55, "83": 55, "99": [55, 57], "15": [55, 57, 58], "72": 55, "know": [55, 57], "littl": 55, "saw": 55, "took": 55, "torchao": [55, 58], "bit": [55, 57, 58], "custom_quantization_config": 55, "68": 55, "19": [55, 58], "76": 55, "69": 55, "95": 55, "67": 55, "4w": 55, "unlik": 55, "won": 55, "engin": 55, "fullmodeltorchtunecheckpoint": 55, "int4weightonlyquant": 55, "groupsiz": 55, "256": 55, "did": [55, 58], "park": 55, "sit": 55, "top": [55, 58], "hill": 55, "beauti": 55, "62": 55, "17": [55, 57], "85": 55, "compil": [55, 58], "hood": [55, 58], "sped": 55, "almost": [55, 57], "3x": 55, "benefit": 55, "yet": 55, "fast": 55, "clone": [55, 57, 58], "assumpt": 55, "satisfi": 55, "new_dir": 55, "output_dict": 55, "sd_1": 55, "sd_2": 55, "dump": 55, "convert_hf_checkpoint": 55, "checkpoint_path": 55, "my": 55, "justin": 55, "am": 55, "school": 55, "math": 55, "teacher": 55, "ws": 55, "94": 55, "103": 55, "28": 55, "bandwidth": 55, "achiev": [55, 57, 58], "1391": 55, "84": 55, "thats": 55, "hopefulli": 55, "gave": 55, "launch": 56, "gate": 56, "grant": 56, "minut": 56, "agreement": 56, "signup": 56, "authent": 56, "dataclass": 56, "hold": 56, "It": [56, 58], "alpaca_llama_full_finetun": 56, "good": [56, 57], "place": 56, "custom_config": 56, "replic": 56, "lower": [56, 57], "sooner": 56, "42": 56, "llama2_7b": [56, 57], "sgd": 56, "crossentropyloss": 56, "enable_activation_checkpoint": 56, "torchrun": 56, "therefor": [56, 58], "nnode": [56, 57], "nproc_per_nod": [56, 57], "immedi": 56, "down": [56, 57, 58], "indic": 56, "succesfulli": 56, "log_1707246452": 56, "manual": [56, 58], "sampler": 56, "7553404569625854": 56, "13000": 56, "03": 56, "e2": 56, "teach": 57, "straight": 57, "jump": 57, "neural": [57, 58], "unfamiliar": 57, "oppos": [57, 58], "substanti": 57, "momentum": 57, "adamw": 57, "further": [57, 58], "arbitrari": 57, "could": 57, "min": 57, "relat": 57, "paper": [57, 58], "aghajanyan": 57, "et": 57, "al": 57, "hypothes": 57, "intrins": 57, "often": 57, "four": 57, "eight": 57, "practic": 57, "imag": 57, "simplifi": 57, "left": 57, "blue": 57, "extra": [57, 58], "rememb": 57, "approx": 57, "15m": 57, "8192": 57, "65k": 57, "minim": [57, 58], "pretrain": [57, 58], "p": [57, 58], "requires_grad": [57, 58], "frozen_out": [57, 58], "lora_out": [57, 58], "omit": 57, "construct": 57, "lora_llama2_7b": 57, "base_model": 57, "choos": 57, "lora_model": 57, "lora_llama_2_7b": [57, 58], "alon": 57, "in_featur": 57, "out_featur": 57, "inplac": 57, "feel": 57, "free": 57, "why": 57, "strict": 57, "whenev": 57, "validate_state_dict_for_lora": 57, "peft_util": 57, "set_trainable_param": 57, "fetch": 57, "lora_param": 57, "total_param": 57, "sum": 57, "numel": 57, "trainable_param": 57, "2f": 57, "6742609920": 57, "4194304": 57, "taken": [57, 58], "vram": 57, "lora_finetune_distribut": 57, "my_model_checkpoint_path": [57, 58], "tokenizer_checkpoint": [57, 58], "my_tokenizer_checkpoint_path": [57, 58], "constraint": 57, "coupl": [57, 58], "factori": 57, "16": [57, 58], "benefici": 57, "long": 57, "impact": 57, "rel": 57, "minor": 57, "64": 57, "lora_experiment_1": 57, "smooth": [57, 58], "curv": [57, 58], "500": 57, "ran": 57, "footprint": 57, "commod": 57, "cogniz": 57, "ax": 57, "parallel": 57, "truthfulqa": 57, "previous": 57, "57": [57, 58], "475": 57, "87": 57, "508": 57, "128": 57, "86": 57, "504": 57, "04": 57, "514": 57, "lowest": 57, "absolut": 57, "4gb": 57, "tradeoff": 57, "even": [57, 58], "potenti": 57, "enhanc": 58, "maintain": 58, "therebi": 58, "highli": 58, "develop": 58, "part": 58, "vanilla": 58, "style": 58, "held": 58, "bespok": 58, "normalfloat": 58, "8x": 58, "retain": 58, "vast": 58, "major": 58, "highlight": 58, "degrad": 58, "normatfloat": 58, "doubl": 58, "themselv": 58, "prune": 58, "deepdiv": 58, "idea": 58, "distinct": 58, "storag": 58, "datatyp": 58, "de": 58, "incur": 58, "consum": 58, "counterpart": 58, "set_default_devic": 58, "qlora_linear": 58, "memory_alloc": 58, "177": 58, "152": 58, "byte": 58, "del": 58, "empty_cach": 58, "lora_linear": 58, "081": 58, "344": 58, "qlora_llama2_7b": 58, "qlora_model": 58, "essenti": 58, "reparametrize_as_dtype_state_dict_post_hook": 58, "entir": 58, "stat": 58, "iter": 58, "alloc": 58, "reserv": 58, "against": 58, "35": 58, "40": 58, "29": 58, "quit": 58, "slow": 58, "slower": 58, "149": 58, "9157477021217346": 58, "25880": 58, "02": 58, "08": 58, "14": 58, "15it": 58, "thing": 58, "nightli": 58, "200": 58, "hundr": 58, "228": 58, "8158286809921265": 58, "59": 58, "95it": 58, "exercis": 58, "portion": 58, "augment": 58, "linear_nf4": 58, "to_nf4": 58, "linear_weight": 58, "autograd": 58, "regular": 58, "incom": 58, "variabl": 58}, "objects": {"torchtune.config": [[9, 0, 1, "", "instantiate"], [10, 0, 1, "", "parse"]], "torchtune.datasets": [[11, 0, 1, "", "alpaca_cleaned_dataset"], [12, 0, 1, "", "alpaca_dataset"], [13, 0, 1, "", "grammar_dataset"], [14, 0, 1, "", "samsum_dataset"], [15, 0, 1, "", "slimorca_dataset"]], "torchtune.models.llama2": [[16, 0, 1, "", "llama2_7b"], [17, 0, 1, "", "lora_llama2"]], "torchtune.modules": [[18, 1, 1, "", "CausalSelfAttention"], [19, 1, 1, "", "FeedForward"], [20, 1, 1, "", "KVCache"], [21, 1, 1, "", "RMSNorm"], [22, 1, 1, "", "RotaryPositionalEmbeddings"], [23, 1, 1, "", "Tokenizer"], [24, 1, 1, "", "TransformerDecoder"], [25, 1, 1, "", "TransformerDecoderLayer"], [27, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[18, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[19, 2, 1, "", "forward"]], "torchtune.modules.RMSNorm": [[21, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[22, 2, 1, "", "forward"]], "torchtune.modules.Tokenizer": [[23, 2, 1, "", "decode"], [23, 2, 1, "", "encode"], [23, 2, 1, "", "from_file"], [23, 2, 1, "", "tokenize_messages"]], "torchtune.modules.TransformerDecoder": [[24, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoderLayer": [[25, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[26, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[28, 1, 1, "", "AdapterModule"], [29, 1, 1, "", "LoRALinear"], [30, 0, 1, "", "get_adapter_params"], [31, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[28, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[29, 2, 1, "", "adapter_params"], [29, 2, 1, "", "forward"]], "torchtune.utils": [[32, 1, 1, "", "FullModelHFCheckpointer"], [33, 1, 1, "", "FullModelMetaCheckpointer"], [34, 1, 1, "", "TuneRecipeArgumentParser"], [35, 0, 1, "", "get_device"], [36, 0, 1, "", "get_dtype"], [37, 0, 1, "", "get_logger"], [38, 0, 1, "", "get_world_size_and_rank"], [39, 0, 1, "", "init_distributed"], [40, 0, 1, "", "list_dtypes"], [45, 0, 1, "", "padded_collate"], [46, 0, 1, "", "profiler"], [47, 0, 1, "", "set_activation_checkpointing"], [48, 0, 1, "", "set_seed"]], "torchtune.utils.FullModelHFCheckpointer": [[32, 2, 1, "", "load_checkpoint"], [32, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[33, 2, 1, "", "load_checkpoint"], [33, 2, 1, "", "save_checkpoint"]], "torchtune.utils.TuneRecipeArgumentParser": [[34, 2, 1, "", "parse_known_args"]], "torchtune.utils.metric_logging": [[41, 1, 1, "", "DiskLogger"], [42, 1, 1, "", "StdoutLogger"], [43, 1, 1, "", "TensorBoardLogger"], [44, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[41, 2, 1, "", "close"], [41, 2, 1, "", "log"], [41, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[42, 2, 1, "", "close"], [42, 2, 1, "", "log"], [42, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[43, 2, 1, "", "close"], [43, 2, 1, "", "log"], [43, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[44, 2, 1, "", "close"], [44, 2, 1, "", "log"], [44, 2, 1, "", "log_config"], [44, 2, 1, "", "log_dict"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 51, 53, 55, 57, 58], "config": [0, 6, 7, 56], "dataset": 1, "model": [2, 3, 8, 55, 56, 57], "llama2": [2, 55, 57, 58], "modul": 3, "compon": [3, 6], "build": [3, 58], "block": 3, "peft": 3, "util": [3, 4], "checkpoint": [4, 5, 8, 55], "distribut": 4, "reduc": 4, "precis": 4, "memori": [4, 57, 58], "manag": 4, "perform": [4, 57], "profil": [4, 46], "metric": [4, 8], "log": [4, 8], "data": 4, "miscellan": 4, "overview": [5, 53, 55], "format": 5, "handl": 5, "differ": 5, "intermedi": 5, "vs": 5, "final": 5, "lora": [5, 55, 57, 58], "put": [5, 58], "thi": 5, "all": [5, 6, 58], "togeth": [5, 58], "about": 6, "where": 6, "do": 6, "paramet": 6, "live": 6, "write": 6, "configur": 6, "us": [6, 7, 55, 58], "instanti": [6, 9], "referenc": 6, "other": [6, 55], "field": 6, "interpol": 6, "valid": 6, "your": [6, 7, 56], "best": 6, "practic": 6, "airtight": 6, "public": 6, "api": 6, "onli": 6, "command": 6, "line": 6, "overrid": 6, "what": [7, 53, 57, 58], "ar": 7, "recip": [7, 56, 57], "script": 7, "class": 7, "run": [7, 55], "cli": 7, "pars": [7, 10], "weight": 8, "bias": 8, "logger": 8, "w": 8, "b": 8, "alpaca_cleaned_dataset": 11, "alpaca_dataset": 12, "grammar_dataset": 13, "samsum_dataset": 14, "slimorca_dataset": 15, "llama2_7b": 16, "lora_llama2": 17, "causalselfattent": 18, "todo": [18, 25], "feedforward": 19, "kvcach": 20, "rmsnorm": 21, "rotarypositionalembed": 22, "token": 23, "transformerdecod": 24, "transformerdecoderlay": 25, "reparametrize_as_dtype_state_dict_post_hook": 26, "get_cosine_schedule_with_warmup": 27, "adaptermodul": 28, "loralinear": 29, "get_adapter_param": 30, "set_trainable_param": 31, "fullmodelhfcheckpoint": 32, "fullmodelmetacheckpoint": 33, "tunerecipeargumentpars": 34, "get_devic": 35, "get_dtyp": 36, "get_logg": 37, "get_world_size_and_rank": 38, "init_distribut": 39, "list_dtyp": 40, "disklogg": 41, "stdoutlogg": 42, "tensorboardlogg": 43, "wandblogg": 44, "padded_col": 45, "set_activation_checkpoint": 47, "set_se": 48, "comput": [50, 54], "time": [50, 54], "welcom": 51, "document": 51, "get": 51, "start": 51, "tutori": 51, "instal": 52, "instruct": 52, "via": 52, "pypi": 52, "git": 52, "clone": 52, "kei": 53, "concept": 53, "design": 53, "principl": 53, "end": 55, "workflow": 55, "download": [55, 56], "7b": 55, "finetun": [55, 56, 57, 58], "evalu": 55, "eleutherai": 55, "s": 55, "eval": 55, "har": 55, "gener": 55, "speed": 55, "up": 55, "quantiz": 55, "librari": 55, "first": 56, "llm": 56, "select": 56, "modifi": 56, "train": 56, "next": 56, "step": 56, "how": 57, "doe": 57, "work": 57, "appli": 57, "trade": 57, "off": 57, "qlora": 58, "save": 58, "deep": 58, "dive": 58, "from": 58}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})