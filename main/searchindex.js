Search.setIndex({"docnames": ["api_ref_config", "api_ref_data", "api_ref_datasets", "api_ref_models", "api_ref_modules", "api_ref_utilities", "deep_dives/checkpointer", "deep_dives/configs", "deep_dives/recipe_deepdive", "deep_dives/wandb_logging", "generated/torchtune.config.instantiate", "generated/torchtune.config.parse", "generated/torchtune.config.validate", "generated/torchtune.data.AlpacaInstructTemplate", "generated/torchtune.data.ChatFormat", "generated/torchtune.data.ChatMLFormat", "generated/torchtune.data.GrammarErrorCorrectionTemplate", "generated/torchtune.data.InstructTemplate", "generated/torchtune.data.Llama2ChatFormat", "generated/torchtune.data.Message", "generated/torchtune.data.MistralChatFormat", "generated/torchtune.data.SummarizeTemplate", "generated/torchtune.data.sharegpt_to_llama2_messages", "generated/torchtune.data.validate_messages", "generated/torchtune.datasets.ChatDataset", "generated/torchtune.datasets.ConcatDataset", "generated/torchtune.datasets.InstructDataset", "generated/torchtune.datasets.PackedDataset", "generated/torchtune.datasets.TextCompletionDataset", "generated/torchtune.datasets.alpaca_cleaned_dataset", "generated/torchtune.datasets.alpaca_dataset", "generated/torchtune.datasets.chat_dataset", "generated/torchtune.datasets.cnn_dailymail_articles_dataset", "generated/torchtune.datasets.grammar_dataset", "generated/torchtune.datasets.instruct_dataset", "generated/torchtune.datasets.samsum_dataset", "generated/torchtune.datasets.slimorca_dataset", "generated/torchtune.datasets.text_completion_dataset", "generated/torchtune.datasets.wikitext_dataset", "generated/torchtune.models.gemma.gemma_2b", "generated/torchtune.models.llama2.llama2_13b", "generated/torchtune.models.llama2.llama2_70b", "generated/torchtune.models.llama2.llama2_7b", "generated/torchtune.models.llama2.lora_llama2_13b", "generated/torchtune.models.llama2.lora_llama2_70b", "generated/torchtune.models.llama2.lora_llama2_7b", "generated/torchtune.models.llama2.qlora_llama2_13b", "generated/torchtune.models.llama2.qlora_llama2_7b", "generated/torchtune.models.llama3.llama3_70b", "generated/torchtune.models.llama3.llama3_8b", "generated/torchtune.models.llama3.lora_llama3_70b", "generated/torchtune.models.llama3.lora_llama3_8b", "generated/torchtune.models.llama3.qlora_llama3_8b", "generated/torchtune.models.mistral.lora_mistral_7b", "generated/torchtune.models.mistral.mistral_7b", "generated/torchtune.models.mistral.qlora_mistral_7b", "generated/torchtune.models.phi3.lora_phi3_mini", "generated/torchtune.models.phi3.phi3_mini", "generated/torchtune.models.phi3.qlora_phi3_mini", "generated/torchtune.modules.CausalSelfAttention", "generated/torchtune.modules.FeedForward", "generated/torchtune.modules.KVCache", "generated/torchtune.modules.RMSNorm", "generated/torchtune.modules.RotaryPositionalEmbeddings", "generated/torchtune.modules.TransformerDecoder", "generated/torchtune.modules.TransformerDecoderLayer", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook", "generated/torchtune.modules.get_cosine_schedule_with_warmup", "generated/torchtune.modules.peft.AdapterModule", "generated/torchtune.modules.peft.LoRALinear", "generated/torchtune.modules.peft.get_adapter_params", "generated/torchtune.modules.peft.set_trainable_params", "generated/torchtune.modules.tokenizers.SentencePieceTokenizer", "generated/torchtune.modules.tokenizers.TikTokenTokenizer", "generated/torchtune.utils.FSDPPolicyType", "generated/torchtune.utils.FullModelHFCheckpointer", "generated/torchtune.utils.FullModelMetaCheckpointer", "generated/torchtune.utils.TuneRecipeArgumentParser", "generated/torchtune.utils.generate", "generated/torchtune.utils.get_device", "generated/torchtune.utils.get_dtype", "generated/torchtune.utils.get_full_finetune_fsdp_wrap_policy", "generated/torchtune.utils.get_logger", "generated/torchtune.utils.get_world_size_and_rank", "generated/torchtune.utils.init_distributed", "generated/torchtune.utils.list_dtypes", "generated/torchtune.utils.metric_logging.DiskLogger", "generated/torchtune.utils.metric_logging.StdoutLogger", "generated/torchtune.utils.metric_logging.TensorBoardLogger", "generated/torchtune.utils.metric_logging.WandBLogger", "generated/torchtune.utils.padded_collate", "generated/torchtune.utils.profiler", "generated/torchtune.utils.set_activation_checkpointing", "generated/torchtune.utils.set_seed", "generated_examples/index", "generated_examples/sg_execution_times", "index", "install", "overview", "sg_execution_times", "tutorials/chat", "tutorials/datasets", "tutorials/e2e_flow", "tutorials/first_finetune_tutorial", "tutorials/llama3", "tutorials/lora_finetune", "tutorials/qlora_finetune"], "filenames": ["api_ref_config.rst", "api_ref_data.rst", "api_ref_datasets.rst", "api_ref_models.rst", "api_ref_modules.rst", "api_ref_utilities.rst", "deep_dives/checkpointer.rst", "deep_dives/configs.rst", "deep_dives/recipe_deepdive.rst", "deep_dives/wandb_logging.rst", "generated/torchtune.config.instantiate.rst", "generated/torchtune.config.parse.rst", "generated/torchtune.config.validate.rst", "generated/torchtune.data.AlpacaInstructTemplate.rst", "generated/torchtune.data.ChatFormat.rst", "generated/torchtune.data.ChatMLFormat.rst", "generated/torchtune.data.GrammarErrorCorrectionTemplate.rst", "generated/torchtune.data.InstructTemplate.rst", "generated/torchtune.data.Llama2ChatFormat.rst", "generated/torchtune.data.Message.rst", "generated/torchtune.data.MistralChatFormat.rst", "generated/torchtune.data.SummarizeTemplate.rst", "generated/torchtune.data.sharegpt_to_llama2_messages.rst", "generated/torchtune.data.validate_messages.rst", "generated/torchtune.datasets.ChatDataset.rst", "generated/torchtune.datasets.ConcatDataset.rst", "generated/torchtune.datasets.InstructDataset.rst", "generated/torchtune.datasets.PackedDataset.rst", "generated/torchtune.datasets.TextCompletionDataset.rst", "generated/torchtune.datasets.alpaca_cleaned_dataset.rst", "generated/torchtune.datasets.alpaca_dataset.rst", "generated/torchtune.datasets.chat_dataset.rst", "generated/torchtune.datasets.cnn_dailymail_articles_dataset.rst", "generated/torchtune.datasets.grammar_dataset.rst", "generated/torchtune.datasets.instruct_dataset.rst", "generated/torchtune.datasets.samsum_dataset.rst", "generated/torchtune.datasets.slimorca_dataset.rst", "generated/torchtune.datasets.text_completion_dataset.rst", "generated/torchtune.datasets.wikitext_dataset.rst", "generated/torchtune.models.gemma.gemma_2b.rst", "generated/torchtune.models.llama2.llama2_13b.rst", "generated/torchtune.models.llama2.llama2_70b.rst", "generated/torchtune.models.llama2.llama2_7b.rst", "generated/torchtune.models.llama2.lora_llama2_13b.rst", "generated/torchtune.models.llama2.lora_llama2_70b.rst", "generated/torchtune.models.llama2.lora_llama2_7b.rst", "generated/torchtune.models.llama2.qlora_llama2_13b.rst", "generated/torchtune.models.llama2.qlora_llama2_7b.rst", "generated/torchtune.models.llama3.llama3_70b.rst", "generated/torchtune.models.llama3.llama3_8b.rst", "generated/torchtune.models.llama3.lora_llama3_70b.rst", "generated/torchtune.models.llama3.lora_llama3_8b.rst", "generated/torchtune.models.llama3.qlora_llama3_8b.rst", "generated/torchtune.models.mistral.lora_mistral_7b.rst", "generated/torchtune.models.mistral.mistral_7b.rst", "generated/torchtune.models.mistral.qlora_mistral_7b.rst", "generated/torchtune.models.phi3.lora_phi3_mini.rst", "generated/torchtune.models.phi3.phi3_mini.rst", "generated/torchtune.models.phi3.qlora_phi3_mini.rst", "generated/torchtune.modules.CausalSelfAttention.rst", "generated/torchtune.modules.FeedForward.rst", "generated/torchtune.modules.KVCache.rst", "generated/torchtune.modules.RMSNorm.rst", "generated/torchtune.modules.RotaryPositionalEmbeddings.rst", "generated/torchtune.modules.TransformerDecoder.rst", "generated/torchtune.modules.TransformerDecoderLayer.rst", "generated/torchtune.modules.common_utils.reparametrize_as_dtype_state_dict_post_hook.rst", "generated/torchtune.modules.get_cosine_schedule_with_warmup.rst", "generated/torchtune.modules.peft.AdapterModule.rst", "generated/torchtune.modules.peft.LoRALinear.rst", "generated/torchtune.modules.peft.get_adapter_params.rst", "generated/torchtune.modules.peft.set_trainable_params.rst", "generated/torchtune.modules.tokenizers.SentencePieceTokenizer.rst", "generated/torchtune.modules.tokenizers.TikTokenTokenizer.rst", "generated/torchtune.utils.FSDPPolicyType.rst", "generated/torchtune.utils.FullModelHFCheckpointer.rst", "generated/torchtune.utils.FullModelMetaCheckpointer.rst", "generated/torchtune.utils.TuneRecipeArgumentParser.rst", "generated/torchtune.utils.generate.rst", "generated/torchtune.utils.get_device.rst", "generated/torchtune.utils.get_dtype.rst", "generated/torchtune.utils.get_full_finetune_fsdp_wrap_policy.rst", "generated/torchtune.utils.get_logger.rst", "generated/torchtune.utils.get_world_size_and_rank.rst", "generated/torchtune.utils.init_distributed.rst", "generated/torchtune.utils.list_dtypes.rst", "generated/torchtune.utils.metric_logging.DiskLogger.rst", "generated/torchtune.utils.metric_logging.StdoutLogger.rst", "generated/torchtune.utils.metric_logging.TensorBoardLogger.rst", "generated/torchtune.utils.metric_logging.WandBLogger.rst", "generated/torchtune.utils.padded_collate.rst", "generated/torchtune.utils.profiler.rst", "generated/torchtune.utils.set_activation_checkpointing.rst", "generated/torchtune.utils.set_seed.rst", "generated_examples/index.rst", "generated_examples/sg_execution_times.rst", "index.rst", "install.rst", "overview.rst", "sg_execution_times.rst", "tutorials/chat.rst", "tutorials/datasets.rst", "tutorials/e2e_flow.rst", "tutorials/first_finetune_tutorial.rst", "tutorials/llama3.rst", "tutorials/lora_finetune.rst", "tutorials/qlora_finetune.rst"], "titles": ["torchtune.config", "torchtune.data", "torchtune.datasets", "torchtune.models", "torchtune.modules", "torchtune.utils", "Checkpointing in torchtune", "All About Configs", "What Are Recipes?", "Logging to Weights &amp; Biases", "instantiate", "parse", "validate", "AlpacaInstructTemplate", "ChatFormat", "ChatMLFormat", "GrammarErrorCorrectionTemplate", "InstructTemplate", "Llama2ChatFormat", "Message", "MistralChatFormat", "SummarizeTemplate", "sharegpt_to_llama2_messages", "validate_messages", "ChatDataset", "ConcatDataset", "InstructDataset", "PackedDataset", "TextCompletionDataset", "alpaca_cleaned_dataset", "alpaca_dataset", "chat_dataset", "cnn_dailymail_articles_dataset", "grammar_dataset", "instruct_dataset", "samsum_dataset", "slimorca_dataset", "text_completion_dataset", "wikitext_dataset", "gemma_2b", "llama2_13b", "llama2_70b", "llama2_7b", "lora_llama2_13b", "lora_llama2_70b", "lora_llama2_7b", "qlora_llama2_13b", "qlora_llama2_7b", "llama3_70b", "llama3_8b", "lora_llama3_70b", "lora_llama3_8b", "qlora_llama3_8b", "lora_mistral_7b", "mistral_7b", "qlora_mistral_7b", "lora_phi3_mini", "phi3_mini", "qlora_phi3_mini", "CausalSelfAttention", "FeedForward", "KVCache", "RMSNorm", "RotaryPositionalEmbeddings", "TransformerDecoder", "TransformerDecoderLayer", "reparametrize_as_dtype_state_dict_post_hook", "get_cosine_schedule_with_warmup", "AdapterModule", "LoRALinear", "get_adapter_params", "set_trainable_params", "SentencePieceTokenizer", "TikTokenTokenizer", "torchtune.utils.FSDPPolicyType", "FullModelHFCheckpointer", "FullModelMetaCheckpointer", "TuneRecipeArgumentParser", "generate", "get_device", "get_dtype", "get_full_finetune_fsdp_wrap_policy", "get_logger", "get_world_size_and_rank", "init_distributed", "list_dtypes", "DiskLogger", "StdoutLogger", "TensorBoardLogger", "WandBLogger", "padded_collate", "profiler", "set_activation_checkpointing", "set_seed", "&lt;no title&gt;", "Computation times", "Welcome to the torchtune Documentation", "Install Instructions", "torchtune Overview", "Computation times", "Fine-tuning Llama3 with Chat Data", "Configuring Datasets for Fine-Tuning", "End-to-End Workflow with torchtune", "Fine-Tune Your First LLM", "Meta Llama3 in torchtune", "Finetuning Llama2 with LoRA", "Finetuning Llama2 with QLoRA"], "terms": {"support": [2, 6, 8, 9, 10, 20, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 57, 59, 69, 76, 80, 85, 98, 100, 101, 102, 103, 104, 105, 106], "sever": [2, 101], "wide": [2, 101], "us": [2, 4, 6, 9, 10, 11, 15, 18, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 59, 60, 62, 63, 64, 65, 66, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 86, 87, 88, 89, 93, 96, 97, 98, 101, 103, 104, 105], "help": [2, 6, 18, 64, 75, 77, 96, 97, 98, 100, 101, 102, 103, 104, 106], "quickli": [2, 7, 28, 100, 101], "bootstrap": [2, 101], "your": [2, 5, 9, 10, 24, 28, 88, 89, 96, 97, 98, 100, 101, 104, 105, 106], "fine": [2, 6, 8, 9, 27, 96, 98, 102, 105], "tune": [2, 3, 6, 7, 8, 9, 11, 27, 96, 97, 98, 102, 105, 106], "also": [2, 6, 7, 8, 9, 10, 31, 37, 59, 64, 69, 79, 81, 89, 97, 100, 101, 102, 103, 104, 105, 106], "common": [2, 4, 7, 100, 101, 104, 105], "format": [2, 5, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 29, 30, 31, 34, 36, 75, 76, 100, 102, 103, 104, 105], "like": [2, 6, 7, 8, 9, 24, 97, 100, 101, 102, 103, 105], "chat": [2, 14, 15, 18, 19, 22, 24, 31, 36], "model": [2, 6, 7, 8, 10, 15, 20, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 75, 76, 78, 81, 91, 92, 96, 98, 100, 101, 106], "instruct": [2, 3, 13, 15, 17, 19, 20, 26, 27, 29, 30, 34, 37, 57, 96, 100, 103, 105, 106], "These": [2, 4, 6, 7, 8, 10, 27, 77, 100, 101, 102, 103, 104, 105, 106], "ar": [2, 4, 6, 7, 9, 10, 13, 16, 17, 18, 19, 20, 21, 23, 26, 27, 29, 30, 31, 33, 34, 35, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 64, 69, 74, 75, 76, 78, 80, 97, 98, 100, 101, 102, 103, 104, 105, 106], "especi": [2, 98, 102], "specifi": [2, 6, 7, 8, 10, 31, 59, 64, 65, 74, 78, 81, 89, 92, 100, 101, 102, 103, 104, 106], "from": [2, 3, 6, 7, 8, 9, 10, 13, 16, 17, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 42, 54, 60, 64, 65, 67, 68, 70, 72, 75, 76, 77, 78, 88, 89, 95, 97, 99, 101, 102, 103, 104, 105], "yaml": [2, 7, 8, 10, 11, 31, 34, 37, 77, 89, 98, 100, 102, 103, 104, 105, 106], "config": [2, 6, 9, 10, 11, 12, 31, 34, 37, 59, 75, 77, 89, 98, 100, 101, 102, 104, 105, 106], "represent": [2, 105, 106], "abov": [2, 6, 66, 97, 102, 104, 105, 106], "all": [3, 4, 8, 12, 24, 25, 27, 31, 59, 60, 64, 66, 73, 75, 77, 94, 96, 98, 99, 100, 102, 103, 104, 105], "famili": [3, 8, 29, 30, 32, 36, 38, 98, 104], "download": [3, 6, 94, 97, 100, 104, 105, 106], "meta": [3, 6, 18, 75, 76, 100, 102, 103], "llama": [3, 6, 18, 24, 31, 62, 63, 75, 76, 100, 102, 103, 104, 105], "8b": [3, 49, 50, 51, 56, 100], "hf": [3, 6, 75, 100, 102, 103, 104], "token": [3, 6, 7, 8, 19, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 59, 63, 64, 65, 72, 73, 78, 81, 101, 102, 103, 104, 105, 106], "access_token": 3, "pre": [3, 18, 27, 97, 100], "train": [3, 5, 6, 8, 9, 18, 24, 25, 26, 27, 29, 30, 31, 33, 34, 35, 36, 59, 63, 64, 65, 66, 67, 75, 76, 80, 91, 96, 98, 100, 101, 102, 104, 105, 106], "can": [3, 4, 6, 7, 8, 9, 10, 12, 19, 24, 25, 26, 28, 29, 30, 31, 32, 34, 37, 38, 62, 63, 72, 74, 75, 77, 81, 88, 89, 92, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106], "hug": [3, 6, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 67, 98, 101, 103, 104], "face": [3, 6, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 67, 98, 101, 103, 104], "hub": [3, 6, 103], "follow": [3, 6, 8, 22, 24, 27, 59, 67, 89, 96, 97, 101, 102, 103, 104, 105, 106], "command": [3, 8, 9, 77, 97, 100, 102, 103, 104, 105, 106], "2": [3, 6, 9, 23, 27, 36, 59, 72, 75, 76, 90, 93, 100, 102, 103, 104, 105], "7b": [3, 6, 26, 28, 29, 30, 32, 34, 37, 38, 42, 45, 47, 53, 54, 75, 76, 100, 103, 104, 105, 106], "mini": [3, 56, 57, 58], "microsoft": [3, 57], "4k": [3, 57], "hf_token": 3, "ignor": [3, 6, 59, 60], "pattern": [3, 73], "ai": [3, 54, 59, 89, 100, 104], "mistralai": 3, "v0": 3, "1": [3, 6, 8, 27, 36, 59, 64, 67, 72, 73, 76, 78, 88, 89, 90, 93, 100, 102, 103, 104, 105, 106], "googl": [3, 39], "2b": [3, 39], "offer": 5, "allow": [5, 25, 88, 106], "seamless": 5, "transit": 5, "between": [5, 6, 75, 102, 104, 105, 106], "interoper": [5, 6, 8, 98, 102, 106], "rest": [5, 100, 106], "ecosystem": [5, 6, 8, 98, 102, 104, 106], "For": [5, 6, 7, 8, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 37, 38, 59, 64, 75, 77, 89, 92, 93, 97, 100, 101, 102, 103, 104, 105, 106], "comprehens": 5, "overview": [5, 7, 9, 103, 105, 106], "pleas": [5, 46, 47, 52, 55, 58, 74, 81, 92, 97, 106], "see": [5, 6, 9, 18, 20, 31, 36, 38, 46, 47, 52, 55, 58, 61, 68, 74, 77, 81, 82, 89, 91, 92, 93, 97, 98, 100, 101, 102, 103, 104, 105, 106], "deep": [5, 6, 7, 8, 9, 98, 103, 104], "dive": [5, 6, 7, 8, 9, 98, 103, 104], "enabl": [5, 7, 8, 9, 25, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 69, 91, 93, 104, 105, 106], "work": [5, 6, 8, 77, 98, 102, 104, 106], "set": [5, 6, 7, 8, 9, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 63, 64, 71, 74, 79, 81, 92, 93, 98, 100, 101, 102, 103, 104, 105], "consumpt": [5, 25], "dure": [5, 6, 25, 26, 27, 29, 30, 33, 35, 59, 61, 63, 64, 65, 66, 100, 102, 104, 105, 106], "provid": [5, 6, 7, 8, 10, 15, 20, 24, 25, 26, 27, 36, 64, 77, 81, 89, 98, 100, 101, 102, 103, 104], "debug": [5, 6, 7, 8], "finetun": [5, 6, 7, 8, 43, 44, 45, 50, 51, 56, 85, 96, 98, 103, 104], "job": [5, 9, 93, 103], "variou": [5, 17], "dataset": [5, 7, 13, 16, 17, 19, 21, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 98, 103, 104], "walk": [6, 8, 88, 98, 100, 101, 102, 103, 106], "you": [6, 7, 8, 9, 10, 17, 18, 24, 26, 28, 29, 30, 32, 34, 37, 38, 77, 78, 88, 89, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106], "through": [6, 7, 8, 9, 60, 98, 100, 101, 102, 103, 106], "design": [6, 8], "behavior": [6, 100, 101], "associ": [6, 7, 8, 78, 102, 105], "util": [6, 7, 8, 9, 10, 25, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 98, 102, 103, 104, 106], "what": [6, 7, 9, 18, 20, 33, 35, 96, 100, 101, 102, 103, 104], "cover": [6, 7, 8, 9, 100, 102, 106], "how": [6, 7, 8, 9, 74, 92, 96, 100, 101, 102, 103, 104, 106], "we": [6, 7, 8, 9, 26, 27, 28, 29, 30, 32, 34, 37, 38, 59, 61, 63, 64, 69, 72, 75, 76, 78, 80, 98, 100, 101, 102, 103, 104, 105, 106], "them": [6, 7, 24, 25, 26, 34, 60, 66, 72, 100, 101, 102, 105, 106], "scenario": [6, 25], "full": [6, 7, 8, 46, 47, 52, 55, 58, 72, 98, 104, 105], "compos": 6, "compon": [6, 8, 12, 91, 98, 101, 103, 105, 106], "which": [6, 8, 25, 26, 27, 29, 30, 33, 35, 43, 44, 45, 50, 51, 53, 56, 59, 63, 64, 65, 67, 72, 75, 76, 80, 86, 89, 92, 98, 100, 101, 102, 103, 104, 105, 106], "plug": 6, "ani": [6, 7, 8, 10, 11, 12, 13, 16, 17, 21, 22, 24, 26, 28, 31, 32, 34, 37, 38, 66, 70, 71, 72, 75, 76, 78, 93, 100, 101, 102, 103, 104, 105], "recip": [6, 7, 9, 10, 11, 60, 75, 76, 98, 100, 101, 102, 104, 106], "evalu": [6, 8, 96, 98, 103, 105, 106], "gener": [6, 8, 13, 16, 21, 24, 26, 27, 32, 36, 72, 93, 94, 96, 100, 101, 105, 106], "each": [6, 8, 14, 17, 25, 27, 43, 44, 45, 50, 51, 53, 56, 59, 63, 64, 65, 72, 73, 93, 98, 101, 102, 103, 104, 105], "make": [6, 7, 8, 9, 59, 65, 98, 102, 103, 104, 105, 106], "easi": [6, 8, 98, 105], "understand": [6, 7, 8, 96, 98, 100, 101, 105, 106], "extend": [6, 8, 98], "befor": [6, 23, 26, 27, 59, 64, 65, 69, 75, 102], "let": [6, 7, 9, 100, 101, 102, 103, 104, 105, 106], "s": [6, 7, 8, 9, 10, 11, 13, 14, 15, 18, 20, 23, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 43, 44, 45, 50, 51, 53, 56, 59, 61, 63, 64, 65, 66, 68, 70, 73, 74, 75, 76, 79, 81, 88, 91, 92, 98, 100, 101, 103, 105, 106], "defin": [6, 7, 8, 60, 68, 69, 70, 103, 105], "some": [6, 7, 15, 70, 71, 96, 98, 100, 102, 103, 105, 106], "concept": [6, 102, 103], "In": [6, 7, 8, 24, 63, 69, 74, 88, 89, 100, 102, 104, 105, 106], "ll": [6, 7, 8, 73, 78, 98, 100, 101, 102, 103, 104, 106], "talk": 6, "about": [6, 8, 75, 89, 98, 100, 102, 103, 104, 105, 106], "take": [6, 7, 8, 10, 60, 61, 66, 75, 77, 79, 100, 101, 102, 103, 104, 105, 106], "close": [6, 8, 86, 87, 88, 89, 105], "look": [6, 7, 8, 88, 97, 100, 101, 102, 103, 104, 105], "veri": [6, 25, 64, 102], "simpli": [6, 7, 27, 100, 101, 102, 104, 106], "dictat": 6, "state_dict": [6, 66, 75, 76, 105, 106], "store": [6, 25, 86, 89, 105, 106], "file": [6, 7, 8, 9, 10, 11, 72, 73, 75, 76, 77, 86, 89, 91, 95, 98, 99, 100, 101, 102, 103, 104, 105, 106], "disk": [6, 28, 86], "weight": [6, 8, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 66, 68, 69, 75, 76, 89, 96, 100, 102, 103, 104, 105, 106], "string": [6, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 68, 72, 73, 79, 80], "kei": [6, 7, 9, 24, 26, 34, 59, 61, 64, 65, 71, 75, 102, 103, 105, 106], "identifi": 6, "state": [6, 8, 66, 70, 71, 75, 76, 102, 104, 105, 106], "dict": [6, 7, 8, 9, 10, 13, 16, 17, 19, 21, 22, 24, 26, 28, 31, 32, 34, 37, 38, 66, 70, 71, 75, 76, 84, 90], "If": [6, 7, 12, 13, 16, 17, 20, 21, 23, 24, 26, 29, 30, 33, 34, 35, 36, 59, 63, 64, 65, 66, 69, 75, 76, 78, 79, 80, 81, 84, 88, 89, 93, 97, 100, 101, 102, 103, 104, 105], "don": [6, 7, 8, 89, 93, 100, 102, 103, 104, 106], "t": [6, 7, 8, 73, 80, 89, 93, 100, 102, 103, 104, 106], "match": [6, 24, 26, 34, 97, 102, 104, 105], "up": [6, 8, 9, 26, 27, 28, 29, 30, 32, 34, 37, 38, 100, 101, 103, 104, 105, 106], "exactli": 6, "those": [6, 105], "definit": [6, 105], "either": [6, 75, 78, 92, 105, 106], "run": [6, 7, 9, 11, 60, 61, 64, 66, 75, 76, 88, 89, 97, 98, 100, 103, 104, 105, 106], "explicit": 6, "error": [6, 7, 23, 75, 93], "load": [6, 8, 24, 25, 26, 27, 28, 75, 76, 77, 88, 100, 102, 104, 105], "rais": [6, 10, 12, 20, 23, 31, 36, 59, 61, 64, 75, 76, 80, 84, 89, 93], "an": [6, 7, 8, 9, 10, 13, 19, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 59, 64, 68, 70, 71, 74, 75, 76, 81, 89, 98, 100, 101, 102, 103, 104, 105, 106], "except": [6, 19, 20, 101], "wors": 6, "silent": [6, 60], "succe": 6, "infer": [6, 18, 24, 59, 61, 63, 64, 65, 96, 100, 102, 103, 104, 106], "expect": [6, 7, 10, 13, 16, 17, 21, 24, 26, 31, 34, 63, 89, 100, 101, 105], "addit": [6, 7, 8, 10, 24, 26, 28, 31, 32, 34, 37, 38, 74, 75, 76, 80, 81, 84, 86, 88, 89, 92, 98, 100, 103, 105], "line": [6, 8, 77, 103, 104], "need": [6, 7, 8, 9, 17, 24, 27, 36, 59, 60, 64, 88, 89, 97, 100, 101, 102, 103, 104, 105, 106], "shape": [6, 59, 61, 63, 64, 65, 69, 78], "valu": [6, 7, 22, 36, 39, 40, 41, 42, 48, 49, 54, 59, 61, 62, 64, 65, 67, 75, 77, 78, 86, 87, 88, 89, 93, 103, 104, 105], "two": [6, 7, 23, 98, 102, 103, 104, 105, 106], "popular": [6, 98, 101, 102], "llama2": [6, 7, 8, 10, 18, 22, 24, 26, 28, 29, 30, 32, 34, 36, 37, 38, 40, 41, 42, 43, 44, 45, 46, 47, 60, 64, 65, 72, 96, 98, 103, 104], "offici": [6, 18, 100, 103, 104], "implement": [6, 8, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 60, 62, 63, 67, 68, 69, 75, 88, 98, 105, 106], "when": [6, 7, 8, 11, 19, 25, 27, 59, 63, 64, 65, 66, 67, 78, 81, 88, 102, 104, 105, 106], "websit": 6, "get": [6, 7, 8, 9, 24, 72, 80, 82, 83, 97, 98, 100, 101, 102, 103, 105], "access": [6, 7, 8, 25, 75, 102, 103], "singl": [6, 7, 10, 13, 14, 15, 16, 17, 18, 20, 21, 22, 25, 27, 59, 75, 76, 100, 101, 102, 103, 104, 105, 106], "pth": [6, 102, 104], "inspect": [6, 102, 105, 106], "content": [6, 19, 22, 24, 72, 100, 101], "easili": [6, 7, 98, 101, 105, 106], "torch": [6, 25, 61, 64, 66, 67, 78, 79, 80, 84, 91, 92, 93, 102, 103, 104, 105, 106], "import": [6, 7, 10, 31, 37, 88, 89, 100, 101, 102, 103, 105, 106], "consolid": [6, 104], "00": [6, 95, 99, 103, 104], "mmap": [6, 102], "true": [6, 7, 19, 26, 27, 29, 30, 31, 33, 35, 46, 47, 52, 55, 58, 59, 64, 65, 66, 72, 73, 74, 75, 76, 81, 84, 88, 100, 101, 102, 104, 105, 106], "weights_onli": 6, "map_loc": [6, 102], "cpu": [6, 8, 66, 80, 97, 102, 106], "tensor": [6, 59, 60, 61, 62, 63, 64, 65, 66, 69, 75, 78, 86, 87, 88, 89, 90, 105, 106], "item": 6, "print": [6, 9, 25, 29, 30, 33, 35, 36, 72, 78, 100, 101, 103, 105, 106], "f": [6, 9, 29, 30, 33, 35, 100, 102, 105, 106], "tok_embed": [6, 64], "size": [6, 8, 10, 29, 30, 33, 35, 59, 61, 62, 63, 64, 65, 83, 98, 101, 102, 103, 104, 105], "32000": [6, 10, 105], "4096": [6, 10, 26, 28, 29, 30, 32, 34, 37, 38, 59, 63, 105], "len": [6, 25, 29, 30, 33, 35, 64], "292": 6, "The": [6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 33, 35, 36, 43, 44, 45, 50, 51, 56, 62, 63, 66, 67, 72, 73, 74, 75, 77, 79, 80, 82, 89, 91, 93, 97, 98, 100, 101, 102, 103, 104, 105, 106], "contain": [6, 19, 25, 27, 28, 37, 59, 61, 63, 64, 65, 68, 70, 71, 72, 73, 75, 76, 77, 88, 90, 100, 102, 104, 105], "includ": [6, 7, 8, 14, 17, 69, 75, 76, 77, 98, 100, 102, 103, 104, 105, 106], "input": [6, 13, 14, 17, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37, 38, 59, 60, 62, 63, 64, 65, 69, 72, 75, 90, 93, 100, 101, 105, 106], "embed": [6, 59, 61, 62, 63, 64, 81, 100, 104], "tabl": [6, 100, 106], "call": [6, 10, 19, 60, 66, 77, 86, 87, 88, 89, 100, 105, 106], "layer": [6, 8, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 64, 65, 69, 74, 81, 98, 104, 105, 106], "have": [6, 7, 10, 59, 61, 68, 77, 81, 88, 91, 97, 100, 101, 102, 103, 104, 105, 106], "dim": [6, 59, 60, 62, 63, 64, 65], "most": [6, 7, 73, 100, 103, 105, 106], "within": [6, 7, 10, 24, 27, 36, 60, 78, 88, 93, 102, 104, 105, 106], "default": [6, 7, 15, 19, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 53, 54, 56, 59, 60, 62, 63, 64, 65, 66, 67, 69, 72, 73, 75, 76, 77, 78, 80, 86, 89, 90, 91, 93, 97, 102, 104, 105, 106], "everi": [6, 8, 60, 88, 97, 106], "repo": [6, 75, 76, 102], "first": [6, 7, 10, 23, 27, 61, 64, 73, 75, 77, 96, 98, 100, 102, 104, 105, 106], "big": [6, 102], "split": [6, 27, 100, 101, 102], "across": [6, 8, 25, 75, 88, 93, 102, 104], "bin": [6, 102], "To": [6, 7, 8, 9, 27, 75, 97, 98, 100, 101, 102, 103, 104, 105, 106], "correctli": [6, 8, 12, 75, 97, 100, 103, 106], "piec": 6, "one": [6, 8, 23, 60, 72, 100, 101, 102, 103, 104, 106], "pytorch_model": [6, 102], "00001": 6, "00002": 6, "embed_token": 6, "241": 6, "Not": 6, "onli": [6, 9, 19, 27, 32, 69, 70, 72, 76, 77, 78, 80, 81, 102, 103, 104, 105, 106], "doe": [6, 20, 24, 27, 57, 59, 64, 65, 68, 75, 77, 100, 102], "fewer": [6, 59], "sinc": [6, 7, 10, 60, 75, 100, 102, 104], "instead": [6, 8, 27, 31, 34, 37, 60, 61, 69, 102, 104, 105], "mismatch": 6, "name": [6, 7, 9, 13, 16, 17, 21, 24, 26, 28, 31, 34, 36, 37, 38, 68, 71, 73, 75, 76, 77, 78, 79, 86, 87, 88, 89, 100, 102, 104], "caus": [6, 72], "try": [6, 7, 100, 102, 103, 104, 106], "same": [6, 7, 43, 44, 45, 50, 51, 56, 59, 61, 65, 72, 77, 81, 89, 100, 102, 104, 105, 106], "As": [6, 7, 8, 9, 69, 98, 102, 104, 106], "re": [6, 7, 73, 98, 100, 102, 103, 104, 105], "care": [6, 60, 75, 102, 104, 105], "end": [6, 8, 19, 25, 73, 96, 98, 100, 104, 105], "number": [6, 8, 24, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 59, 61, 64, 67, 75, 76, 78, 83, 93, 103, 105], "just": [6, 13, 98, 100, 101, 103, 104, 105], "save": [6, 8, 9, 66, 75, 76, 81, 89, 96, 100, 102, 104, 105], "less": [6, 36, 102, 103, 104, 106], "prone": 6, "manag": [6, 25, 91, 100], "invari": 6, "accept": [6, 7, 36, 72, 74, 103, 106], "multipl": [6, 7, 8, 19, 24, 25, 59, 64, 65, 69, 86, 87, 88, 89, 101, 103, 104], "sourc": [6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 53, 54, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 100, 101, 102], "worri": [6, 100, 103], "explicitli": [6, 68, 98, 105], "convert": [6, 22, 24, 75, 90, 100, 102, 106], "time": [6, 72, 86, 88, 100, 102, 104, 106], "produc": [6, 106], "back": [6, 23, 75, 105, 106], "origin": [6, 29, 30, 66, 69, 100, 101, 102, 104, 105, 106], "form": [6, 7, 8, 23], "One": [6, 102], "advantag": [6, 105], "being": [6, 75, 76, 79, 106], "should": [6, 7, 8, 14, 17, 18, 19, 20, 22, 27, 31, 34, 37, 43, 44, 45, 50, 51, 53, 56, 59, 60, 68, 74, 77, 86, 87, 88, 89, 97, 98, 101, 102, 103, 104, 105, 106], "abl": [6, 8, 101, 102, 103, 104], "post": [6, 106], "tool": [6, 102, 103], "quantiz": [6, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 69, 96, 103, 106], "eval": [6, 96, 98], "without": [6, 7, 9, 97, 98, 100, 101, 102, 105], "code": [6, 8, 64, 94, 98, 101, 103], "chang": [6, 7, 9, 13, 97, 101, 102, 103, 104, 105, 106], "OR": 6, "convers": [6, 14, 15, 18, 20, 22, 23, 24, 31, 36, 75, 98, 100, 101, 102, 104, 105, 106], "script": [6, 9, 102, 103, 104], "wai": [6, 7, 24, 100, 101, 102, 103, 104], "surround": [6, 8, 98], "load_checkpoint": [6, 8, 75, 76], "save_checkpoint": [6, 8, 9, 75, 76], "method": [6, 7, 8, 9, 11, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 66, 68, 70, 77, 97, 98, 102, 104, 105, 106], "convertor": 6, "avail": [6, 8, 38, 77, 79, 80, 98, 102, 104, 105], "here": [6, 7, 9, 15, 33, 62, 63, 100, 101, 102, 103, 104, 105, 106], "three": [6, 8, 103], "hfcheckpoint": 6, "read": [6, 75, 76, 98], "write": [6, 8, 75, 76, 86, 100, 101, 103], "compat": [6, 75], "transform": [6, 8, 24, 26, 43, 44, 45, 50, 51, 53, 56, 64, 65, 67, 92, 105], "framework": [6, 8, 98], "mention": [6, 102, 106], "assum": [6, 13, 16, 17, 21, 26, 34, 59, 63, 64, 65, 67, 70, 73, 80, 102, 105], "checkpoint_dir": [6, 7, 75, 76, 102, 104], "necessari": [6, 36, 86, 87, 88, 89, 100, 105], "json": [6, 75, 91, 102], "easiest": [6, 102, 103], "sure": [6, 7, 102, 103, 104, 105, 106], "everyth": [6, 8, 77, 98, 103], "flow": [6, 24, 26, 27, 106], "By": [6, 104, 105, 106], "safetensor": 6, "output": [6, 17, 29, 30, 33, 36, 43, 44, 45, 50, 51, 53, 56, 59, 60, 62, 63, 64, 65, 69, 71, 78, 81, 87, 91, 97, 100, 101, 102, 103, 104, 105, 106], "dir": [6, 89, 97, 102, 103, 104], "output_dir": [6, 7, 75, 76, 91, 102, 104, 105, 106], "argument": [6, 7, 10, 17, 24, 26, 28, 31, 32, 34, 36, 37, 38, 46, 47, 52, 55, 58, 59, 74, 77, 81, 84, 86, 88, 89, 92, 100, 104, 105], "snippet": [6, 101], "explain": 6, "setup": [6, 7, 8, 64, 92, 102, 105, 106], "_component_": [6, 7, 9, 10, 31, 37, 100, 101, 102, 104, 105], "fullmodelhfcheckpoint": [6, 102], "directori": [6, 7, 75, 76, 86, 88, 89, 102, 103, 104], "sort": [6, 75], "id": [6, 24, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 59, 63, 64, 65, 72, 73, 75, 78, 90, 100, 102], "so": [6, 7, 27, 75, 77, 97, 98, 100, 102, 103, 104, 105, 106], "order": [6, 8, 75, 88, 89, 103], "matter": [6, 75, 105], "checkpoint_fil": [6, 7, 9, 75, 76, 102, 104, 105, 106], "restart": 6, "previou": [6, 27, 75, 76], "more": [6, 7, 8, 31, 36, 61, 63, 74, 77, 89, 91, 92, 93, 98, 101, 102, 103, 104, 105, 106], "next": [6, 27, 78, 104, 106], "section": [6, 8, 96, 102, 104, 106], "recipe_checkpoint": [6, 75, 76], "null": [6, 7], "usual": [6, 63, 75, 89, 102, 105], "model_typ": [6, 75, 76, 102, 104], "resume_from_checkpoint": [6, 75, 76], "fals": [6, 7, 19, 22, 24, 26, 27, 29, 30, 31, 33, 34, 35, 36, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 64, 65, 69, 72, 73, 75, 76, 91, 100, 101, 102, 104, 105, 106], "requir": [6, 7, 25, 36, 75, 88, 89, 93, 97, 100, 101, 103, 106], "param": [6, 8, 43, 44, 45, 50, 51, 56, 69, 70, 71, 75, 105, 106], "directli": [6, 7, 8, 10, 31, 34, 37, 74, 75, 101, 102, 103, 104, 105, 106], "ensur": [6, 7, 12, 23, 36, 59, 75, 80, 98, 103], "out": [6, 7, 8, 24, 26, 29, 30, 31, 33, 35, 75, 76, 96, 98, 100, 102, 103, 104, 105, 106], "case": [6, 8, 9, 19, 59, 75, 80, 86, 92, 98, 100, 101, 102, 104, 105, 106], "discrep": [6, 75], "along": [6, 104, 105], "detail": [6, 31, 36, 61, 74, 81, 91, 93, 102, 103, 104, 105, 106], "found": [6, 7, 9, 62, 63, 105, 106], "metacheckpoint": 6, "github": [6, 10, 43, 44, 45, 50, 51, 56, 59, 62, 63, 67, 97, 103], "repositori": [6, 18, 102, 103], "fullmodelmetacheckpoint": [6, 104], "torchtunecheckpoint": 6, "perform": [6, 27, 60, 78, 98, 100, 102, 104, 106], "current": [6, 27, 57, 59, 61, 63, 64, 65, 76, 81, 83, 86, 88, 93, 102, 103, 104], "test": [6, 7, 8, 98, 100], "complet": [6, 8, 27, 32, 100, 101, 102, 103, 104], "written": [6, 7, 8, 75, 76, 86, 87, 88, 89, 98], "begin": [6, 27, 72, 73, 100, 104, 106], "partit": [6, 106], "ha": [6, 68, 70, 72, 101, 102, 103, 104, 105, 106], "standard": [6, 87, 98, 100, 102, 104], "key_1": 6, "weight_1": 6, "key_2": 6, "weight_2": 6, "mid": 6, "chekpoint": 6, "middl": [6, 102], "inform": [6, 19, 89, 92, 98, 102, 103, 104], "subsequ": [6, 8], "recipe_st": [6, 75, 76], "pt": [6, 9, 75, 76, 102, 104], "epoch": [6, 8, 9, 67, 75, 76, 100, 102, 103, 104], "optim": [6, 7, 8, 25, 57, 67, 100, 102, 103, 104, 105, 106], "etc": [6, 8, 75, 103], "prevent": [6, 27], "flood": 6, "overwritten": 6, "note": [6, 7, 17, 19, 64, 68, 72, 75, 91, 93, 100, 101, 102, 105, 106], "updat": [6, 7, 8, 61, 97, 100, 102, 103, 104, 105, 106], "hf_model_0001_0": [6, 102], "hf_model_0002_0": [6, 102], "both": [6, 25, 102, 105, 106], "adapt": [6, 68, 69, 70, 71, 75, 76, 100, 102, 105, 106], "merg": [6, 10, 75, 102, 104, 106], "would": [6, 7, 9, 27, 64, 97, 100, 101, 102, 105, 106], "our": [6, 8, 98, 100, 101, 102, 103, 105, 106], "tutori": [6, 92, 98, 100, 101, 102, 103, 104, 105, 106], "primari": [6, 7, 8, 103], "want": [6, 7, 8, 9, 10, 24, 78, 97, 100, 102, 103, 104, 105], "resum": [6, 8, 67, 75, 76, 106], "initi": [6, 8, 11, 25, 27, 39, 40, 41, 42, 48, 49, 54, 84, 103, 105, 106], "frozen": [6, 105, 106], "base": [6, 10, 26, 36, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 63, 67, 69, 71, 75, 77, 81, 86, 96, 100, 102, 103, 104, 105, 106], "well": [6, 7, 8, 98, 101, 102, 104, 106], "learnt": [6, 100, 102], "someth": [6, 8, 9, 100, 102], "NOT": 6, "refer": [6, 7, 8, 62, 63, 98, 105], "adapter_checkpoint": [6, 75, 76], "adapter_0": [6, 102], "now": [6, 72, 100, 101, 102, 103, 104, 105, 106], "knowledg": 6, "creat": [6, 7, 10, 27, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 61, 67, 74, 75, 76, 86, 88, 100, 101, 102, 104, 106], "simpl": [6, 8, 96, 103, 105, 106], "forward": [6, 8, 59, 60, 62, 63, 64, 65, 69, 104, 105, 106], "13b": [6, 40, 43, 46], "modeltyp": [6, 75, 76], "llama2_13b": [6, 43], "right": [6, 75, 102, 104, 105], "pytorch_fil": 6, "00003": 6, "torchtune_sd": 6, "load_state_dict": [6, 105], "successfulli": [6, 103], "vocab": [6, 10, 64, 104], "70": [6, 48], "x": [6, 59, 60, 62, 63, 64, 65, 69, 78, 105, 106], "randint": 6, "0": [6, 8, 27, 43, 44, 45, 46, 47, 59, 64, 67, 69, 72, 78, 88, 89, 90, 93, 95, 99, 100, 102, 103, 104, 105, 106], "no_grad": 6, "6": [6, 27, 62, 90, 102, 106], "3989": 6, "9": [6, 102, 106], "0531": 6, "3": [6, 27, 56, 57, 73, 77, 82, 90, 100, 102, 103, 104, 106], "2375": 6, "5": [6, 67, 90, 91, 102, 103, 104], "2822": 6, "4": [6, 36, 59, 90, 98, 102, 104, 105, 106], "4872": 6, "7469": 6, "8": [6, 29, 30, 33, 35, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 102, 105, 106], "6737": 6, "11": [6, 102, 104, 106], "0023": 6, "8235": 6, "6819": 6, "2424": 6, "0109": 6, "6915": 6, "7": [6, 90], "3618": 6, "1628": 6, "8594": 6, "5857": 6, "1151": 6, "7808": 6, "2322": 6, "8850": 6, "9604": 6, "7624": 6, "6040": 6, "3159": 6, "5849": 6, "8039": 6, "9322": 6, "2010": 6, "6824": 6, "8929": 6, "8465": 6, "3794": 6, "3500": 6, "6145": 6, "5931": 6, "do": [6, 8, 24, 26, 34, 36, 89, 100, 101, 102, 103, 104, 105], "find": [6, 8, 9, 102, 103, 105], "list": [6, 7, 14, 15, 18, 20, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 34, 36, 37, 38, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 68, 69, 72, 73, 75, 76, 77, 78, 82, 85, 90, 100, 101, 103, 104], "builder": [6, 32, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 100, 101, 106], "hope": 6, "deeper": [6, 103], "insight": [6, 102], "happi": [6, 102], "thi": [7, 8, 9, 10, 19, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 57, 59, 60, 63, 64, 65, 66, 67, 68, 72, 74, 75, 76, 77, 78, 79, 80, 86, 88, 89, 91, 92, 93, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106], "guid": [7, 9, 98, 100, 101, 103, 105], "pars": [7, 10, 73, 77, 100, 103], "effect": 7, "cli": [7, 9, 11, 97, 102, 103], "prerequisit": [7, 100, 101, 102, 103, 104, 105, 106], "Be": [7, 100, 102, 103, 104, 105, 106], "familiar": [7, 100, 102, 103, 104, 105, 106], "torchtun": [7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 97, 100, 101, 103], "instal": [7, 9, 88, 89, 96, 102, 103, 104, 105, 106], "fundament": 7, "There": [7, 14, 23, 100, 102, 103, 104, 105], "entri": [7, 8, 103], "point": [7, 8, 22, 101, 102, 103, 104, 105, 106], "locat": [7, 104, 105, 106], "thei": [7, 8, 19, 25, 64, 77, 100, 101, 105], "truth": [7, 102, 104], "reproduc": 7, "overridden": [7, 60, 77], "quick": [7, 25], "experiment": 7, "modifi": [7, 8, 9, 66, 98, 102, 104, 105, 106], "serv": [7, 74, 101, 105], "particular": [7, 24, 25, 36, 74, 101, 105, 106], "seed": [7, 8, 9, 93, 103], "shuffl": [7, 27], "devic": [7, 8, 79, 80, 100, 102, 103, 104, 105], "cuda": [7, 79, 80, 97, 102, 106], "dtype": [7, 8, 61, 64, 66, 80, 85, 102, 106], "fp32": [7, 106], "enable_fsdp": 7, "mani": [7, 27, 101, 102], "object": [7, 10, 14, 15, 18, 20, 59, 74, 100, 101], "keyword": [7, 10, 24, 26, 28, 31, 32, 34, 36, 37, 38, 66, 100], "loss": [7, 8, 26, 29, 30, 33, 35, 103, 105, 106], "function": [7, 8, 10, 11, 24, 59, 60, 66, 74, 78, 79, 83, 93, 98, 100, 101, 106], "exampl": [7, 8, 9, 10, 11, 15, 18, 20, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 59, 68, 72, 74, 75, 76, 78, 88, 89, 90, 94, 95, 97, 99, 100, 101, 102, 104, 105, 106], "subfield": 7, "dotpath": 7, "wish": 7, "exact": [7, 10, 102], "path": [7, 8, 9, 10, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 72, 73, 75, 76, 77, 91, 100, 102, 104, 105], "normal": [7, 24, 27, 62, 64, 65, 72, 100, 101, 105, 106], "python": [7, 73, 77, 82, 89, 93, 94, 102], "alpaca_dataset": [7, 29, 101], "custom": [7, 8, 24, 26, 31, 34, 37, 92, 98, 102, 103, 104, 105], "train_on_input": [7, 22, 24, 26, 29, 30, 31, 33, 34, 35, 36, 101], "onc": [7, 102, 103, 104, 105, 106], "ve": [7, 61, 73, 100, 101, 102, 104, 105], "instanc": [7, 10, 25, 60, 66, 70, 71, 105], "cfg": [7, 8, 11, 12], "automat": [7, 9, 10, 31, 102, 106], "under": [7, 102, 104, 106], "preced": [7, 10, 101, 104, 105], "actual": [7, 9, 24, 100], "throw": 7, "notic": [7, 100, 101, 105], "miss": [7, 105], "posit": [7, 10, 27, 59, 61, 63, 64, 65, 104], "anoth": [7, 102], "handl": [7, 11, 19, 25, 72, 100, 102, 105, 106], "def": [7, 8, 9, 11, 74, 100, 101, 105, 106], "dictconfig": [7, 8, 10, 11, 12, 89], "arg": [7, 10, 64, 66, 68, 77, 87], "tupl": [7, 10, 25, 36, 61, 66, 72, 73, 74, 77, 83, 90], "kwarg": [7, 10, 66, 68, 77, 84, 86, 87, 88, 89, 92], "str": [7, 10, 13, 16, 17, 19, 21, 22, 24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 66, 68, 69, 70, 71, 72, 73, 75, 76, 77, 79, 80, 82, 85, 86, 87, 88, 89, 90, 91, 93, 100], "mean": [7, 59, 62, 64, 65, 100, 103, 105], "pass": [7, 10, 24, 25, 26, 28, 31, 32, 34, 37, 38, 59, 60, 66, 74, 80, 81, 84, 88, 89, 92, 100, 105, 106], "add": [7, 9, 24, 27, 73, 77, 101, 102, 104, 105, 106], "d": [7, 19, 59, 61, 64, 65, 73, 100, 101, 105], "llama2_token": [7, 102], "tmp": [7, 100, 103, 104], "option": [7, 8, 13, 16, 17, 21, 24, 26, 27, 28, 31, 32, 34, 36, 37, 38, 43, 44, 45, 50, 51, 53, 56, 59, 63, 64, 65, 66, 72, 73, 75, 76, 78, 79, 80, 82, 86, 89, 91, 93, 97, 98, 102], "bool": [7, 19, 22, 24, 26, 27, 29, 30, 31, 33, 34, 35, 36, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 66, 69, 72, 73, 74, 75, 76, 81, 84, 88, 91, 92, 106], "max_seq_len": [7, 10, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 59, 61, 63, 64, 72, 73, 100, 101], "int": [7, 9, 24, 25, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 61, 62, 63, 64, 67, 69, 72, 73, 74, 75, 76, 78, 81, 83, 86, 87, 88, 89, 90, 92, 93, 100, 101, 105, 106], "512": [7, 29, 30, 101, 106], "instructdataset": [7, 29, 30, 33, 34, 35, 101], "alreadi": [7, 84, 97, 102, 105], "overwrit": [7, 97], "duplic": [7, 8, 98], "sometim": 7, "than": [7, 23, 36, 59, 61, 74, 100, 102, 103, 104, 105, 106], "resolv": [7, 103], "alpaca": [7, 13, 29, 30, 43, 44, 45, 50, 51, 56, 101], "metric_logg": [7, 8, 9], "metric_log": [7, 9, 86, 87, 88, 89], "disklogg": 7, "log_dir": [7, 86, 88, 89], "conveni": [7, 8], "verifi": [7, 79, 80, 81, 100, 103, 105], "properli": 7, "experi": [7, 89, 96, 98, 100, 104, 105], "wa": [7, 100, 102, 104, 105, 106], "cp": [7, 97, 100, 102, 103, 104], "7b_lora_single_devic": [7, 102, 103, 105, 106], "my_config": 7, "discuss": [7, 103, 105], "guidelin": 7, "while": [7, 8, 43, 44, 45, 50, 51, 56, 60, 98, 102, 106], "mai": [7, 9, 81, 91, 100, 101, 103, 105], "tempt": 7, "put": [7, 8, 103, 105], "much": [7, 102, 104, 105, 106], "give": [7, 105], "maximum": [7, 24, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 59, 61, 63, 64, 73], "flexibl": [7, 25, 101], "switch": 7, "encourag": [7, 105], "clariti": 7, "significantli": 7, "easier": [7, 102, 103], "dont": 7, "slimorca_dataset": 7, "privat": 7, "typic": [7, 27, 106], "expos": [7, 8, 100, 101, 103], "parent": 7, "modul": [7, 10, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 81, 92, 93, 100, 103, 105, 106], "__init__": [7, 8, 105, 106], "py": [7, 10, 43, 44, 45, 50, 51, 56, 59, 61, 62, 63, 67, 102, 104], "guarante": 7, "stabil": [7, 98, 106], "underscor": 7, "_alpaca": 7, "collect": [7, 78, 103], "differ": [7, 9, 24, 25, 26, 72, 98, 100, 102, 104, 105, 106], "itself": 7, "via": [7, 9, 31, 37, 69, 75, 105, 106], "pair": [7, 90, 101], "k1": [7, 8], "v1": [7, 8, 38], "k2": [7, 8], "v2": [7, 8], "lora_finetune_single_devic": [7, 100, 102, 103, 104, 105, 106], "checkpoint": [7, 8, 66, 73, 75, 76, 89, 92, 98, 104, 105, 106], "home": 7, "my_model_checkpoint": 7, "file_1": 7, "file_2": 7, "my_tokenizer_path": 7, "class": [7, 9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 31, 34, 59, 60, 61, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 75, 76, 77, 86, 87, 88, 89, 100, 101, 103, 105, 106], "assign": 7, "nest": 7, "dot": 7, "notat": [7, 59, 63, 64, 65], "core": [8, 98, 101, 103, 106], "i": [8, 18, 20, 59, 64, 65, 66, 71, 73, 78, 101, 102, 104, 106], "structur": [8, 14, 15, 18, 20, 24, 100, 101, 102], "new": [8, 32, 54, 86, 88, 100, 102, 103, 104, 105, 106], "user": [8, 14, 15, 18, 19, 20, 22, 23, 24, 59, 72, 100, 101, 103], "thought": [8, 98, 103, 106], "target": [8, 98], "pipelin": [8, 98], "llm": [8, 96, 98, 101, 102, 105], "eg": [8, 64, 75, 98], "meaning": [8, 98, 102], "featur": [8, 9, 97, 98, 102, 103], "fsdp": [8, 74, 81, 98, 103, 104], "activ": [8, 60, 92, 98, 106], "gradient": [8, 98, 102, 104, 105, 106], "accumul": [8, 98], "mix": [8, 102], "precis": [8, 66, 80, 98, 103, 106], "appli": [8, 24, 26, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 62, 63, 64, 65, 92, 98, 106], "given": [8, 10, 17, 23, 69, 78, 79, 80, 98, 105], "complex": 8, "becom": [8, 97, 101], "harder": 8, "anticip": 8, "architectur": [8, 18, 20, 64, 101], "methodolog": 8, "reason": [8, 78, 102], "possibl": [8, 24, 27, 31, 101], "trade": 8, "off": [8, 72, 102], "memori": [8, 25, 26, 27, 28, 29, 30, 32, 34, 37, 38, 66, 81, 96, 98, 101, 102, 103, 104], "vs": [8, 103], "qualiti": [8, 102, 105], "believ": 8, "best": [8, 100], "suit": [8, 103], "specif": [8, 10, 81, 100, 101, 102, 106], "b": [8, 59, 61, 63, 64, 65, 69, 89, 105, 106], "fit": [8, 24, 26, 27, 28, 29, 30, 32, 34, 37, 38], "solut": 8, "result": [8, 72, 102, 104, 105, 106], "meant": [8, 66], "depend": [8, 9, 13, 102, 105, 106], "level": [8, 82, 98, 106], "expertis": 8, "routin": 8, "yourself": [8, 104, 105], "exist": [8, 97, 101, 102, 103, 104, 106], "ad": [8, 72, 100, 105, 106], "ones": 8, "modular": [8, 98], "build": [8, 31, 34, 37, 98, 104, 105], "block": [8, 27, 43, 44, 45, 50, 51, 53, 56, 98], "wandb": [8, 9, 89, 103], "log": [8, 82, 86, 87, 88, 89, 102, 103, 104, 106], "fulli": [8, 25], "nativ": [8, 96, 98, 105, 106], "pytorch": [8, 64, 66, 74, 88, 91, 92, 93, 96, 97, 98, 104, 105, 106], "correct": [8, 16, 33, 62, 63, 64, 79, 98, 100, 101], "numer": [8, 98], "pariti": [8, 98], "verif": 8, "extens": [8, 98], "comparison": [8, 105, 106], "benchmark": [8, 93, 98, 102, 104, 105], "limit": 8, "hidden": [8, 60], "behind": 8, "100": [8, 26, 29, 30, 33, 35, 36, 78, 90, 91, 105, 106], "flag": [8, 26, 29, 30, 33, 35, 74, 81, 106], "prefer": [8, 98, 101], "over": [8, 67, 77, 98, 101, 102, 104, 105, 106], "unnecessari": 8, "abstract": [8, 14, 17, 98, 103, 106], "No": [8, 98], "inherit": [8, 77, 98], "go": [8, 18, 20, 72, 98, 101, 102, 103, 106], "upon": [8, 25, 104], "figur": [8, 105, 106], "spectrum": 8, "decid": 8, "interact": [8, 96, 103], "start": [8, 9, 25, 73, 97, 98, 100, 101, 102, 103], "paradigm": 8, "consist": [8, 38, 103], "configur": [8, 26, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 65, 98, 100, 103, 104, 105, 106], "paramet": [8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 53, 54, 56, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 92, 93, 96, 98, 100, 101, 102, 103, 104, 105, 106], "overrid": [8, 11, 102, 103, 104, 106], "togeth": [8, 27, 89, 103, 105], "valid": [8, 23, 97, 102, 103], "environ": [8, 97, 102, 103], "logic": [8, 75, 98, 103, 105], "api": [8, 9, 46, 47, 52, 55, 58, 100, 102, 103, 104, 106], "closer": [8, 105], "monolith": [8, 98], "trainer": [8, 83], "A": [8, 9, 22, 25, 27, 59, 64, 65, 66, 69, 72, 73, 74, 75, 77, 90, 95, 96, 99, 100, 102, 105, 106], "wrapper": [8, 72, 73, 105], "around": [8, 24, 72, 73, 91, 100, 102, 105, 106], "extern": 8, "primarili": [8, 25, 105], "eleutherai": [8, 98, 105], "har": [8, 98, 105], "control": [8, 26, 29, 30, 33, 35, 93, 102], "multi": [8, 24, 59, 104], "stage": 8, "distil": 8, "oper": [8, 25, 91, 93], "turn": [8, 19, 23, 24, 73, 100], "dataload": [8, 27, 29, 30, 33, 35], "applic": [8, 59, 75, 76, 89], "clean": [8, 9, 29], "after": [8, 59, 61, 62, 64, 65, 86, 87, 88, 89, 100, 106], "process": [8, 9, 66, 93, 103, 106], "group": [8, 59, 86, 87, 88, 89, 104], "init_process_group": [8, 84], "backend": 8, "gloo": 8, "els": [8, 77, 89, 98, 106], "nccl": 8, "fullfinetunerecipedistribut": 8, "cleanup": 8, "other": [8, 10, 25, 77, 81, 101, 103, 104, 105], "stuff": 8, "carri": 8, "relev": [8, 19, 102, 105], "interfac": [8, 14, 17, 25, 68], "metric": [8, 103], "logger": [8, 82, 86, 87, 88, 89, 103], "self": [8, 9, 27, 43, 44, 45, 50, 51, 53, 56, 59, 64, 65, 68, 101, 105, 106], "_devic": 8, "get_devic": 8, "_dtype": 8, "get_dtyp": 8, "ckpt_dict": 8, "wrap": [8, 74, 81, 91, 92, 100], "_model": 8, "_setup_model": 8, "_token": [8, 101], "_setup_token": 8, "_optim": 8, "_setup_optim": 8, "_loss_fn": 8, "_setup_loss": 8, "_sampler": 8, "_dataload": 8, "_setup_data": 8, "backward": [8, 106], "zero_grad": 8, "curr_epoch": 8, "rang": [8, 93, 104], "epochs_run": [8, 9], "total_epoch": [8, 9], "idx": [8, 27], "batch": [8, 27, 29, 30, 33, 35, 59, 61, 63, 64, 65, 72, 90, 98, 101, 103, 104, 105], "enumer": 8, "_autocast": 8, "logit": [8, 78], "label": [8, 24, 26, 27, 28, 29, 30, 31, 32, 34, 36, 37, 38, 90], "global_step": 8, "_log_every_n_step": 8, "_metric_logg": 8, "log_dict": [8, 86, 87, 88, 89], "step": [8, 27, 64, 67, 73, 86, 87, 88, 89, 91, 96, 102, 105, 106], "learn": [8, 25, 67, 98, 100, 101, 103, 104, 105, 106], "decor": [8, 11], "recipe_main": [8, 11], "none": [8, 9, 12, 13, 16, 17, 20, 21, 23, 24, 26, 27, 28, 31, 32, 34, 36, 37, 38, 59, 61, 63, 64, 65, 71, 72, 73, 75, 76, 78, 79, 80, 82, 86, 87, 88, 89, 92, 93, 100, 102], "fullfinetunerecip": 8, "direct": [8, 97], "wandblogg": [9, 105, 106], "workspac": 9, "seen": [9, 105, 106], "screenshot": 9, "below": [9, 63, 74, 101, 104, 105, 106], "packag": [9, 88, 89, 97], "pip": [9, 88, 89, 97, 102, 104], "Then": [9, 103], "login": [9, 89, 102], "built": [9, 97, 100, 101, 103, 106], "project": [9, 43, 44, 45, 50, 51, 53, 56, 59, 60, 81, 89, 96, 105, 106], "grab": [9, 104], "tab": 9, "tip": 9, "straggler": 9, "background": 9, "crash": 9, "otherwis": [9, 100], "exit": [9, 97], "resourc": [9, 86, 87, 88, 89], "kill": 9, "ps": 9, "aux": 9, "grep": 9, "awk": 9, "xarg": 9, "click": 9, "sampl": [9, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 34, 36, 37, 59, 63, 64, 65, 78, 100, 101, 102], "desir": [9, 24, 100], "suggest": 9, "approach": [9, 25, 101], "full_finetun": 9, "joinpath": 9, "_checkpoint": [9, 102], "_output_dir": [9, 75, 76], "torchtune_model_": 9, "with_suffix": 9, "wandb_at": 9, "artifact": 9, "type": [9, 10, 11, 19, 22, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 53, 54, 56, 57, 59, 61, 62, 63, 64, 65, 66, 69, 70, 72, 73, 74, 75, 76, 78, 80, 81, 82, 83, 84, 91, 92, 102, 105, 106], "descript": [9, 31, 36], "whatev": 9, "metadata": 9, "seed_kei": 9, "epochs_kei": 9, "total_epochs_kei": 9, "max_steps_kei": 9, "max_steps_per_epoch": 9, "add_fil": 9, "log_artifact": 9, "field": [10, 17, 19, 22, 24, 27, 29, 30, 33, 35], "hydra": 10, "facebook": 10, "research": 10, "http": [10, 24, 26, 28, 31, 32, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 50, 51, 52, 54, 55, 56, 57, 58, 59, 62, 63, 67, 74, 75, 76, 77, 82, 88, 89, 91, 92, 93, 97, 102], "com": [10, 43, 44, 45, 50, 51, 56, 59, 62, 63, 67, 97], "facebookresearch": [10, 62, 63], "blob": [10, 43, 44, 45, 50, 51, 56, 59, 62, 63, 67], "main": [10, 11, 59, 62, 63, 97, 102, 104], "_intern": 10, "_instantiate2": 10, "l148": 10, "omegaconf": 10, "num_lay": [10, 64], "32": [10, 104, 105, 106], "num_head": [10, 59, 61, 63, 64], "num_kv_head": [10, 59, 61], "vocab_s": 10, "must": [10, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 68, 73, 77, 106], "return": [10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 53, 54, 56, 57, 59, 61, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 90, 91, 93, 100, 101, 105, 106], "nn": [10, 59, 60, 61, 64, 65, 66, 68, 70, 71, 74, 92, 105, 106], "parsed_yaml": 10, "embed_dim": [10, 59, 63, 65, 105], "valueerror": [10, 20, 23, 31, 36, 59, 61, 64, 75, 76, 80, 93], "callabl": [11, 24, 26, 64, 74, 78, 81, 92], "With": [11, 102, 105, 106], "my_recip": 11, "foo": 11, "bar": [11, 98, 103], "instanti": [12, 39, 40, 41, 42, 43, 44, 45, 48, 49, 50, 51, 53, 54, 56, 57], "configerror": 12, "cannot": [12, 104], "data": [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 86, 87, 88, 89, 101, 102, 106], "prompt": [13, 14, 16, 17, 18, 20, 21, 22, 24, 26, 29, 30, 31, 33, 34, 35, 36, 37, 64, 72, 78, 101, 102, 104], "templat": [13, 14, 16, 17, 21, 24, 26, 29, 30, 33, 34, 35, 36], "style": [13, 27, 29, 30, 31, 36, 106], "slightli": 13, "classmethod": [13, 14, 15, 16, 17, 18, 19, 20, 21], "map": [13, 16, 17, 21, 22, 24, 25, 26, 27, 34, 71, 75, 86, 87, 88, 89, 100, 102, 105], "column_map": [13, 16, 17, 21, 24, 26, 34, 101], "placehold": [13, 14, 16, 17, 21, 24, 26, 34], "column": [13, 16, 17, 21, 24, 26, 28, 34, 37, 59, 64, 65, 100], "ident": [13, 16, 17, 20, 21, 26, 27, 34, 102], "role": [14, 19, 22, 24, 72, 100, 101], "system": [14, 15, 18, 19, 20, 22, 23, 24, 72, 100, 101], "assist": [14, 15, 18, 19, 22, 23, 24, 72, 78, 100, 101], "messag": [14, 15, 18, 20, 22, 23, 24, 31, 72, 73, 97, 100, 101], "accord": [14, 20, 100], "openai": 15, "markup": 15, "languag": [15, 69, 78, 105], "It": [15, 20, 100, 101, 106], "huggingfac": [15, 24, 26, 28, 31, 32, 34, 37, 38, 57, 67, 75, 76, 101, 102], "im_start": 15, "context": [15, 57, 91, 101], "im_end": 15, "goe": 15, "respons": [15, 72, 101, 102, 103, 104], "appropri": [15, 18, 20, 25, 67, 101, 106], "tag": [15, 18, 20, 24, 73, 86, 87, 88, 89, 100], "grammar": [16, 33, 101], "sentenc": [16, 27], "alwai": [17, 77], "human": [18, 22, 100], "taken": [18, 105, 106], "inst": [18, 20, 24, 100, 101], "sy": [18, 100, 101], "respect": [18, 25, 71, 100, 101], "honest": [18, 100, 101], "am": [18, 20, 100, 101, 102, 104], "pari": [18, 20, 101], "capit": [18, 20, 101], "franc": [18, 20, 101], "known": [18, 20, 72, 101], "its": [18, 20, 27, 59, 63, 64, 65, 93, 101, 102, 104, 105], "stun": [18, 20, 101], "liter": [19, 43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58], "mask": [19, 26, 27, 29, 30, 33, 35, 59, 64, 65, 72, 73, 100, 101], "ipython": 19, "eot": 19, "dataclass": [19, 100], "repres": [19, 100], "individu": [19, 27, 89, 92, 100, 101], "tiktoken": [19, 73, 104], "special": [19, 24, 73], "variabl": [19, 24, 25, 26, 34, 106], "writer": 19, "whether": [19, 22, 24, 26, 29, 30, 31, 33, 34, 35, 36, 43, 44, 45, 50, 51, 53, 56, 66, 69, 72, 73, 74, 80, 100], "correspond": [19, 68, 70, 80, 103, 104], "consecut": [19, 23], "from_dict": [19, 100], "construct": [19, 105], "dictionari": [19, 27, 86, 87, 88, 89, 102], "mistral": [20, 24, 36, 53, 54, 55, 100, 102, 103], "llama2chatformat": [20, 100, 101], "summar": [21, 35, 100, 101], "task": [21, 25, 32, 100, 101, 102, 104, 105, 106], "dialogu": [21, 35, 100], "dialog": 21, "adher": 22, "sharegpt": [22, 31, 101], "gpt": [22, 59, 102], "remain": [22, 67, 105], "unmask": 22, "forth": 23, "come": [23, 68, 105], "empti": 23, "shorter": 23, "length": [23, 25, 26, 27, 28, 29, 30, 32, 34, 36, 37, 38, 57, 59, 61, 63, 64, 65, 72, 73, 76, 90], "min": [23, 105], "invalid": 23, "convert_to_messag": [24, 100], "chat_format": [24, 31, 36, 100, 101], "chatformat": [24, 31, 101], "load_dataset_kwarg": [24, 26, 28, 31, 32, 34, 37, 38], "multiturn": [24, 100], "foreach": 24, "prepar": [24, 100], "truncat": [24, 26, 27, 28, 32, 34, 36, 37, 38, 72, 73], "encod": [24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 72, 73, 100], "decod": [24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 64, 72, 73, 78, 100], "anyth": [24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], "load_dataset": [24, 26, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 100], "co": [24, 26, 28, 31, 32, 34, 37, 38, 57, 75, 76, 102], "doc": [24, 26, 28, 31, 32, 34, 37, 38, 74, 77, 82, 88, 89, 91, 93, 102], "en": [24, 26, 28, 31, 32, 34, 37, 38], "package_refer": [24, 26, 28, 31, 32, 34, 37, 38], "loading_method": [24, 26, 28, 31, 32, 34, 37, 38], "text": [24, 27, 28, 32, 37, 38, 72, 73, 100, 101, 102], "extra": [24, 97, 105, 106], "still": [24, 77, 105, 106], "llama3": [24, 36, 48, 49, 50, 51, 52, 78, 81, 96], "where": [24, 25, 29, 30, 33, 35, 59, 64, 69, 72, 101], "unless": 24, "check": [24, 31, 64, 80, 96, 100, 102, 103, 105], "concaten": [25, 72, 101], "sub": [25, 88], "unifi": 25, "were": [25, 100, 103], "simplifi": [25, 105], "simultan": 25, "intern": [25, 77], "aggreg": 25, "transpar": 25, "index": [25, 59, 63, 64, 65, 67, 90, 97, 100, 102], "howev": [25, 97], "constitu": 25, "might": [25, 102], "larg": [25, 69, 106], "comput": [25, 59, 60, 63, 64, 93, 102, 106], "cumul": 25, "maintain": [25, 106], "indic": [25, 27, 59, 63, 64, 65, 74, 100, 101], "deleg": 25, "retriev": [25, 81], "lead": [25, 72], "high": [25, 98, 105], "scale": [25, 43, 44, 45, 50, 51, 53, 56, 69, 78, 105, 106], "consid": 25, "strategi": 25, "stream": [25, 82], "demand": 25, "deriv": [25, 60, 64, 65], "_dataset": 25, "_len": 25, "total": [25, 67, 83, 95, 99, 102, 104, 105], "combin": [25, 101], "_index": 25, "lookup": 25, "dataset1": 25, "mycustomdataset": 25, "params1": 25, "dataset2": 25, "params2": 25, "concat_dataset": 25, "data_point": 25, "1500": 25, "element": [25, 73, 102], "focus": [25, 103], "enhanc": [25, 106], "divers": 25, "machin": [25, 79, 102], "instructtempl": [26, 101], "contribut": [26, 29, 30, 33, 35], "replac": [26, 29, 30, 33, 35, 66, 105], "disabl": [26, 28, 32, 34, 37, 38, 93], "recommend": [26, 28, 29, 30, 32, 34, 37, 38, 88, 100, 102, 106], "highest": [26, 28, 29, 30, 32, 34, 37, 38], "sequenc": [26, 27, 28, 29, 30, 32, 34, 36, 37, 38, 59, 61, 63, 64, 65, 72, 73, 90, 100], "ds": [27, 36], "max_pack": 27, "split_across_pack": 27, "greedi": 27, "pack": [27, 29, 30, 31, 33, 34, 35, 36, 59, 63, 64, 65], "done": [27, 80, 105, 106], "preprocess": 27, "outsid": [27, 93, 102, 104, 105], "sampler": [27, 103], "part": [27, 100, 106], "buffer": 27, "long": [27, 100, 105], "enough": [27, 100], "attent": [27, 43, 44, 45, 50, 51, 53, 56, 57, 59, 61, 63, 64, 65, 104, 105, 106], "lower": [27, 105], "triangular": 27, "cross": 27, "attend": [27, 59, 64, 65], "rel": [27, 59, 63, 64, 65, 105], "pad": [27, 78, 90], "max": [27, 36, 64, 67, 72, 105], "wise": 27, "collat": [27, 90], "made": [27, 31, 34, 37, 63, 102], "smaller": [27, 102, 104, 105, 106], "jam": 27, "vari": 27, "s1": [27, 72], "s2": [27, 72], "s3": 27, "s4": 27, "contamin": 27, "input_po": [27, 59, 61, 63, 64, 65], "matrix": 27, "causal": [27, 59, 64, 65], "continu": 27, "increment": 27, "last": [27, 67], "move": [27, 64], "entir": [27, 100, 106], "avoid": [27, 62, 66, 93, 106], "freeform": [28, 37], "unstructur": [28, 38], "corpu": [28, 32, 38], "local": [28, 89, 93, 97, 100, 102, 103], "yahma": 29, "codebas": [29, 30, 33, 35, 102], "prior": [29, 30, 31, 33, 34, 35, 36], "alpaca_d": [29, 30], "batch_siz": [29, 30, 33, 35, 59, 61, 64, 65, 102], "tatsu": [30, 101], "lab": [30, 101], "conversation_styl": [31, 101], "chatdataset": [31, 36, 100], "friendli": [31, 34, 37, 78, 100], "huggingfaceh4": 31, "no_robot": 31, "chatmlformat": 31, "2096": [31, 37], "accomplish": [31, 37], "ccdv": 32, "cnn_dailymail": 32, "textcompletiondataset": [32, 37, 38], "similar": [32, 38, 101, 102, 104, 105, 106], "cnn": 32, "dailymail": 32, "articl": [32, 38], "extract": 32, "highlight": [32, 106], "liweili": 33, "c4_200m": 33, "variant": [33, 35], "mirror": [33, 35], "llama_recip": [33, 35], "grammar_d": 33, "samsum": [35, 101], "summari": [35, 101], "samsum_d": 35, "open": [36, 39, 101, 102], "orca": [36, 101], "slimorca": [36, 101], "dedup": [36, 101], "1024": [36, 101], "prescrib": 36, "least": [36, 104, 105], "though": [36, 100], "10": [36, 90, 102, 104, 106], "351": 36, "82": [36, 102], "391": 36, "221": 36, "220": 36, "193": 36, "12": [36, 97], "471": 36, "textdataset": 37, "allenai": 37, "c4": 37, "data_dir": [37, 101], "realnewslik": 37, "wikitext": 38, "subset": [38, 70], "103": [38, 102], "raw": 38, "wikipedia": 38, "page": [38, 97, 98, 103, 104], "gemma": 39, "gemmatransformerdecod": 39, "w": [39, 40, 41, 42, 48, 49, 54, 88, 89, 100, 102, 105, 106], "blog": 39, "technolog": 39, "develop": [39, 106], "transformerdecod": [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 78, 105], "arxiv": [40, 41, 42, 46, 47, 52, 55, 58, 59, 62, 63], "org": [40, 41, 42, 46, 47, 52, 55, 58, 59, 62, 63, 74, 77, 82, 88, 91, 92, 93, 97], "ab": [40, 41, 42, 46, 47, 52, 55, 58, 63], "2307": [40, 41, 42], "09288": [40, 41, 42], "70b": [41, 44, 48, 50, 104], "lora_attn_modul": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 105, 106], "q_proj": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 105, 106], "k_proj": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 105, 106], "v_proj": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 105, 106], "output_proj": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 105, 106], "apply_lora_to_mlp": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 105], "apply_lora_to_output": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 105], "lora_rank": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 105], "lora_alpha": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 105], "float": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 59, 62, 67, 69, 78, 86, 87, 88, 89, 105, 106], "16": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 105, 106], "lora_dropout": [43, 44, 45, 46, 47], "05": [43, 44, 45, 46, 47], "quantize_bas": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 69, 106], "lora": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 69, 75, 96, 98, 100, 103, 104], "tloen": [43, 44, 45, 50, 51, 56], "8bb8579e403dc78e37fe81ffbb253c413007323f": [43, 44, 45, 50, 51, 56], "l41": [43, 44, 45, 50, 51, 56], "l43": [43, 44, 45, 50, 51, 56], "linear": [43, 44, 45, 46, 47, 50, 51, 52, 53, 55, 56, 58, 64, 68, 69, 105, 106], "mlp": [43, 44, 45, 50, 51, 53, 56, 64, 65, 104, 105], "final": [43, 44, 45, 50, 51, 53, 56, 60, 64, 73, 102, 104, 105, 106], "rank": [43, 44, 45, 50, 51, 53, 56, 69, 83, 93, 103, 105, 106], "low": [43, 44, 45, 50, 51, 53, 56, 69, 102, 105, 106], "approxim": [43, 44, 45, 50, 51, 53, 56, 69, 105], "factor": [43, 44, 45, 50, 51, 53, 56, 69, 102], "llama2_70b": 44, "llama2_7b": [45, 105], "qlora": [46, 47, 52, 55, 58, 66, 96, 98, 104, 105], "per": [46, 47, 52, 55, 58, 61, 66, 104, 106], "paper": [46, 47, 52, 55, 58, 105, 106], "2305": [46, 47, 52, 55, 58, 59], "14314": [46, 47, 52, 55, 58], "lora_llama2_13b": 46, "lora_llama2_7b": [47, 105], "llama3_70b": 50, "llama3_8b": [51, 78, 104], "lora_llama3_8b": 52, "announc": 54, "lora_mistral_7b": 55, "phi3": [56, 57, 58], "phi3_mini": 56, "ref": [57, 89], "phi": 57, "128k": 57, "nor": 57, "slide": 57, "window": 57, "lora_phi3_mini": 58, "head_dim": [59, 61, 64], "pos_embed": [59, 105], "kv_cach": 59, "kvcach": [59, 64], "attn_dropout": [59, 64], "head": [59, 61, 63, 64, 104], "queri": [59, 61, 64, 65, 104], "gqa": 59, "introduc": [59, 62, 69, 100, 105, 106], "pdf": [59, 62], "13245v1": 59, "version": [59, 78, 97, 104, 106], "multihead": 59, "mha": [59, 64], "n": [59, 72, 73, 95, 99, 100, 101], "extrem": 59, "share": [59, 101, 102], "mqa": 59, "credit": 59, "document": [59, 74, 81], "lightn": 59, "lit": 59, "lit_gpt": 59, "v": [59, 64, 105], "k": [59, 105], "q": [59, 105], "n_kv_head": 59, "dimens": [59, 61, 63, 64, 69, 104, 105, 106], "calcul": [59, 64, 104], "e": [59, 66, 68, 71, 75, 97, 102, 104, 105, 106], "g": [59, 68, 75, 104, 105, 106], "rotarypositionalembed": [59, 105], "cach": [59, 61, 63, 64, 97], "rope": [59, 63], "dropout": [59, 69, 105, 106], "onto": 59, "scaled_dot_product_attent": 59, "seq_length": [59, 65, 78], "boolean": [59, 64, 65, 74], "softmax": [59, 64, 65], "row": [59, 64, 65, 100], "j": [59, 64, 65], "seq_len": 59, "bigger": 59, "n_h": [59, 63], "num": [59, 63], "n_kv": 59, "kv": [59, 61, 64], "emb": [59, 64, 65], "h_d": [59, 63], "gate_proj": 60, "down_proj": 60, "up_proj": 60, "silu": 60, "feed": [60, 65], "network": [60, 105, 106], "fed": [60, 100], "multipli": 60, "subclass": [60, 77], "although": [60, 105], "afterward": 60, "former": 60, "regist": [60, 66, 106], "hook": [60, 66, 106], "latter": 60, "standalon": 61, "past": 61, "becaus": [61, 64, 100, 102, 104], "expand": 61, "dpython": [61, 64, 66], "reset": [61, 64], "zero": [61, 62, 102, 104], "k_val": 61, "v_val": 61, "h": [61, 97], "longer": 61, "ep": 62, "1e": 62, "06": [62, 105], "root": [62, 88, 89], "squar": 62, "1910": 62, "07467": 62, "verfic": [62, 63], "small": [62, 102], "divis": 62, "10000": 63, "rotari": [63, 104], "propos": 63, "2104": 63, "09864": 63, "l450": 63, "upto": 63, "init": [63, 89, 106], "exceed": 63, "freq": 63, "recomput": 63, "geometr": 63, "progress": [63, 103], "rotat": 63, "angl": 63, "todo": 63, "effici": [63, 81, 96, 98, 102, 103, 105], "transformerdecoderlay": 64, "norm": [64, 65], "space": 64, "belong": 64, "reduc": [64, 98, 101, 105, 106], "statement": 64, "improv": [64, 81, 102, 104, 105], "readabl": [64, 102], "At": 64, "arang": 64, "prompt_length": 64, "causal_mask": 64, "m_": 64, "seq": 64, "reset_cach": 64, "setup_cach": 64, "attn": [65, 105, 106], "causalselfattent": [65, 105], "sa_norm": 65, "mlp_norm": 65, "ff": 65, "common_util": 66, "bfloat16": [66, 102, 103, 104, 105], "offload_to_cpu": 66, "nf4": [66, 106], "restor": 66, "higher": [66, 104, 106], "offload": [66, 106], "increas": [66, 67, 104, 105], "peak": [66, 102, 104, 105, 106], "gpu": [66, 102, 103, 104, 105, 106], "usag": [66, 97, 102, 103, 104, 106], "_register_state_dict_hook": 66, "m": [66, 73, 78, 100], "mymodul": 66, "_after_": 66, "nf4tensor": [66, 106], "unquant": [66, 102, 106], "unus": 66, "num_warmup_step": 67, "num_training_step": 67, "num_cycl": 67, "last_epoch": 67, "lambdalr": 67, "rate": [67, 98, 103], "schedul": [67, 91, 103], "linearli": 67, "lr": 67, "decreas": [67, 105, 106], "cosin": 67, "v4": 67, "23": [67, 104], "src": 67, "l104": 67, "warmup": [67, 91], "phase": 67, "wave": 67, "half": 67, "lr_schedul": 67, "peft": [68, 69, 70, 71, 75, 105, 106], "protocol": 68, "adapter_param": [68, 69, 70, 71], "proj": 68, "in_dim": [68, 69, 105, 106], "out_dim": [68, 69, 105, 106], "bia": [68, 69, 105, 106], "loralinear": [68, 105, 106], "alpha": [69, 105, 106], "use_bia": 69, "perturb": 69, "decomposit": [69, 105], "matric": [69, 105, 106], "trainabl": [69, 71, 105, 106], "mapsto": 69, "w_0x": 69, "r": [69, 73, 105], "bax": 69, "probabl": [69, 78, 102], "lora_a": [69, 105, 106], "lora_b": [69, 105, 106], "get_adapter_param": [71, 105], "sentencepieceprocessor": 72, "pretrain": [72, 73, 100, 103, 105, 106], "non": 72, "spm_model": [72, 100], "tokenized_text": 72, "hello": [72, 100, 102, 104], "world": [72, 83, 102], "add_bo": [72, 73, 100], "add_eo": [72, 73, 100], "31587": 72, "29644": 72, "102": 72, "trim_leading_whitespac": 72, "prefix": 72, "unbatch": 72, "prepend": [72, 73], "bo": [72, 73, 100], "append": [72, 97], "eo": [72, 73, 100], "trim": 72, "whitespac": 72, "underli": [72, 106], "sentencepiec": [72, 104], "due": [72, 105, 106], "tokenize_messag": [72, 73, 100, 101], "problem": 72, "slice": 72, "tokenizer_path": 72, "separ": [72, 75, 100, 103, 104, 105, 106], "concat": 72, "1788": 72, "2643": 72, "13": [72, 102, 104, 106], "1792": 72, "9508": 72, "465": 72, "22137": 72, "2933": 72, "join": 72, "attribut": 72, "llama3_tiktoken": 73, "p": [73, 74, 105, 106], "l": 73, "all_special_token": 73, "bos_token": 73, "begin_of_text": [73, 100], "eos_token": 73, "end_of_text": 73, "start_header_id": [73, 100], "end_header_id": [73, 100], "step_id": 73, "eom_id": 73, "eot_id": [73, 100], "python_tag": 73, "identif": 73, "regex": 73, "second": [73, 102, 104, 105, 106], "uniqu": 73, "256": [73, 101, 102, 104], "header": [73, 100], "token_id": 73, "truncate_at_eo": 73, "tokenize_head": 73, "datatyp": [74, 106], "polici": [74, 81, 92], "denot": 74, "integ": [74, 90, 93], "auto_wrap_polici": [74, 81, 92], "submodul": 74, "obei": 74, "contract": 74, "get_fsdp_polici": 74, "modules_to_wrap": [74, 81], "min_num_param": 74, "my_fsdp_polici": 74, "recurs": [74, 88], "isinst": 74, "sum": [74, 105], "numel": [74, 105], "1000": 74, "functool": 74, "partial": 74, "stabl": [74, 88, 91, 93, 97], "html": [74, 77, 82, 88, 91, 92, 93], "alia": 74, "from_pretrain": 75, "few": [75, 101, 104, 105, 106], "0001_of_0003": 75, "0002_of_0003": 75, "preserv": [75, 106], "weight_map": [75, 102], "intermediate_checkpoint": [75, 76], "parit": 75, "_weight_map": 75, "shard": [76, 104], "wip": 76, "argpars": 77, "argumentpars": 77, "builtin": 77, "said": 77, "noth": 77, "treat": [77, 100], "consult": 77, "info": [77, 103], "librari": [77, 82, 93, 96, 98, 106], "parse_known_arg": 77, "namespac": 77, "act": 77, "precid": 77, "parse_arg": 77, "properti": [77, 105], "too": [77, 104], "max_generated_token": 78, "pad_id": 78, "temperatur": [78, 102], "top_k": [78, 102], "stop_token": 78, "custom_generate_next_token": 78, "condit": [78, 101], "bsz": 78, "predict": 78, "prune": [78, 106], "stop": 78, "compil": [78, 102, 104, 106], "generate_next_token": 78, "llama3_token": [78, 104], "hi": [78, 100], "my": [78, 100, 102, 104], "jeremi": 78, "availab": 79, "distribut": [79, 84, 92, 93, 98, 103, 104], "bf16": [80, 106], "request": [80, 101, 102], "inde": [80, 102], "kernel": 80, "runtimeerror": [80, 84], "float32": 80, "isn": 80, "hardwar": [80, 98, 102, 105], "memory_efficient_fsdp_wrap": 81, "maxim": [81, 96, 98], "been": [81, 104], "workload": 81, "15": [81, 100, 102, 105, 106], "alongsid": 81, "ac": 81, "fullyshardeddataparallel": 81, "const": 81, "fsdppolicytyp": 81, "handler": 82, "aka": 83, "filenam": 86, "log_": 86, "unixtimestamp": 86, "txt": [86, 103], "thread": 86, "safe": 86, "flush": [86, 87, 88, 89], "union": [86, 87, 88, 89, 92, 93], "ndarrai": [86, 87, 88, 89], "scalar": [86, 87, 88, 89], "record": [86, 87, 88, 89], "payload": [86, 87, 88, 89], "organize_log": 88, "tensorboard": 88, "subdirectori": 88, "compar": [88, 102, 105, 106], "logdir": 88, "startup": 88, "tree": [88, 101, 102], "tfevent": 88, "encount": 88, "frontend": 88, "organ": 88, "accordingli": 88, "my_log_dir": 88, "view": [88, 102, 103], "my_metr": [88, 89], "termin": [88, 89], "entiti": 89, "bias": 89, "sent": 89, "usernam": 89, "my_project": 89, "my_ent": 89, "my_group": 89, "importerror": 89, "account": [89, 105, 106], "log_config": 89, "link": [89, 102], "capecap": 89, "6053ofw0": 89, "torchtune_config_j67sb73v": 89, "padding_idx": 90, "ignore_idx": 90, "longest": 90, "token_pair": 90, "torchtune_perf_trac": 91, "contextmanag": 91, "wait": 91, "trace": 91, "speed": [91, 104, 106], "reduct": [91, 105], "acwrappolicytyp": 92, "describ": [92, 101], "author": [92, 98, 103, 106], "intermedi": [92, 104, 106], "fsdp_adavnced_tutori": 92, "debug_mod": 93, "pseudo": 93, "random": [93, 103], "commonli": [93, 102, 105, 106], "numpi": 93, "own": [93, 100, 101, 102, 105], "determinist": 93, "global": 93, "warn": 93, "nondeterminist": 93, "addition": [93, 105], "cudnn": 93, "set_deterministic_debug_mod": 93, "algorithm": 93, "generated_examples_python": 94, "zip": 94, "galleri": [94, 99], "sphinx": 94, "000": [95, 99, 104], "execut": [95, 99], "generated_exampl": 95, "mem": [95, 99], "mb": [95, 99], "topic": 96, "gentl": 96, "introduct": 96, "readi": [96, 100], "workflow": [96, 101, 103, 105], "requisit": 97, "proper": [97, 103], "host": [97, 103], "latest": [97, 103, 106], "confirm": 97, "And": [97, 102, 104], "ls": [97, 102, 103, 104], "welcom": 97, "show": [97, 100, 105], "greatest": [97, 103], "contributor": 97, "cd": [97, 102], "even": [97, 100, 104, 105, 106], "commit": 97, "branch": 97, "url": 97, "whl": 97, "therebi": [97, 106], "forc": 97, "reinstal": 97, "opt": [97, 103], "suffix": 97, "cu121": 97, "On": [98, 105], "pointer": 98, "emphas": 98, "aspect": 98, "simplic": 98, "component": 98, "reus": 98, "prove": 98, "democrat": 98, "box": [98, 106], "zoo": 98, "varieti": [98, 105], "techniqu": [98, 102, 103, 105], "integr": [98, 102, 103, 104, 105, 106], "excit": 98, "checkout": 98, "quickstart": 98, "attain": 98, "better": [98, 100, 101, 102], "chekckpoint": 98, "hyperparamet": [98, 103, 105, 106], "embodi": 98, "philosophi": 98, "usabl": 98, "composit": 98, "hard": 98, "outlin": 98, "unecessari": 98, "never": 98, "thoroughli": 98, "unit": 98, "know": [100, 101, 102, 104, 105], "align": 100, "intend": 100, "nice": 100, "meet": 100, "overhaul": 100, "sai": [100, 101, 103], "accompani": 100, "who": 100, "influenti": 100, "hip": 100, "hop": 100, "artist": [100, 104], "2pac": 100, "rakim": 100, "c": 100, "na": 100, "flavor": [100, 101], "certain": 100, "msg": 100, "formatted_messag": [100, 101], "nyou": [100, 101], "nwho": 100, "sentencepiecetoken": 100, "why": [100, 103, 105], "user_messag": 100, "518": 100, "25580": 100, "29962": 100, "3532": 100, "14816": 100, "29903": 100, "6778": 100, "piece_to_id": 100, "reserv": [100, 106], "vector": 100, "place": 100, "manual": [100, 106], "529": 100, "29879": 100, "29958": 100, "tiktokentoken": 100, "nhere": 100, "_encode_special_token": 100, "128000": 100, "128009": 100, "pure": 100, "That": 100, "won": [100, 102, 104], "mess": 100, "govern": 100, "prime": 100, "strictli": 100, "summarizetempl": [100, 101], "lightweight": 100, "ask": 100, "untouch": 100, "nsummari": 100, "robust": 100, "csv": 100, "question": [100, 101, 102, 104], "answer": [100, 102, 104], "onlin": 100, "forum": 100, "panda": 100, "pd": 100, "df": 100, "read_csv": 100, "your_fil": 100, "nrow": 100, "tolist": 100, "iloc": 100, "gp": 100, "receiv": 100, "commun": [100, 102], "satellit": 100, "thing": [100, 106], "message_convert": 100, "input_msg": 100, "output_msg": 100, "assistant_messag": 100, "But": [100, 102, 104, 105], "mistralchatformat": 100, "custom_dataset": 100, "2048": 100, "data_fil": 100, "honor": 100, "copi": [100, 102, 103, 104, 106], "8b_lora_single_devic": [100, 104], "launch": [100, 103], "custom_8b_lora_single_devic": 100, "steer": 101, "wheel": 101, "publicli": 101, "great": [101, 102], "iter": [101, 106], "knob": 101, "tweak": 101, "footprint": [101, 105], "could": [101, 105], "achiev": [101, 102, 104, 105, 106], "concatdataset": 101, "instruct_dataset": 101, "vicgal": 101, "gpt4": 101, "alpacainstructtempl": 101, "demonstr": 101, "fix": 101, "goal": 101, "agnost": 101, "respond": 101, "further": [101, 105, 106], "classifi": 101, "anim": 101, "plant": 101, "miner": 101, "oak": 101, "copper": 101, "ore": 101, "eleph": 101, "mydataset": 101, "onthehub": 101, "customtempl": 101, "quit": [101, 106], "similarli": 101, "chat_dataset": 101, "incorpor": 101, "advanc": 101, "preferencedataset": 101, "rlhf": 101, "adjust": 101, "chosen": 101, "reject": 101, "chosen_messag": 101, "transformed_sampl": 101, "key_chosen": 101, "rejected_messag": 101, "key_reject": 101, "chosen_input_id": 101, "c_mask": 101, "chosen_label": 101, "np": 101, "cross_entropy_ignore_idx": 101, "rejected_input_id": 101, "r_mask": 101, "rejected_label": 101, "purpos": [101, 103, 104], "stack_exchanged_paired_dataset": 101, "had": 101, "lvwerra": 101, "stack": 101, "exchang": 101, "stackexchangedpairedtempl": 101, "response_j": 101, "response_k": 101, "rl": 101, "favorit": [102, 104, 105], "seemlessli": 102, "beyond": [102, 106], "connect": 102, "larger": [102, 104], "amount": 102, "natur": 102, "export": 102, "mobil": 102, "phone": 102, "leverag": [102, 104, 106], "mode": 102, "lot": 102, "plai": 102, "freez": [102, 105], "percentag": 102, "learnabl": 102, "keep": [102, 105], "16gb": [102, 105], "rtx": 102, "3090": 102, "4090": 102, "hour": 102, "full_finetune_single_devic": [102, 103], "7b_full_low_memori": [102, 103], "full_finetune_distribut": [102, 103], "7b_full": [102, 103], "13b_full": [102, 103], "7b_qlora_single_devic": [102, 103, 106], "473": 102, "98": [102, 106], "gb": [102, 104, 105, 106], "50": 102, "484": 102, "01": [102, 103], "fact": [102, 104, 105], "third": 102, "realli": 102, "eleuther_ev": [102, 104], "eleuther_evalu": [102, 104], "lm_eval": [102, 104], "plan": 102, "custom_eval_config": [102, 104], "truthfulqa_mc2": [102, 104, 105], "measur": [102, 104], "propens": [102, 104], "shot": [102, 104], "accuraci": [102, 104, 105, 106], "baselin": [102, 105], "324": 102, "loglikelihood": 102, "195": 102, "121": 102, "27": 102, "197": 102, "acc": 102, "388": 102, "38": 102, "shown": 102, "489": 102, "48": [102, 106], "seem": 102, "custom_generation_config": [102, 104], "kick": 102, "300": 102, "interest": 102, "site": 102, "visit": 102, "bai": 102, "area": 102, "92": [102, 104], "exploratorium": 102, "san": 102, "francisco": 102, "magazin": 102, "awesom": 102, "bridg": 102, "pretti": 102, "cool": 102, "96": [102, 106], "61": 102, "sec": [102, 104], "25": 102, "83": 102, "99": [102, 105], "72": 102, "littl": 102, "saw": 102, "took": [102, 104], "torchao": [102, 104, 106], "bit": [102, 104, 105, 106], "custom_quantization_config": [102, 104], "68": 102, "19": [102, 104, 106], "76": 102, "69": 102, "95": [102, 104], "67": 102, "4w": [102, 104], "unlik": [102, 104], "engin": [102, 104], "fullmodeltorchtunecheckpoint": [102, 104], "int4weightonlyquant": [102, 104], "groupsiz": [102, 104], "did": [102, 104, 106], "park": 102, "sit": 102, "top": [102, 106], "hill": 102, "beauti": 102, "62": [102, 104], "17": [102, 105], "85": 102, "hood": [102, 106], "sped": 102, "almost": [102, 104, 105], "3x": [102, 104], "benefit": 102, "doesn": 102, "yet": 102, "fast": 102, "clone": [102, 105, 106], "assumpt": 102, "satisfi": 102, "new_dir": 102, "output_dict": 102, "sd_1": 102, "sd_2": 102, "dump": 102, "convert_hf_checkpoint": 102, "checkpoint_path": 102, "justin": 102, "school": 102, "math": 102, "teacher": 102, "ws": 102, "94": [102, 104], "28": 102, "bandwidth": [102, 104], "1391": 102, "84": 102, "thats": 102, "seamlessli": 102, "authent": [102, 103], "hopefulli": 102, "gave": 102, "gate": 103, "grant": 103, "minut": 103, "agreement": 103, "altern": 103, "hackabl": 103, "singularli": 103, "technic": 103, "depth": 103, "principl": 103, "minim": [103, 105, 106], "boilerpl": 103, "hold": 103, "substanti": [103, 105], "custom_config": 103, "replic": 103, "lorafinetunerecipesingledevic": 103, "lora_finetune_output": 103, "log_1713194212": 103, "52": 103, "3697006702423096": 103, "25880": [103, 106], "24": [103, 104], "55": 103, "83it": 103, "monitor": 103, "tqdm": 103, "interv": 103, "e2": 103, "releas": 104, "focu": 104, "128": [104, 105], "theta": 104, "gain": 104, "illustr": 104, "basic": 104, "observ": 104, "18": 104, "consum": [104, 106], "vram": [104, 105], "overal": 104, "nproc_per_nod": [104, 105], "lora_finetune_distribut": [104, 105], "8b_lora": 104, "8b_qlora_single_devic": 104, "alloc": [104, 106], "coupl": [104, 105, 106], "122": 104, "sarah": 104, "busi": 104, "mum": 104, "young": 104, "children": 104, "live": 104, "north": 104, "east": 104, "england": 104, "135": 104, "88": 104, "138": 104, "346": 104, "09": 104, "139": 104, "31": 104, "far": 104, "drill": 104, "90": 104, "93": 104, "91": 104, "104": 104, "four": [104, 105], "again": 104, "jake": 104, "disciplin": 104, "passion": 104, "draw": 104, "paint": 104, "57": [104, 105, 106], "speedup": 104, "broader": 104, "teach": 105, "straight": 105, "jump": 105, "neural": [105, 106], "unfamiliar": 105, "oppos": [105, 106], "momentum": 105, "adamw": 105, "arbitrari": 105, "relat": 105, "aghajanyan": 105, "et": 105, "al": 105, "hypothes": 105, "intrins": 105, "down": [105, 106], "often": 105, "eight": 105, "practic": 105, "imag": 105, "left": 105, "blue": 105, "rememb": 105, "approx": 105, "15m": 105, "8192": 105, "65k": 105, "requires_grad": [105, 106], "frozen_out": [105, 106], "lora_out": [105, 106], "omit": 105, "base_model": 105, "choos": 105, "lora_model": 105, "lora_llama_2_7b": [105, 106], "alon": 105, "in_featur": 105, "out_featur": 105, "inplac": 105, "feel": 105, "free": 105, "strict": 105, "whenev": 105, "validate_state_dict_for_lora": 105, "peft_util": 105, "set_trainable_param": 105, "fetch": 105, "lora_param": 105, "total_param": 105, "trainable_param": 105, "2f": 105, "6742609920": 105, "4194304": 105, "nnode": 105, "7b_lora": 105, "my_model_checkpoint_path": [105, 106], "tokenizer_checkpoint": [105, 106], "my_tokenizer_checkpoint_path": [105, 106], "constraint": 105, "factori": 105, "benefici": 105, "impact": 105, "minor": 105, "good": 105, "64": 105, "lora_experiment_1": 105, "smooth": [105, 106], "curv": [105, 106], "500": 105, "ran": 105, "commod": 105, "cogniz": 105, "ax": 105, "parallel": 105, "truthfulqa": 105, "previous": 105, "475": 105, "87": 105, "508": 105, "86": 105, "504": 105, "04": 105, "514": 105, "lowest": 105, "absolut": 105, "4gb": 105, "tradeoff": 105, "potenti": 105, "highli": 106, "vanilla": 106, "held": 106, "therefor": 106, "bespok": 106, "normalfloat": 106, "8x": 106, "retain": 106, "vast": 106, "major": 106, "degrad": 106, "normatfloat": 106, "doubl": 106, "themselv": 106, "deepdiv": 106, "idea": 106, "distinct": 106, "storag": 106, "de": 106, "incur": 106, "counterpart": 106, "set_default_devic": 106, "qlora_linear": 106, "memory_alloc": 106, "177": 106, "152": 106, "byte": 106, "del": 106, "empty_cach": 106, "lora_linear": 106, "081": 106, "344": 106, "qlora_llama2_7b": 106, "qlora_model": 106, "essenti": 106, "reparametrize_as_dtype_state_dict_post_hook": 106, "stat": 106, "against": 106, "35": 106, "40": 106, "29": 106, "slow": 106, "slower": 106, "149": 106, "9157477021217346": 106, "02": 106, "08": 106, "14": 106, "15it": 106, "nightli": 106, "200": 106, "hundr": 106, "228": 106, "8158286809921265": 106, "59": 106, "95it": 106, "exercis": 106, "portion": 106, "augment": 106, "linear_nf4": 106, "to_nf4": 106, "linear_weight": 106, "autograd": 106, "regular": 106, "incom": 106}, "objects": {"torchtune.config": [[10, 0, 1, "", "instantiate"], [11, 0, 1, "", "parse"], [12, 0, 1, "", "validate"]], "torchtune.data": [[13, 1, 1, "", "AlpacaInstructTemplate"], [14, 1, 1, "", "ChatFormat"], [15, 1, 1, "", "ChatMLFormat"], [16, 1, 1, "", "GrammarErrorCorrectionTemplate"], [17, 1, 1, "", "InstructTemplate"], [18, 1, 1, "", "Llama2ChatFormat"], [19, 1, 1, "", "Message"], [20, 1, 1, "", "MistralChatFormat"], [21, 1, 1, "", "SummarizeTemplate"], [22, 0, 1, "", "sharegpt_to_llama2_messages"], [23, 0, 1, "", "validate_messages"]], "torchtune.data.AlpacaInstructTemplate": [[13, 2, 1, "", "format"]], "torchtune.data.ChatFormat": [[14, 2, 1, "", "format"]], "torchtune.data.ChatMLFormat": [[15, 2, 1, "", "format"]], "torchtune.data.GrammarErrorCorrectionTemplate": [[16, 2, 1, "", "format"]], "torchtune.data.InstructTemplate": [[17, 2, 1, "", "format"]], "torchtune.data.Llama2ChatFormat": [[18, 2, 1, "", "format"]], "torchtune.data.Message": [[19, 2, 1, "", "from_dict"]], "torchtune.data.MistralChatFormat": [[20, 2, 1, "", "format"], [20, 3, 1, "", "system"]], "torchtune.data.SummarizeTemplate": [[21, 2, 1, "", "format"]], "torchtune.datasets": [[24, 1, 1, "", "ChatDataset"], [25, 1, 1, "", "ConcatDataset"], [26, 1, 1, "", "InstructDataset"], [27, 1, 1, "", "PackedDataset"], [28, 1, 1, "", "TextCompletionDataset"], [29, 0, 1, "", "alpaca_cleaned_dataset"], [30, 0, 1, "", "alpaca_dataset"], [31, 0, 1, "", "chat_dataset"], [32, 0, 1, "", "cnn_dailymail_articles_dataset"], [33, 0, 1, "", "grammar_dataset"], [34, 0, 1, "", "instruct_dataset"], [35, 0, 1, "", "samsum_dataset"], [36, 0, 1, "", "slimorca_dataset"], [37, 0, 1, "", "text_completion_dataset"], [38, 0, 1, "", "wikitext_dataset"]], "torchtune.models.gemma": [[39, 0, 1, "", "gemma_2b"]], "torchtune.models.llama2": [[40, 0, 1, "", "llama2_13b"], [41, 0, 1, "", "llama2_70b"], [42, 0, 1, "", "llama2_7b"], [43, 0, 1, "", "lora_llama2_13b"], [44, 0, 1, "", "lora_llama2_70b"], [45, 0, 1, "", "lora_llama2_7b"], [46, 0, 1, "", "qlora_llama2_13b"], [47, 0, 1, "", "qlora_llama2_7b"]], "torchtune.models.llama3": [[48, 0, 1, "", "llama3_70b"], [49, 0, 1, "", "llama3_8b"], [50, 0, 1, "", "lora_llama3_70b"], [51, 0, 1, "", "lora_llama3_8b"], [52, 0, 1, "", "qlora_llama3_8b"]], "torchtune.models.mistral": [[53, 0, 1, "", "lora_mistral_7b"], [54, 0, 1, "", "mistral_7b"], [55, 0, 1, "", "qlora_mistral_7b"]], "torchtune.models.phi3": [[56, 0, 1, "", "lora_phi3_mini"], [57, 0, 1, "", "phi3_mini"], [58, 0, 1, "", "qlora_phi3_mini"]], "torchtune.modules": [[59, 1, 1, "", "CausalSelfAttention"], [60, 1, 1, "", "FeedForward"], [61, 1, 1, "", "KVCache"], [62, 1, 1, "", "RMSNorm"], [63, 1, 1, "", "RotaryPositionalEmbeddings"], [64, 1, 1, "", "TransformerDecoder"], [65, 1, 1, "", "TransformerDecoderLayer"], [67, 0, 1, "", "get_cosine_schedule_with_warmup"]], "torchtune.modules.CausalSelfAttention": [[59, 2, 1, "", "forward"]], "torchtune.modules.FeedForward": [[60, 2, 1, "", "forward"]], "torchtune.modules.KVCache": [[61, 2, 1, "", "reset"], [61, 2, 1, "", "update"]], "torchtune.modules.RMSNorm": [[62, 2, 1, "", "forward"]], "torchtune.modules.RotaryPositionalEmbeddings": [[63, 2, 1, "", "forward"]], "torchtune.modules.TransformerDecoder": [[64, 2, 1, "", "forward"], [64, 2, 1, "", "reset_caches"], [64, 2, 1, "", "setup_caches"]], "torchtune.modules.TransformerDecoderLayer": [[65, 2, 1, "", "forward"]], "torchtune.modules.common_utils": [[66, 0, 1, "", "reparametrize_as_dtype_state_dict_post_hook"]], "torchtune.modules.peft": [[68, 1, 1, "", "AdapterModule"], [69, 1, 1, "", "LoRALinear"], [70, 0, 1, "", "get_adapter_params"], [71, 0, 1, "", "set_trainable_params"]], "torchtune.modules.peft.AdapterModule": [[68, 2, 1, "", "adapter_params"]], "torchtune.modules.peft.LoRALinear": [[69, 2, 1, "", "adapter_params"], [69, 2, 1, "", "forward"]], "torchtune.modules.tokenizers": [[72, 1, 1, "", "SentencePieceTokenizer"], [73, 1, 1, "", "TikTokenTokenizer"]], "torchtune.modules.tokenizers.SentencePieceTokenizer": [[72, 2, 1, "", "decode"], [72, 2, 1, "", "encode"], [72, 2, 1, "", "tokenize_messages"]], "torchtune.modules.tokenizers.TikTokenTokenizer": [[73, 2, 1, "", "decode"], [73, 2, 1, "", "encode"], [73, 2, 1, "", "tokenize_message"], [73, 2, 1, "", "tokenize_messages"]], "torchtune.utils": [[74, 4, 1, "", "FSDPPolicyType"], [75, 1, 1, "", "FullModelHFCheckpointer"], [76, 1, 1, "", "FullModelMetaCheckpointer"], [77, 1, 1, "", "TuneRecipeArgumentParser"], [78, 0, 1, "", "generate"], [79, 0, 1, "", "get_device"], [80, 0, 1, "", "get_dtype"], [81, 0, 1, "", "get_full_finetune_fsdp_wrap_policy"], [82, 0, 1, "", "get_logger"], [83, 0, 1, "", "get_world_size_and_rank"], [84, 0, 1, "", "init_distributed"], [85, 0, 1, "", "list_dtypes"], [90, 0, 1, "", "padded_collate"], [91, 0, 1, "", "profiler"], [92, 0, 1, "", "set_activation_checkpointing"], [93, 0, 1, "", "set_seed"]], "torchtune.utils.FullModelHFCheckpointer": [[75, 2, 1, "", "load_checkpoint"], [75, 2, 1, "", "save_checkpoint"]], "torchtune.utils.FullModelMetaCheckpointer": [[76, 2, 1, "", "load_checkpoint"], [76, 2, 1, "", "save_checkpoint"]], "torchtune.utils.TuneRecipeArgumentParser": [[77, 2, 1, "", "parse_known_args"]], "torchtune.utils.metric_logging": [[86, 1, 1, "", "DiskLogger"], [87, 1, 1, "", "StdoutLogger"], [88, 1, 1, "", "TensorBoardLogger"], [89, 1, 1, "", "WandBLogger"]], "torchtune.utils.metric_logging.DiskLogger": [[86, 2, 1, "", "close"], [86, 2, 1, "", "log"], [86, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.StdoutLogger": [[87, 2, 1, "", "close"], [87, 2, 1, "", "log"], [87, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.TensorBoardLogger": [[88, 2, 1, "", "close"], [88, 2, 1, "", "log"], [88, 2, 1, "", "log_dict"]], "torchtune.utils.metric_logging.WandBLogger": [[89, 2, 1, "", "close"], [89, 2, 1, "", "log"], [89, 2, 1, "", "log_config"], [89, 2, 1, "", "log_dict"]]}, "objtypes": {"0": "py:function", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:data"}, "objnames": {"0": ["py", "function", "Python function"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "data", "Python data"]}, "titleterms": {"torchtun": [0, 1, 2, 3, 4, 5, 6, 74, 96, 98, 102, 104, 105, 106], "config": [0, 7, 8, 103], "data": [1, 5, 100], "instruct": [1, 97, 101, 104], "templat": [1, 100, 101], "chat": [1, 100, 101], "format": [1, 6, 101], "type": 1, "convert": 1, "helper": 1, "func": 1, "dataset": [2, 100, 101], "exampl": 2, "gener": [2, 78, 102, 104], "builder": 2, "class": [2, 8], "model": [3, 4, 9, 102, 103, 104, 105], "llama3": [3, 100, 104], "llama2": [3, 100, 102, 105, 106], "phi": 3, "3": 3, "mistral": 3, "gemma": 3, "modul": 4, "compon": [4, 7], "build": [4, 97, 106], "block": 4, "token": [4, 100], "peft": 4, "util": [4, 5, 74], "checkpoint": [5, 6, 9, 102], "distribut": 5, "reduc": 5, "precis": 5, "memori": [5, 105, 106], "manag": 5, "perform": [5, 105], "profil": [5, 91], "metric": [5, 9], "log": [5, 9], "miscellan": 5, "overview": [6, 98, 102], "handl": 6, "differ": 6, "intermedi": 6, "vs": 6, "final": 6, "lora": [6, 102, 105, 106], "put": [6, 106], "thi": 6, "all": [6, 7, 106], "togeth": [6, 106], "about": 7, "where": 7, "do": 7, "paramet": 7, "live": 7, "write": 7, "configur": [7, 101], "us": [7, 8, 100, 102, 106], "instanti": [7, 10], "referenc": 7, "other": [7, 102], "field": 7, "interpol": 7, "valid": [7, 12], "your": [7, 8, 102, 103], "best": 7, "practic": 7, "airtight": 7, "public": 7, "api": 7, "onli": 7, "command": 7, "line": 7, "overrid": 7, "what": [8, 98, 105, 106], "ar": 8, "recip": [8, 103, 105], "script": 8, "run": [8, 102], "cli": 8, "pars": [8, 11], "weight": 9, "bias": 9, "logger": 9, "w": 9, "b": 9, "alpacainstructtempl": 13, "chatformat": 14, "chatmlformat": 15, "grammarerrorcorrectiontempl": 16, "instructtempl": 17, "llama2chatformat": 18, "messag": 19, "mistralchatformat": 20, "summarizetempl": 21, "sharegpt_to_llama2_messag": 22, "validate_messag": 23, "chatdataset": 24, "concatdataset": 25, "instructdataset": 26, "packeddataset": 27, "textcompletiondataset": 28, "alpaca_cleaned_dataset": 29, "alpaca_dataset": 30, "chat_dataset": 31, "cnn_dailymail_articles_dataset": 32, "grammar_dataset": 33, "instruct_dataset": 34, "samsum_dataset": 35, "slimorca_dataset": 36, "text_completion_dataset": 37, "wikitext_dataset": 38, "gemma_2b": 39, "llama2_13b": 40, "llama2_70b": 41, "llama2_7b": 42, "lora_llama2_13b": 43, "lora_llama2_70b": 44, "lora_llama2_7b": 45, "qlora_llama2_13b": 46, "qlora_llama2_7b": 47, "llama3_70b": 48, "llama3_8b": 49, "lora_llama3_70b": 50, "lora_llama3_8b": 51, "qlora_llama3_8b": 52, "lora_mistral_7b": 53, "mistral_7b": 54, "qlora_mistral_7b": 55, "lora_phi3_mini": 56, "phi3_mini": 57, "qlora_phi3_mini": 58, "causalselfattent": 59, "todo": [59, 65], "feedforward": 60, "kvcach": 61, "rmsnorm": 62, "rotarypositionalembed": 63, "transformerdecod": 64, "transformerdecoderlay": 65, "reparametrize_as_dtype_state_dict_post_hook": 66, "get_cosine_schedule_with_warmup": 67, "adaptermodul": 68, "loralinear": 69, "get_adapter_param": 70, "set_trainable_param": 71, "sentencepiecetoken": 72, "tiktokentoken": 73, "fsdppolicytyp": 74, "fullmodelhfcheckpoint": 75, "fullmodelmetacheckpoint": 76, "tunerecipeargumentpars": 77, "get_devic": 79, "get_dtyp": 80, "get_full_finetune_fsdp_wrap_polici": 81, "get_logg": 82, "get_world_size_and_rank": 83, "init_distribut": 84, "list_dtyp": 85, "disklogg": 86, "stdoutlogg": 87, "tensorboardlogg": 88, "wandblogg": 89, "padded_col": 90, "set_activation_checkpoint": 92, "set_se": 93, "comput": [95, 99], "time": [95, 99], "welcom": 96, "document": 96, "get": [96, 104], "start": 96, "tutori": 96, "instal": 97, "via": [97, 104], "pypi": 97, "git": 97, "clone": 97, "nightli": 97, "kei": 98, "concept": 98, "design": 98, "principl": 98, "fine": [100, 101, 103, 104], "tune": [100, 101, 103, 104], "chang": 100, "from": [100, 106], "prompt": 100, "special": 100, "when": 100, "should": 100, "i": 100, "custom": [100, 101], "fulli": 101, "end": 102, "workflow": 102, "download": [102, 103], "7b": 102, "finetun": [102, 105, 106], "evalu": [102, 104], "eleutherai": [102, 104], "s": [102, 104], "eval": [102, 104], "har": [102, 104], "speed": 102, "up": 102, "quantiz": [102, 104], "librari": 102, "upload": 102, "hug": 102, "face": 102, "hub": 102, "first": 103, "llm": 103, "select": 103, "modifi": 103, "train": 103, "next": 103, "step": 103, "meta": 104, "8b": 104, "access": 104, "text": 104, "our": 104, "faster": 104, "how": 105, "doe": 105, "work": 105, "appli": 105, "trade": 105, "off": 105, "qlora": 106, "save": 106, "deep": 106, "dive": 106}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 56}})